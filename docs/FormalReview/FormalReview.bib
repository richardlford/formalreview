
@article{calcagno_compositional_2011,
	title = {Compositional Shape Analysis by Means of Bi-Abduction},
	volume = {58},
	issn = {00045411},
	url = {http://dl.acm.org/citation.cfm?doid=2049697.2049700},
	doi = {10.1145/2049697.2049700},
	pages = {1--66},
	number = {6},
	journaltitle = {Journal of the {ACM}},
	author = {Calcagno, Cristiano and Distefano, Dino and O’Hearn, Peter W. and Yang, Hongseok},
	urldate = {2019-01-30},
	date = {2011-12-01},
	langid = {english},
	file = {Submitted Version:/Users/richardford/Zotero/storage/F7XZGISE/Calcagno et al. - 2011 - Compositional Shape Analysis by Means of Bi-Abduct.pdf:application/pdf}
}

@inproceedings{krishnan_modelling_2018,
	location = {Bengaluru},
	title = {Modelling and validating 1553B protocol using the {SPIN} model checker},
	isbn = {978-1-5386-1182-1},
	url = {http://ieeexplore.ieee.org/document/8328247/},
	doi = {10.1109/COMSNETS.2018.8328247},
	eventtitle = {2018 10th International Conference on Communication Systems \& Networks ({COMSNETS})},
	pages = {472--475},
	booktitle = {2018 10th International Conference on Communication Systems \& Networks ({COMSNETS})},
	publisher = {{IEEE}},
	author = {Krishnan, Ranjani and Lalithambika, V R},
	urldate = {2019-01-31},
	date = {2018-01},
	note = {1553B/08328247.pdf}
}

@article{jung_rustbelt:_2017,
	title = {{RustBelt}: securing the foundations of the rust programming language},
	volume = {2},
	issn = {24751421},
	url = {http://dl.acm.org/citation.cfm?doid=3177123.3158154},
	doi = {10.1145/3158154},
	shorttitle = {{RustBelt}},
	pages = {1--34},
	issue = {{POPL}},
	journaltitle = {Proceedings of the {ACM} on Programming Languages},
	author = {Jung, Ralf and Jourdan, Jacques-Henri and Krebbers, Robbert and Dreyer, Derek},
	urldate = {2019-01-31},
	date = {2017-12-27},
	langid = {english},
	file = {Full Text:/Users/richardford/Zotero/storage/8KU8PUZ4/Jung et al. - 2017 - RustBelt securing the foundations of the rust pro.pdf:application/pdf}
}

@article{ohearn_separation_2019,
	title = {Separation logic},
	volume = {62},
	issn = {00010782},
	url = {http://dl.acm.org/citation.cfm?doid=3310134.3211968},
	doi = {10.1145/3211968},
	pages = {86--95},
	number = {2},
	journaltitle = {Communications of the {ACM}},
	author = {O'Hearn, Peter},
	urldate = {2019-01-31},
	date = {2019-01-28},
	langid = {english}
}

@misc{ohearn_peter_nodate,
	title = {Peter W O'hearn - acm profile},
	url = {https://dl.acm.org/author_page.cfm?id=81332519314&coll=DL&dl=ACM&trk=0},
	author = {O'Hearn, Peter W.}
}

@article{gorogiannis_true_2019,
	title = {A true positives theorem for a static race detector},
	volume = {3},
	issn = {24751421},
	url = {http://dl.acm.org/citation.cfm?doid=3302515.3290370},
	doi = {10.1145/3290370},
	pages = {1--29},
	issue = {{POPL}},
	journaltitle = {Proceedings of the {ACM} on Programming Languages},
	author = {Gorogiannis, Nikos and O'Hearn, Peter W. and Sergey, Ilya},
	urldate = {2019-01-31},
	date = {2019-01-02},
	langid = {english},
	file = {Submitted Version:/Users/richardford/Zotero/storage/4765ZUM2/Gorogiannis et al. - 2019 - A true positives theorem for a static race detecto.pdf:application/pdf}
}

@inproceedings{ohearn_continuous_2018,
	location = {Oxford, United Kingdom},
	title = {Continuous Reasoning: Scaling the impact of formal methods},
	isbn = {978-1-4503-5583-4},
	url = {http://dl.acm.org/citation.cfm?doid=3209108.3209109},
	doi = {10.1145/3209108.3209109},
	shorttitle = {Continuous Reasoning},
	eventtitle = {the 33rd Annual {ACM}/{IEEE} Symposium},
	pages = {13--25},
	booktitle = {Proceedings of the 33rd Annual {ACM}/{IEEE} Symposium on Logic in Computer Science  - {LICS} '18},
	publisher = {{ACM} Press},
	author = {O'Hearn, Peter W.},
	urldate = {2019-01-31},
	date = {2018},
	langid = {english},
	file = {Full Text:/Users/richardford/Zotero/storage/CTESDFKX/O'Hearn - 2018 - Continuous Reasoning Scaling the impact of formal.pdf:application/pdf}
}

@article{brookes_concurrent_2016,
	title = {Concurrent Separation Logic},
	volume = {3},
	issn = {2372-3491},
	url = {http://doi.acm.org/10.1145/2984450.2984457},
	doi = {10.1145/2984450.2984457},
	pages = {47--65},
	number = {3},
	journaltitle = {{ACM} {SIGLOG} News},
	author = {Brookes, Stephen and O'Hearn, Peter W.},
	date = {2016-08}
}

@article{brookes_semantics_2007,
	title = {A semantics for concurrent separation logic},
	volume = {375},
	issn = {03043975},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0304397506009248},
	doi = {10.1016/j.tcs.2006.12.034},
	pages = {227--270},
	number = {1},
	journaltitle = {Theoretical Computer Science},
	author = {Brookes, Stephen},
	urldate = {2019-01-31},
	date = {2007-05},
	langid = {english},
	file = {Submitted Version:/Users/richardford/Zotero/storage/E2WWQBZ9/Brookes - 2007 - A semantics for concurrent separation logic.pdf:application/pdf}
}

@inproceedings{ohearn_categorical_2015,
	location = {Washington, {DC}, {USA}},
	title = {From Categorical Logic to Facebook Engineering},
	isbn = {978-1-4799-8875-4},
	url = {https://doi.org/10.1109/LICS.2015.11},
	doi = {10.1109/LICS.2015.11},
	series = {{LICS} '15},
	pages = {17--20},
	booktitle = {Proceedings of the 2015 30th Annual {ACM}/{IEEE} Symposium on Logic in Computer Science ({LICS})},
	publisher = {{IEEE} Computer Society},
	author = {O'Hearn, Peter},
	urldate = {2019-01-31},
	date = {2015},
	file = {ACM Full Text PDF:/Users/richardford/Zotero/storage/TX6UGV37/O'Hearn - 2015 - From Categorical Logic to Facebook Engineering.pdf:application/pdf}
}

@inreference{wikipedia_category:formal_2017,
	title = {Category:Formal methods people},
	rights = {Creative Commons Attribution-{ShareAlike} License},
	url = {https://en.wikipedia.org/w/index.php?title=Category:Formal_methods_people&oldid=812800009},
	shorttitle = {Category},
	abstract = {People involved with formal methods.},
	booktitle = {Wikipedia},
	author = {Wikipedia},
	urldate = {2019-01-31},
	date = {2017-11-29},
	langid = {english},
	note = {Page Version {ID}: 812800009},
	file = {Snapshot:/Users/richardford/Zotero/storage/652994AH/index.html:text/html}
}

@article{qureshi_formal_nodate,
	title = {Formal Modelling and Analysis of Mission-Critical Software in Military Avionics Systems},
	url = {http://crpit.com/confpapers/CRPITV69Qureshi.pdf},
	abstract = {A typical avionics mission system of a military aircraft is a complex real-time system consisting of a mission control computer, different kinds of sensors, navigation and communication subsystems, and various displays and stores; all interconnected by a number of serial data buses. The mission capability is increasingly implemented in the mission-critical software and the robustness of this software is vital for mission success. The complexity and real-time requirements of mission systems represent major challenges to the Australian Defence Force during new acquisitions, upgrades and maintenance. This paper describes the experiences on a joint research project between the University of South Australia and Australia’s Defence Science and Technology Organisation into the modelling and analysis of avionics mission systems. The paper provides a summary of the key aspects of our previous research work on the modelling of a generic mission system using Coloured Petri Nets and the analysis of task scheduling on the mission computer. Finally, the paper briefly discusses the extension of the generic model to obtain a formal model of the mission system of the {AP}3C Orion maritime surveillance aircraft..},
	pages = {11},
	journaltitle = {11th Australian Workshop on Safety Related Programmable Systems ({SCS}’06)},
	author = {Qureshi, Zahid H},
	langid = {english},
	file = {Qureshi - Formal Modelling and Analysis of Mission-Critical .pdf:/Users/richardford/Zotero/storage/9N3AY53T/Qureshi - Formal Modelling and Analysis of Mission-Critical .pdf:application/pdf}
}

@inproceedings{conchon_alt-ergo_2018,
	location = {Oxford, United Kingdom},
	title = {Alt-Ergo 2.2},
	url = {https://hal.inria.fr/hal-01960203},
	abstract = {Alt-Ergo is an {SMT} solver jointly developed by Université Paris-Sud and the {OCamlPro} company. The first version was released in 2006. Since then, its architecture has been continuously adapted for proving formulas generated by software development frameworks. As type systems with polymorphism arise naturally is such platforms, the design of Alt-Ergo has been guided (and constrained) by a native-and non {SMT}-{LIB} compliant-input language for a polymorphic first-order logic. In this paper, we present the last version of Alt-Ergo, its architecture and main features. The main recent work is a support for a conservative polymorphic extension of the {SMT}-{LIB} 2 standard. We measure Alt-Ergo's performances with this new frontend on a set of benchmarks coming from the deductive program verification systems Frama-C, {SPARK} 2014, Why3 and Atelier-B, as well as from the {SMT}-{LIB} benchmarks library.},
	booktitle = {{SMT} Workshop: International Workshop on Satisfiability Modulo Theories},
	author = {Conchon, Sylvain and Coquereau, Albin and Iguernlala, Mohamed and Mebsout, Alain},
	urldate = {2019-01-31},
	date = {2018-07},
	note = {alt-ergo/Alt-Ergo-2.2--{SMT}-Workshop-2018.pdf},
	file = {HAL PDF Full Text:/Users/richardford/Zotero/storage/WC8K3BIA/Conchon et al. - 2018 - Alt-Ergo 2.2.pdf:application/pdf}
}

@inproceedings{conchon_increasing_2016,
	title = {Increasing Proofs Automation Rate of Atelier-B Thanks to Alt-Ergo},
	isbn = {978-3-319-33951-1},
	series = {Lecture Notes in Computer Science},
	abstract = {In this paper, we report on our recent improvements in the Alt-Ergo {SMT} solver to make it effective in discharging proof obligations ({POs}) translated from the Atelier-B framework. In particular, we made important modifications in its internal data structures to boost performances of its core decision procedures, we improved quantifiers instantiation heuristics, and enhanced the interaction between the {SAT} solver and the decision procedures. We also introduced a new plugin architecture to facilitate experiments with different {SAT} engines, and implemented a profiling plugin to track and identify “bottlenecks” when a formula requires a long time to be discharged, or makes the solver timeout. Experiments made with more than 10,000 {POs} generated from real industrial B projects show significant improvements compared to both previous versions of Alt-Ergo and Atelier-B’s automatic main prover.},
	pages = {243--253},
	booktitle = {Reliability, Safety, and Security of Railway Systems. Modelling, Analysis, Verification, and Certification},
	publisher = {Springer International Publishing},
	author = {Conchon, Sylvain and Iguernlala, Mohamed},
	editor = {Lecomte, Thierry and Pinger, Ralf and Romanovsky, Alexander},
	date = {2016},
	langid = {english},
	note = {alt-ergo/Alt-Ergo--Atelier-B--{RSSR}-2016.pdf},
	keywords = {B method, B proof obligations, {SMT} solvers},
	file = {Conchon and Iguernlala - Increasing Proofs Automation Rate of Thanks to Ate.pdf:/Users/richardford/Zotero/storage/RG6FY56C/Conchon and Iguernlala - Increasing Proofs Automation Rate of Thanks to Ate.pdf:application/pdf}
}

@article{altenkirch_quotient_2018,
	title = {Quotient inductive-inductive types},
	volume = {10803},
	url = {http://arxiv.org/abs/1612.02346},
	doi = {10.1007/978-3-319-89366-2_16},
	abstract = {Higher inductive types ({HITs}) in Homotopy Type Theory ({HoTT}) allow the definition of datatypes which have constructors for equalities over the defined type. {HITs} generalise quotient types and allow to define types which are not sets in the sense of {HoTT} (i.e. do not satisfy uniqueness of equality proofs) such as spheres, suspensions and the torus. However, there are also interesting uses of {HITs} to define sets, such as the Cauchy reals, the partiality monad, and the internal, total syntax of type theory. In each of these examples we define several types that depend on each other mutually, i.e. they are inductive-inductive definitions. We call those {HITs} quotient inductive-inductive types ({QIITs}). Although there has been recent progress on the general theory of {HITs}, there isn't yet a theoretical foundation of the combination of equality constructors and induction-induction, despite having many interesting applications. In the present paper we present a first step towards a semantic definition of {QIITs}. In particular, we give an initial-algebra semantics and show that this is equivalent to the section induction principle, which justifies the intuitively expected elimination rules.},
	pages = {293--310},
	journaltitle = {{arXiv}:1612.02346 [cs]},
	author = {Altenkirch, Thorsten and Capriotti, Paolo and Dijkstra, Gabe and Kraus, Nicolai and Forsberg, Fredrik Nordvall},
	urldate = {2019-01-31},
	date = {2018},
	eprinttype = {arxiv},
	eprint = {1612.02346,},
	note = {altenkirch/Quotient\_inductive-inductive\_types.pdf},
	keywords = {03B15 (Primary) 18C10 (Secondary), Computer Science - Logic in Computer Science},
	file = {arXiv\:1612.02346 PDF:/Users/richardford/Zotero/storage/I6YHMRQZ/Altenkirch et al. - 2018 - Quotient inductive-inductive types.pdf:application/pdf;arXiv.org Snapshot:/Users/richardford/Zotero/storage/BQTKDAZL/1612.html:text/html}
}

@inproceedings{hritcu_micro-policies:_2015,
	location = {Prague, Czech Republic},
	title = {Micro-Policies: Formally Verified, Tag-Based Security Monitors},
	isbn = {978-1-4503-3661-1},
	url = {http://dl.acm.org/citation.cfm?doid=2786558.2786560},
	doi = {10.1145/2786558.2786560},
	shorttitle = {Micro-Policies},
	eventtitle = {the 10th {ACM} Workshop},
	pages = {1--1},
	booktitle = {Proceedings of the 10th {ACM} Workshop on Programming Languages and Analysis for Security - {PLAS}'15},
	publisher = {{ACM} Press},
	author = {Hriţcu, Cǎtǎlin},
	urldate = {2019-01-31},
	date = {2015},
	langid = {english},
	note = {amorim/nicro-policies.pdf}
}

@inproceedings{hobor_theory_2010,
	location = {New York, {NY}, {USA}},
	title = {A Theory of Indirection via Approximation},
	isbn = {978-1-60558-479-9},
	url = {http://doi.acm.org/10.1145/1706299.1706322},
	doi = {10.1145/1706299.1706322},
	series = {{POPL} '10},
	abstract = {Building semantic models that account for various kinds of indirect reference has traditionally been a difficult problem. Indirect reference can appear in many guises, such as heap pointers, higher-order functions, object references, and shared-memory mutexes. We give a general method to construct models containing indirect reference by presenting a "theory of indirection". Our method can be applied in a wide variety of settings and uses only simple, elementary mathematics. In addition to various forms of indirect reference, the resulting models support powerful features such as impredicative quantification and equirecursion; moreover they are compatible with the kind of powerful substructural accounting required to model (higher-order) separation logic. In contrast to previous work, our model is easy to apply to new settings and has a simple axiomatization, which is complete in the sense that all models of it are isomorphic. Our proofs are machine-checked in Coq.},
	pages = {171--184},
	booktitle = {Proceedings of the 37th Annual {ACM} {SIGPLAN}-{SIGACT} Symposium on Principles of Programming Languages},
	publisher = {{ACM}},
	author = {Hobor, Aquinas and Dockins, Robert and Appel, Andrew W.},
	urldate = {2019-01-31},
	date = {2010},
	keywords = {indirection theory, step-indexed models},
	file = {ACM Full Text PDF:/Users/richardford/Zotero/storage/LDZGVN4K/Hobor et al. - 2010 - A Theory of Indirection via Approximation.pdf:application/pdf}
}

@article{cao_vst-floyd:_2018,
	title = {{VST}-Floyd: A Separation Logic Tool to Verify Correctness of C Programs},
	volume = {61},
	issn = {0168-7433},
	url = {https://doi.org/10.1007/s10817-018-9457-5},
	doi = {10.1007/s10817-018-9457-5},
	shorttitle = {{VST}-Floyd},
	abstract = {The Verified Software Toolchain builds foundational machine-checked proofs of the functional correctness of C programs. Its program logic, Verifiable C, is a shallowly embedded higher-order separation Hoare logic which is proved sound in Coq with respect to the operational semantics of {CompCert} Clight. This paper introduces {VST}-Floyd, a verification assistant which offers a set of semiautomatic tactics helping users build functional correctness proofs for C programs using Verifiable C.},
	pages = {367--422},
	number = {1},
	journaltitle = {J. Autom. Reason.},
	author = {Cao, Qinxiang and Beringer, Lennart and Gruetter, Samuel and Dodds, Josiah and Appel, Andrew W.},
	urldate = {2019-01-31},
	date = {2018-06},
	keywords = {Program verification, Proof automation, Separation logic, Symbolic execution},
	file = {Cao et al. - 2018 - VST-Floyd A Separation Logic Tool to Verify Corre.pdf:/Users/richardford/Zotero/storage/FCBL8RIJ/Cao et al. - 2018 - VST-Floyd A Separation Logic Tool to Verify Corre.pdf:application/pdf}
}

@incollection{hutchison_verified_2014,
	location = {Berlin, Heidelberg},
	title = {Verified Compilation for Shared-Memory C},
	volume = {8410},
	isbn = {978-3-642-54832-1 978-3-642-54833-8},
	url = {http://link.springer.com/10.1007/978-3-642-54833-8_7},
	pages = {107--127},
	booktitle = {Programming Languages and Systems},
	publisher = {Springer Berlin Heidelberg},
	author = {Beringer, Lennart and Stewart, Gordon and Dockins, Robert and Appel, Andrew W.},
	editor = {Shao, Zhong},
	editorb = {Hutchison, David and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M. and Mattern, Friedemann and Mitchell, John C. and Naor, Moni and Nierstrasz, Oscar and Pandu Rangan, C. and Steffen, Bernhard and Sudan, Madhu and Terzopoulos, Demetri and Tygar, Doug and Vardi, Moshe Y. and Weikum, Gerhard},
	editorbtype = {redactor},
	urldate = {2019-01-31},
	date = {2014},
	doi = {10.1007/978-3-642-54833-8_7,},
	note = {appel/shmemc.pdf is a preview},
	file = {Full Text:/Users/richardford/Zotero/storage/TXJ95W6N/Beringer et al. - 2014 - Verified Compilation for Shared-Memory C.pdf:application/pdf}
}

@book{appel_verifiabble_2014,
	location = {Cambridge},
	title = {Verifiabble C, Version 2.2},
	isbn = {978-1-107-25655-2},
	url = {http://ebooks.cambridge.org/ref/id/CBO9781107256552},
	publisher = {Cambridge University Press},
	author = {Appel, Andrew W. and Dockins, Robert and Hobor, Aquinas and Beringer, Lennart and Dodds, Josiah and Stewart, Gordon and Blazy, Sandrine and Leroy, Xavier},
	urldate = {2019-01-31},
	date = {2014},
	langid = {english},
	doi = {10.1017/CBO9781107256552},
	file = {Verifiable C Version 2.2:/Users/richardford/Zotero/storage/GRBISGXR/Appel et al. - 2014 - Program Logics for Certified Compilers.pdf:application/pdf}
}

@article{appel_verification_2015,
	title = {Verification of a Cryptographic Primitive: {SHA}-256},
	volume = {37},
	issn = {0164-0925},
	url = {http://doi.acm.org/10.1145/2701415},
	doi = {10.1145/2701415},
	shorttitle = {Verification of a Cryptographic Primitive},
	abstract = {This article presents a full formal machine-checked verification of a C program: the {OpenSSL} implementation of {SHA}-256. This is an interactive proof of functional correctness in the Coq proof assistant, using the Verifiable C program logic. Verifiable C is a separation logic for the C language, proved sound with respect to the operational semantics for C, connected to the {CompCert} verified optimizing C compiler.},
	pages = {7:1--7:31},
	number = {2},
	journaltitle = {{ACM} Trans. Program. Lang. Syst.},
	author = {Appel, Andrew W.},
	urldate = {2019-01-31},
	date = {2015-04},
	keywords = {Cryptography},
	file = {ACM Full Text PDF:/Users/richardford/Zotero/storage/8N6RDMZK/Appel - 2015 - Verification of a Cryptographic Primitive SHA-256.pdf:application/pdf}
}

@incollection{jouannaud_verismall:_2011,
	location = {Berlin, Heidelberg},
	title = {{VeriSmall}: Verified Smallfoot Shape Analysis},
	volume = {7086},
	isbn = {978-3-642-25378-2 978-3-642-25379-9},
	url = {http://link.springer.com/10.1007/978-3-642-25379-9_18},
	shorttitle = {{VeriSmall}},
	pages = {231--246},
	booktitle = {Certified Programs and Proofs},
	publisher = {Springer Berlin Heidelberg},
	author = {Appel, Andrew W.},
	editor = {Jouannaud, Jean-Pierre and Shao, Zhong},
	urldate = {2019-01-31},
	date = {2011},
	doi = {10.1007/978-3-642-25379-9_18},
	file = {Submitted Version:/Users/richardford/Zotero/storage/98T3SKZJ/Appel - 2011 - VeriSmall Verified Smallfoot Shape Analysis.pdf:application/pdf}
}

@inproceedings{stewart_verified_2012,
	location = {New York, {NY}, {USA}},
	title = {Verified Heap Theorem Prover by Paramodulation},
	isbn = {978-1-4503-1054-3},
	url = {http://doi.acm.org/10.1145/2364527.2364531},
	doi = {10.1145/2364527.2364531},
	series = {{ICFP} '12},
	abstract = {We present {VeriStar}, a verified theorem prover for a decidable subset of separation logic. Together with {VeriSmall} [3], a proved-sound Smallfoot-style program analysis for C minor, {VeriStar} demonstrates that fully machine-checked static analyses equipped with efficient theorem provers are now within the reach of formal methods. As a pair, {VeriStar} and {VeriSmall} represent the first application of the Verified Software Toolchain [4], a tightly integrated collection of machine-verified program logics and compilers giving foundational correctness guarantees. {VeriStar} is (1) purely functional, (2) machine-checked, (3) end-to-end, (4) efficient and (5) modular. By purely functional, we mean it is implemented in Gallina, the pure functional programming language embedded in the Coq theorem prover. By machine-checked, we mean it has a proof in Coq that when the prover says "valid", the checked entailment holds in a proved-sound separation logic for C minor. By end-to-end, we mean that when the static analysis+theorem prover says a C minor program is safe, the program will be compiled to a semantically equivalent assembly program that runs on real hardware. By efficient, we mean that the prover implements a state-of-the-art algorithm for deciding heap entailments and uses highly tuned verified functional data structures. By modular, we mean that {VeriStar} can be retrofitted to other static analyses as a plug-compatible entailment checker and its soundness proof can easily be ported to other separation logics.},
	pages = {3--14},
	booktitle = {Proceedings of the 17th {ACM} {SIGPLAN} International Conference on Functional Programming},
	publisher = {{ACM}},
	author = {Stewart, Gordon and Beringer, Lennart and Appel, Andrew W.},
	urldate = {2019-01-31},
	date = {2012},
	keywords = {paramodulation, separation logic, theorem proving},
	file = {ACM Full Text PDF:/Users/richardford/Zotero/storage/99IVRGUA/Stewart et al. - 2012 - Verified Heap Theorem Prover by Paramodulation.pdf:application/pdf}
}

@inproceedings{appel_verified_2012,
	location = {Berlin, Heidelberg},
	title = {Verified Software Toolchain},
	isbn = {978-3-642-28890-6},
	url = {http://dx.doi.org/10.1007/978-3-642-28891-3_2},
	doi = {10.1007/978-3-642-28891-3_2},
	series = {{NFM}'12},
	abstract = {The software toolchain includes static analyzers to check assertions about programs; optimizing compilers to translate programs to machine language; operating systems and libraries to supply context for programs. Our Verified Software Toolchain verifies with machine-checked proofs that the assertions claimed at the top of the toolchain really hold in the machine-language program, running in the operating-system context, on a weakly-consistent-shared-memory machine. Our verification approach is modular, in that proofs about operating systems or concurrency libraries are oblivious of the programming language or machine language, proofs about compilers are oblivious of the program logic used to verify static analyzers, and so on. The approach is scalable, in that each component is verified in the semantic idiom most natural for that component. Finally, the verification is foundational: the trusted base for proofs of observable properties of the machine-language program includes only the operational semantics of the machine language, not the source language, the compiler, the program logic, or any other part of the toolchain--even when these proofs are carried out by source-level static analyzers. In this paper I explain the construction of a a verified toolchain, using the Coq proof assistant. I will illustrate with shape analysis for C programs based on separation logic.},
	pages = {2--2},
	booktitle = {Proceedings of the 4th International Conference on {NASA} Formal Methods},
	publisher = {Springer-Verlag},
	author = {Appel, Andrew W.},
	urldate = {2019-01-31},
	date = {2012},
	file = {Submitted Version:/Users/richardford/Zotero/storage/I5S7W94U/Appel - 2012 - Verified Software Toolchain.pdf:application/pdf}
}

@inproceedings{kastner_program_2015,
	location = {Paris, France},
	title = {Program Analysis on Evolving Software},
	url = {https://hal.archives-ouvertes.fr/hal-01192985},
	abstract = {Static analysis is well-suited for continuous verification during the software development stage since it only works on the source code and does not require a running system for testing. However, applying the program analysis during software development means that the analysis has to cope with evolving software and evolving analyzer configurations, especially in a model-based development process. In this article we present a unique history-aware concept for program analysis that has been developed for the static analyzer Astrée. It not only provides the ability to backtrack and access previous versions of the analysis configuration, it can also automatically determine the differences between two analysis configurations and relate them to the correct source code versions. Users can explicitly create a revision, i.e. a snapshot of the analysis project; changes of the source code, analysis options, analysis directives and results in different revisions are automatically detected and highlighted. The analyzer provides automatic correctness checks for all specified analysis directives, e.g., to tune the precision of the analyzer or provide information about the environment. This makes software verification applicable during the implementation stage, significantly reduces the effort to adapt the analyzer configuration to new source code versions, and makes analysis results on previous software versions easily reproducible.},
	booktitle = {{CARS} 2015 - Critical Automotive applications: Robustness \& Safety},
	author = {Kästner, Daniel and Pohland, Jan},
	editor = {Roy, Matthieu},
	urldate = {2019-01-31},
	date = {2015-09},
	file = {HAL PDF Full Text:/Users/richardford/Zotero/storage/LEVP5BEU/Kästner and Pohland - 2015 - Program Analysis on Evolving Software.pdf:application/pdf}
}

@article{monniaux_parallel_2005,
	title = {The parallel implementation of the Astr{\textbackslash}'\{e\}e static analyzer},
	volume = {3780},
	url = {http://arxiv.org/abs/cs/0701191},
	doi = {10.1007/11575467_7},
	abstract = {The Astr{\textbackslash}'\{e\}e static analyzer is a specialized tool that can prove the absence of runtime errors, including arithmetic overflows, in large critical programs. Keeping analysis times reasonable for industrial use is one of the design objectives. In this paper, we discuss the parallel implementation of the analysis.},
	pages = {86--96},
	journaltitle = {{arXiv}:cs/0701191},
	author = {Monniaux, David},
	urldate = {2019-01-31},
	date = {2005},
	eprinttype = {arxiv},
	eprint = {cs/0701191},
	keywords = {Computer Science - Performance, Computer Science - Programming Languages, D.2.4},
	file = {arXiv\:cs/0701191 PDF:/Users/richardford/Zotero/storage/XJI5L7X9/Monniaux - 2005 - The parallel implementation of the Astr'\{e\}e stat.pdf:application/pdf;arXiv.org Snapshot:/Users/richardford/Zotero/storage/M3ZXKGYR/0701191.html:text/html}
}

@article{kastner_astree:_nodate,
	title = {Astree: Proving the Absence of Runtime Errors},
	url = {https://www.di.ens.fr/~rival/papers/erts10.pdf},
	abstract = {Safety-critical embedded software has to satisfy stringent quality requirements. Testing and validation consumes a large – and growing – fraction of development cost. The last years have seen the emergence of semantics-based static analysis tools in various application areas, from runtime error analysis to worst-case execution time prediction. Their appeal is that they have the potential to reduce testing eﬀort while providing 100\% coverage, thus enhancing safety. Static runtime error analysis is applicable to large industryscale projects and produces a list of deﬁnite runtime errors and of potential runtime errors which might be true errors or false alarms. In the past, often only the deﬁnite errors were ﬁxed because manually inspecting each alarm was too time-consuming due to a large number of false alarms. Therefore no proof of the absence of runtime errors could be given. In this article the parameterizable static analyzer Astr´ee is presented. By specialization and parameterization Astr´ee can be adapted to the software under analysis. This enables Astr´ee to eﬃciently compute precise results. Astr´ee has successfully been used to analyze large-scale safety-critical avionics software with zero false alarms.},
	pages = {9},
	author = {Kästner, D and Wilhelm, S and Nenova, S and Miné, A and Rival, X and Mauborgne, L and Feret, J and Cousot, P and Cousot, R},
	langid = {english},
	note = {astree/astee-proving-absence-rte.pdf},
	file = {Kästner et al. - Astree Proving the Absence of Runtime Errors.pdf:/Users/richardford/Zotero/storage/USSVMPAS/Kästner et al. - Astree Proving the Absence of Runtime Errors.pdf:application/pdf}
}

@inproceedings{mine_taking_2016,
	location = {Toulouse, France},
	title = {Taking Static Analysis to the Next Level: Proving the Absence of Run-Time Errors and Data Races with Astrée},
	url = {https://hal.archives-ouvertes.fr/hal-01271552},
	shorttitle = {Taking Static Analysis to the Next Level},
	abstract = {We present an extension of Astrée to concurrent C software. Astrée is a sound static analyzer for run-time errors previously limited to sequential C software. Our extension employs a scalable abstraction which covers all possible thread interleavings, and soundly reports all run-time errors and data races: when the analyzer does not report any alarm, the program is proven free from those classes of errors. We show how this extension is able to support a variety of operating systems (such as {POSIX} threads, {ARINC} 653, {OSEK}/{AUTOSAR}) and report on experimental results obtained on concurrent software from different domains, including large industrial software.},
	booktitle = {8th European Congress on Embedded Real Time Software and Systems ({ERTS} 2016)},
	author = {Miné, Antoine and Mauborgne, Laurent and Rival, Xavier and Feret, Jerome and Cousot, Patrick and Kästner, Daniel and Wilhelm, Stephan and Ferdinand, Christian},
	urldate = {2019-01-31},
	date = {2016-01},
	file = {HAL PDF Full Text:/Users/richardford/Zotero/storage/76NS6CAS/Miné et al. - 2016 - Taking Static Analysis to the Next Level Proving .pdf:application/pdf}
}

@article{bedford_coqatoo:_nodate,
	title = {Coqatoo: Generating Natural Language Versions of Coq Proofs - Slides},
	pages = {16},
	author = {Bedford, Andrew},
	langid = {english},
	file = {Bedford - Generating Natural Language Versions of Coq Proofs.pdf:/Users/richardford/Zotero/storage/NKL4736M/Bedford - Generating Natural Language Versions of Coq Proofs.pdf:application/pdf}
}

@article{bedford_coqatoo:_2017,
	title = {Coqatoo: Generating Natural Language Versions of Coq Proofs},
	url = {http://arxiv.org/abs/1712.03894},
	shorttitle = {Coqatoo},
	abstract = {Due to their numerous advantages, formal proofs and proof assistants, such as Coq, are becoming increasingly popular. However, one disadvantage of using proof assistants is that the resulting proofs can sometimes be hard to read and understand, particularly for less-experienced users. To address this issue, we have implemented a tool capable of generating natural language versions of Coq proofs called Coqatoo, which we present in this paper.},
	journaltitle = {{arXiv}:1712.03894 [cs]},
	author = {Bedford, Andrew},
	urldate = {2019-01-31},
	date = {2017-12-11},
	eprinttype = {arxiv},
	eprint = {1712.03894},
	keywords = {Computer Science - Programming Languages},
	file = {arXiv\:1712.03894 PDF:/Users/richardford/Zotero/storage/HUTDVY7Z/Bedford - 2017 - Coqatoo Generating Natural Language Versions of C.pdf:application/pdf;arXiv.org Snapshot:/Users/richardford/Zotero/storage/UBK7X3KY/1712.html:text/html}
}

@thesis{sherman_making_2017,
	location = {Cambridge, {MA}},
	title = {Making Discrete Decisions Based on Continuous Values},
	url = {http://adam.chlipala.net/theses/sherman_sm.pdf},
	abstract = {Many safety-critical software systems are cyber-physical systems that compute with continuous values; confirming their safety requires guaranteeing the accuracy of their computations. It is impossible for these systems to compute (total and deterministic) discrete computations (e.g., decisions) based on connected input spaces such as R. We propose a programming language based on constructive topology, whose types are spaces and programs are executable continuous maps, that facilitates making formal guarantees of accuracy of computed results. We demonstrate that discrete decisions can be made based on continuous values by permitting nondeterminism. This thesis describes variants of the programming language allowing nondeterminism and/or partiality, and introduces two tools for creating nondeterministic programs on spaces. Overlapping pattern matching is a generalization of pattern matching in functional programming, where patterns need not represent decidable predicates and also may overlap, allowing potentially nondeterministic behavior in overlapping regions. Binary covers, which are pairs of predicates such that at least one of them holds, yield a formal logic for constructing approximate decision procedures.},
	pagetotal = {105},
	institution = {{MIT}},
	type = {Master of Science},
	author = {Sherman, Benjamin},
	date = {2017-06},
	langid = {english},
	note = {ben-sherman/sm-thesis.pdf},
	file = {Sherman - Making Discrete Decisions Based on Continuous Valu.pdf:/Users/richardford/Zotero/storage/KF9N82CU/Sherman - Making Discrete Decisions Based on Continuous Valu.pdf:application/pdf}
}

@inproceedings{boulier_next_2017,
	title = {The next 700 syntactical models of type theory},
	url = {https://hal.inria.fr/hal-01445835/document},
	doi = {10.1145/3018610.3018620},
	abstract = {A family of syntactic models for the calculus of construction with universes ({CC} ω) is described, all of them preserving conversion of the calculus definitionally, and thus giving rise directly to a program transformation of {CC} ω into itself. Those models are based on the remark that negative type constructors (e.g., dependent product, coinductive types or universes) are underspecified in type theory—which leaves some freedom on extra intensional specifications. The model construction can be seen as a compilation phase from a complex type theory into a simpler type theory. Such models can be used to derive (the negative part of) independence results with respect to {CC} ω , such as functional extensional-ity, propositional extensionality, univalence or the fact that bisimulation on a coinductive type may not coincide with equality. They can also be used to add new principles to the theory, which we illustrate by defining a version of {CC} ω with ad-hoc polymorphism that shows in particular that para-metricity is not an implicit requirement of type theory. The correctness of some of the models/program transformations have been checked in the {COQ} proof assistant and have been instrumented as a {COQ} plugin.},
	eventtitle = {Certified Programs and Proofs ({CPP} 2017)},
	pages = {182 -- 194},
	author = {Boulier, Simon and Pédrot, Pierre-Marie and Tabareau, Nicolas},
	urldate = {2019-01-31},
	date = {2017-01-16},
	langid = {english},
	file = {Full Text PDF:/Users/richardford/Zotero/storage/63IAMKPN/Boulier et al. - 2017 - The next 700 syntactical models of type theory.pdf:application/pdf;Snapshot:/Users/richardford/Zotero/storage/VKLAKHTH/hal-01445835.html:text/html}
}

@book{bowman_j1:_nodate,
	title = {J1: a small Forth {CPU} Core for {FPGAs}},
	shorttitle = {J1},
	abstract = {Abstract—This paper describes a 16-bit Forth {CPU} core, intended for {FPGAs}. The instruction set closely matches the Forth programming language, simplifying cross-compilation. Because it has higher throughput than comparable {CPU} cores, it can stream uncompressed video over Ethernet using a simple software loop.The entire system (source Verilog,cross compiler, and {TCP}/{IP} networking code) is published under the {BSD} license. The core is less than 200 lines of Verilog, and operates reliably at 80 {MHz} in a Xilinx Spartan R○-3E {FPGA}, delivering approximately 100 {ANS} Forth {MIPS}. I.},
	author = {Bowman, James},
	file = {Citeseer - Full Text PDF:/Users/richardford/Zotero/storage/T8LQY54B/Bowman - J1 a small Forth CPU Core for FPGAs.pdf:application/pdf;Citeseer - Snapshot:/Users/richardford/Zotero/storage/W6VSU9EW/summary.html:text/html}
}

@inproceedings{gu_deep_2015,
	location = {New York, {NY}, {USA}},
	title = {Deep Specifications and Certified Abstraction Layers},
	isbn = {978-1-4503-3300-9},
	url = {http://doi.acm.org/10.1145/2676726.2676975},
	doi = {10.1145/2676726.2676975},
	series = {{POPL} '15},
	abstract = {Modern computer systems consist of a multitude of abstraction layers (e.g., {OS} kernels, hypervisors, device drivers, network protocols), each of which defines an interface that hides the implementation details of a particular set of functionality. Client programs built on top of each layer can be understood solely based on the interface, independent of the layer implementation. Despite their obvious importance, abstraction layers have mostly been treated as a system concept; they have almost never been formally specified or verified. This makes it difficult to establish strong correctness properties, and to scale program verification across multiple layers. In this paper, we present a novel language-based account of abstraction layers and show that they correspond to a strong form of abstraction over a particularly rich class of specifications which we call deep specifications. Just as data abstraction in typed functional languages leads to the important representation independence property, abstraction over deep specification is characterized by an important implementation independence property: any two implementations of the same deep specification must have contextually equivalent behaviors. We present a new layer calculus showing how to formally specify, program, verify, and compose abstraction layers. We show how to instantiate the layer calculus in realistic programming languages such as C and assembly, and how to adapt the {CompCert} verified compiler to compile certified C layers such that they can be linked with assembly layers. Using these new languages and tools, we have successfully developed multiple certified {OS} kernels in the Coq proof assistant, the most realistic of which consists of 37 abstraction layers, took less than one person year to develop, and can boot a version of Linux as a guest.},
	pages = {595--608},
	booktitle = {Proceedings of the 42Nd Annual {ACM} {SIGPLAN}-{SIGACT} Symposium on Principles of Programming Languages},
	publisher = {{ACM}},
	author = {Gu, Ronghui and Koenig, Jérémie and Ramananandro, Tahina and Shao, Zhong and Wu, Xiongnan (Newman) and Weng, Shu-Chun and Zhang, Haozhong and Guo, Yu},
	urldate = {2019-01-31},
	date = {2015},
	keywords = {abstraction layer, certified compilers, certified os kernels, deep specification, modularity, program verification},
	file = {ACM Full Text PDF:/Users/richardford/Zotero/storage/7DPCTJMC/Gu et al. - 2015 - Deep Specifications and Certified Abstraction Laye.pdf:application/pdf}
}

@article{murawski_invitation_2016,
	title = {An Invitation to Game Semantics},
	volume = {3},
	issn = {2372-3491},
	url = {http://doi.acm.org/10.1145/2948896.2948902},
	doi = {10.1145/2948896.2948902},
	abstract = {Game semantics is a flexible semantic theory that has led in recent years to an unprecedented number of full abstraction results for various programming paradigms. We present a gentle introduction to the subject, focussing on high-level ideas and examples with a view to providing a bridge to more technical literature.},
	pages = {56--67},
	number = {2},
	journaltitle = {{ACM} {SIGLOG} News},
	author = {Murawski, Andrzej S. and Tzevelekos, Nikos},
	urldate = {2019-01-31},
	date = {2016-05},
	file = {ACM Full Text PDF:/Users/richardford/Zotero/storage/ITYEIVIF/Murawski and Tzevelekos - 2016 - An Invitation to Game Semantics.pdf:application/pdf}
}

@article{herlihy_linearizability:_1990,
	title = {Linearizability: A Correctness Condition for Concurrent Objects},
	volume = {12},
	issn = {0164-0925},
	url = {http://doi.acm.org/10.1145/78969.78972},
	doi = {10.1145/78969.78972},
	shorttitle = {Linearizability},
	abstract = {A concurrent object is a data object shared by concurrent processes. Linearizability is a correctness condition for concurrent objects that exploits the semantics of abstract data types. It permits a high degree of concurrency, yet it permits programmers to specify and reason about concurrent objects using known techniques from the sequential domain. Linearizability provides the illusion that each operation applied by concurrent processes takes effect instantaneously at some point between its invocation and its response, implying that the meaning of a concurrent object's operations can be given by pre- and post-conditions. This paper defines linearizability, compares it to other correctness conditions, presents and demonstrates a method for proving the correctness of implementations, and shows how to reason about concurrent objects, given they are linearizable.},
	pages = {463--492},
	number = {3},
	journaltitle = {{ACM} Trans. Program. Lang. Syst.},
	author = {Herlihy, Maurice P. and Wing, Jeannette M.},
	urldate = {2019-01-31},
	date = {1990-07},
	file = {ACM Full Text PDF:/Users/richardford/Zotero/storage/XCLSDXNI/Herlihy and Wing - 1990 - Linearizability A Correctness Condition for Concu.pdf:application/pdf}
}

@inproceedings{gu_certikos:_2016,
	location = {Berkeley, {CA}, {USA}},
	title = {{CertiKOS}: An Extensible Architecture for Building Certified Concurrent {OS} Kernels},
	isbn = {978-1-931971-33-1},
	url = {http://dl.acm.org/citation.cfm?id=3026877.3026928},
	series = {{OSDI}'16},
	shorttitle = {{CertiKOS}},
	abstract = {Complete formal verification of a non-trivial concurrent {OS} kernel is widely considered a grand challenge. We present a novel compositional approach for building certified concurrent {OS} kernels. Concurrency allows interleaved execution of kernel/user modules across different layers of abstraction. Each such layer can have a different set of observable events. We insist on formally specifying these layers and their observable events, and then verifying each kernel module at its proper abstraction level. To support certified linking with other {CPUs} or threads, we prove a strong contextual refinement property for every kernel function, which states that the implementation of each such function will behave like its specification under any kernel/user context with any valid interleaving. We have successfully developed a practical concurrent {OS} kernel and verified its (contextual) functional correctness in Coq. Our certified kernel is written in 6500 lines of C and x86 assembly and runs on stock x86 multicore machines. To our knowledge, this is the first proof of functional correctness of a complete, general-purpose concurrent {OS} kernel with fine-grained locking.},
	pages = {653--669},
	booktitle = {Proceedings of the 12th {USENIX} Conference on Operating Systems Design and Implementation},
	publisher = {{USENIX} Association},
	author = {Gu, Ronghui and Shao, Zhong and Chen, Hao and Wu, Xiongnan and Kim, Jieung and Sjöberg, Vilhelm and Costanzo, David},
	urldate = {2019-01-31},
	date = {2016},
	file = {Gu et al. - 2016 - CertiKOS An Extensible Architecture for Building .pdf:/Users/richardford/Zotero/storage/A928RE7F/Gu et al. - 2016 - CertiKOS An Extensible Architecture for Building .pdf:application/pdf}
}

@article{costanzo_end--end_nodate,
	title = {End-to-End Veriﬁcation of Information-Flow Security for C and Assembly Programs - Tech Report},
	url = {http://flint.cs.yale.edu/certikos/publications/security-tr.pdf},
	abstract = {Protecting the conﬁdentiality of information manipulated by a computing system is one of the most important challenges facing today’s cybersecurity community. A promising step toward conquering this challenge is to formally verify that the end-to-end behavior of the computing system really satisﬁes various information-ﬂow policies. Unfortunately, because today’s system software still consists of both C and assembly programs, the end-to-end veriﬁcation necessarily requires that we not only prove the security properties of individual components, but also carefully preserve these properties through compilation and cross-language linking.},
	pages = {21},
	author = {Costanzo, David and Shao, Zhong and Gu, Ronghui},
	langid = {english},
	note = {certikos/pldi16-certikos-security-tr.pdf},
	file = {Costanzo et al. - End-to-End Veriﬁcation of Information-Flow Securit.pdf:/Users/richardford/Zotero/storage/L2E38WJM/Costanzo et al. - End-to-End Veriﬁcation of Information-Flow Securit.pdf:application/pdf}
}

@inproceedings{costanzo_end--end_2016,
	location = {New York, {NY}, {USA}},
	title = {End-to-end Verification of Information-flow Security for C and Assembly Programs},
	isbn = {978-1-4503-4261-2},
	url = {http://doi.acm.org/10.1145/2908080.2908100},
	doi = {10.1145/2908080.2908100},
	series = {{PLDI} '16},
	abstract = {Protecting the confidentiality of information manipulated by a computing system is one of the most important challenges facing today's cybersecurity community. A promising step toward conquering this challenge is to formally verify that the end-to-end behavior of the computing system really satisfies various information-flow policies. Unfortunately, because today's system software still consists of both C and assembly programs, the end-to-end verification necessarily requires that we not only prove the security properties of individual components, but also carefully preserve these properties through compilation and cross-language linking. In this paper, we present a novel methodology for formally verifying end-to-end security of a software system that consists of both C and assembly programs. We introduce a general definition of observation function that unifies the concepts of policy specification, state indistinguishability, and whole-execution behaviors. We show how to use different observation functions for different levels of abstraction, and how to link different security proofs across abstraction levels using a special kind of simulation that is guaranteed to preserve state indistinguishability. To demonstrate the effectiveness of our new methodology, we have successfully constructed an end-to-end security proof, fully formalized in the Coq proof assistant, of a nontrivial operating system kernel (running on an extended {CompCert} x86 assembly machine model). Some parts of the kernel are written in C and some are written in assembly; we verify all of the code, regardless of language.},
	pages = {648--664},
	booktitle = {Proceedings of the 37th {ACM} {SIGPLAN} Conference on Programming Language Design and Implementation},
	publisher = {{ACM}},
	author = {Costanzo, David and Shao, Zhong and Gu, Ronghui},
	urldate = {2019-01-31},
	date = {2016},
	keywords = {Certified {OS} Kernels, Information Flow Control, Program Verification, Security Policy Specification, Security-Preserving Simulation},
	file = {ACM Full Text PDF:/Users/richardford/Zotero/storage/HCL3RZNR/Costanzo et al. - 2016 - End-to-end Verification of Information-flow Securi.pdf:application/pdf}
}

@inproceedings{gu_certified_2018,
	location = {New York, {NY}, {USA}},
	title = {Certified Concurrent Abstraction Layers},
	isbn = {978-1-4503-5698-5},
	url = {http://doi.acm.org/10.1145/3192366.3192381},
	doi = {10.1145/3192366.3192381},
	series = {{PLDI} 2018},
	abstract = {Concurrent abstraction layers are ubiquitous in modern computer systems because of the pervasiveness of multithreaded programming and multicore hardware. Abstraction layers are used to hide the implementation details (e.g., fine-grained synchronization) and reduce the complex dependencies among components at different levels of abstraction. Despite their obvious importance, concurrent abstraction layers have not been treated formally. This severely limits the applicability of layer-based techniques and makes it difficult to scale verification across multiple concurrent layers.   In this paper, we present {CCAL}---a fully mechanized programming toolkit developed under the {CertiKOS} project---for specifying, composing, compiling, and linking certified concurrent abstraction layers. {CCAL} consists of three technical novelties: a new game-theoretical, strategy-based compositional semantic model for concurrency (and its associated program verifiers), a set of formal linking theorems for composing multithreaded and multicore concurrent layers, and a new {CompCertX} compiler that supports certified thread-safe compilation and linking. The {CCAL} toolkit is implemented in Coq and supports layered concurrent programming in both C and assembly. It has been successfully applied to build a fully certified concurrent {OS} kernel with fine-grained locking.},
	pages = {646--661},
	booktitle = {Proceedings of the 39th {ACM} {SIGPLAN} Conference on Programming Language Design and Implementation},
	publisher = {{ACM}},
	author = {Gu, Ronghui and Shao, Zhong and Kim, Jieung and Wu, Xiongnan (Newman) and Koenig, Jérémie and Sjöberg, Vilhelm and Chen, Hao and Costanzo, David and Ramananandro, Tahina},
	urldate = {2019-01-31},
	date = {2018},
	keywords = {abstraction layer, certified compilers, modularity, certified {OS} kernels, concurrency, Verification},
	file = {ACM Full Text PDF:/Users/richardford/Zotero/storage/84F5S82K/Gu et al. - 2018 - Certified Concurrent Abstraction Layers.pdf:application/pdf}
}

@inproceedings{chargueraud_program_2010,
	location = {New York, {NY}, {USA}},
	title = {Program Verification Through Characteristic Formulae},
	isbn = {978-1-60558-794-3},
	url = {http://doi.acm.org/10.1145/1863543.1863590},
	doi = {10.1145/1863543.1863590},
	series = {{ICFP} '10},
	abstract = {This paper describes {CFML}, the first program verification tool based on characteristic formulae. Given the source code of a pure Caml program, this tool generates a logical formula that implies any valid post-condition for that program. One can then prove that the program satisfies a given specification by reasoning interactively about the characteristic formula using a proof assistant such as Coq. Our characteristic formulae improve over Honda et al's total characteristic assertion pairs in that they are expressible in standard higher-order logic, allowing to exploit them in practice to verify programs using existing proof assistants. Our technique has been applied to formally verify more than half of the content of Okasaki's Purely Functional Data Structures reference book},
	pages = {321--332},
	booktitle = {Proceedings of the 15th {ACM} {SIGPLAN} International Conference on Functional Programming},
	publisher = {{ACM}},
	author = {Charguéraud, Arthur},
	urldate = {2019-01-31},
	date = {2010},
	keywords = {characteristic formula, functional program, total correctness},
	file = {ACM Full Text PDF:/Users/richardford/Zotero/storage/LP9W7JLK/Charguéraud - 2010 - Program Verification Through Characteristic Formul.pdf:application/pdf}
}

@inproceedings{chargueraud_characteristic_2011,
	location = {New York, {NY}, {USA}},
	title = {Characteristic Formulae for the Verification of Imperative Programs},
	isbn = {978-1-4503-0865-6},
	url = {http://doi.acm.org/10.1145/2034773.2034828},
	doi = {10.1145/2034773.2034828},
	series = {{ICFP} '11},
	abstract = {In previous work, we introduced an approach to program verification based on characteristic formulae. The approach consists of generating a higher-order logic formula from the source code of a program. This characteristic formula is constructed in such a way that it gives a sound and complete description of the semantics of that program. The formula can thus be exploited in an interactive proof assistant to formally verify that the program satisfies a particular specification. This previous work was, however, only concerned with purely-functional programs. In the present paper, we describe the generalization of characteristic formulae to an imperative programming language. In this setting, characteristic formulae involve specifications expressed in the style of Separation Logic. They also integrate the frame rule, which enables local reasoning. We have implemented a tool based on characteristic formulae. This tool, called {CFML}, supports the verification of imperative Caml programs using the Coq proof assistant. Using {CFML}, we have formally verified nontrivial imperative algorithms, as well as {CPS} functions, higher-order iterators, and programs involving higher-order stores.},
	pages = {418--430},
	booktitle = {Proceedings of the 16th {ACM} {SIGPLAN} International Conference on Functional Programming},
	publisher = {{ACM}},
	author = {Charguéraud, Arthur},
	urldate = {2019-01-31},
	date = {2011},
	keywords = {characteristic formula, total correctness, interactive verification},
	file = {ACM Full Text PDF:/Users/richardford/Zotero/storage/2GURSGU7/Charguéraud - 2011 - Characteristic Formulae for the Verification of Im.pdf:application/pdf}
}

@thesis{chargueraud_characteristic_2010,
	location = {Paris, France},
	title = {Characteristic Formulae for Mechanized Program Verification},
	abstract = {This dissertation describes a new approach to program veri cation,
based on characteristic formulae. The characteristic formula of a program
is a higher-order logic formula that describes the behavior of that
program, in the sense that it is sound and complete with respect to
the semantics. This formula can be exploited in an interactive theorem
prover to establish that the program satis es a speci cation expressed
in the style of Separation Logic, with respect to total correctness.
The characteristic formula of a program is automatically generated
from its source code alone. In particular, there is no need to annotate the
source code with speci cations or loop invariants, as such information
can be given in interactive proof scripts. One key feature of characteristic
formulae is that they are of linear size and that they can be prettyprinted
in a way that closely resemble the source code they describe, even
though they do not refer to the syntax of the programming language.
Characteristic formulae serve as a basis for a tool, called {CFML}, that
supports the veri cation of Caml programs using the Coq proof assistant.
{CFML} has been employed to verify about half of the content of
Okasaki's book on purely functional data structures, and to verify several
imperative data structures such as mutable lists, sparse arrays and
union- nd. {CFML} also supports reasoning on higher-order imperative
functions, such as functions in {CPS} form and higher-order iterators},
	pagetotal = {185},
	institution = {{UNIVERSITÉ} {PARIS}.{DIDEROT}},
	type = {phdthesis},
	author = {Charguéraud, Arthur},
	date = {2010-12-16},
	langid = {english},
	note = {chargueraud/chargueraud\_thesis\_final.pdf},
	file = {Charguéraud - Characteristic Formulae for Mechanized Program Ver.pdf:/Users/richardford/Zotero/storage/PZZIGKPW/Charguéraud - Characteristic Formulae for Mechanized Program Ver.pdf:application/pdf}
}

@article{chlipala_introduction_nodate,
	title = {An Introduction to Programming and Proving with Dependent Types in Coq},
	volume = {3},
	abstract = {Computer proof assistants vary along many dimensions. Among the mature implementations, the Coq system is distinguished by two key features. First, we have support for programming with
dependent types in the tradition of type theory, based on dependent function types and inductive type families. Second, we have a domain-specific language for coding correct-by-construction proof automation. Though the Coq user community has grown quite large, neither of the aspects
I highlight is widely used. In this tutorial, I aim to provide a pragmatic introduction to both, showing how they can bring significant improvements in productivity.},
	pages = {93},
	number = {2},
	journaltitle = {Journal of Formalized Reasoning},
	author = {Chlipala, Adam},
	langid = {english},
	note = {chlipala/1978-4445-1-{PB}.pdf},
	file = {Chlipala - An Introduction to Programming and Proving with De.pdf:/Users/richardford/Zotero/storage/KS4N39J7/Chlipala - An Introduction to Programming and Proving with De.pdf:application/pdf}
}

@book{chlipala_certified_2013,
	location = {Cambridge, {MA}},
	title = {Certified programming with dependent types: a pragmatic introduction to the Coq proof assistant},
	isbn = {978-0-262-02665-9},
	url = {http://adam.chlipala.net/cpdt/},
	shorttitle = {Certified programming with dependent types},
	pagetotal = {424},
	publisher = {The {MIT} Press},
	author = {Chlipala, Adam},
	date = {2013},
	keywords = {Automatic theorem proving, Computer programming, Computer programs, Coq (Electronic resource)}
}

@article{chlipala_certied_nodate,
	title = {Certiﬁed Programming with Dependent Types},
	pages = {369},
	author = {Chlipala, Adam},
	langid = {english},
	file = {Chlipala - Certiﬁed Programming with Dependent Types.pdf:/Users/richardford/Zotero/storage/DYCT99N4/Chlipala - Certiﬁed Programming with Dependent Types.pdf:application/pdf}
}

@software{chlipala_formal_2019,
	title = {Formal Reasoning About Programs - Github},
	url = {https://github.com/achlipala/frap},
	author = {Chlipala, Adam},
	urldate = {2019-01-31},
	date = {2019-01-31},
	note = {original-date: 2016-02-02T18:43:56Z},
	file = {frap_book.pdf:/Users/richardford/Zotero/storage/W5SBG74C/frap_book.pdf:application/pdf}
}

@article{pit-claudel_extensible_nodate,
	title = {Extensible Extraction of Efﬁcient Imperative Programs with Foreign Functions, Manually Managed Memory, and Proofs},
	url = {http://pit-claudel.fr/clement/papers/fiat-to-facade.pdf},
	abstract = {We present an original approach to sound program extraction in a proof assistant, using syntax-driven automation to derive correct-by-construction imperative programs from nondeterministic functional source code. Our approach does not require committing to a single inﬂexible compilation strategy and instead makes it straightforward to create domainspeciﬁc code translators. In addition to a small set of core definitions, our framework is a large, user-extensible collection of compilation rules each phrased to handle speciﬁc language constructs, code patterns, or data manipulations. By mixing and matching these pieces of logic, users can easily tailor extraction to their own domains and programs, getting maximum performance and ensuring correctness of the resulting assembly code. Using this approach, we complete the ﬁrst proof-generating pipeline that goes automatically from high-level speciﬁcations to assembly code. In our main case study, the original speciﬁcations are phrased to resemble {SQL}-style queries, while the ﬁnal assembly code does manual memory management, calls out to foreign data structures and functions, and is suitable to deploy on resource-constrained platforms. The pipeline runs entirely within the Coq proof assistant, leading to ﬁnal, linked assembly code inside Coq with overall full-functional-correctness proofs in separation logic.},
	pages = {14},
	author = {Pit-Claudel, Clément and Wang, Peng and Delaware, Benjamin and Gross, Jason and Chlipala, Adam},
	langid = {english},
	note = {clement/fiat-to-facade.pdg},
	file = {Pit-Claudel et al. - Extensible Extraction of Efﬁcient Imperative Progr.pdf:/Users/richardford/Zotero/storage/PBAPDPGG/Pit-Claudel et al. - Extensible Extraction of Efﬁcient Imperative Progr.pdf:application/pdf}
}

@incollection{feng_correct-by-construction_2018,
	location = {Cham},
	title = {Correct-by-Construction Implementation of Runtime Monitors Using Stepwise Refinement},
	volume = {10998},
	isbn = {978-3-319-99932-6 978-3-319-99933-3},
	url = {http://link.springer.com/10.1007/978-3-319-99933-3_3},
	pages = {31--49},
	booktitle = {Dependable Software Engineering. Theories, Tools, and Applications},
	publisher = {Springer International Publishing},
	author = {Zhang, Teng and Wiegley, John and Giannakopoulos, Theophilos and Eakman, Gregory and Pit-Claudel, Clément and Lee, Insup and Sokolsky, Oleg},
	editor = {Feng, Xinyu and Müller-Olm, Markus and Yang, Zijiang},
	urldate = {2019-01-31},
	date = {2018},
	doi = {10.1007/978-3-319-99933-3_3},
	file = {Zhang et al. - 2018 - Correct-by-Construction Implementation of Runtime .pdf:/Users/richardford/Zotero/storage/TFNK7T59/Zhang et al. - 2018 - Correct-by-Construction Implementation of Runtime .pdf:application/pdf}
}

@book{martin_mastering_2013,
	location = {Clifton Park, {NY}},
	edition = {6. ed},
	title = {Mastering {CMake}: a cross-platform build system ; covers installing and running {CMake} ; details converting existing build processes to {CMake} ; create powerful cross-platform build scripts},
	isbn = {978-1-930934-26-9},
	shorttitle = {Mastering {CMake}},
	pagetotal = {640},
	publisher = {Kitware},
	author = {Martin, Ken and Hoffman, Bill and Cedilnik, Andy},
	date = {2013},
	note = {{OCLC}: 869872480},
	file = {mastering-cmake.pdf:/Users/richardford/Zotero/storage/ZJ8TN7IN/mastering-cmake.pdf:application/pdf;Table of Contents PDF:/Users/richardford/Zotero/storage/J9EPKEK2/Martin et al. - 2013 - Mastering CMake a cross-platform build system \; c.pdf:application/pdf}
}

@online{absint_compcert_nodate,
	title = {{CompCert} - Publications},
	url = {http://compcert.inria.fr/publi.html},
	author = {Absint},
	urldate = {2019-01-31},
	file = {CompCert - Publications:/Users/richardford/Zotero/storage/98Y2B9GJ/publi.html:text/html}
}

@incollection{chaudhuri_trigger_2016,
	location = {Cham},
	title = {Trigger Selection Strategies to Stabilize Program Verifiers},
	volume = {9779},
	isbn = {978-3-319-41527-7 978-3-319-41528-4},
	url = {http://link.springer.com/10.1007/978-3-319-41528-4_20},
	pages = {361--381},
	booktitle = {Computer Aided Verification},
	publisher = {Springer International Publishing},
	author = {Leino, K. R. M. and Pit-Claudel, Clément},
	editor = {Chaudhuri, Swarat and Farzan, Azadeh},
	urldate = {2019-01-31},
	date = {2016},
	doi = {10.1007/978-3-319-41528-4_20},
	file = {Leino and Pit-Claudel - 2016 - Trigger Selection Strategies to Stabilize Program .pdf:/Users/richardford/Zotero/storage/455BEULC/Leino and Pit-Claudel - 2016 - Trigger Selection Strategies to Stabilize Program .pdf:application/pdf}
}

@online{pit-claudel_clement_nodate,
	title = {Clément Pit-Claudel},
	url = {http://pit-claudel.fr/clement/},
	author = {Pit-Claudel, Clément},
	urldate = {2019-01-31},
	file = {Clément Pit-Claudel:/Users/richardford/Zotero/storage/DKTZXDT7/clement.html:text/html}
}

@book{bertot_interactive_2004,
	location = {Berlin ; New York},
	title = {Interactive theorem proving and program development: Coq'Art: the calculus of inductive constructions},
	isbn = {978-3-540-20854-9},
	url = {http://www.labri.fr/perso/casteran/CoqArt/index.html},
	series = {Texts in theoretical computer science},
	shorttitle = {Interactive theorem proving and program development},
	pagetotal = {469},
	publisher = {Springer},
	author = {Bertot, Yves and Castéran, P.},
	date = {2004},
	note = {{OCLC}: ocm55514299},
	keywords = {Automatic theorem proving, Computer programming}
}

@online{casteran_pierre_nodate,
	title = {Pierre Castéran's Home page},
	url = {http://www.labri.fr/perso/casteran/index.html},
	author = {Castéran, Pierre},
	urldate = {2019-01-31},
	file = {Pierre Castéran's Home page:/Users/richardford/Zotero/storage/DYKI8IUV/index.html:text/html}
}

@online{bertot_yves_nodate,
	title = {Yves Bertot},
	url = {http://www-sop.inria.fr/members/Yves.Bertot/index.html},
	author = {Bertot, Yves},
	urldate = {2019-01-31},
	file = {Yves Bertot:/Users/richardford/Zotero/storage/XCTTX2DV/index.html:text/html}
}

@online{inria_inria_nodate,
	title = {Inria - Inventors for the digital world},
	url = {https://www.inria.fr/en},
	abstract = {Inria is a public research body dedicated to digital science and technology.},
	titleaddon = {Inria},
	author = {Inria},
	urldate = {2019-01-31},
	langid = {english},
	file = {Snapshot:/Users/richardford/Zotero/storage/7PRHEUQG/en.html:text/html}
}

@inproceedings{crary_modules_2017,
	location = {New York, {NY}, {USA}},
	title = {Modules, Abstraction, and Parametric Polymorphism},
	isbn = {978-1-4503-4660-3},
	url = {http://doi.acm.org/10.1145/3009837.3009892},
	doi = {10.1145/3009837.3009892},
	series = {{POPL} 2017},
	abstract = {Reynolds's Abstraction theorem forms the mathematical foundation for data abstraction. His setting was the polymorphic lambda calculus. Today, many modern languages, such as the {ML} family, employ rich module systems designed to give more expressive support for data abstraction than the polymorphic lambda calculus, but analogues of the Abstraction theorem for such module systems have lagged far behind.   We give an account of the Abstraction theorem for a modern module calculus supporting generative and applicative functors, higher-order functors, sealing, and translucent signatures. The main issues to be overcome are: (1) the fact that modules combine both types and terms, so they must be treated as both simultaneously, (2) the effect discipline that models the distinction between transparent and opaque modules, and (3) a very rich language of type constructors supporting singleton kinds. We define logical equivalence for modules and show that it coincides with contextual equivalence. This substantiates the folk theorem that modules are good for data abstraction. All our proofs are formalized in Coq.},
	pages = {100--113},
	booktitle = {Proceedings of the 44th {ACM} {SIGPLAN} Symposium on Principles of Programming Languages},
	publisher = {{ACM}},
	author = {Crary, Karl},
	urldate = {2019-01-31},
	date = {2017},
	note = {crary/crary-mapp.pdf},
	keywords = {Abstraction, logical relations, modules, parametricity},
	file = {ACM Full Text PDF:/Users/richardford/Zotero/storage/NL7K5PQH/Crary - 2017 - Modules, Abstraction, and Parametric Polymorphism.pdf:application/pdf}
}

@inbook{platzer_differential_2018,
	location = {Cham},
	title = {Differential Equations \& Differential Invariants},
	isbn = {978-3-319-63587-3 978-3-319-63588-0},
	url = {http://link.springer.com/10.1007/978-3-319-63588-0_10},
	pages = {287--322},
	booktitle = {Logical Foundations of Cyber-Physical Systems},
	publisher = {Springer International Publishing},
	author = {Platzer, André},
	bookauthor = {Platzer, André},
	urldate = {2019-01-31},
	date = {2018},
	langid = {english},
	doi = {10.1007/978-3-319-63588-0_10},
	file = {Platzer - 2018 - Differential Equations & Differential Invariants.pdf:/Users/richardford/Zotero/storage/PS8YT9GP/Platzer - 2018 - Differential Equations & Differential Invariants.pdf:application/pdf}
}

@article{platzer_differential_2015,
	title = {Differential Game Logic},
	volume = {17},
	issn = {1529-3785},
	url = {http://doi.acm.org/10.1145/2817824},
	doi = {10.1145/2817824},
	abstract = {Differential game logic ({dGL}) is a logic for specifying and verifying properties of hybrid games, i.e., games that combine discrete, continuous, and adversarial dynamics. Unlike hybrid systems, hybrid games allow choices in the system dynamics to be resolved adversarially by different players with different objectives. The logic {dGL} can be used to study the existence of winning strategies for such hybrid games, i.e., ways of resolving the player’s choices in some way so that he wins by achieving his objective for all choices of the opponent. Hybrid games are determined, i.e., from each state, one player has a winning strategy, yet computing their winning regions may take transfinitely many steps. The logic {dGL}, nevertheless, has a sound and complete axiomatization relative to any expressive logic. Separating axioms are identified that distinguish hybrid games from hybrid systems. Finally, {dGL} is proved to be strictly more expressive than the corresponding logic of hybrid systems by characterizing the expressiveness of both.},
	pages = {1:1--1:51},
	number = {1},
	journaltitle = {{ACM} Trans. Comput. Logic},
	author = {Platzer, André},
	urldate = {2019-01-31},
	date = {2015-11},
	keywords = {axiomatization, expressiveness, Game logic, hybrid games},
	file = {ACM Full Text PDF:/Users/richardford/Zotero/storage/35WLKIMB/Platzer - 2015 - Differential Game Logic.pdf:application/pdf}
}

@article{platzer_differential_2008,
	title = {Differential Dynamic Logic for Hybrid Systems},
	volume = {41},
	issn = {0168-7433, 1573-0670},
	url = {http://link.springer.com/10.1007/s10817-008-9103-8},
	doi = {10.1007/s10817-008-9103-8},
	pages = {143--189},
	number = {2},
	journaltitle = {Journal of Automated Reasoning},
	author = {Platzer, André},
	urldate = {2019-01-31},
	date = {2008-08},
	langid = {english},
	file = {Submitted Version:/Users/richardford/Zotero/storage/RNX9KZZM/Platzer - 2008 - Differential Dynamic Logic for Hybrid Systems.pdf:application/pdf}
}

@incollection{hutchison_verifying_2007,
	location = {Berlin, Heidelberg},
	title = {Verifying Object-Oriented Programs with {KeY}: A Tutorial},
	volume = {4709},
	isbn = {978-3-540-74791-8 978-3-540-74792-5},
	url = {http://link.springer.com/10.1007/978-3-540-74792-5_4},
	shorttitle = {Verifying Object-Oriented Programs with {KeY}},
	abstract = {This paper is a tutorial on performing formal speciﬁcation and semi-automatic veriﬁcation of Java programs with the formal software development tool {KeY}. This tutorial aims to ﬁll the gap between elementary introductions using toy examples and state-of-art case studies by going through a self-contained, yet non-trivial, example. It is hoped that this contributes to explain the problems encountered in veriﬁcation of imperative, object-oriented programs to a readership outside the limited community of active researchers.},
	pages = {70--101},
	booktitle = {Formal Methods for Components and Objects},
	publisher = {Springer Berlin Heidelberg},
	author = {Ahrendt, Wolfgang and Beckert, Bernhard and Hähnle, Reiner and Rümmer, Philipp and Schmitt, Peter H.},
	editor = {de Boer, Frank S. and Bonsangue, Marcello M. and Graf, Susanne and de Roever, Willem-Paul},
	editorb = {Hutchison, David and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M. and Mattern, Friedemann and Mitchell, John C. and Naor, Moni and Nierstrasz, Oscar and Pandu Rangan, C. and Steffen, Bernhard and Sudan, Madhu and Terzopoulos, Demetri and Tygar, Doug and Vardi, Moshe Y. and Weikum, Gerhard},
	editorbtype = {redactor},
	urldate = {2019-01-31},
	date = {2007},
	langid = {english},
	doi = {10.1007/978-3-540-74792-5_4},
	file = {Ahrendt et al. - 2007 - Verifying Object-Oriented Programs with KeY A Tut.pdf:/Users/richardford/Zotero/storage/DYP7E6HN/Ahrendt et al. - 2007 - Verifying Object-Oriented Programs with KeY A Tut.pdf:application/pdf}
}

@book{platzer_logical_2018,
	title = {Logical Foundations of Cyber-Physical Systems},
	isbn = {978-3-319-63587-3},
	url = {https://www.springer.com/gp/book/9783319635873},
	abstract = {Cyber-physical systems ({CPSs}) combine cyber capabilities, such as computation or communication, with physical capabilities, such as motion or other physical processes. Cars, aircraft, and robots are prime examples, because they move physically in space in a way that is determined by discrete computerized control algorithms. Designing these algorithms is challenging due to their tight coupling with physical behavior, while it is vital that these algorithms be correct because we rely on them for safety-critical tasks. This textbook teaches undergraduate students the core principles behind {CPSs}. It shows them how to develop models and controls; identify safety specifications and critical properties; reason rigorously about {CPS} models; leverage multi-dynamical systems compositionality to tame {CPS} complexity; identify required control constraints; verify {CPS} models of appropriate scale in logic; and develop an intuition for operational effects. The book is supported with homework exercises, lecture videos, and slides.},
	publisher = {Springer International Publishing},
	author = {Platzer, Andre},
	urldate = {2019-01-31},
	date = {2018},
	langid = {english},
	file = {Snapshot:/Users/richardford/Zotero/storage/TA7J9P9Y/9783319635873.html:text/html}
}

@online{platzer_keymaera_nodate,
	title = {{KeYmaera} X: Documentation},
	url = {http://www.ls.cs.cmu.edu/KeYmaeraX/documentation.html},
	author = {Platzer, André},
	urldate = {2019-01-31},
	file = {KeYmaera X\: Documentation:/Users/richardford/Zotero/storage/YGNHU67P/documentation.html:text/html}
}

@incollection{felty_keymaera_2015,
	location = {Cham},
	title = {{KeYmaera} X: An Axiomatic Tactical Theorem Prover for Hybrid Systems},
	volume = {9195},
	isbn = {978-3-319-21400-9 978-3-319-21401-6},
	url = {http://link.springer.com/10.1007/978-3-319-21401-6_36},
	shorttitle = {{KeYmaera} X},
	abstract = {{KeYmaera} X is a theorem prover for differential dynamic logic ({dL}), a logic for specifying and verifying properties of hybrid systems. Reasoning about complicated hybrid systems models requires support for sophisticated proof techniques, efﬁcient computation, and a user interface that crystallizes salient properties of the system. {KeYmaera} X allows users to specify custom proof search techniques as tactics, execute these tactics in parallel, and interface with partial proofs via an extensible user interface.},
	pages = {527--538},
	booktitle = {Automated Deduction - {CADE}-25},
	publisher = {Springer International Publishing},
	author = {Fulton, Nathan and Mitsch, Stefan and Quesel, Jan-David and Völp, Marcus and Platzer, André},
	editor = {Felty, Amy P. and Middeldorp, Aart},
	urldate = {2019-01-31},
	date = {2015},
	langid = {english},
	doi = {10.1007/978-3-319-21401-6_36},
	file = {Fulton et al. - 2015 - KeYmaera X An Axiomatic Tactical Theorem Prover f.pdf:/Users/richardford/Zotero/storage/WHPK2YJR/Fulton et al. - 2015 - KeYmaera X An Axiomatic Tactical Theorem Prover f.pdf:application/pdf}
}

@book{platzer_logical_2018-1,
	location = {Cham},
	title = {Logical Foundations of Cyber-Physical Systems - Slides},
	isbn = {978-3-319-63587-3 978-3-319-63588-0},
	url = {http://link.springer.com/10.1007/978-3-319-63588-0},
	publisher = {Springer International Publishing},
	author = {Platzer, André},
	urldate = {2019-01-31},
	date = {2018},
	langid = {english},
	doi = {10.1007/978-3-319-63588-0},
	file = {Platzer - 2018 - Logical Foundations of Cyber-Physical Systems.pdf:/Users/richardford/Zotero/storage/XG3XYH4A/Platzer - 2018 - Logical Foundations of Cyber-Physical Systems.pdf:application/pdf}
}

@article{platzer_complete_2017,
	title = {A Complete Uniform Substitution Calculus for Differential Dynamic Logic},
	volume = {59},
	issn = {0168-7433, 1573-0670},
	url = {http://arxiv.org/abs/1601.06183},
	doi = {10.1007/s10817-016-9385-1},
	abstract = {This article introduces a relatively complete proof calculus for differential dynamic logic ({dL}) that is entirely based on uniform substitution, a proof rule that substitutes a formula for a predicate symbol everywhere. Uniform substitutions make it possible to use axioms instead of axiom schemata, thereby substantially simplifying implementations. Instead of subtle schema variables and soundness-critical side conditions on the occurrence patterns of logical variables to restrict infinitely many axiom schema instances to sound ones, the resulting calculus adopts only a finite number of ordinary {dL} formulas as axioms, which uniform substitutions instantiate soundly. The static semantics of differential dynamic logic and the soundness-critical restrictions it imposes on proof steps is captured exclusively in uniform substitutions and variable renamings as opposed to being spread in delicate ways across the prover implementation. In addition to sound uniform substitutions, this article introduces differential forms for differential dynamic logic that make it possible to internalize differential invariants, differential substitutions, and derivatives as first-class axioms to reason about differential equations axiomatically. The resulting axiomatization of differential dynamic logic is proved to be sound and relatively complete.},
	pages = {219--265},
	number = {2},
	journaltitle = {Journal of Automated Reasoning},
	author = {Platzer, André},
	urldate = {2019-01-31},
	date = {2017-08},
	eprinttype = {arxiv},
	eprint = {1601.06183},
	keywords = {Computer Science - Logic in Computer Science, Computer Science - Programming Languages, 03F03, 03B70, 34A38, F.3.1, F.3.2, F.4.1, I.2.3, Mathematics - Logic},
	file = {arXiv\:1601.06183 PDF:/Users/richardford/Zotero/storage/8URQWUMX/Platzer - 2017 - A Complete Uniform Substitution Calculus for Diffe.pdf:application/pdf;arXiv.org Snapshot:/Users/richardford/Zotero/storage/R9XNPMRW/1601.html:text/html}
}

@collection{beckert_verification_2006,
	location = {Berlin, Heidelberg},
	title = {Verification of Object-Oriented Software. The {KeY} Approach},
	volume = {4334},
	isbn = {978-3-540-68977-5},
	url = {http://link.springer.com/10.1007/978-3-540-69061-0},
	series = {Lecture Notes in Computer Science},
	publisher = {Springer Berlin Heidelberg},
	editor = {Beckert, Bernhard and Hähnle, Reiner and Schmitt, Peter H.},
	urldate = {2019-01-31},
	date = {2006},
	langid = {english},
	doi = {10.1007/978-3-540-69061-0},
	file = {Beckert et al. - 2006 - Verification of Object-Oriented Software. The KeY .pdf:/Users/richardford/Zotero/storage/BRH2UR4H/Beckert et al. - 2006 - Verification of Object-Oriented Software. The KeY .pdf:application/pdf}
}

@inproceedings{bohrer_veriphy:_2018,
	location = {Philadelphia, {PA}, {USA}},
	title = {{VeriPhy}: verified controller executables from verified cyber-physical system models},
	isbn = {978-1-4503-5698-5},
	url = {http://dl.acm.org/citation.cfm?doid=3192366.3192406},
	doi = {10.1145/3192366.3192406},
	shorttitle = {{VeriPhy}},
	eventtitle = {the 39th {ACM} {SIGPLAN} Conference},
	pages = {617--630},
	booktitle = {Proceedings of the 39th {ACM} {SIGPLAN} Conference on Programming Language Design and Implementation  - {PLDI} 2018},
	publisher = {{ACM} Press},
	author = {Bohrer, Brandon and Tan, Yong Kiam and Mitsch, Stefan and Myreen, Magnus O. and Platzer, André},
	urldate = {2019-01-31},
	date = {2018},
	langid = {english}
}

@online{ahrendt_deductive_nodate,
	title = {Deductive Software Verification – The {KeY} {BookFrom} Theory to Practice – The {KeY} Project},
	url = {https://www.key-project.org/thebook2/},
	author = {Ahrendt, Wolfgang},
	urldate = {2019-01-31},
	langid = {american},
	note = {cyber-physical/{KeY} directory has pdfs for the chapters.},
	file = {Snapshot:/Users/richardford/Zotero/storage/S6JS29Q6/thebook2.html:text/html}
}

@online{czajka_coqhammer:_nodate,
	title = {{CoqHammer}: Strong Automation for Program Verification - {CoqPL} 2018},
	url = {https://popl18.sigplan.org/event/coqpl-2018-coqhammer-strong-automation-for-program-verification},
	abstract = {We present {CoqHammer}: the first full hammer system for
the Coq proof assistant. The system translates Coq logic
to untyped first-order logic and uses external automated
theorem provers ({ATPs}) to prove the translations of user
given conjectures. Based on the output of the {ATPs}, the
conjecture is then re-proved in the logic of Coq using an
eauto-type proof search algorithm. Together with machinelearning
based selection of relevant premises this constitutes
a full hammer system.
The performance of the overall procedure has been evaluated
in a bootstrapping scenario emulating the development
of the Coq standard library. Over 40\% of the theorems in
the Coq standard library can be proved in a push-button
mode in about 40 seconds of real time on a 8-{CPU} system.
This offers a huge saving of human work in programming
language formalizations.},
	author = {Czajka, Lukasz and Kaliszyk, Cezary},
	urldate = {2019-01-31},
	file = {CoqHammer\: Strong Automation for Program Verification - POPL 2018:/Users/richardford/Zotero/storage/QP8A5J8F/coqpl-2018-coqhammer-strong-automation-for-program-verification.html:text/html;Czajka-Kaliszyk-CoqPL18-Slides.pdf:/Users/richardford/Zotero/storage/9XNB7DCK/Czajka-Kaliszyk-CoqPL18-Slides.pdf:application/pdf;CzajkaKaliszyk-CoqPL18-coqhammer.pdf:/Users/richardford/Zotero/storage/E9SCXEBU/CzajkaKaliszyk-CoqPL18-coqhammer.pdf:application/pdf}
}

@online{acm_coqpl_nodate,
	title = {{CoqPL} 2019 The Fifth International Workshop on Coq for Programming Languages - {POPL} 2019},
	url = {https://popl19.sigplan.org/track/CoqPL-2019#program},
	author = {acm},
	urldate = {2019-01-31},
	file = {CoqPL 2019 The Fifth International Workshop on Coq for Programming Languages - POPL 2019:/Users/richardford/Zotero/storage/CMD6KF5K/CoqPL-2019.html:text/html}
}

@online{acm_coqpl_nodate-1,
	title = {{CoqPL} 2018 The Fourth International Workshop on Coq for Programming Languages - {POPL} 2018},
	url = {https://popl18.sigplan.org/track/CoqPL-2018},
	author = {acm},
	urldate = {2019-01-31},
	file = {CoqPL 2018 The Fourth International Workshop on Coq for Programming Languages - POPL 2018:/Users/richardford/Zotero/storage/H23PH3DM/CoqPL-2018.html:text/html;CoqPL 2018 The Fourth International Workshop on Coq for Programming Languages - POPL 2018:/Users/richardford/Zotero/storage/53TLPA9U/CoqPL-2018.html:text/html}
}

@online{acm_coq_nodate,
	title = {Coq for {PL} conference series - {CoqPL} 2019},
	url = {https://popl18.sigplan.org/series/CoqPL},
	author = {acm},
	urldate = {2019-01-31},
	file = {Coq for PL conference series - CoqPL 2019:/Users/richardford/Zotero/storage/82G7Q28U/CoqPL.html:text/html}
}

@online{acm_popl_nodate,
	title = {{POPL} conference series - {POPL} 2020},
	url = {https://popl18.sigplan.org/series/POPL},
	author = {acm},
	urldate = {2019-01-31},
	file = {POPL conference series - POPL 2020:/Users/richardford/Zotero/storage/WXNCFC9B/POPL.html:text/html}
}

@article{cousot_$^2$i:_2019,
	title = {A\${\textasciicircum}2\$I: Abstract\${\textasciicircum}2\$ Interpretation},
	volume = {3},
	issn = {2475-1421},
	url = {http://doi.acm.org/10.1145/3290355},
	doi = {10.1145/3290355},
	shorttitle = {A\${\textasciicircum}2\$I},
	abstract = {The fundamental idea of Abstract2 Interpretation (A2I), also called meta-abstract interpretation, is to apply abstract interpretation to abstract interpretation-based static program analyses. A2I is generally meant to use abstract interpretation to analyse properties of program analysers. A2I can be either offline or online. Offline A2I is performed either before the program analysis, such as variable packing used by the Astrée program analyser, or after the program analysis, such as in alarm diagnosis. Online A2I is performed during the program analysis, such as Venet’s cofibred domains or Halbwachs et al.’s and Singh et al.’s variable partitioning techniques for fast polyhedra/numerical abstract domains. We formalize offline and online meta-abstract interpretation and illustrate this notion with the design of widenings and the decomposition of relational abstract domains to speed-up program analyses. This shows how novel static analyses can be extracted as meta-abstract interpretations to design efficient and precise program analysis algorithms.},
	pages = {42:1--42:31},
	issue = {{POPL}},
	journaltitle = {Proc. {ACM} Program. Lang.},
	author = {Cousot, Patrick and Giacobazzi, Roberto and Ranzato, Francesco},
	urldate = {2019-01-31},
	date = {2019-01},
	keywords = {Abstract interpretation, meta-abstract interpretation, program analysis},
	file = {ACM Full Text PDF:/Users/richardford/Zotero/storage/ZVG3RMZK/Cousot et al. - 2019 - A\$^2\$I Abstract\$^2\$ Interpretation.pdf:application/pdf}
}

@article{polikarpova_structuring_2019,
	title = {Structuring the Synthesis of Heap-manipulating Programs},
	volume = {3},
	issn = {2475-1421},
	url = {http://doi.acm.org/10.1145/3290385},
	doi = {10.1145/3290385},
	abstract = {This paper describes a deductive approach to synthesizing imperative programs with pointers from declarative specifications expressed in Separation Logic. Our synthesis algorithm takes as input a pair of assertions—a pre- and a postcondition—which describe two states of the symbolic heap, and derives a program that transforms one state into the other, guided by the shape of the heap. Our approach to program synthesis is grounded in proof theory: we introduce the novel framework of Synthetic Separation Logic ({SSL}), which generalises the classical notion of heap entailment P ⊢ Q to incorporate a possibility of transforming a heap satisfying an assertion P into a heap satisfying an assertion Q. A synthesized program represents a proof term for a transforming entailment statement P ↝ Q, and the synthesis procedure corresponds to a proof search. The derived programs are, thus, correct by construction, in the sense that they satisfy the ascribed pre/postconditions, and are accompanied by complete proof derivations, which can be checked independently.  We have implemented a proof search engine for {SSL} in a form of the program synthesizer called {SuSLik}. For efficiency, the engine exploits properties of {SSL} rules, such as invertibility and commutativity of rule applications on separate heaps, to prune the space of derivations it has to consider. We explain and showcase the use of {SSL} on characteristic examples, describe the design of {SuSLik}, and report on our experience of using it to synthesize a series of benchmark programs manipulating heap-based linked data structures.},
	pages = {72:1--72:30},
	issue = {{POPL}},
	journaltitle = {Proc. {ACM} Program. Lang.},
	author = {Polikarpova, Nadia and Sergey, Ilya},
	urldate = {2019-01-31},
	date = {2019-01},
	keywords = {Program Synthesis, Proof Systems, Separation Logic, Type Theory},
	file = {ACM Full Text PDF:/Users/richardford/Zotero/storage/LR6EKQYG/Polikarpova and Sergey - 2019 - Structuring the Synthesis of Heap-manipulating Pro.pdf:application/pdf}
}

@article{leino_assertional_2015,
	title = {An Assertional Proof of the Stability and Correctness of Natural Mergesort},
	volume = {17},
	issn = {1529-3785},
	url = {http://doi.acm.org/10.1145/2814571},
	doi = {10.1145/2814571},
	abstract = {We present a mechanically verified implementation of the sorting algorithm Natural Mergesort that consists of a few methods specified by their contracts of pre/post conditions. Methods are annotated with assertions that allow the automatic verification of the contract satisfaction. This program-proof is made using the state-of-the-art verifier Dafny. We verify not only the standard sortedness property, but also that the algorithm performs a stable sort. Throughout the article, we provide and explain the complete text of the program-proof.},
	pages = {6:1--6:22},
	number = {1},
	journaltitle = {{ACM} Trans. Comput. Logic},
	author = {Leino, K. Rustan M. and Lucio, Paqui},
	urldate = {2019-01-31},
	date = {2015-11},
	keywords = {theorem proving, dafny, formal methods, natural mergesort, software engineering, sorting, stability, Verification},
	file = {ACM Full Text PDF:/Users/richardford/Zotero/storage/KNJPYQ9I/Leino and Lucio - 2015 - An Assertional Proof of the Stability and Correctn.pdf:application/pdf}
}

@inproceedings{christakis_collaborative_2012,
	title = {Collaborative Verification and Testing with Explicit Assumptions},
	isbn = {978-3-642-32759-9},
	series = {Lecture Notes in Computer Science},
	abstract = {Many mainstream static code checkers make a number of compromises to improve automation, performance, and accuracy. These compromises include not checking certain program properties as well as making implicit, unsound assumptions. Consequently, the results of such static checkers do not provide definite guarantees about program correctness, which makes it unclear which properties remain to be tested. We propose a technique for collaborative verification and testing that makes compromises of static checkers explicit such that they can be compensated for by complementary checkers or testing. Our experiments suggest that our technique finds more errors and proves more properties than static checking alone, testing alone, and combinations that do not explicitly document the compromises made by static checkers. Our technique is also useful to obtain small test suites for partially-verified programs.},
	pages = {132--146},
	booktitle = {{FM} 2012: Formal Methods},
	publisher = {Springer Berlin Heidelberg},
	author = {Christakis, Maria and Müller, Peter and Wüstholz, Valentin},
	editor = {Giannakopoulou, Dimitra and Méry, Dominique},
	date = {2012},
	langid = {english},
	keywords = {Static Checker, Symbolic Execution, Test Case Generation, Testing Tool, Tool Chain},
	file = {Christakis et al. - 2012 - Collaborative Verification and Testing with Explic.pdf:/Users/richardford/Zotero/storage/N3T6EIWH/Christakis et al. - 2012 - Collaborative Verification and Testing with Explic.pdf:application/pdf}
}

@article{leino_co-induction_2013,
	title = {Co-Induction Simply: Automatic Co-Inductive Proofs in a Program Verifier},
	url = {https://www.microsoft.com/en-us/research/publication/co-induction-simply-automatic-co-inductive-proofs-in-a-program-verifier/},
	shorttitle = {Co-Induction Simply},
	abstract = {Program verification relies heavily on induction, which has received decades of attention in mechanical verification tools. When program correctness is best described by infinite structures, program verification is usefully aided also by co-induction, which has not benefited from the same degree of tool support. Co-induction is complicated to work with in interactive proof assistants and …},
	author = {Leino, Rustan and Moskal, Michal},
	urldate = {2019-01-31},
	date = {2013-07-12},
	langid = {american},
	file = {Full Text PDF:/Users/richardford/Zotero/storage/UEL7SVLY/Leino and Moskal - 2013 - Co-Induction Simply Automatic Co-Inductive Proofs.pdf:application/pdf;Snapshot:/Users/richardford/Zotero/storage/DXHEKVNI/co-induction-simply-automatic-co-inductive-proofs-in-a-program-verifier.html:text/html}
}

@article{amin_computing_2016,
	title = {Computing with an {SMT} Solver},
	volume = {8570},
	url = {https://www.microsoft.com/en-us/research/publication/computing-smt-solver/},
	abstract = {Satisfiability modulo theories ({SMT}) solvers that support quantifier instantiations via matching triggers can be programmed to give practical support for user-defined theories. Care must be taken to avoid so-called matching loops, which may prevent termination of the solver. By design, such avoidance limits the extent to which the {SMT} solver is able to apply the …},
	author = {Amin, Nada and Leino, Rustan and Rompf, Tiark},
	urldate = {2019-01-31},
	date = {2016-12-28},
	langid = {american},
	file = {Full Text PDF:/Users/richardford/Zotero/storage/TD5DRRJV/Amin et al. - 2016 - Computing with an SMT Solver.pdf:application/pdf;Snapshot:/Users/richardford/Zotero/storage/PMXMDKIE/computing-smt-solver.html:text/html}
}

@article{hatcliff_behavioral_2012,
	title = {Behavioral Interface Specification Languages},
	volume = {44},
	issn = {0360-0300},
	url = {http://doi.acm.org/10.1145/2187671.2187678},
	doi = {10.1145/2187671.2187678},
	abstract = {Behavioral interface specification languages provide formal code-level annotations, such as preconditions, postconditions, invariants, and assertions that allow programmers to express the intended behavior of program modules. Such specifications are useful for precisely documenting program behavior, for guiding implementation, and for facilitating agreement between teams of programmers in modular development of software. When used in conjunction with automated analysis and program verification tools, such specifications can support detection of common code vulnerabilities, capture of light-weight application-specific semantic properties, generation of test cases and test oracles, and full formal program verification. This article surveys behavioral interface specification languages with a focus toward automatic program verification and with a view towards aiding the Verified Software Initiative—a fifteen-year, cooperative, international project directed at the scientific challenges of large-scale software verification.},
	pages = {16:1--16:58},
	number = {3},
	journaltitle = {{ACM} Comput. Surv.},
	author = {Hatcliff, John and Leavens, Gary T. and Leino, K. Rustan M. and Müller, Peter and Parkinson, Matthew},
	urldate = {2019-01-31},
	date = {2012-06},
	keywords = {separation logic, Abstraction, assertion, behavioral subtyping, frame conditions, interface specification language, invariant, {JML}, postcondition, precondition, {SPARK}, Spec\#},
	file = {ACM Full Text PDF:/Users/richardford/Zotero/storage/F4MQHIJH/Hatcliff et al. - 2012 - Behavioral Interface Specification Languages.pdf:application/pdf}
}

@article{leino_verification_2016,
	title = {Verification of Concurrent Programs with Chalice},
	url = {https://www.microsoft.com/en-us/research/publication/verification-concurrent-programs-chalice/},
	abstract = {A program verifier is a tool that allows developers to prove that their code satisfies its specification for every possible input and every thread schedule. These lecture notes describe a verifier for concurrent programs called Chalice. Chalice’s verification methodology centers around permissions and permission transfer. In particular, a memory location may be accessed by a …},
	author = {Leino, Rustan and Müller, Peter and Smans, Jan},
	urldate = {2019-01-31},
	date = {2016-12-29},
	langid = {american},
	file = {Full Text PDF:/Users/richardford/Zotero/storage/ZMNMZ55Z/Leino et al. - 2016 - Verification of Concurrent Programs with Chalice.pdf:application/pdf;Snapshot:/Users/richardford/Zotero/storage/C9ZBR9ZX/verification-concurrent-programs-chalice.html:text/html}
}

@article{leino_stepwise_2016,
	title = {Stepwise Refinement of Heap-Manipulating Code in Chalice},
	url = {https://www.microsoft.com/en-us/research/publication/stepwise-refinement-heap-manipulating-code-chalice/},
	abstract = {Stepwise refinement is a well-studied technique for developing a program from an abstract description to a concrete implementation. This paper describes a system with automated tool support for refinement, powered by a stateof-the-art verification engine that uses an {SMT} solver. Unlike previous refinement systems, users of the presented system interact only via declarations in the …},
	author = {Leino, Rustan and Yessenov, Kuat},
	urldate = {2019-01-31},
	date = {2016-12-29},
	langid = {american},
	file = {Full Text PDF:/Users/richardford/Zotero/storage/8RNI6Q8U/Leino and Yessenov - 2016 - Stepwise Refinement of Heap-Manipulating Code in C.pdf:application/pdf;Snapshot:/Users/richardford/Zotero/storage/6YWHWCEJ/stepwise-refinement-heap-manipulating-code-chalice.html:text/html}
}

@article{leino_fine-grained_2016,
	title = {Fine-grained Caching of Verification Results},
	volume = {9206},
	url = {https://www.microsoft.com/en-us/research/publication/fine-grained-caching-verification-results/},
	abstract = {Developing provably correct programs is an incremental process that often involves a series of interactions with a program verifier. To increase the responsiveness of the program verifier during such interactions, we designed a system for fine-grained caching of verification results. The caching system uses the program’s call graph and control-flow graph to focus the verification …},
	author = {Leino, Rustan and Wüstholz, Valentin},
	urldate = {2019-01-31},
	date = {2016-12-28},
	langid = {american},
	file = {Full Text PDF:/Users/richardford/Zotero/storage/4WMA66J9/Leino and Wüstholz - 2016 - Fine-grained Caching of Verification Results.pdf:application/pdf;Snapshot:/Users/richardford/Zotero/storage/DCH5FZKS/fine-grained-caching-verification-results.html:text/html}
}

@article{koenig_programming_2016,
	title = {Programming Language Features for Refinement},
	url = {https://www.microsoft.com/en-us/research/publication/programming-language-features-refinement/},
	abstract = {Algorithmic and data refinement are well studied topics that provide a mathematically rigorous approach to gradually introducing details in the implementation of software. Program refinements are performed in the context of some programming language, but mainstream languages lack features for recording the sequence of refinement steps in the program text. To experiment with the combination …},
	author = {Koenig, Jason and Leino, Rustan},
	urldate = {2019-01-31},
	date = {2016-12-28},
	langid = {american},
	file = {Full Text PDF:/Users/richardford/Zotero/storage/2F7P595B/Koenig and Leino - 2016 - Programming Language Features for Refinement.pdf:application/pdf;Snapshot:/Users/richardford/Zotero/storage/MF44ARJ2/programming-language-features-refinement.html:text/html}
}

@article{leino_compiling_2016,
	title = {Compiling Hilbert's epsilon Operator},
	volume = {35},
	url = {https://www.microsoft.com/en-us/research/publication/compiling-hilberts-%cf%b5-operator/},
	abstract = {Hilbert’s epsilon (ϵ) operator is a binder that picks an arbitrary element from a nonempty set. The operator is typically used in logics and proof engines. This paper contributes a discussion of considerations in supporting this operator in a programming language. More specifically, the paper presents the design choices made around supporting this operator in …},
	journaltitle = {{LPAR}-20. 20th International Conferences on Logic for Programming, Artificial Intelligence and Reasoning},
	author = {Leino, Rustan},
	urldate = {2019-01-31},
	date = {2016-12-28},
	langid = {american},
	file = {Full Text PDF:/Users/richardford/Zotero/storage/WIX4KMWE/Leino - 2016 - Compiling Hilbert's Ïµ Operator.pdf:application/pdf;Snapshot:/Users/richardford/Zotero/storage/NMJWCA8C/compiling-hilberts-ϵ-operator.html:text/html}
}

@article{parkinson_relationship_nodate,
	title = {The Relationship between Separation Logic and Implicit Dynamic Frames},
	volume = {6602},
	abstract = {Separation logic is a concise method for specifying programs that manipulate dynamically allocated storage. Partially inspired by separation logic, Implicit Dynamic Frames has recently been proposed, aiming at ﬁrst-order tool support. In this paper, we provide a total heap semantics for a standard separation logic, and prove it equivalent to the standard model. With small adaptations, we then show how to give a direct semantics to implicit dynamic frames and show this semantics correctly captures the existing deﬁnitions. This precisely connects the two logics. As a consequence of this connection, we show that a fragment of separation logic can be faithfully encoded in a ﬁrst-order automatic veriﬁcation tool (Chalice).},
	pages = {439--458},
	journaltitle = {{LNCS}},
	author = {Parkinson, Matthew J and Summers, Alexander J},
	langid = {english},
	note = {{ESOP} 2011},
	file = {Parkinson and Summers - The Relationship between Separation Logic and Impl.pdf:/Users/richardford/Zotero/storage/LMRQWFDB/Parkinson and Summers - The Relationship between Separation Logic and Impl.pdf:application/pdf}
}

@article{leino_verified_2016,
	title = {Verified Calculations},
	url = {https://www.microsoft.com/en-us/research/publication/verified-calculations/},
	abstract = {Calculational proofs—proofs by stepwise formula manipulation—are praised for their rigor, readability, and elegance. It seems desirable to reuse this style, often employed on paper, in the context of mechanized reasoning, and in particular, program verification. This work leverages the power of {SMT} solvers to machine-check calculational proofs at the level of detail they are usually …},
	author = {Leino, Rustan and Polikarpova, Nadia},
	urldate = {2019-01-31},
	date = {2016-12-28},
	langid = {american},
	file = {Full Text PDF:/Users/richardford/Zotero/storage/E2KFJ246/Leino and Polikarpova - 2016 - Verified Calculations.pdf:application/pdf;Snapshot:/Users/richardford/Zotero/storage/HHI48KJD/verified-calculations.html:text/html}
}

@article{leino_well-founded_2016,
	title = {Well-Founded Functions and Extreme Predicates in Dafny: A Tutorial},
	volume = {40},
	url = {https://www.microsoft.com/en-us/research/publication/well-founded-functions-extreme-predicates-dafny-tutorial/},
	shorttitle = {Well-Founded Functions and Extreme Predicates in Dafny},
	abstract = {A recursive function is well defined if its every recursive call corresponds a decrease in some well-founded order. Such well-founded functions are useful for example in computer programs when computing a value from some input. A boolean function can also be defined as an extreme solution to a recurrence relation, that is, as a least …},
	author = {Leino, Rustan},
	urldate = {2019-01-31},
	date = {2016-12-28},
	langid = {american},
	file = {Full Text PDF:/Users/richardford/Zotero/storage/55G4TL2T/Leino - 2016 - Well-Founded Functions and Extreme Predicates in D.pdf:application/pdf;Snapshot:/Users/richardford/Zotero/storage/L5BADAPF/well-founded-functions-extreme-predicates-dafny-tutorial.html:text/html}
}

@online{acm_acm_nodate,
	title = {{ACM} Classification Codes},
	url = {https://cran.r-project.org/web/classifications/ACM.html},
	author = {acm},
	urldate = {2019-02-01},
	file = {ACM Classification Codes:/Users/richardford/Zotero/storage/Q64UNUSQ/ACM.html:text/html}
}

@online{acm_msc2010_nodate,
	title = {{MSC}2010 database},
	url = {https://mathscinet.ams.org/msc/msc2010.html},
	author = {acm},
	urldate = {2019-02-01},
	file = {MSC2010 database:/Users/richardford/Zotero/storage/D2RWK6JM/msc2010.html:text/html}
}

@online{sozeau_typed_nodate,
	title = {Typed Template Coq - {POPL} 2018},
	url = {https://popl18.sigplan.org/event/coqpl-2018-typed-template-coq},
	author = {Sozeau, Matthieu},
	urldate = {2019-02-01},
	file = {Typed Template Coq - POPL 2018:/Users/richardford/Zotero/storage/YNUW6KVH/coqpl-2018-typed-template-coq.html:text/html}
}

@article{anand_typed_nodate,
	title = {Typed Template Coq},
	abstract = {Template-Coq1 is a plugin for Coq, originally implemented by Malecha [7], which provides a reifier for Coq terms and global declarations, as represented in the Coq kernel, as well as a denotation command. Initially, it was developed for the purpose of writing functions on Coq’s {AST} in Gallina. Recently, its use was extended for the needs of the {CertiCoq} certified compiler project [2], which uses it as its front-end language and to derive parametricity properties [1], and the work of [5] on extracting Coq terms to a {CBV} λ-calculus. However, the syntax currently lacks semantics, be it typing semantics or operational semantics, which should reflect, as formal specifications in Coq, the semantics of Coq itself. This is an issue for {CertiCoq} where both a non-deterministic small step semantics and a deterministic call-by-value big step semantics had to be defined and preserved, without an “official” reference specification to refer to. Our hope with this work is to remedy this situation and provide a formal semantics of Coq’s implemented type theory, that can independently be refined and studied. By implementing a (partial) independent checker in Coq, we can also help formalize certified translations from Coq to Coq (Section 3).},
	pages = {2},
	author = {Anand, Abhishek and Tabareau, Simon Boulier Nicolas and Sozeau, Matthieu},
	langid = {english},
	file = {Anand et al. - Typed Template Coq.pdf:/Users/richardford/Zotero/storage/3GZEWLIT/Anand et al. - Typed Template Coq.pdf:application/pdf}
}

@article{sozeau_typed_nodate-1,
	title = {Typed Template Coq - Slides},
	pages = {11},
	author = {Sozeau, Matthieu},
	langid = {english},
	file = {Typed Template Coq.pdf:/Users/richardford/Zotero/storage/4PGZZ48U/Typed Template Coq.pdf:application/pdf}
}

@online{appel_certicoq:_nodate,
	title = {{CertiCoq}: A verified compiler for Coq - {POPL} 2017},
	url = {https://popl17.sigplan.org/event/main-certicoq-a-verified-compiler-for-coq},
	author = {Appel, Andrew W.},
	urldate = {2019-02-01},
	file = {CertiCoq A verified compiler for Coq - POPL 2017.pdf:/Users/richardford/Zotero/storage/FPWSH4GR/CertiCoq A verified compiler for Coq - POPL 2017.pdf:application/pdf;CertiCoq\: A verified compiler for Coq - POPL 2017:/Users/richardford/Zotero/storage/E3YEVA9B/main-certicoq-a-verified-compiler-for-coq.html:text/html}
}

@online{adewale_implementing_nodate,
	title = {Implementing a high-performance key-value store using a trie of B+-Trees with cursors {\textbar} Computer Science Department at Princeton University},
	url = {https://www.cs.princeton.edu/research/techreps/TR-004-18},
	abstract = {Abstract
In this paper, we discuss the implementation of a serial main-memory key-value store based on Masstree[6]. Similar to Masstree, the key-value store is implemented as a trie-like tree of B+-Trees, where each B+-Tree is responsible for a xed-length slice of a variable-length key. However, one of the major dierences between our key-value store and Masstree is that our B+-tree implementation (a component of the key-value store) takes linear time to insert a set of sorted records. This is compared to a traditional B+-tree implementation that would take linearithmic time. Moreover, partially sorting a sequence of operation leads to substantial performance gains. This is made possible using a data structure for navigating B+-trees called a B+-tree cursor. As our next operation is amortized constant time, our B+-tree does not need to maintain cross links between leaf nodes. We also briefy show that this same data structure can be extended to the trie of B+-Trees to ensure amortized linear time for bulk insertion of key-value pairs in the key-value store. We were inspired with this idea of B+-Tree cursors from the {SQLite} [5] B-tree source code.},
	author = {Adewale, Oluwatosin},
	urldate = {2019-02-01},
	file = {Implementing a high-performance key-value store us.pdf:/Users/richardford/Zotero/storage/HAARNTAN/Implementing a high-performance key-value store us.pdf:application/pdf;Implementing a high-performance key-value store using a trie of B+-Trees with cursors | Computer Science Department at Princeton University:/Users/richardford/Zotero/storage/ZNDWIDJ3/TR-004-18.html:text/html}
}

@article{barriere_vst_nodate,
	title = {{VST} Veriﬁcation of B+Trees with Cursors},
	abstract = {The {DeepSpecDB} project aims to deﬁne, specify and verify a high-performance concurrent in-memory database system. Based on {MassTree}, it uses B+Trees, a well-studied key-value data structure. Our sequential B+Trees library uses cursors, introduced in the database engine {SQLite}. Such cursors reduce the complexity of operations when dealing with partially sorted data. We deﬁne a Coq formal model for such trees, then use it to specify and prove the correctness of the C implementation using the Veriﬁed Software Toolchain.},
	pages = {19},
	author = {Barriere, Aurele and Appel, Andrew},
	langid = {english},
	file = {Barriere and Appel - VST Veriﬁcation of B+Trees with Cursors.pdf:/Users/richardford/Zotero/storage/8NTCGXZV/Barriere and Appel - VST Veriﬁcation of B+Trees with Cursors.pdf:application/pdf}
}

@software{appel_deepspecdb_2019,
	title = {{DeepSpecDB} - github},
	rights = {View license},
	url = {https://github.com/PrincetonUniversity/DeepSpecDB},
	publisher = {{PrincetonUniversity}},
	author = {Appel, Andrew W.},
	urldate = {2019-02-01},
	date = {2019-01-31},
	note = {original-date: 2017-11-30T14:24:30Z}
}

@article{chen_project_nodate,
	title = {Project Report on {DeepSpecDB}},
	abstract = {Recent years have witnessed a rapid development of mainmemory database systems thanks to the growingly aﬀordable memory. {DeepSpecDB} is another main-memory database management system implemented in C with deep speciﬁcation and end-to-end veriﬁcation guaranteeing the correctness of the system.},
	pages = {35},
	author = {Chen, Yixuan},
	langid = {english},
	file = {Chen - Project Report on DeepSpecDB.pdf:/Users/richardford/Zotero/storage/HNLI2SEC/Chen - Project Report on DeepSpecDB.pdf:application/pdf}
}

@inproceedings{sozeau_equations:_2010,
	title = {Equations: A Dependent Pattern-Matching Compiler},
	isbn = {978-3-642-14052-5},
	series = {Lecture Notes in Computer Science},
	shorttitle = {Equations},
	abstract = {We present a compiler for definitions made by pattern matching on inductive families in the Coq system. It allows to write structured, recursive dependently-typed functions as a set of equations, automatically find their realization in the core type theory and generate proofs to ease reasoning on them. It provides a complete package to define and reason on functions in the proof assistant, substantially reducing the boilerplate code and proofs one usually has to write, also hiding the intricacies related to the use of dependent types and complex recursion schemes.},
	pages = {419--434},
	booktitle = {Interactive Theorem Proving},
	publisher = {Springer Berlin Heidelberg},
	author = {Sozeau, Matthieu},
	editor = {Kaufmann, Matt and Paulson, Lawrence C.},
	date = {2010},
	langid = {english},
	keywords = {Type Theory, Proof Assistant, Recursive Call, Split Node, User Node},
	file = {equations.pdf:/Users/richardford/Zotero/storage/FLLAR78Y/equations.pdf:application/pdf;Sozeau - 2010 - Equations A Dependent Pattern-Matching Compiler.pdf:/Users/richardford/Zotero/storage/FSGZK8IK/Sozeau - 2010 - Equations A Dependent Pattern-Matching Compiler.pdf:application/pdf}
}

@inproceedings{delaware_fiat:_2015,
	location = {New York, {NY}, {USA}},
	title = {Fiat: Deductive Synthesis of Abstract Data Types in a Proof Assistant},
	isbn = {978-1-4503-3300-9},
	url = {http://doi.acm.org/10.1145/2676726.2677006},
	doi = {10.1145/2676726.2677006},
	series = {{POPL} '15},
	shorttitle = {Fiat},
	abstract = {We present Fiat, a library for the Coq proof assistant supporting refinement of declarative specifications into efficient functional programs with a high degree of automation. Each refinement process leaves a proof trail, checkable by the normal Coq kernel, justifying its soundness. We focus on the synthesis of abstract data types that package methods with private data. We demonstrate the utility of our framework by applying it to the synthesis of query structures -- abstract data types with {SQL}-like query and insert operations. Fiat includes a library for writing specifications of query structures in {SQL}-inspired notation, expressing operations over relations (tables) in terms of mathematical sets. This library includes a suite of tactics for automating the refinement of specifications into efficient, correct-by-construction {OCaml} code. Using these tactics, a programmer can generate such an implementation completely automatically by only specifying the equivalent of {SQL} indexes, data structures capturing useful views of the abstract data. Throughout we speculate on the new programming modularity possibilities enabled by an automated refinement system with proved-correct rules.},
	pages = {689--700},
	booktitle = {Proceedings of the 42Nd Annual {ACM} {SIGPLAN}-{SIGACT} Symposium on Principles of Programming Languages},
	publisher = {{ACM}},
	author = {Delaware, Benjamin and Pit-Claudel, Clément and Gross, Jason and Chlipala, Adam},
	urldate = {2019-02-01},
	date = {2015},
	keywords = {deductive synthesis, mechanized derivation of abstract data types},
	file = {ACM Full Text PDF:/Users/richardford/Zotero/storage/N7HNG7DV/Delaware et al. - 2015 - Fiat Deductive Synthesis of Abstract Data Types i.pdf:application/pdf}
}

@online{chlipala_end_nodate,
	title = {{THE} {END} {OF} {HISTORY}? {USING} A {PROOF} {ASSISTANT} {TO} {REPLACE} {LANGUAGE} {DESIGN} {WITH} {LIBRARY} {DESIGN}},
	url = {https://snapl.org/2017/abstracts/Chlipala.html},
	abstract = {Functionality of software systems has exploded in part because of advances in programming-language support for packaging reusable functionality as libraries. Developers benefit from the uniformity that comes of exposing many interfaces in the same language, as opposed to stringing together hodgepodges of command-line tools. Domain-specific languages may be viewed as an evolution of the power of reusable interfaces, when those interfaces become so flexible as to deserve to be called programming languages. However, common approaches to domain-specific languages give up many of the hard-won advantages of library-building in a rich common language, and even the traditional approach poses significant challenges in learning new {APIs}. We suggest that instead of continuing to develop new domain-specific languages, our community should embrace library-based ecosystems within very expressive languages that mix programming and theorem proving. Our prototype framework Fiat, a library for the Coq proof assistant, turns languages into easily comprehensible libraries via the key idea of modularizing functionality and performance away from each other, the former via macros that desugar into higher-order logic and the latter via optimization scripts that derive efficient code from logical programs.},
	author = {Chlipala, Adam and Delaware, Benjamin and Duchovni, Samuel and Gross, Jason and Pit-Claudel, Clément and Suriyakarn, Sorawit and Wang, Peng and ye, Katherine},
	urldate = {2019-02-01},
	file = {SNAPL 2017:/Users/richardford/Zotero/storage/2SE673GH/Chlipala.html:text/html;SNAPL 2017.pdf:/Users/richardford/Zotero/storage/M7L2Z5GW/SNAPL 2017.pdf:application/pdf}
}

@article{gonthier_formal_2008,
	title = {Formal Proof—The Four- Color Theorem},
	volume = {55},
	pages = {12},
	number = {11},
	author = {Gonthier, Georges},
	date = {2008},
	langid = {english},
	file = {Gonthier - 2008 - Formal Proof—The Four- Color Theorem.pdf:/Users/richardford/Zotero/storage/2DIXM75Q/Gonthier - 2008 - Formal Proof—The Four- Color Theorem.pdf:application/pdf}
}

@article{wiedijk_formal_2008,
	title = {Formal Proof—Getting Started},
	volume = {55},
	pages = {7},
	number = {11},
	author = {Wiedijk, Freek},
	date = {2008},
	langid = {english},
	file = {Wiedijk - 2008 - Formal Proof—Getting Started.pdf:/Users/richardford/Zotero/storage/J3KGYSKG/Wiedijk - 2008 - Formal Proof—Getting Started.pdf:application/pdf}
}

@article{harrison_formal_2008,
	title = {Formal Proof—Theory and Practice},
	volume = {55},
	pages = {12},
	number = {11},
	author = {Harrison, John},
	date = {2008},
	langid = {english},
	file = {Harrison - 2008 - Formal Proof—Theory and Practice.pdf:/Users/richardford/Zotero/storage/AUC8R3WS/Harrison - 2008 - Formal Proof—Theory and Practice.pdf:application/pdf}
}

@inproceedings{petcher_foundational_2015,
	title = {The Foundational Cryptography Framework},
	isbn = {978-3-662-46666-7},
	url = {http://www.cs.cornell.edu/~jgm/papers/FCF.pdf},
	series = {Lecture Notes in Computer Science},
	abstract = {We present the Foundational Cryptography Framework ({FCF}) for developing and checking complete proofs of security for cryptographic schemes within a proof assistant. This is a general-purpose framework that is capable of modeling and reasoning about a wide range of cryptographic schemes, security definitions, and assumptions. Security is proven in the computational model, and the proof provides concrete bounds as well as asymptotic conclusions. {FCF} provides a language for probabilistic programs, a theory that is used to reason about programs, and a library of tactics and definitions that are useful in proofs about cryptography. The framework is designed to leverage fully the existing theory and capabilities of the Coq proof assistant in order to reduce the effort required to develop proofs.},
	pages = {53--72},
	booktitle = {Principles of Security and Trust},
	publisher = {Springer Berlin Heidelberg},
	author = {Petcher, Adam and Morrisett, Greg},
	editor = {Focardi, Riccardo and Myers, Andrew},
	date = {2015},
	langid = {english},
	keywords = {Cryptography, Coq, Proof Assistant, Protocol Verification},
	file = {Petcher and Morrisett - 2015 - The Foundational Cryptography Framework.pdf:/Users/richardford/Zotero/storage/8JFX6AUD/Petcher and Morrisett - 2015 - The Foundational Cryptography Framework.pdf:application/pdf}
}

@article{fisher_kathleen_hacms_2017,
	title = {The {HACMS} program: using formal methods to eliminate exploitable bugs},
	volume = {375},
	url = {https://royalsocietypublishing.org/doi/10.1098/rsta.2015.0401},
	doi = {10.1098/rsta.2015.0401},
	shorttitle = {The {HACMS} program},
	abstract = {For decades, formal methods have offered the promise of verified software that does not have exploitable bugs. Until recently, however, it has not been possible to verify software of sufficient complexity to be useful. Recently, that situation has changed. {SeL}4 is an open-source operating system microkernel efficient enough to be used in a wide range of practical applications. Its designers proved it to be fully functionally correct, ensuring the absence of buffer overflows, null pointer exceptions, use-after-free errors, etc., and guaranteeing integrity and confidentiality. The {CompCert} Verifying C Compiler maps source C programs to provably equivalent assembly language, ensuring the absence of exploitable bugs in the compiler. A number of factors have enabled this revolution, including faster processors, increased automation, more extensive infrastructure, specialized logics and the decision to co-develop code and correctness proofs rather than verify existing artefacts. In this paper, we explore the promise and limitations of current formal-methods techniques. We discuss these issues in the context of {DARPA}’s {HACMS} program, which had as its goal the creation of high-assurance software for vehicles, including quadcopters, helicopters and automobiles.This article is part of the themed issue ‘Verified trustworthy software systems’.},
	pages = {20150401},
	number = {2104},
	journaltitle = {Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences},
	author = {{Fisher Kathleen} and {Launchbury John} and {Richards Raymond}},
	urldate = {2019-02-01},
	date = {2017-10-13},
	file = {Full Text PDF:/Users/richardford/Zotero/storage/P6Z2SRJK/Fisher Kathleen et al. - 2017 - The HACMS program using formal methods to elimina.pdf:application/pdf;Snapshot:/Users/richardford/Zotero/storage/Z7N5TJNE/rsta.2015.html:text/html}
}

@online{royalsociety_philosophical_nodate,
	title = {Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences},
	url = {https://royalsocietypublishing.org/journal/rsta},
	author = {royalsociety},
	urldate = {2019-02-01},
	file = {Home | Philosophical Transactions of the Royal Society A\: Mathematical, Physical and Engineering Sciences:/Users/richardford/Zotero/storage/UL78NAHS/rsta.html:text/html}
}

@online{royalsociety_proceedings_nodate,
	title = {Proceedings of the Royal Society A: Mathematical, Physical and Engineering Sciences},
	url = {https://royalsocietypublishing.org/journal/rspa},
	author = {royalsociety},
	urldate = {2019-02-01},
	file = {Home | Proceedings of the Royal Society A\: Mathematical, Physical and Engineering Sciences:/Users/richardford/Zotero/storage/M8HSK2QL/rspa.html:text/html}
}

@article{choi_kami:_2017,
	title = {Kami: A Platform for High-level Parametric Hardware Specification and Its Modular Verification},
	volume = {1},
	issn = {2475-1421},
	url = {http://doi.acm.org/10.1145/3110268},
	doi = {10.1145/3110268},
	shorttitle = {Kami},
	abstract = {It has become fairly standard in the programming-languages research world to verify functional programs in proof assistants using induction, algebraic simplification, and rewriting. In this paper, we introduce Kami, a Coq library that enables similar expressive and modular reasoning for hardware designs expressed in the style of the Bluespec language. We can specify, implement, and verify realistic designs entirely within Coq, ending with automatic extraction into a pipeline that bottoms out in {FPGAs}. Our methodology, using labeled transition systems, has been evaluated in a case study verifying an infinite family of multicore systems, with cache-coherent shared memory and pipelined cores implementing (the base integer subset of) the {RISC}-V instruction set.},
	pages = {24:1--24:30},
	issue = {{ICFP}},
	journaltitle = {Proc. {ACM} Program. Lang.},
	author = {Choi, Joonwon and Vijayaraghavan, Muralidaran and Sherman, Benjamin and Chlipala, Adam and {Arvind}},
	urldate = {2019-02-01},
	date = {2017-08},
	keywords = {formal verification, hardware, proof assistants},
	file = {ACM Full Text PDF:/Users/richardford/Zotero/storage/MC26D45K/Choi et al. - 2017 - Kami A Platform for High-level Parametric Hardwar.pdf:application/pdf}
}

@article{delaware_narcissus:_2018,
	title = {Narcissus: Deriving Correct-By-Construction Decoders and Encoders from Binary Formats},
	url = {https://arxiv.org/abs/1803.04870v2},
	shorttitle = {Narcissus},
	abstract = {It is a neat result from functional programming that libraries of parser
combinators can support rapid construction of decoders for quite a range of
formats. With a little more work, the same combinator program can denote both a
decoder and an encoder. Unfortunately, the real world is full of gnarly
formats, as with the packet formats that make up the standard Internet protocol
stack. Most past parser-combinator approaches cannot handle these formats, and
the few exceptions require redundancy -- one part of the natural grammar needs
to be hand-translated into hints in multiple parts of a parser program. We show
how to recover very natural and nonredundant format specifications, covering
all popular network packet formats and generating both decoders and encoders
automatically. The catch is that we use the Coq proof assistant to derive both
kinds of artifacts using tactics, automatically, in a way that guarantees that
they form inverses of each other. We used our approach to reimplement packet
processing for a full Internet protocol stack, inserting our replacement into
the {OCaml}-based {MirageOS} unikernel, resulting in minimal performance
degradation.},
	author = {Delaware, Benjamin and Suriyakarn, Sorawit and Pit--Claudel, Clément and Ye, Qianchuan and Chlipala, Adam},
	urldate = {2019-02-01},
	date = {2018-03-13},
	langid = {english},
	file = {Full Text PDF:/Users/richardford/Zotero/storage/HPDJVDBJ/Delaware et al. - 2018 - Narcissus Deriving Correct-By-Construction Decode.pdf:application/pdf;Snapshot:/Users/richardford/Zotero/storage/JEN8SSZV/1803.html:text/html}
}

@article{klein_gerwin_provably_2017,
	title = {Provably trustworthy systems},
	volume = {375},
	url = {https://royalsocietypublishing.org/doi/10.1098/rsta.2015.0404},
	doi = {10.1098/rsta.2015.0404},
	abstract = {We present recent work on building and scaling trustworthy systems with formal, machine-checkable proof from the ground up, including the operating system kernel, at the level of binary machine code. We first give a brief overview of the {seL}4 microkernel verification and how it can be used to build verified systems. We then show two complementary techniques for scaling these methods to larger systems: proof engineering, to estimate verification effort; and code/proof co-generation, for scalable development of provably trustworthy applications.This article is part of the themed issue ‘Verified trustworthy software systems’.},
	pages = {20150404},
	number = {2104},
	journaltitle = {Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences},
	author = {{Klein Gerwin} and {Andronick June} and {Keller Gabriele} and {Matichuk Daniel} and {Murray Toby} and {O'Connor Liam}},
	urldate = {2019-02-01},
	date = {2017-10-13},
	file = {Full Text PDF:/Users/richardford/Zotero/storage/5NUUJ5IV/Klein Gerwin et al. - 2017 - Provably trustworthy systems.pdf:application/pdf;Snapshot:/Users/richardford/Zotero/storage/XR76Z7EA/rsta.2015.html:text/html}
}

@article{batty_mark_compositional_2017,
	title = {Compositional relaxed concurrency},
	volume = {375},
	url = {https://royalsocietypublishing.org/doi/10.1098/rsta.2015.0406},
	doi = {10.1098/rsta.2015.0406},
	abstract = {There is a broad design space for concurrent computer processors: they can be optimized for low power, low latency or high throughput. This freedom to tune each processor design to its niche has led to an increasing diversity of machines, from powerful pocketable devices to those responsible for complex and critical tasks, such as car guidance systems. Given this context, academic concurrency research sounds notes of both caution and optimism. Caution because recent work has uncovered flaws in the way we explain the subtle memory behaviour of concurrent systems: specifications have been shown to be incorrect, leading to bugs throughout the many layers of the system. And optimism because our tools and methods for verifying the correctness of concurrent code—although built above an idealized model of concurrency—are becoming more mature. This paper looks at the way we specify the memory behaviour of concurrent systems and suggests a new direction. Currently, there is a siloed approach, with each processor and programming language specified separately in an incomparable way. But this does not match the structure of our programs, which may use multiple processors and languages together. Instead we propose a compositional approach, where program components carry with them a description of the sort of concurrency they rely on, and there is a mechanism for composing these. This will support not only components written for the multiple varied processors found in a modern system but also those that use idealized models of concurrency, providing a sound footing for mature verification techniques.This article is part of the themed issue ‘Verified trustworthy software systems’.},
	pages = {20150406},
	number = {2104},
	journaltitle = {Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences},
	author = {{Batty Mark}},
	urldate = {2019-02-01},
	date = {2017-10-13},
	file = {Full Text PDF:/Users/richardford/Zotero/storage/F3KZSHAP/Batty Mark - 2017 - Compositional relaxed concurrency.pdf:application/pdf;Snapshot:/Users/richardford/Zotero/storage/2VP9GJZV/rsta.2015.html:text/html}
}

@article{appel_andrew_w._position_2017,
	title = {Position paper: the science of deep specification},
	volume = {375},
	url = {https://royalsocietypublishing.org/doi/10.1098/rsta.2016.0331},
	doi = {10.1098/rsta.2016.0331},
	shorttitle = {Position paper},
	abstract = {We introduce our efforts within the project ‘The science of deep specification’ to work out the key formal underpinnings of industrial-scale formal specifications of software and hardware components, anticipating a world where large verified systems are routinely built out of smaller verified components that are also used by many other projects. We identify an important class of specification that has already been used in a few experiments that connect strong component-correctness theorems across the work of different teams. To help popularize the unique advantages of that style, we dub it deep specification, and we say that it encompasses specifications that are rich, two-sided, formal and live (terms that we define in the article). Our core team is developing a proof-of-concept system (based on the Coq proof assistant) whose specification and verification work is divided across largely decoupled subteams at our four institutions, encompassing hardware microarchitecture, compilers, operating systems and applications, along with cross-cutting principles and tools for effective specification. We also aim to catalyse interest in the approach, not just by basic researchers but also by users in industry.This article is part of the themed issue ‘Verified trustworthy software systems’.},
	pages = {20160331},
	number = {2104},
	journaltitle = {Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences},
	author = {{Appel Andrew W.} and {Beringer Lennart} and {Chlipala Adam} and {Pierce Benjamin C.} and {Shao Zhong} and {Weirich Stephanie} and {Zdancewic Steve}},
	urldate = {2019-02-01},
	date = {2017-10-13},
	file = {Full Text PDF:/Users/richardford/Zotero/storage/6IKBBI2V/Appel Andrew W. et al. - 2017 - Position paper the science of deep specification.pdf:application/pdf;Snapshot:/Users/richardford/Zotero/storage/492EXHEP/rsta.2016.html:text/html}
}

@article{david_cristina_program_2017,
	title = {Program synthesis: challenges and opportunities},
	volume = {375},
	url = {https://royalsocietypublishing.org/doi/10.1098/rsta.2015.0403},
	doi = {10.1098/rsta.2015.0403},
	shorttitle = {Program synthesis},
	abstract = {Program synthesis is the mechanized construction of software, dubbed ‘self-writing code’. Synthesis tools relieve the programmer from thinking about how the problem is to be solved; instead, the programmer only provides a description of what is to be achieved. Given a specification of what the program should do, the synthesizer generates an implementation that provably satisfies this specification. From a logical point of view, a program synthesizer is a solver for second-order existential logic. Owing to the expressiveness of second-order logic, program synthesis has an extremely broad range of applications. We survey some of these applications as well as recent trends in the algorithms that solve the program synthesis problem. In particular, we focus on an approach that has raised the profile of program synthesis and ushered in a generation of new synthesis tools, namely counter-example-guided inductive synthesis ({CEGIS}). We provide a description of the {CEGIS} architecture, followed by recent algorithmic improvements. We conjecture that the capacity of program synthesis engines will see further step change, in a manner that is transparent to the applications, which will open up an even broader range of use-cases.This article is part of the themed issue ‘Verified trustworthy software systems’.},
	pages = {20150403},
	number = {2104},
	journaltitle = {Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences},
	author = {{David Cristina} and {Kroening Daniel}},
	urldate = {2019-02-01},
	date = {2017-10-13},
	file = {Full Text PDF:/Users/richardford/Zotero/storage/N5ZN828M/David Cristina and Kroening Daniel - 2017 - Program synthesis challenges and opportunities.pdf:application/pdf;Snapshot:/Users/richardford/Zotero/storage/IULWXC2L/rsta.2015.html:text/html}
}

@article{white_neil_formal_2017,
	title = {Formal verification: will the seedling ever flower?},
	volume = {375},
	url = {https://royalsocietypublishing.org/doi/10.1098/rsta.2015.0402},
	doi = {10.1098/rsta.2015.0402},
	shorttitle = {Formal verification},
	abstract = {In one sense, formal specification and verification have been highly successful: techniques have been developed in pioneering academic research, transferred to software companies through training and partnerships, and successfully deployed in systems with national significance. Altran {UK} has been in the vanguard of this movement. This paper summarizes some of our key deployments of formal techniques over the past 20 years, including both security- and safety-critical systems. The impact of formal techniques, however, remains within an industrial niche, and while government and suppliers across industry search for solutions to the problems of poor-quality software, the wider software industry remains resistant to adoption of this proven solution. We conclude by reflecting on some of the challenges we face as a community in ensuring that formal techniques achieve their true potential impact on society.This article is part of the themed issue ‘Verified trustworthy software systems’.},
	pages = {20150402},
	number = {2104},
	journaltitle = {Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences},
	author = {{White Neil} and {Matthews Stuart} and {Chapman Roderick}},
	urldate = {2019-02-01},
	date = {2017-10-13},
	file = {Full Text PDF:/Users/richardford/Zotero/storage/CPL6R6HS/White Neil et al. - 2017 - Formal verification will the seedling ever flower.pdf:application/pdf;Snapshot:/Users/richardford/Zotero/storage/SZBRJG4C/rsta.2015.html:text/html}
}

@article{hunt_warren_a._industrial_2017,
	title = {Industrial hardware and software verification with {ACL}2},
	volume = {375},
	url = {https://royalsocietypublishing.org/doi/10.1098/rsta.2015.0399},
	doi = {10.1098/rsta.2015.0399},
	abstract = {The {ACL}2 theorem prover has seen sustained industrial use since the mid-1990s. Companies that have used {ACL}2 regularly include {AMD}, Centaur Technology, {IBM}, Intel, Kestrel Institute, Motorola/Freescale, Oracle and Rockwell Collins. This paper introduces {ACL}2 and focuses on how and why {ACL}2 is used in industry. {ACL}2 is well-suited to its industrial application to numerous software and hardware systems, because it is an integrated programming/proof environment supporting a subset of the {ANSI} standard Common Lisp programming language. As a programming language {ACL}2 permits the coding of efficient and robust programs; as a prover {ACL}2 can be fully automatic but provides many features permitting domain-specific human-supplied guidance at various levels of abstraction. {ACL}2 specifications and models often serve as efficient execution engines for the modelled artefacts while permitting formal analysis and proof of properties. Crucially, {ACL}2 also provides support for the development and verification of other formal analysis tools. However, {ACL}2 did not find its way into industrial use merely because of its technical features. The core {ACL}2 user/development community has a shared vision of making mechanized verification routine when appropriate and has been committed to this vision for the quarter century since the Computational Logic, Inc., Verified Stack. The community has focused on demonstrating the viability of the tool by taking on industrial projects (often at the expense of not being able to publish much).This article is part of the themed issue ‘Verified trustworthy software systems’.},
	pages = {20150399},
	number = {2104},
	journaltitle = {Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences},
	author = {{Hunt Warren A.} and {Kaufmann Matt} and {Moore J Strother} and {Slobodova Anna}},
	urldate = {2019-02-01},
	date = {2017-10-13},
	file = {Full Text PDF:/Users/richardford/Zotero/storage/FB2ESHYL/Hunt Warren A. et al. - 2017 - Industrial hardware and software verification with.pdf:application/pdf;Snapshot:/Users/richardford/Zotero/storage/VVZ2CQLI/rsta.2015.html:text/html}
}

@inproceedings{ekici_smtcoq:_2017,
	title = {{SMTCoq}: A Plug-In for Integrating {SMT} Solvers into Coq},
	isbn = {978-3-319-63390-9},
	series = {Lecture Notes in Computer Science},
	shorttitle = {{SMTCoq}},
	abstract = {This paper describes {SMTCoq}, a plug-in for the integration of external solvers into the Coq proof assistant. Based on a checker for generic first-order proof certificates fully implemented and proved correct in Coq, {SMTCoq} offers facilities to check answers from external {SAT} and {SMT} solvers and to increase Coq’s automation using such solvers, all in a safe way. The current version supports proof certificates produced by the {SAT} solver {ZChaff}, for propositional logic, and the {SMT} solvers {veriT} and {CVC}4, for the quantifier-free fragment of the combined theory of fixed-size bit vectors, functional arrays with extensionality, linear integer arithmetic, and uninterpreted function symbols.},
	pages = {126--133},
	booktitle = {Computer Aided Verification},
	publisher = {Springer International Publishing},
	author = {Ekici, Burak and Mebsout, Alain and Tinelli, Cesare and Keller, Chantal and Katz, Guy and Reynolds, Andrew and Barrett, Clark},
	editor = {Majumdar, Rupak and Kunčak, Viktor},
	date = {2017},
	langid = {english},
	file = {Ekici et al. - 2017 - SMTCoq A Plug-In for Integrating SMT Solvers into.pdf:/Users/richardford/Zotero/storage/HR5VZETR/Ekici et al. - 2017 - SMTCoq A Plug-In for Integrating SMT Solvers into.pdf:application/pdf}
}

@online{anand_towards_nodate,
	title = {Towards Certified Meta-Programming with Typed Template-Coq {\textbar} {SpringerLink}},
	url = {https://link.springer.com/chapter/10.1007%2F978-3-319-94821-8_2},
	abstract = {Template-Coq (https://template-coq.github.io/template-coq) is a plugin for Coq, originally implemented by Malecha [18], which provides a reifier for Coq terms and global declarations, as represented in the Coq kernel, as well as a denotation command. Initially, it was developed for the purpose of writing functions on Coq’s {AST} in Gallina. Recently, it was used in the {CertiCoq} certified compiler project [4], as its front-end language, to derive parametricity properties [3], and to extract Coq terms to a {CBV}   𝜆 -calculus [13]. However, the syntax lacked semantics, be it typing semantics or operational semantics, which should reflect, as formal specifications in Coq, the semantics of Coq’s type theory itself. The tool was also rather bare bones, providing only rudimentary quoting and unquoting commands. We generalize it to handle the entire Calculus of Inductive Constructions ({CIC}), as implemented by Coq, including the kernel’s declaration structures for definitions and inductives, and implement a monad for general manipulation of Coq’s logical environment. We demonstrate how this setup allows Coq users to define many kinds of general purpose plugins, whose correctness can be readily proved in the system itself, and that can be run efficiently after extraction. We give a few examples of implemented plugins, including a parametricity translation. We also advocate the use of Template-Coq as a foundation for higher-level tools.},
	author = {Anand, Abhishek and Boulier, Simon and Cohen, Cyril and Sozeau, Matthieu and Tabareau, Nicolas},
	urldate = {2019-02-01},
	file = {Towards Certified Meta-Programming with Typed T em.pdf:/Users/richardford/Zotero/storage/2SRA4KVS/Towards Certified Meta-Programming with Typed T em.pdf:application/pdf;Towards Certified Meta-Programming with Typed T emplate-C oq | SpringerLink:/Users/richardford/Zotero/storage/8VTIEBSI/10.html:text/html}
}

@software{malecha_reflection_2018,
	title = {Reflection library for Coq. Contribute to gmalecha/template-coq development by creating an account on {GitHub}},
	rights = {{MIT}},
	url = {https://github.com/gmalecha/template-coq},
	author = {Malecha, Gregory},
	urldate = {2019-02-01},
	date = {2018-03-02},
	note = {original-date: 2014-07-09T20:13:52Z}
}

@software{sozeau_metacoq_2019,
	title = {{MetaCoq} - Metaprogramming in Coq (Was template-coq)},
	rights = {{MIT}},
	url = {https://github.com/MetaCoq/metacoq},
	publisher = {{MetaCoq}},
	author = {Sozeau, Matthieu},
	urldate = {2019-02-01},
	date = {2019-01-22},
	note = {original-date: 2017-10-19T11:10:54Z}
}

@book{parigot_logic_2000,
	location = {Berlin, Heidelberg},
	title = {Logic for Programming and Automated Reasoning: 7th International Conference, {LPAR} 2000 Reunion Island, France, November 6-10, 2000 Proceedings},
	isbn = {978-3-540-41285-4 978-3-540-44404-6},
	shorttitle = {Logic for Programming and Automated Reasoning},
	abstract = {This book constitutes the refereed proceedings of the 7th International Conference on Logic for Programming and Automated Reasoning, {LPAR} 2000, held in Reunion Island, France in November 2000. The 26 revised full papers presented together with four invited contributions were carefully reviewed and selected from 65 submissions. The papers are organized in topical sections on nonmonotonic reasoning, descriptive complexity, specification and automatic proof-assistants, theorem proving, verification, logic programming and constraint logic programming, nonclassical logics and the lambda calculus, logic and databases, program analysis, mu-calculus, planning and reasoning about actions.},
	publisher = {Springer Berlin Heidelberg},
	author = {Parigot, Michel and Voronkov, Andrei},
	date = {2000},
	note = {{OCLC}: 851805469}
}

@incollection{parigot_tactic_2000,
	location = {Berlin, Heidelberg},
	title = {A Tactic Language for the System Coq},
	volume = {1955},
	isbn = {978-3-540-41285-4},
	url = {http://link.springer.com/10.1007/3-540-44404-1_7},
	pages = {85--95},
	booktitle = {Logic for Programming and Automated Reasoning},
	publisher = {Springer Berlin Heidelberg},
	author = {Delahaye, David},
	editor = {Parigot, Michel and Voronkov, Andrei},
	urldate = {2019-02-01},
	date = {2000},
	langid = {english},
	doi = {10.1007/3-540-44404-1_7},
	file = {Submitted Version:/Users/richardford/Zotero/storage/7N982YMB/Delahaye - 2000 - A Tactic Language for the System Coq.pdf:application/pdf}
}

@book{bate_fundamentals_1971,
	location = {New York},
	title = {Fundamentals of astrodynamics},
	isbn = {978-0-486-60061-1},
	pagetotal = {455},
	publisher = {Dover Publications},
	author = {Bate, Roger R. and Mueller, Donald D. and White, Jerry E.},
	date = {1971},
	keywords = {Astrodynamics},
	file = {Bate et al. - 1971 - Fundamentals of astrodynamics.pdf:/Users/richardford/Zotero/storage/BPLR2VUG/Bate et al. - 1971 - Fundamentals of astrodynamics.pdf:application/pdf}
}

@online{fowler_deriving_nodate,
	title = {Deriving Kepler’s Laws from the Inverse-Square Law},
	url = {http://galileo.phys.virginia.edu/classes/152.mf1i.spring02/KeplersLaws.htm},
	author = {Fowler, Michael},
	urldate = {2019-02-01},
	file = {Deriving Kepler’s Laws from the Inverse-Square Law:/Users/richardford/Zotero/storage/AETWJHIJ/KeplersLaws.html:text/html}
}

@article{lancaster_unified_1969,
	title = {A unified form of lambert's theorem},
	volume = {{TN} D-5368},
	pages = {18},
	journaltitle = {{NASA} Technical Note},
	author = {Lancaster, E R and Blanchard, R C},
	date = {1969-09},
	langid = {english},
	file = {Lancaster and Blanchard - A unified form of lambert's theorem.pdf:/Users/richardford/Zotero/storage/SHT4J5E2/Lancaster and Blanchard - A unified form of lambert's theorem.pdf:application/pdf}
}

@article{protzenko_verified_2017,
	title = {Verified Low-level Programming Embedded in F*},
	volume = {1},
	issn = {2475-1421},
	url = {http://doi.acm.org/10.1145/3110261},
	doi = {10.1145/3110261},
	abstract = {We present Low*, a language for low-level programming and verification, and its application to high-assurance optimized cryptographic libraries. Low* is a shallow embedding of a small, sequential, well-behaved subset of C in F*, a dependently- typed variant of {ML} aimed at program verification. Departing from {ML}, Low* does not involve any garbage collection or implicit heap allocation; instead, it has a structured memory model à la {CompCert}, and it provides the control required for writing efficient low-level security-critical code.   By virtue of typing, any Low* program is memory safe. In addition, the programmer can make full use of the verification power of F* to write high-level specifications and verify the functional correctness of Low* code using a combination of {SMT} automation and sophisticated manual proofs. At extraction time, specifications and proofs are erased, and the remaining code enjoys a predictable translation to C. We prove that this translation preserves semantics and side-channel resistance.   We provide a new compiler back-end from Low* to C and, to evaluate our approach, we implement and verify various cryptographic algorithms, constructions, and tools for a total of about 28,000 lines of code. We show that our Low* code delivers performance competitive with existing (unverified) C cryptographic libraries, suggesting our approach may be applicable to larger-scale low-level software.},
	pages = {17:1--17:29},
	issue = {{ICFP}},
	journaltitle = {Proc. {ACM} Program. Lang.},
	author = {Protzenko, Jonathan and Zinzindohoué, Jean-Karim and Rastogi, Aseem and Ramananandro, Tahina and Wang, Peng and Zanella-Béguelin, Santiago and Delignat-Lavaud, Antoine and Hriţcu, Cătălin and Bhargavan, Karthikeyan and Fournet, Cédric and Swamy, Nikhil},
	urldate = {2019-02-01},
	date = {2017-08},
	keywords = {Compilers, Functional languages, Semantics, Software verifcation, Source code generation, Type theory, źSoftware and its engineering ź Correctness, źTheory of computation ź Hoare logic},
	file = {ACM Full Text PDF:/Users/richardford/Zotero/storage/BG9T92IN/Protzenko et al. - 2017 - Verified Low-level Programming Embedded in F.pdf:application/pdf}
}

@article{delignat-lavaud_implementing_2017,
	title = {Implementing and Proving the {TLS} 1.3 Record Layer},
	url = {https://www.microsoft.com/en-us/research/publication/implementing-proving-tls-1-3-record-layer/},
	abstract = {The record layer is the main bridge between {TLS} applications and internal sub-protocols. Its core functionality is an elaborate form of authenticated encryption: streams of messages for each sub-protocol (handshake, alert, and application data) are fragmented, multiplexed, and encrypted with optional padding to hide their lengths. Conversely, the sub-protocols may provide fresh keys or signal …},
	author = {Delignat-Lavaud, Antoine and Fournet, Cédric and Kohlweiss, Markulf and Protzenko, Jonathan and Rastogi, Aseem and Swamy, Nikhil and Zanella-Beguelin, Santiago and Bhargavan, Karthikeyan and Pan, Jianyang and Zinzindohoue, Jean Karim},
	urldate = {2019-02-01},
	date = {2017-08-17},
	langid = {american},
	file = {Full Text PDF:/Users/richardford/Zotero/storage/DB23BSB5/Delignat-Lavaud et al. - 2017 - Implementing and Proving the TLS 1.3 Record Layer.pdf:application/pdf;Snapshot:/Users/richardford/Zotero/storage/HYVJCGU9/implementing-proving-tls-1-3-record-layer.html:text/html}
}

@online{cea_frama-c_nodate,
	title = {Frama-C},
	url = {https://frama-c.com/},
	author = {cea},
	urldate = {2019-02-01},
	file = {Frama-C:/Users/richardford/Zotero/storage/8D695LDW/frama-c.com.html:text/html}
}

@inproceedings{brahmi_formalise_2018,
	location = {Toulouse, France},
	title = {Formalise to automate: deployment of a safe and cost-efficient process for avionics software},
	url = {https://hal.archives-ouvertes.fr/hal-01708332},
	shorttitle = {Formalise to automate},
	abstract = {For over a decade, Airbus have been introducing formal techniques into the verification processes of some of their avionics software products, to cope with the steady increase of the size and complexity of related avionics systems. These techniques have come of age for large-scale industrial deployment. All design and verification processes are currently being revised to take maximum advantage from them, i.e. improve industrial efficiency while maintaining the safety and reliability of avionics systems. To achieve this goal, all human-engineered design artefacts are being formalised using languages with well-defined syntaxes and semantics, in order to allow for the automatic generation of all subsequent, computable design or verification artefacts, and the preparation of the input data for non computable activities. To this aim, several domain-specific languages and related compilers have been developed internally, which cover all design activities, and bridge the gaps to integrate external tools into the overall development processes, e.g. sound, semantics-based, static analysis tools. For instance, the formalisation of detailed designs in the form of function contracts expressed in a first-order logic-based language allows for a hybrid approach to unit verification. Designs may be compiled down to {ACSL} [5] contracts, allowing for program proof with Frama-C [22], or they may be compiled down to test contracts, allowing for semi-automatic unit tests.},
	booktitle = {9th European Congress on Embedded Real Time Software and Systems ({ERTS} 2018)},
	author = {Brahmi, Abderrahmane and Delmas, David and Essoussi, Mohamed Habib and Randimbivololona, Famantanantsoa and Atki, Abdellatif and Marie, Thomas},
	urldate = {2019-02-01},
	date = {2018-01},
	keywords = {formal methods, avionics software, compilation, design, development process, {DO}-178C, domain-specific languages, formalisation, industrial application, static analysis},
	file = {HAL PDF Full Text:/Users/richardford/Zotero/storage/3NK7R5HC/Brahmi et al. - 2018 - Formalise to automate deployment of a safe and co.pdf:application/pdf}
}

@article{brahmi_formalise_nodate,
	title = {Formalise to automate: deployment of a safe and cost-efﬁcient process for avionics software -Extended},
	abstract = {For over a decade, Airbus have been introducing formal techniques into the veriﬁcation processes of some of their avionics software products, to cope with the steady increase of the size and complexity of related avionics systems. These techniques have come of age for large-scale industrial deployment. All design and veriﬁcation processes are currently being revised to take maximum advantage from them, i.e. improve industrial efﬁciency while maintaining the safety and reliability of avionics systems.},
	pages = {17},
	author = {Brahmi, Abderrahmane and Delmas, David and Essoussi, Mohamed Habib and Randimbivololona, Famantanantsoa and Informatics, {CEPRESY} and Nauzere, La and Atki, Abdellatif and Marie, Thomas},
	langid = {english},
	file = {Brahmi et al. - Formalise to automate deployment of a safe and co.pdf:/Users/richardford/Zotero/storage/TDP2UBY6/Brahmi et al. - Formalise to automate deployment of a safe and co.pdf:application/pdf}
}

@online{jeannet_apron_nodate,
	title = {{APRON} numerical abstract domain library},
	url = {http://apron.cri.ensmp.fr/library/},
	author = {Jeannet, Bertrand and Miné, Antoine},
	urldate = {2019-02-01},
	file = {APRON numerical abstract domain library:/Users/richardford/Zotero/storage/KPYS6U8G/library.html:text/html;APRON numerical abstract domain library.pdf:/Users/richardford/Zotero/storage/EN24RJTG/APRON numerical abstract domain library.pdf:application/pdf}
}

@article{blanchard_concurrent_2017,
	title = {From Concurrent Programs to Simulating Sequential Programs: Correctness of a Transformation},
	volume = {253},
	issn = {2075-2180},
	url = {http://arxiv.org/abs/1708.07226},
	doi = {10.4204/EPTCS.253.9},
	shorttitle = {From Concurrent Programs to Simulating Sequential Programs},
	abstract = {Frama-C is a software analysis framework that provides a common infrastructure and a common behavioral specification language to plugins that implement various static and dynamic analyses of C programs. Most plugins do not support concurrency. We have proposed Conc2Seq, a Frama-C plugin based on program transformation, capable to leverage the existing huge code base of plugins and to handle concurrent C programs. In this paper we formalize and sketch the proof of correctness of the program transformation principle behind Conc2Seq, and present an effort towards the full mechanization of both the formalization and proofs with the proof assistant Coq.},
	pages = {109--123},
	journaltitle = {Electronic Proceedings in Theoretical Computer Science},
	author = {Blanchard, Allan and Loulergue, Frédéric and Kosmatov, Nikolai},
	urldate = {2019-02-01},
	date = {2017-08-23},
	eprinttype = {arxiv},
	eprint = {1708.07226},
	keywords = {Computer Science - Programming Languages},
	file = {arXiv\:1708.07226 PDF:/Users/richardford/Zotero/storage/DKA444GJ/Blanchard et al. - 2017 - From Concurrent Programs to Simulating Sequential .pdf:application/pdf;arXiv.org Snapshot:/Users/richardford/Zotero/storage/E2K4HQ84/1708.html:text/html}
}

@article{petiot_how_2018,
	title = {How testing helps to diagnose proof failures},
	volume = {30},
	issn = {1433-299X},
	url = {https://doi.org/10.1007/s00165-018-0456-4},
	doi = {10.1007/s00165-018-0456-4},
	abstract = {Applying deductive verification to formally prove that a program respects its formal specification is a very complex and time-consuming task due in particular to the lack of feedback in case of proof failures. Along with a non-compliance between the code and its specification (due to an error in at least one of them), possible reasons of a proof failure include a missing or too weak specification for a called function or a loop, and lack of time or simply incapacity of the prover to finish a particular proof. This work proposes a methodology where test generation helps to identify the reason of a proof failure and to exhibit a counterexample clearly illustrating the issue. We define the categories of proof failures, introduce two subcategories of contract weaknesses (single and global ones), and examine their properties. We describe how to transform a C program formally specified in an executable specification language into C code suitable for testing, and illustrate the benefits of the method on comprehensive examples. The method has been implemented in {StaDy}, a plugin of the software analysis platform Frama-C. Initial experiments show that detecting non-compliances and contract weaknesses allows to precisely diagnose most proof failures.},
	pages = {629--657},
	number = {6},
	journaltitle = {Form Asp Comp},
	author = {Petiot, Guillaume and Kosmatov, Nikolai and Botella, Bernard and Giorgetti, Alain and Julliand, Jacques},
	urldate = {2019-02-01},
	date = {2018-11-01},
	langid = {english},
	keywords = {Deductive verification, Frama-C, Proof debugging, Specification, Test generation},
	file = {Submitted Version:/Users/richardford/Zotero/storage/7PS4JCYI/Petiot et al. - 2018 - How testing helps to diagnose proof failures.pdf:application/pdf}
}

@article{petiot_your_2015,
	title = {Your Proof Fails? Testing Helps to Find the Reason},
	url = {http://arxiv.org/abs/1508.01691},
	shorttitle = {Your Proof Fails?},
	abstract = {Applying deductive verification to formally prove that a program respects its formal specification is a very complex and time-consuming task due in particular to the lack of feedback in case of proof failures. Along with a non-compliance between the code and its specification (due to an error in at least one of them), possible reasons of a proof failure include a missing or too weak specification for a called function or a loop, and lack of time or simply incapacity of the prover to finish a particular proof. This work proposes a new methodology where test generation helps to identify the reason of a proof failure and to exhibit a counter-example clearly illustrating the issue. We describe how to transform an annotated C program into C code suitable for testing and illustrate the benefits of the method on comprehensive examples. The method has been implemented in {STADY}, a plugin of the software analysis platform {FRAMA}-C. Initial experiments show that detecting non-compliances and contract weaknesses allows to precisely diagnose most proof failures.},
	journaltitle = {{arXiv}:1508.01691 [cs]},
	author = {Petiot, Guillaume and Kosmatov, Nikolai and Botella, Bernard and Giorgetti, Alain and Julliand, Jacques},
	urldate = {2019-02-01},
	date = {2015-08-07},
	eprinttype = {arxiv},
	eprint = {1508.01691},
	keywords = {D.2.4, Computer Science - Software Engineering, D.2.5},
	file = {arXiv\:1508.01691 PDF:/Users/richardford/Zotero/storage/HKJL6G88/Petiot et al. - 2015 - Your Proof Fails Testing Helps to Find the Reason.pdf:application/pdf;arXiv.org Snapshot:/Users/richardford/Zotero/storage/QZ7UD9YV/1508.html:text/html}
}

@inproceedings{blatter_static_2018,
	title = {Static and Dynamic Verification of Relational Properties on Self-composed C Code},
	isbn = {978-3-319-92994-1},
	series = {Lecture Notes in Computer Science},
	abstract = {Function contracts are a well-established way of formally specifying the intended behavior of a function. However, they usually only describe what should happen during a single call. Relational properties, on the other hand, link several function calls. They include such properties as non-interference, continuity and monotonicity. Other examples relate sequences of function calls, for instance, to show that decrypting an encrypted message with the appropriate key gives back the original message. Such properties cannot be expressed directly in the traditional setting of modular deductive verification, but are amenable to verification through self-composition. This paper presents a verification technique dedicated to relational properties in C programs and its implementation in the form of a Frama-C plugin called {RPP} and based on self-composition. It supports functions with side effects and recursive functions. The proposed approach makes it possible to prove a relational property, to check it at runtime, to generate a counterexample using testing and to use it as a hypothesis in the subsequent verification. Our initial experiments on existing benchmarks confirm that the proposed technique is helpful for static and dynamic analysis of relational properties.},
	pages = {44--62},
	booktitle = {Tests and Proofs},
	publisher = {Springer International Publishing},
	author = {Blatter, Lionel and Kosmatov, Nikolai and Le Gall, Pascale and Prevosto, Virgile and Petiot, Guillaume},
	editor = {Dubois, Catherine and Wolff, Burkhart},
	date = {2018},
	langid = {english},
	keywords = {Deductive verification, Frama-C, Specification, Dynamic verification, Relational properties, Self-composition},
	file = {Blatter et al. - 2018 - Static and Dynamic Verification of Relational Prop.pdf:/Users/richardford/Zotero/storage/4HABAVL9/Blatter et al. - 2018 - Static and Dynamic Verification of Relational Prop.pdf:application/pdf}
}

@online{melquiond_why3_nodate,
	title = {Why3},
	url = {http://why3.lri.fr/},
	author = {Melquiond, Guillaume},
	urldate = {2019-02-01},
	file = {Why3:/Users/richardford/Zotero/storage/RE6KJZXJ/why3.lri.fr.html:text/html}
}

@article{dijkstra_guarded_1975,
	title = {Guarded Commands, Nondeterminacy and Formal Derivation of Programs},
	volume = {18},
	issn = {0001-0782},
	url = {http://doi.acm.org/10.1145/360933.360975},
	doi = {10.1145/360933.360975},
	abstract = {So-called “guarded commands” are introduced as a building block for alternative and repetitive constructs that allow nondeterministic program components for which at least the activity evoked, but possibly even the final state, is not necessarily uniquely determined by the initial state. For the formal derivation of programs expressed in terms of these constructs, a calculus will be be shown.},
	pages = {453--457},
	number = {8},
	journaltitle = {Commun. {ACM}},
	author = {Dijkstra, Edsger W.},
	urldate = {2019-02-01},
	date = {1975-08},
	keywords = {case-construction, correctness proof, derivation of programs, nondeterminancy, program semantics, programming language semantics, programming languages, programming methodology, repetition, sequencing primitives, termination},
	file = {ACM Full Text PDF:/Users/richardford/Zotero/storage/4XF5W5ZR/Dijkstra - 1975 - Guarded Commands, Nondeterminacy and Formal Deriva.pdf:application/pdf}
}

@article{swamy_verifying_2013,
	title = {Verifying Higher-order Programs with the Dijkstra Monad},
	url = {https://www.microsoft.com/en-us/research/publication/verifying-higher-order-programs-with-the-dijkstra-monad/},
	abstract = {Modern programming languages, ranging from Haskell and {ML}, to {JavaScript}, C\# and Java, all make extensive use of higher-order state. This paper advocates a new verification methodology for higher-order stateful programs, based on a new monad of predicate transformers called the Dijkstra monad. Using the Dijkstra monad has a number of benefits. First, the monad …},
	author = {Swamy, Nikhil and Chen, Juan and Livshits, Ben},
	urldate = {2019-02-01},
	date = {2013-06-01},
	langid = {american},
	file = {Full Text PDF:/Users/richardford/Zotero/storage/DTN54LGK/Swamy et al. - 2013 - Verifying Higher-order Programs with the Dijkstra .pdf:application/pdf;Snapshot:/Users/richardford/Zotero/storage/NVGHR97J/verifying-higher-order-programs-with-the-dijkstra-monad.html:text/html}
}

@inproceedings{swamy_dependent_2016,
	location = {New York, {NY}, {USA}},
	title = {Dependent Types and Multi-monadic Effects in F*},
	isbn = {978-1-4503-3549-2},
	url = {http://doi.acm.org/10.1145/2837614.2837655},
	doi = {10.1145/2837614.2837655},
	series = {{POPL} '16},
	abstract = {We present a new, completely redesigned, version of F*, a language that works both as a proof assistant as well as a general-purpose, verification-oriented, effectful programming language. In support of these complementary roles, F* is a dependently typed, higher-order, call-by-value language with \_primitive\_ effects including state, exceptions, divergence and {IO}. Although primitive, programmers choose the granularity at which to specify effects by equipping each effect with a monadic, predicate transformer semantics. F* uses this to efficiently compute weakest preconditions and discharges the resulting proof obligations using a combination of {SMT} solving and manual proofs. Isolated from the effects, the core of F* is a language of pure functions used to write specifications and proof terms---its consistency is maintained by a semantic termination check based on a well-founded order. We evaluate our design on more than 55,000 lines of F* we have authored in the last year, focusing on three main case studies. Showcasing its use as a general-purpose programming language, F* is programmed (but not verified) in F*, and bootstraps in both {OCaml} and F\#. Our experience confirms F*'s pay-as-you-go cost model: writing idiomatic {ML}-like code with no finer specifications imposes no user burden. As a verification-oriented language, our most significant evaluation of F* is in verifying several key modules in an implementation of the {TLS}-1.2 protocol standard. For the modules we considered, we are able to prove more properties, with fewer annotations using F* than in a prior verified implementation of {TLS}-1.2. Finally, as a proof assistant, we discuss our use of F* in mechanizing the metatheory of a range of lambda calculi, starting from the simply typed lambda calculus to System F-omega and even micro-F*, a sizeable fragment of F* itself---these proofs make essential use of F*'s flexible combination of {SMT} automation and constructive proofs, enabling a tactic-free style of programming and proving at a relatively large scale.},
	pages = {256--270},
	booktitle = {Proceedings of the 43rd Annual {ACM} {SIGPLAN}-{SIGACT} Symposium on Principles of Programming Languages},
	publisher = {{ACM}},
	author = {Swamy, Nikhil and Hriţcu, Cătălin and Keller, Chantal and Rastogi, Aseem and Delignat-Lavaud, Antoine and Forest, Simon and Bhargavan, Karthikeyan and Fournet, Cédric and Strub, Pierre-Yves and Kohlweiss, Markulf and Zinzindohoue, Jean-Karim and Zanella-Béguelin, Santiago},
	urldate = {2019-02-01},
	date = {2016},
	keywords = {proof assistants, effectful programming, verification},
	file = {ACM Full Text PDF:/Users/richardford/Zotero/storage/X6CZXAKM/Swamy et al. - 2016 - Dependent Types and Multi-monadic Effects in F.pdf:application/pdf}
}

@inproceedings{ahman_dijkstra_2017,
	location = {New York, {NY}, {USA}},
	title = {Dijkstra Monads for Free},
	isbn = {978-1-4503-4660-3},
	url = {http://doi.acm.org/10.1145/3009837.3009878},
	doi = {10.1145/3009837.3009878},
	series = {{POPL} 2017},
	abstract = {Dijkstra monads enable a dependent type theory to be enhanced with support for specifying and verifying effectful code via weakest preconditions. Together with their closely related counterparts, Hoare monads, they provide the basis on which verification tools like F*, Hoare Type Theory ({HTT}), and Ynot are built. We show that Dijkstra monads can be derived "for free" by applying a continuation-passing style ({CPS}) translation to the standard monadic definitions of the underlying computational effects. Automatically deriving Dijkstra monads in this way provides a correct-by-construction and efficient way of reasoning about user-defined effects in dependent type theories. We demonstrate these ideas in {EMF}*, a new dependently typed calculus, validating it via both formal proof and a prototype implementation within F*. Besides equipping F* with a more uniform and extensible effect system, {EMF}* enables a novel mixture of intrinsic and extrinsic proofs within F*.},
	pages = {515--529},
	booktitle = {Proceedings of the 44th {ACM} {SIGPLAN} Symposium on Principles of Programming Languages},
	publisher = {{ACM}},
	author = {Ahman, Danel and Hriţcu, Cătălin and Maillard, Kenji and Martínez, Guido and Plotkin, Gordon and Protzenko, Jonathan and Rastogi, Aseem and Swamy, Nikhil},
	urldate = {2019-02-01},
	date = {2017},
	keywords = {proof assistants, effectful programming, verification, dependent types},
	file = {ACM Full Text PDF:/Users/richardford/Zotero/storage/79A2MM4V/Ahman et al. - 2017 - Dijkstra Monads for Free.pdf:application/pdf}
}

@article{hritcu_quest_nodate,
	title = {The Quest for Formally Secure Compartmentalizing Compilation},
	abstract = {Severe low-level vulnerabilities abound in today’s computer systems, allowing cyber-attackers to remotely gain full control. This happens in big part because our programming languages, compilation chains, and architectures too often trade o security for e ciency. The semantics of mainstream low-level languages like C is inherently insecure, and even for safer languages, all guarantees are lost when interacting with low-level code, for instance when using low-level libraries. This habilitation presents my ongoing quest to build formally secure compartmentalizing compilation chains that defend against such attacks. In particular, we propose several formal de nitions that characterize what it means for a compartmentalizing compilation chain to be secure, both in the case of safe and of unsafe source languages.},
	pages = {96},
	author = {Hriţcu, Cătălin},
	langid = {english},
	file = {Hriţcu - The Quest for Formally Secure Compartmentalizing Com.pdf:/Users/richardford/Zotero/storage/GGGX8C7Q/Hriţcu - The est for Formally Secure Compartmentalizing Com.pdf:application/pdf}
}

@article{ahman_recalling_2017,
	title = {Recalling a Witness: Foundations and Applications of Monotonic State},
	volume = {2},
	issn = {2475-1421},
	url = {http://doi.acm.org/10.1145/3158153},
	doi = {10.1145/3158153},
	shorttitle = {Recalling a Witness},
	abstract = {We provide a way to ease the verification of programs whose state evolves monotonically. The main idea is that a property witnessed in a prior state can be soundly recalled in the current state, provided (1) state evolves according to a given preorder, and (2) the property is preserved by this preorder. In many scenarios, such monotonic reasoning yields concise modular proofs, saving the need for explicit program invariants. We distill our approach into the monotonic-state monad, a general yet compact interface for Hoare-style reasoning about monotonic state in a dependently typed language. We prove the soundness of the monotonic-state monad and use it as a unified foundation for reasoning about monotonic state in the F⋆ verification system. Based on this foundation, we build libraries for various mutable data structures like monotonic references and apply these libraries at scale to the verification of several distributed applications.},
	pages = {65:1--65:30},
	issue = {{POPL}},
	journaltitle = {Proc. {ACM} Program. Lang.},
	author = {Ahman, Danel and Fournet, Cédric and Hriţcu, Cătălin and Maillard, Kenji and Rastogi, Aseem and Swamy, Nikhil},
	urldate = {2019-02-01},
	date = {2017-12},
	keywords = {Program Verification, Formal Foundations, Hoare Logic, Modular Reasoning, Monotonic References, Monotonic-State Monad, Secure File Transfer, State Continuity},
	file = {ACM Full Text PDF:/Users/richardford/Zotero/storage/T2Z4NUBR/Ahman et al. - 2017 - Recalling a Witness Foundations and Applications .pdf:application/pdf}
}

@software{syme_fsharp_2019,
	title = {Fsharp design: {RFCs} and docs related to the F\# language design process,},
	url = {https://github.com/fsharp/fslang-design},
	shorttitle = {{RFCs} and docs related to the F\# language design process, see https},
	publisher = {F\# Software Foundation Repositories},
	author = {Syme, Don},
	urldate = {2019-02-01},
	date = {2019-01-29},
	note = {original-date: 2014-06-25T13:07:35Z}
}

@software{syme_fsharp_2019-1,
	title = {The Fsharp Compiler, Core Library \& Tools (F\# Software Foundation Repository): fsharp/fsharp},
	rights = {{MIT}},
	url = {https://github.com/fsharp/fsharp},
	shorttitle = {The F\# Compiler, Core Library \& Tools (F\# Software Foundation Repository)},
	publisher = {F\# Software Foundation Repositories},
	author = {Syme, Don},
	urldate = {2019-02-01},
	date = {2019-01-30},
	note = {original-date: 2010-12-13T00:19:52Z}
}

@article{martinez_meta-f*:_2018,
	title = {Meta-F*: Proof Automation with {SMT}, Tactics, and Metaprograms},
	url = {http://arxiv.org/abs/1803.06547},
	shorttitle = {Meta-F*},
	abstract = {We introduce Meta-F*, a tactics and metaprogramming framework for the F* program verifier. The main novelty of Meta-F* is allowing to use tactics and metaprogramming to discharge assertions not solvable by {SMT}, or to just simplify them into well-behaved {SMT} fragments. Plus, Meta-F* can be used to generate verified code automatically. Meta-F* is implemented as an F* effect, which, given the powerful effect system of F*, heavily increases code reuse and even enables the lightweight verification of metaprograms. Metaprograms can be either interpreted, or compiled to efficient native code that can be dynamically loaded into the F* type-checker and can interoperate with interpreted code. Evaluation on realistic case studies shows that Meta-F* provides substantial gains in proof development, efficiency, and robustness.},
	journaltitle = {{arXiv}:1803.06547 [cs]},
	author = {Martínez, Guido and Ahman, Danel and Dumitrescu, Victor and Giannarakis, Nick and Hawblitzel, Chris and Hritcu, Catalin and Narasimhamurthy, Monal and Paraskevopoulou, Zoe and Pit-Claudel, Clément and Protzenko, Jonathan and Ramananandro, Tahina and Rastogi, Aseem and Swamy, Nikhil},
	urldate = {2019-02-01},
	date = {2018-03-17},
	eprinttype = {arxiv},
	eprint = {1803.06547},
	keywords = {Computer Science - Logic in Computer Science, Computer Science - Programming Languages},
	file = {arXiv\:1803.06547 PDF:/Users/richardford/Zotero/storage/D6VDW32P/Martínez et al. - 2018 - Meta-F Proof Automation with SMT, Tactics, and M.pdf:application/pdf;arXiv.org Snapshot:/Users/richardford/Zotero/storage/4UGPV8V2/1803.html:text/html}
}

@inproceedings{filinski_representing_1994,
	location = {New York, {NY}, {USA}},
	title = {Representing Monads},
	isbn = {978-0-89791-636-3},
	url = {http://doi.acm.org/10.1145/174675.178047},
	doi = {10.1145/174675.178047},
	series = {{POPL} '94},
	abstract = {We show that any monad whose unit and extension operations are expressible as purely functional terms can be embedded in a call-by-value language with “composable continuations”. As part of the development, we extend Meyer and Wand's characterization of the relationship between continuation-passing and direct style to one for continuation-passing vs. general “monadic” style. We further show that the composable-continuations construct can itself be represented using ordinary, non-composable first-class continuations and a single piece of state. Thus, in the presence of two specific computational effects - storage and escapes - any expressible monadic structure (e.g., nondeterminism as represented by the list monad) can be added as a purely definitional extension, without requiring a reinterpretation of the whole language. The paper includes an implementation of the construction (in Standard {ML} with some New Jersey extensions) and several examples.},
	pages = {446--457},
	booktitle = {Proceedings of the 21st {ACM} {SIGPLAN}-{SIGACT} Symposium on Principles of Programming Languages},
	publisher = {{ACM}},
	author = {Filinski, Andrzej},
	urldate = {2019-02-01},
	date = {1994},
	file = {ACM Full Text PDF:/Users/richardford/Zotero/storage/474UWRAK/Filinski - 1994 - Representing Monads.pdf:application/pdf}
}

@inproceedings{filinski_representing_1999,
	location = {New York, {NY}, {USA}},
	title = {Representing Layered Monads},
	isbn = {978-1-58113-095-9},
	url = {http://doi.acm.org/10.1145/292540.292557},
	doi = {10.1145/292540.292557},
	series = {{POPL} '99},
	abstract = {There has already been considerable research on constructing modular, monad-based specifications of computational effects (state, exceptions, nondeterminism, etc.) in programming languages. We present a simple framework in this tradition, based on a Church-style effect-typing system for an {ML}-like language. The semantics of this language is formally defined by a series of monadic translations, each one expanding away a layer of effects. Such a layered specification is easy to reason about, but its direct implementation (whether by parameterized interpretation or by actual translation) is often prohibitively inefficient.By exploiting deeper semantic properties of monads, however, it is also possible to derive a vastly more efficient implementation: we show that each layer of effects can be uniformly simulated by continuation-passing, and further that multiple such layers can themselves be simulated by a standard semantics for call/cc and mutable state. Thus, even multi-effect programs can be executed in Scheme or {SML}/{NJ} at full native speed, generalizing an earlier single-effect result. As an example, we show how a simple resumption-based semantics of concurrency allows us to directly simulate a shared-state program across all possible dynamic interleavings of execution threads.},
	pages = {175--188},
	booktitle = {Proceedings of the 26th {ACM} {SIGPLAN}-{SIGACT} Symposium on Principles of Programming Languages},
	publisher = {{ACM}},
	author = {Filinski, Andrzej},
	urldate = {2019-02-01},
	date = {1999},
	file = {ACM Full Text PDF:/Users/richardford/Zotero/storage/973MQ2DE/Filinski - 1999 - Representing Layered Monads.pdf:application/pdf}
}

@article{gonthier_introduction_2010,
	title = {An introduction to small scale reflection in Coq},
	volume = {3},
	rights = {Copyright (c) 2010 Georges Gonthier, Assia Mahboubi},
	issn = {1972-5787},
	url = {https://jfr.unibo.it/article/view/1979},
	doi = {10.6092/issn.1972-5787/1979},
	abstract = {This tutorial presents the {SSReflect} extension to the Coq system. This extension consists of an extension to the Coq language of script, and of a set of libraries, originating from the formal proof of the Four Color theorem. This tutorial proposes a guided tour in some of the basic libraries distributed in the {SSReflect} package. It focuses on the application of the small scale reflection methodology to the formalization of finite objects in intuitionistic type theory.},
	pages = {95--152},
	number = {2},
	journaltitle = {Journal of Formalized Reasoning},
	author = {Gonthier, Georges and Mahboubi, Assia},
	urldate = {2019-02-01},
	date = {2010},
	langid = {english},
	file = {Full Text PDF:/Users/richardford/Zotero/storage/GAA6PEIJ/Gonthier and Mahboubi - 2010 - An introduction to small scale reflection in Coq.pdf:application/pdf;Snapshot:/Users/richardford/Zotero/storage/ZX32HUEX/1979.html:text/html}
}

@inproceedings{gonthier_how_2011,
	location = {New York, {NY}, {USA}},
	title = {How to Make Ad Hoc Proof Automation Less Ad Hoc},
	isbn = {978-1-4503-0865-6},
	url = {http://doi.acm.org/10.1145/2034773.2034798},
	doi = {10.1145/2034773.2034798},
	series = {{ICFP} '11},
	abstract = {Most interactive theorem provers provide support for some form of user-customizable proof automation. In a number of popular systems, such as Coq and Isabelle, this automation is achieved primarily through tactics, which are programmed in a separate language from that of the prover's base logic. While tactics are clearly useful in practice, they can be difficult to maintain and compose because, unlike lemmas, their behavior cannot be specified within the expressive type system of the prover itself. We propose a novel approach to proof automation in Coq that allows the user to specify the behavior of custom automated routines in terms of Coq's own type system. Our approach involves a sophisticated application of Coq's canonical structures, which generalize Haskell type classes and facilitate a flexible style of dependently-typed logic programming. Specifically, just as Haskell type classes are used to infer the canonical implementation of an overloaded term at a given type, canonical structures can be used to infer the canonical proof of an overloaded lemma for a given instantiation of its parameters. We present a series of design patterns for canonical structure programming that enable one to carefully and predictably coax Coq's type inference engine into triggering the execution of user-supplied algorithms during unification, and we illustrate these patterns through several realistic examples drawn from Hoare Type Theory. We assume no prior knowledge of Coq and describe the relevant aspects of Coq type inference from first principles.},
	pages = {163--175},
	booktitle = {Proceedings of the 16th {ACM} {SIGPLAN} International Conference on Functional Programming},
	publisher = {{ACM}},
	author = {Gonthier, Georges and Ziliani, Beta and Nanevski, Aleksandar and Dreyer, Derek},
	urldate = {2019-02-01},
	date = {2011},
	keywords = {canonical structures, coq, custom proof automation, hoare type theory, interactive theorem proving, tactics, type classes},
	file = {ACM Full Text PDF:/Users/richardford/Zotero/storage/2TR7VDJX/Gonthier et al. - 2011 - How to Make Ad Hoc Proof Automation Less Ad Hoc.pdf:application/pdf}
}

@inproceedings{mokhov_algebraic_2017,
	location = {New York, {NY}, {USA}},
	title = {Algebraic Graphs with Class (Functional Pearl)},
	isbn = {978-1-4503-5182-9},
	url = {http://doi.acm.org/10.1145/3122955.3122956},
	doi = {10.1145/3122955.3122956},
	series = {Haskell 2017},
	abstract = {The paper presents a minimalistic and elegant approach to working with graphs in Haskell. It is built on a rigorous mathematical foundation --- an algebra of graphs --- that allows us to apply equational reasoning for proving the correctness of graph transformation algorithms. Algebraic graphs let us avoid partial functions typically caused by `malformed graphs' that contain an edge referring to a non-existent vertex. This helps to liberate {APIs} of existing graph libraries from partial functions.   The algebra of graphs can represent directed, undirected, reflexive and transitive graphs, as well as hypergraphs, by appropriately choosing the set of underlying axioms. The flexibility of the approach is demonstrated by developing a library for constructing and transforming polymorphic graphs.},
	pages = {2--13},
	booktitle = {Proceedings of the 10th {ACM} {SIGPLAN} International Symposium on Haskell},
	publisher = {{ACM}},
	author = {Mokhov, Andrey},
	urldate = {2019-02-01},
	date = {2017},
	keywords = {algebra, graph theory, Haskell},
	file = {ACM Full Text PDF:/Users/richardford/Zotero/storage/5HHBHF8J/Mokhov - 2017 - Algebraic Graphs with Class (Functional Pearl).pdf:application/pdf}
}

@article{ramsey_applicative_2006,
	title = {An Applicative Control-Flow Graph Based on Huet's Zipper},
	volume = {148},
	issn = {1571-0661},
	url = {http://www.sciencedirect.com/science/article/pii/S1571066106001289},
	doi = {10.1016/j.entcs.2005.11.042},
	series = {Proceedings of the {ACM}-{SIGPLAN} Workshop on {ML} ({ML} 2005)},
	abstract = {We are using {ML} to build a compiler that does low-level optimization. To support optimizations in classic imperative style, we built a control-flow graph using mutable pointers and other mutable state in the nodes. This decision proved unfortunate: the mutable flow graph was big and complex, and it led to many bugs. We have replaced it by a smaller, simpler, applicative flow graph based on Huet's [Huet, Gérard, 1997. The Zipper. Journal of Functional Programming, 7(5):549–554. Functional Pearl] zipper. The new flow graph is a success; this paper presents its design and shows how it leads to a gratifyingly simple implementation of the dataflow framework developed by [Lerner, Sorin, David Grove, and Craig Chambers. 2002. Composing dataflow analyses and transformations. Conference Record of the 29th Annual {ACM} Symposium on Principles of Programming Languages, in {SIGPLAN} Notices, 31(1):270–282].},
	pages = {105--126},
	number = {2},
	journaltitle = {Electronic Notes in Theoretical Computer Science},
	author = {Ramsey, Norman and Dias, João},
	urldate = {2019-02-01},
	date = {2006-03-24},
	keywords = {applicative data structures, compilers, control-flow graphs, dataflow analysis, optimization},
	file = {ScienceDirect Full Text PDF:/Users/richardford/Zotero/storage/A52SVHPL/Ramsey and Dias - 2006 - An Applicative Control-Flow Graph Based on Huet's .pdf:application/pdf;ScienceDirect Snapshot:/Users/richardford/Zotero/storage/PT5VGVPI/S1571066106001289.html:text/html}
}

@article{harper_framework_1993,
	title = {A Framework for Defining Logics},
	volume = {40},
	issn = {0004-5411},
	url = {http://doi.acm.org/10.1145/138027.138060},
	doi = {10.1145/138027.138060},
	abstract = {The Edinburgh Logical Framework ({LF}) provides a means to define (or present) logics. It is based on a general treatment of syntax, rules, and proofs by means of a typed \&lgr;-calculus with dependent types. Syntax is treated in a style similar to, but more general than, Martin-Lo¨f's system of arities. The treatment of rules and proofs focuses on his notion of a judgment. Logics are represented in {LF} via a new principle, the judgments as types principle, whereby each judgment is identified with the type of its proofs. This allows for a smooth treatment of discharge and variable occurence conditions and leads to a uniform treatment of rules and proofs whereby rules are viewed as proofs of higher-order judgments and proof checking is reduced to type checking. The practical benefit of our treatment of formal systems is that logic-independent tools, such as proof editors and proof checkers, can be constructed.},
	pages = {143--184},
	number = {1},
	journaltitle = {J. {ACM}},
	author = {Harper, Robert and Honsell, Furio and Plotkin, Gordon},
	urldate = {2019-02-01},
	date = {1993-01},
	keywords = {interactive theorem proving, formal systems, proof checking, typed lambda calculus},
	file = {ACM Full Text PDF:/Users/richardford/Zotero/storage/VEYR93NU/Harper et al. - 1993 - A Framework for Defining Logics.pdf:application/pdf}
}

@article{harrison_hol_2013,
	title = {The {HOL} Light Theory of Euclidean Space},
	volume = {50},
	issn = {0168-7433, 1573-0670},
	url = {http://link.springer.com/10.1007/s10817-012-9250-9},
	doi = {10.1007/s10817-012-9250-9},
	pages = {173--190},
	number = {2},
	journaltitle = {Journal of Automated Reasoning},
	author = {Harrison, John},
	urldate = {2019-02-01},
	date = {2013-02},
	langid = {english},
	file = {Harrison - 2013 - The HOL Light Theory of Euclidean Space.pdf:/Users/richardford/Zotero/storage/65KRY862/Harrison - 2013 - The HOL Light Theory of Euclidean Space.pdf:application/pdf}
}

@inproceedings{spector-zabusky_total_2018,
	location = {New York, {NY}, {USA}},
	title = {Total Haskell is Reasonable Coq},
	isbn = {978-1-4503-5586-5},
	url = {http://doi.acm.org/10.1145/3167092},
	doi = {10.1145/3167092},
	series = {{CPP} 2018},
	abstract = {We would like to use the Coq proof assistant to mechanically verify properties of Haskell programs. To that end, we present a tool, named {\textless}tt{\textgreater}hs-to-coq{\textless}/tt{\textgreater}, that translates total Haskell programs into Coq programs via a shallow embedding. We apply our tool in three case studies – a lawful {\textless}tt{\textgreater}Monad{\textless}/tt{\textgreater} instance, “Hutton’s razor”, and an existing data structure library – and prove their correctness. These examples show that this approach is viable: both that {\textless}tt{\textgreater}hs-to-coq{\textless}/tt{\textgreater} applies to existing Haskell code, and that the output it produces is amenable to verification.},
	pages = {14--27},
	booktitle = {Proceedings of the 7th {ACM} {SIGPLAN} International Conference on Certified Programs and Proofs},
	publisher = {{ACM}},
	author = {Spector-Zabusky, Antal and Breitner, Joachim and Rizkallah, Christine and Weirich, Stephanie},
	urldate = {2019-02-01},
	date = {2018},
	keywords = {Coq, verification, Haskell},
	file = {ACM Full Text PDF:/Users/richardford/Zotero/storage/WVT2FG9M/Spector-Zabusky et al. - 2018 - Total Haskell is Reasonable Coq.pdf:application/pdf}
}

@incollection{hutchison_fresh_2009,
	location = {Berlin, Heidelberg},
	title = {A Fresh Look at Separation Algebras and Share Accounting},
	volume = {5904},
	isbn = {978-3-642-10671-2 978-3-642-10672-9},
	url = {http://link.springer.com/10.1007/978-3-642-10672-9_13},
	abstract = {Separation Algebras serve as models of Separation Logics; Share Accounting allows reasoning about concurrent-read/exclusive-write resources in Separation Logic. In designing a Concurrent Separation Logic and in mechanizing proofs of its soundness, we found previous axiomatizations of separation algebras and previous systems of share accounting to be useful but ﬂawed. We adjust the axioms of separation algebras; we demonstrate an operator calculus for constructing new separation algebras; we present a more powerful system of share accounting with a new, simple model; and we provide a reusable Coq development.},
	pages = {161--177},
	booktitle = {Programming Languages and Systems},
	publisher = {Springer Berlin Heidelberg},
	author = {Dockins, Robert and Hobor, Aquinas and Appel, Andrew W.},
	editor = {Hu, Zhenjiang},
	editorb = {Hutchison, David and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M. and Mattern, Friedemann and Mitchell, John C. and Naor, Moni and Nierstrasz, Oscar and Pandu Rangan, C. and Steffen, Bernhard and Sudan, Madhu and Terzopoulos, Demetri and Tygar, Doug and Vardi, Moshe Y. and Weikum, Gerhard},
	editorbtype = {redactor},
	urldate = {2019-02-01},
	date = {2009},
	langid = {english},
	doi = {10.1007/978-3-642-10672-9_13},
	file = {Dockins et al. - 2009 - A Fresh Look at Separation Algebras and Share Acco.pdf:/Users/richardford/Zotero/storage/47RRWA4Y/Dockins et al. - 2009 - A Fresh Look at Separation Algebras and Share Acco.pdf:application/pdf}
}

@online{swamy_project_nodate,
	title = {Project Everest - Verified Secure Implementations of the {HTTPS} Ecosystem},
	url = {https://www.microsoft.com/en-us/research/project/project-everest-verified-secure-implementations-https-ecosystem/},
	abstract = {This project proposes to deﬁnitively solve the problem of a brittle {HTTPS} ecosystem by constructing a more secure, high performance, standards-compliant, veriﬁed implementation of the full {HTTPS} ecosystem. Unlike other veriﬁed software projects, our expedition aims to deploy Everest within existing software as a drop-in replacement in mainstream web browsers, servers, and other popular tools.},
	titleaddon = {Microsoft Research},
	author = {Swamy, Nikhil},
	urldate = {2019-02-01},
	langid = {american},
	file = {Snapshot:/Users/richardford/Zotero/storage/SDMUE4PX/project-everest-verified-secure-implementations-https-ecosystem.html:text/html;Snapshot:/Users/richardford/Zotero/storage/PZSK85HV/project-everest-verified-secure-implementations-https-ecosystem.html:text/html}
}

@article{fournet_deploying_nodate,
	title = {Deploying a Veriﬁed Secure Implementation of the {HTTPS} Ecosystem},
	pages = {10},
	author = {Fournet, Cedric and Hawblitzel, Chris and Parno, Bryan and Swamy, Nikhil},
	langid = {english},
	file = {Fournet et al. - Deploying a Veriﬁed Secure Implementation of the H.pdf:/Users/richardford/Zotero/storage/4TJJYC6N/Fournet et al. - Deploying a Veriﬁed Secure Implementation of the H.pdf:application/pdf}
}

@article{hawblitzel_ironclad_nodate,
	title = {Ironclad Apps: End-to-End Security via Automated Full-System Veriﬁcation},
	abstract = {An Ironclad App lets a user securely transmit her data to a remote machine with the guarantee that every instruction executed on that machine adheres to a formal abstract speciﬁcation of the app’s behavior. This does more than eliminate implementation vulnerabilities such as buffer overﬂows, parsing errors, or data leaks; it tells the user exactly how the app will behave at all times. We provide these guarantees via complete, low-level software veriﬁcation. We then use cryptography and secure hardware to enable secure channels from the veriﬁed software to remote users. To achieve such complete veriﬁcation, we developed a set of new and modiﬁed tools, a collection of techniques and engineering disciplines, and a methodology focused on rapid development of veriﬁed systems software. We describe our methodology, formal results, and lessons we learned from building a full stack of veriﬁed software. That software includes a veriﬁed kernel; veriﬁed drivers; veriﬁed system and crypto libraries including {SHA}, {HMAC}, and {RSA}; and four Ironclad Apps.},
	pages = {18},
	author = {Hawblitzel, Chris and Howell, Jon and Lorch, Jacob R and Narayan, Arjun and Parno, Bryan and Zhang, Danfeng and Zill, Brian},
	langid = {english},
	file = {Hawblitzel et al. - Ironclad Apps End-to-End Security via Automated F.pdf:/Users/richardford/Zotero/storage/W6P597PJ/Hawblitzel et al. - Ironclad Apps End-to-End Security via Automated F.pdf:application/pdf}
}

@inproceedings{hawblitzel_ironfleet:_2015,
	location = {New York, {NY}, {USA}},
	title = {{IronFleet}: Proving Practical Distributed Systems Correct},
	isbn = {978-1-4503-3834-9},
	url = {http://doi.acm.org/10.1145/2815400.2815428},
	doi = {10.1145/2815400.2815428},
	series = {{SOSP} '15},
	shorttitle = {{IronFleet}},
	abstract = {Distributed systems are notorious for harboring subtle bugs. Verification can, in principle, eliminate these bugs a priori, but verification has historically been difficult to apply at full-program scale, much less distributed-system scale. We describe a methodology for building practical and provably correct distributed systems based on a unique blend of {TLA}-style state-machine refinement and Hoare-logic verification. We demonstrate the methodology on a complex implementation of a Paxos-based replicated state machine library and a lease-based sharded key-value store. We prove that each obeys a concise safety specification, as well as desirable liveness requirements. Each implementation achieves performance competitive with a reference system. With our methodology and lessons learned, we aim to raise the standard for distributed systems from "tested" to "correct."},
	pages = {1--17},
	booktitle = {Proceedings of the 25th Symposium on Operating Systems Principles},
	publisher = {{ACM}},
	author = {Hawblitzel, Chris and Howell, Jon and Kapritsos, Manos and Lorch, Jacob R. and Parno, Bryan and Roberts, Michael L. and Setty, Srinath and Zill, Brian},
	urldate = {2019-02-01},
	date = {2015},
	file = {ACM Full Text PDF:/Users/richardford/Zotero/storage/RP6MRQV6/Hawblitzel et al. - 2015 - IronFleet Proving Practical Distributed Systems C.pdf:application/pdf}
}

@inproceedings{hawblitzel_automated_2015,
	title = {Automated and Modular Refinement Reasoning for Concurrent Programs},
	url = {https://link.springer.com/chapter/10.1007/978-3-319-21668-3_26},
	doi = {10.1007/978-3-319-21668-3_26},
	abstract = {We present civl, a language and verifier for concurrent programs based on automated and modular refinement reasoning. civlsupports reasoning about a concurrent program at many levels of abstraction....},
	eventtitle = {International Conference on Computer Aided Verification},
	pages = {449--465},
	booktitle = {Computer Aided Verification},
	publisher = {Springer, Cham},
	author = {Hawblitzel, Chris and Petrank, Erez and Qadeer, Shaz and Tasiran, Serdar},
	urldate = {2019-02-01},
	date = {2015-07-18},
	langid = {english},
	file = {Hawblitzel et al. - 2015 - Automated and Modular Refinement Reasoning for Con.pdf:/Users/richardford/Zotero/storage/X2AJPSSW/Hawblitzel et al. - 2015 - Automated and Modular Refinement Reasoning for Con.pdf:application/pdf;Snapshot:/Users/richardford/Zotero/storage/89G4CJY3/10.html:text/html}
}

@inproceedings{lahiri_automatic_2015,
	title = {Automatic Rootcausing for Program Equivalence Failures in Binaries},
	isbn = {978-3-319-21690-4},
	series = {Lecture Notes in Computer Science},
	abstract = {Equivalence checking of imperative programs has several applications including compiler validation and cross-version verification. Debugging equivalence failures can be tedious for large examples, especially for low-level binary programs. In this paper, we formalize a simple yet precise notion of verifiable rootcause for equivalence failures that leverages semantic similarity between two programs. Unlike existing works on program repair, our definition of rootcause avoids the need for a template of fixes or the need for a complete repair to ensure equivalence. We show progressively weaker checks for detecting rootcauses that can be applicable even when multiple fixes are required to make the two programs equivalent. We provide optimizations based on Maximum Satisfiability ({MAXSAT}) and binary search to prune the search space of such rootcauses. We have implemented the techniques in {SymDiff} and provide an evaluation on a set of real-world compiler validation binary benchmarks.},
	pages = {362--379},
	booktitle = {Computer Aided Verification},
	publisher = {Springer International Publishing},
	author = {Lahiri, Shuvendu K. and Sinha, Rohit and Hawblitzel, Chris},
	editor = {Kroening, Daniel and Păsăreanu, Corina S.},
	date = {2015},
	langid = {english},
	file = {Lahiri et al. - 2015 - Automatic Rootcausing for Program Equivalence Fail.pdf:/Users/richardford/Zotero/storage/LJCRZ2BD/Lahiri et al. - 2015 - Automatic Rootcausing for Program Equivalence Fail.pdf:application/pdf}
}

@article{yang_safe_2011,
	title = {Safe to the last instruction: automated verification of a type-safe operating system},
	volume = {54},
	issn = {00010782},
	url = {http://dl.acm.org/citation.cfm?doid=2043174.2043197},
	doi = {10.1145/2043174.2043197},
	shorttitle = {Safe to the last instruction},
	pages = {123},
	number = {12},
	journaltitle = {Communications of the {ACM}},
	author = {Yang, Jean and Hawblitzel, Chris},
	urldate = {2019-02-01},
	date = {2011-12-01},
	langid = {english},
	file = {Full Text:/Users/richardford/Zotero/storage/NJ2ZPC4C/Yang and Hawblitzel - 2011 - Safe to the last instruction automated verificati.pdf:application/pdf}
}

@inproceedings{lahiri_symdiff:_2012,
	title = {{SYMDIFF}: A Language-Agnostic Semantic Diff Tool for Imperative Programs},
	isbn = {978-3-642-31424-7},
	series = {Lecture Notes in Computer Science},
	shorttitle = {{SYMDIFF}},
	abstract = {In this paper, we describe {SymDiff}, a language-agnostic tool for equivalence checking and displaying semantic (behavioral) differences over imperative programs. The tool operates on an intermediate verification language Boogie, for which translations exist from various source languages such as C, C\# and x86. We discuss the tool and the front-end interface to target various source languages. Finally, we provide a brief description of the front-end for C programs.},
	pages = {712--717},
	booktitle = {Computer Aided Verification},
	publisher = {Springer Berlin Heidelberg},
	author = {Lahiri, Shuvendu K. and Hawblitzel, Chris and Kawaguchi, Ming and Rebêlo, Henrique},
	editor = {Madhusudan, P. and Seshia, Sanjit A.},
	date = {2012},
	langid = {english},
	keywords = {Symbolic Execution, Equivalence Check, Imperative Language, Imperative Program, Source Language},
	file = {Springer Full Text PDF:/Users/richardford/Zotero/storage/NDSQ5WIC/Lahiri et al. - 2012 - SYMDIFF A Language-Agnostic Semantic Diff Tool fo.pdf:application/pdf}
}

@article{adams_common_2015,
	title = {The Common {HOL} Platform},
	volume = {186},
	issn = {2075-2180},
	url = {http://arxiv.org/abs/1507.08718},
	doi = {10.4204/EPTCS.186.6},
	abstract = {The Common {HOL} project aims to facilitate porting source code and proofs between members of the {HOL} family of theorem provers. At the heart of the project is the Common {HOL} Platform, which defines a standard {HOL} theory and {API} that aims to be compatible with all {HOL} systems. So far, {HOL} Light and hol90 have been adapted for conformance, and {HOL} Zero was originally developed to conform. In this paper we provide motivation for a platform, give an overview of the Common {HOL} Platform's theory and {API} components, and show how to adapt legacy systems. We also report on the platform's successful application in the hand-translation of a few thousand lines of source code from {HOL} Light to {HOL} Zero.},
	pages = {42--56},
	journaltitle = {Electronic Proceedings in Theoretical Computer Science},
	author = {Adams, Mark},
	urldate = {2019-02-01},
	date = {2015-07-30},
	eprinttype = {arxiv},
	eprint = {1507.08718},
	keywords = {Computer Science - Logic in Computer Science, Computer Science - Digital Libraries},
	file = {arXiv\:1507.08718 PDF:/Users/richardford/Zotero/storage/4DPSDJ3D/Adams - 2015 - The Common HOL Platform.pdf:application/pdf;arXiv.org Snapshot:/Users/richardford/Zotero/storage/T6XBJWLE/1507.html:text/html}
}

@online{shulman_hott_2013,
	title = {The {HoTT} Book},
	url = {https://homotopytypetheory.org/book/},
	abstract = {Homotopy Type Theory: Univalent Foundations of Mathematics The Univalent Foundations Program Institute for Advanced Study Buy a hardcover copy for \$22.05. [620 pages, 6″ × 9″ size, hard…},
	titleaddon = {Homotopy Type Theory},
	author = {Shulman, Mike},
	urldate = {2019-02-01},
	date = {2013-03-12},
	langid = {english},
	file = {Snapshot:/Users/richardford/Zotero/storage/TCY2DTGX/book.html:text/html}
}

@article{voevodsky_homotopy_nodate,
	title = {Homotopy Type Theory: Univalent Foundations of Mathematics},
	pages = {490},
	author = {Voevodsky, Vladimir},
	langid = {english},
	file = {Homotopy Type Theory Univalent Foundations of Mat.pdf:/Users/richardford/Zotero/storage/933KJZF5/Homotopy Type Theory Univalent Foundations of Mat.pdf:application/pdf}
}

@inproceedings{nelson_hyperkernel:_2017,
	location = {New York, {NY}, {USA}},
	title = {Hyperkernel: Push-Button Verification of an {OS} Kernel},
	isbn = {978-1-4503-5085-3},
	url = {http://doi.acm.org/10.1145/3132747.3132748},
	doi = {10.1145/3132747.3132748},
	series = {{SOSP} '17},
	shorttitle = {Hyperkernel},
	abstract = {This paper describes an approach to designing, implementing, and formally verifying the functional correctness of an {OS} kernel, named Hyperkernel, with a high degree of proof automation and low proof burden. We base the design of Hyperkernel's interface on xv6, a Unix-like teaching operating system. Hyperkernel introduces three key ideas to achieve proof automation: it finitizes the kernel interface to avoid unbounded loops or recursion; it separates kernel and user address spaces to simplify reasoning about virtual memory; and it performs verification at the {LLVM} intermediate representation level to avoid modeling complicated C semantics. We have verified the implementation of Hyperkernel with the Z3 {SMT} solver, checking a total of 50 system calls and other trap handlers. Experience shows that Hyperkernel can avoid bugs similar to those found in xv6, and that the verification of Hyperkernel can be achieved with a low proof burden.},
	pages = {252--269},
	booktitle = {Proceedings of the 26th Symposium on Operating Systems Principles},
	publisher = {{ACM}},
	author = {Nelson, Luke and Sigurbjarnarson, Helgi and Zhang, Kaiyuan and Johnson, Dylan and Bornholt, James and Torlak, Emina and Wang, Xi},
	urldate = {2019-02-01},
	date = {2017},
	file = {ACM Full Text PDF:/Users/richardford/Zotero/storage/79Z44YVX/Nelson et al. - 2017 - Hyperkernel Push-Button Verification of an OS Ker.pdf:application/pdf}
}

@inproceedings{nelson_hyperkernel:_2017-1,
	location = {Shanghai, China},
	title = {Hyperkernel: Push-Button Verification of an {OS} Kernel - Slides},
	isbn = {978-1-4503-5085-3},
	url = {http://dl.acm.org/citation.cfm?doid=3132747.3132748},
	doi = {10.1145/3132747.3132748},
	shorttitle = {Hyperkernel},
	eventtitle = {the 26th Symposium},
	pages = {252--269},
	booktitle = {Proceedings of the 26th Symposium on Operating Systems Principles  - {SOSP} '17},
	publisher = {{ACM} Press},
	author = {Nelson, Luke and Sigurbjarnarson, Helgi and Zhang, Kaiyuan and Johnson, Dylan and Bornholt, James and Torlak, Emina and Wang, Xi},
	urldate = {2019-02-01},
	date = {2017},
	langid = {english},
	file = {Nelson et al. - 2017 - Hyperkernel Push-Button Verification of an OS Ker.pdf:/Users/richardford/Zotero/storage/WR6NX9HN/Nelson et al. - 2017 - Hyperkernel Push-Button Verification of an OS Ker.pdf:application/pdf}
}

@online{jung_iris_nodate,
	title = {Iris Project},
	url = {https://iris-project.org/},
	author = {Jung, Ralf},
	urldate = {2019-02-01},
	file = {Iris Project:/Users/richardford/Zotero/storage/2R8EYKZ5/iris-project.org.html:text/html}
}

@online{birkedal_iris_nodate,
	title = {Iris Tutorial},
	url = {https://iris-project.org/tutorial-material.html},
	author = {Birkedal, Lars and Bizjak, Aleš},
	urldate = {2019-02-01},
	file = {Iris Tutorial:/Users/richardford/Zotero/storage/WF7L6JWA/tutorial-material.html:text/html}
}

@article{jung_iris_2018,
	title = {Iris from the ground up: A modular foundation for higher-order concurrent separation logic},
	volume = {28},
	issn = {0956-7968, 1469-7653},
	url = {https://www.cambridge.org/core/journals/journal-of-functional-programming/article/iris-from-the-ground-up-a-modular-foundation-for-higherorder-concurrent-separation-logic/26301B518CE2C52796BFA12B8BAB5B5F},
	doi = {10.1017/S0956796818000151},
	shorttitle = {Iris from the ground up},
	abstract = {Iris is a framework for higher-order concurrent separation logic, which has been implemented in the Coq proof assistant and deployed very effectively in a wide variety of verification projects. Iris was designed with the express goal of simplifying and consolidating the foundations of modern separation logics, but it has evolved over time, and the design and semantic foundations of Iris itself have yet to be fully written down and explained together properly in one place. Here, we attempt to fill this gap, presenting a reasonably complete picture of the latest version of Iris (version 3.1), from first principles and in one coherent narrative.},
	journaltitle = {Journal of Functional Programming},
	author = {Jung, Ralf and Krebbers, Robbert and Jourdan, Jacques-Henri and Bizjak, Aleš and Birkedal, Lars and Dreyer, Derek},
	urldate = {2019-02-01},
	date = {2018},
	langid = {english},
	file = {Snapshot:/Users/richardford/Zotero/storage/3QJUK97X/26301B518CE2C52796BFA12B8BAB5B5F.html:text/html}
}

@article{paulson_foundation_2000,
	title = {The Foundation of a Generic Theorem Prover},
	url = {http://arxiv.org/abs/cs/9301105},
	abstract = {Isabelle is an interactive theorem prover that supports a variety of logics. It represents rules as propositions (not as functions) and builds proofs by combining rules. These operations constitute a meta-logic (or `logical framework') in which the object-logics are formalized. Isabelle is now based on higher-order logic -- a precise and well-understood foundation. Examples illustrate use of this meta-logic to formalize logics and proofs. Axioms for first-order logic are shown sound and complete. Backwards proof is formalized by meta-reasoning about object-level entailment. Higher-order logic has several practical advantages over other meta-logics. Many proof techniques are known, such as Huet's higher-order unification procedure.},
	journaltitle = {{arXiv}:cs/9301105},
	author = {Paulson, Lawrence C.},
	urldate = {2019-02-01},
	date = {2000-10-30},
	eprinttype = {arxiv},
	eprint = {cs/9301105},
	keywords = {Computer Science - Logic in Computer Science, F.3.1, F.4.1},
	file = {arXiv\:cs/9301105 PDF:/Users/richardford/Zotero/storage/Y5PBFBXS/Paulson - 2000 - The Foundation of a Generic Theorem Prover.pdf:application/pdf;arXiv.org Snapshot:/Users/richardford/Zotero/storage/SLUTEXCX/9301105.html:text/html}
}

@article{wenzel_isabelle/isar_2018,
	title = {The Isabelle/Isar Reference Manual},
	url = {https://core.ac.uk/display/22830292},
	abstract = {Intelligible semi-automated reasoning (Isar) is a generic approach to readable formal proof documents. It sets out to bridge the semantic gap between any internal notions of proof based on primitive inferences and tactics, and an appropriate level of abstraction for user-level work. The Isar formal proof language has been designed to satisfy quite contradictory requirements, being both \&quot;declarative\&quot; and immediately \&quot;executable\&quot;, by virtue of the Isar/{VM}  interpreter. The Isabelle/Isar system provides an interpreter for the Isar formal proof language. The input may consist either of proper document constructors, or improper auxiliary commands (for diagnostics, exploration etc.). Proof texts consisting of proper elements only admit a purely static reading, thus being intelligible later without requiring dynamic replay that is so typical for traditional proof scripts. Any of the Isabelle/Isar commands may be executed in single-steps, so basically the interpreter has a proof text debugger ..},
	author = {Wenzel, Markus},
	urldate = {2019-02-01},
	date = {2018},
	langid = {english},
	file = {Snapshot:/Users/richardford/Zotero/storage/M7HKI4WD/22830292.html:text/html;Wenzel - The IsabelleIsar Reference Manual.pdf:/Users/richardford/Zotero/storage/R6VSCXHR/Wenzel - The IsabelleIsar Reference Manual.pdf:application/pdf}
}

@article{ishtiaq_bi_2011,
	title = {{BI} As an Assertion Language for Mutable Data Structures},
	volume = {46},
	issn = {0362-1340},
	url = {http://doi.acm.org/10.1145/1988042.1988050},
	doi = {10.1145/1988042.1988050},
	abstract = {Reynolds has developed a logic for reasoning about mutable data structures in which the pre- and postconditions are written in an intuitionistic logic enriched with a spatial form of conjunction. We investigate the approach from the point of view of the logic {BI} of bunched implications of O'Hearn and Pym. We begin by giving a model in which the law of the excluded middle holds, thus showing that the approach is compatible with classical logic. The relationship between the intuitionistic and classical versions of the system is established by a translation, analogous to a translation from intuitionistic logic into the modal logic S4. We also consider the question of completeness of the axioms. {BI}'s spatial implication is used to express weakest preconditions for object-component assignments, and an axiom for allocating a cons cell is shown to be complete under an interpretation of triples that allows a command to be applied to states with dangling pointers. We make this latter a feature, by incorporating an operation, and axiom, for disposing of memory. Finally, we describe a local character enjoyed by specifications in the logic, and show how this enables a class of frame axioms, which say what parts of the heap don't change, to be inferred automatically.},
	pages = {84--96},
	number = {4},
	journaltitle = {{SIGPLAN} Not.},
	author = {Ishtiaq, Samin and O'Hearn, Peter W.},
	urldate = {2019-02-01},
	date = {2011-05},
	file = {ACM Full Text PDF:/Users/richardford/Zotero/storage/FT687HNC/Ishtiaq and O'Hearn - 2011 - BI As an Assertion Language for Mutable Data Struc.pdf:application/pdf}
}

@incollection{hutchison_seloger:_2013,
	location = {Berlin, Heidelberg},
	title = {{SeLoger}: A Tool for Graph-Based Reasoning in Separation Logic},
	volume = {8044},
	isbn = {978-3-642-39798-1 978-3-642-39799-8},
	url = {http://link.springer.com/10.1007/978-3-642-39799-8_55},
	shorttitle = {{SeLoger}},
	abstract = {This paper introduces the tool {SeLoger}, which is a reasoner for satisﬁability and entailment in a fragment of separation logic with pointers and linked lists. {SeLoger} builds upon and extends graphbased algorithms that have recently been introduced in order to settle both decision problems in polynomial time. Running {SeLoger} on standard benchmarks shows that the tool outperforms current state-of-theart tools by orders of magnitude.},
	pages = {790--795},
	booktitle = {Computer Aided Verification},
	publisher = {Springer Berlin Heidelberg},
	author = {Haase, Christoph and Ishtiaq, Samin and Ouaknine, Joël and Parkinson, Matthew J.},
	editor = {Sharygina, Natasha and Veith, Helmut},
	editorb = {Hutchison, David and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M. and Mattern, Friedemann and Mitchell, John C. and Naor, Moni and Nierstrasz, Oscar and Pandu Rangan, C. and Steffen, Bernhard and Sudan, Madhu and Terzopoulos, Demetri and Tygar, Doug and Vardi, Moshe Y. and Weikum, Gerhard},
	editorbtype = {redactor},
	urldate = {2019-02-01},
	date = {2013},
	langid = {english},
	doi = {10.1007/978-3-642-39799-8_55},
	file = {Haase et al. - 2013 - SeLoger A Tool for Graph-Based Reasoning in Separ.pdf:/Users/richardford/Zotero/storage/PQPRK2IX/Haase et al. - 2013 - SeLoger A Tool for Graph-Based Reasoning in Separ.pdf:application/pdf}
}

@article{crick_share_2014,
	title = {"Share and Enjoy": Publishing Useful and Usable Scientific Models},
	url = {http://arxiv.org/abs/1409.0367},
	shorttitle = {"Share and Enjoy"},
	abstract = {The reproduction and replication of reported scientific results is a hot topic within the academic community. The retraction of numerous studies from a wide range of disciplines, from climate science to bioscience, has drawn the focus of many commentators, but there exists a wider socio-cultural problem that pervades the scientific community. Sharing code, data and models often requires extra effort; this is currently seen as a significant overhead that may not be worth the time investment. Automated systems, which allow easy reproduction of results, offer the potential to incentivise a culture change and drive the adoption of new techniques to improve the efficiency of scientific exploration. In this paper, we discuss the value of improved access and sharing of the two key types of results arising from work done in the computational sciences: models and algorithms. We propose the development of an integrated cloud-based system underpinning computational science, linking together software and data repositories, toolchains, workflows and outputs, providing a seamless automated infrastructure for the verification and validation of scientific models and in particular, performance benchmarks.},
	journaltitle = {{arXiv}:1409.0367 [cs]},
	author = {Crick, Tom and Hall, Benjamin A. and Ishtiaq, Samin and Takeda, Kenji},
	urldate = {2019-02-01},
	date = {2014-09-01},
	eprinttype = {arxiv},
	eprint = {1409.0367},
	keywords = {Computer Science - Computational Engineering, Finance, and Science},
	file = {arXiv\:1409.0367 PDF:/Users/richardford/Zotero/storage/LKKTEADA/Crick et al. - 2014 - Share and Enjoy Publishing Useful and Usable Sc.pdf:application/pdf;arXiv.org Snapshot:/Users/richardford/Zotero/storage/YWG36WKR/1409.html:text/html}
}

@inproceedings{brockschmidt_t2:_2016,
	title = {T2: Temporal Property Verification},
	isbn = {978-3-662-49674-9},
	series = {Lecture Notes in Computer Science},
	shorttitle = {T2},
	abstract = {We present the open-source tool T2, the first public release from the {TERMINATOR} project [9]. T2 has been extended over the past decade to support automatic temporal-logic proving techniques and to handle a general class of user-provided liveness and safety properties. Input can be provided in a native format and in C, via the support of the {LLVM} compiler framework. We briefly discuss T2’s architecture, its underlying techniques, and conclude with an experimental illustration of its competitiveness and directions for future extensions.},
	pages = {387--393},
	booktitle = {Tools and Algorithms for the Construction and Analysis of Systems},
	publisher = {Springer Berlin Heidelberg},
	author = {Brockschmidt, Marc and Cook, Byron and Ishtiaq, Samin and Khlaaf, Heidy and Piterman, Nir},
	editor = {Chechik, Marsha and Raskin, Jean-François},
	date = {2016},
	langid = {english},
	file = {Brockschmidt et al. - 2016 - T2 Temporal Property Verification.pdf:/Users/richardford/Zotero/storage/NTYHNVUJ/Brockschmidt et al. - 2016 - T2 Temporal Property Verification.pdf:application/pdf}
}

@article{arias_jscoq:_2017,
	title = {{jsCoq}: Towards Hybrid Theorem Proving Interfaces},
	volume = {239},
	issn = {2075-2180},
	url = {http://arxiv.org/abs/1701.07125},
	doi = {10.4204/EPTCS.239.2},
	shorttitle = {{jsCoq}},
	abstract = {We describe {jsCcoq}, a new platform and user environment for the Coq interactive proof assistant. The {jsCoq} system targets the {HTML}5-{ECMAScript} 2015 specification, and it is typically run inside a standards-compliant browser, without the need of external servers or services. Targeting educational use, {jsCoq} allows the user to start interaction with proof scripts right away, thanks to its self-contained nature. Indeed, a full Coq environment is packed along the proof scripts, easing distribution and installation. Starting to use {jsCoq} is as easy as clicking on a link. The current release ships more than 10 popular Coq libraries, and supports popular books such as Software Foundations or Certified Programming with Dependent Types. The new target platform has opened up new interaction and display possibilities. It has also fostered the development of some new Coq-related technology. In particular, we have implemented a new serialization-based protocol for interaction with the proof assistant, as well as a new package format for library distribution.},
	pages = {15--27},
	journaltitle = {Electronic Proceedings in Theoretical Computer Science},
	author = {Arias, Emilio Jesús Gallego and Pin, Benoît and Jouvelot, Pierre},
	urldate = {2019-02-01},
	date = {2017-01-24},
	eprinttype = {arxiv},
	eprint = {1701.07125},
	keywords = {Computer Science - Logic in Computer Science, Computer Science - Programming Languages, Computer Science - Human-Computer Interaction, Computer Science - Machine Learning},
	file = {arXiv\:1701.07125 PDF:/Users/richardford/Zotero/storage/KW34YHZU/Arias et al. - 2017 - jsCoq Towards Hybrid Theorem Proving Interfaces.pdf:application/pdf;arXiv.org Snapshot:/Users/richardford/Zotero/storage/6S4YQDBI/1701.html:text/html}
}

@online{kaiser_destruct_nodate,
	title = {A “destruct” Tactic for Mtac2 - {POPL} 2018},
	url = {https://popl18.sigplan.org/event/coqpl-2018-a-destruct-tactic-for-mtac2},
	author = {Kaiser, Jan-Oliver and Ziliani, Beta},
	urldate = {2019-02-01},
	file = {A “destruct” Tactic for Mtac2 - POPL 2018:/Users/richardford/Zotero/storage/P2PWXNIY/coqpl-2018-a-destruct-tactic-for-mtac2.html:text/html;A “destruct” Tactic for Mtac2 - POPL 2018.pdf:/Users/richardford/Zotero/storage/LQW2W8LV/A “destruct” Tactic for Mtac2 - POPL 2018.pdf:application/pdf}
}

@inproceedings{hathhorn_defining_2015,
	location = {New York, {NY}, {USA}},
	title = {Defining the Undefinedness of C},
	isbn = {978-1-4503-3468-6},
	url = {http://doi.acm.org/10.1145/2737924.2737979},
	doi = {10.1145/2737924.2737979},
	series = {{PLDI} '15},
	abstract = {We present a ``negative'' semantics of the C11 language---a semantics that does not just give meaning to correct programs, but also rejects undefined programs. We investigate undefined behavior in C and discuss the techniques and special considerations needed for formally specifying it. We have used these techniques to modify and extend a semantics of C into one that captures undefined behavior. The amount of semantic infrastructure and effort required to achieve this was unexpectedly high, in the end nearly doubling the size of the original semantics. From our semantics, we have automatically extracted an undefinedness checker, which we evaluate against other popular analysis tools, using our own test suite in addition to a third-party test suite. Our checker is capable of detecting examples of all 77 categories of core language undefinedness appearing in the C11 standard, more than any other tool we considered. Based on this evaluation, we argue that our work is the most comprehensive and complete semantic treatment of undefined behavior in C, and thus of the C language itself.},
	pages = {336--345},
	booktitle = {Proceedings of the 36th {ACM} {SIGPLAN} Conference on Programming Language Design and Implementation},
	publisher = {{ACM}},
	author = {Hathhorn, Chris and Ellison, Chucky and Roşu, Grigore},
	urldate = {2019-02-01},
	date = {2015},
	keywords = {C11, K Framework, Programming language semantics, Undefined behavior},
	file = {ACM Full Text PDF:/Users/richardford/Zotero/storage/5UX692DD/Hathhorn et al. - 2015 - Defining the Undefinedness of C.pdf:application/pdf}
}

@online{kubota_foundations_nodate,
	title = {Foundations of Mathematics – Owl of Minerva Press},
	url = {http://owlofminerva.net/foundations-of-mathematics/},
	author = {Kubota, Ken},
	urldate = {2019-02-01},
	langid = {american},
	file = {Snapshot:/Users/richardford/Zotero/storage/TBEEJ37H/foundations-of-mathematics.html:text/html}
}

@article{kubota_foundations_2016,
	title = {Foundations of Mathematics},
	url = {http://www.owlofminerva.net/doi/10.4444/100/111/},
	doi = {10.4444/100.111},
	author = {Kubota, Ken},
	urldate = {2019-02-01},
	date = {2016},
	langid = {english},
	file = {Kubota - 2016 - Foundations of Mathematics.pdf:/Users/richardford/Zotero/storage/LTUGMTBE/Kubota - 2016 - Foundations of Mathematics.pdf:application/pdf}
}

@online{lamport_specifying_nodate,
	title = {Specifying Systems},
	url = {https://lamport.azurewebsites.net/tla/book.html},
	author = {Lamport, Leslie},
	urldate = {2019-02-01},
	file = {Specifying Systems:/Users/richardford/Zotero/storage/KYBHG99K/book.html:text/html;Specifying Systems.pdf:/Users/richardford/Zotero/storage/2XZL6LR2/Specifying Systems.pdf:application/pdf}
}

@online{wikibook_latex_nodate,
	title = {{LaTeX} - Wikibooks, open books for an open world},
	url = {https://en.wikibooks.org/wiki/LaTeX},
	author = {wikibook},
	urldate = {2019-02-01},
	file = {LaTeX - Wikibooks, open books for an open world:/Users/richardford/Zotero/storage/6ML74WS9/LaTeX.html:text/html;LaTeX - Wikibooks, open books for an open world.pdf:/Users/richardford/Zotero/storage/6K57KTSZ/LaTeX - Wikibooks, open books for an open world.pdf:application/pdf}
}

@article{pakin_comprehensive_nodate,
	title = {The Comprehensive {LaTeX} Symbol List},
	abstract = {This document lists 14283 symbols and the corresponding {LATEX} commands that produce them. Some of these symbols are guaranteed to be available in every {LATEX} 2������ system; others require fonts and packages that may not accompany a given distribution and that therefore need to be installed. All of the fonts and packages used to prepare this document—as well as this document itself—are freely available from the Comprehensive {TEX} Archive Network (http://www.ctan.org/).},
	pages = {358},
	author = {Pakin, Scott},
	langid = {english},
	file = {Pakin - The Comprehensive LaTeX Symbol List.pdf:/Users/richardford/Zotero/storage/8ZIDMML6/Pakin - The Comprehensive LaTeX Symbol List.pdf:application/pdf}
}

@article{ebner_metaprogramming_2017,
	title = {A Metaprogramming Framework for Formal Verification},
	volume = {1},
	issn = {2475-1421},
	url = {http://doi.acm.org/10.1145/3110278},
	doi = {10.1145/3110278},
	abstract = {We describe the metaprogramming framework currently used in Lean, an interactive theorem prover based on dependent type theory. This framework extends Lean's object language with an {API} to some of Lean's internal structures and procedures, and provides ways of reflecting object-level expressions into the metalanguage. We provide evidence to show that our implementation is performant, and that it provides a convenient and flexible way of writing not only small-scale interactive tactics, but also more substantial kinds of automation.},
	pages = {34:1--34:29},
	issue = {{ICFP}},
	journaltitle = {Proc. {ACM} Program. Lang.},
	author = {Ebner, Gabriel and Ullrich, Sebastian and Roesch, Jared and Avigad, Jeremy and de Moura, Leonardo},
	urldate = {2019-02-01},
	date = {2017-08},
	keywords = {theorem proving, dependent type theory, metaprogramming, tactic language},
	file = {ACM Full Text PDF:/Users/richardford/Zotero/storage/BQCSENJ7/Ebner et al. - 2017 - A Metaprogramming Framework for Formal Verificatio.pdf:application/pdf}
}

@online{letouzey_certified_nodate,
	title = {Certified functional programming : Program extraction within Coq proof assistant},
	url = {https://www.researchgate.net/publication/280790704_Certified_functional_programming_Program_extraction_within_Coq_proof_assistant},
	shorttitle = {(8) ({PDF}) Certified functional programming},
	abstract = {{NOTA}: {THIS} {IS} {THE} {ENGLISH} {TRANSLATION} {OF} {MY} {FRENCH} {PHD} {MANUSCRIPT}. This work concerns the generation of programs which are certified to be correct by construction. These programs are obtained by extracting relevant information from constructive proofs made with the Coq proof assistant. Such a translation, named ``extraction'', of constructive proofs into functional programs is not new, and corresponds to an isomorphism known as Curry-Howard's. An extraction tool has been part of Coq assistant for a long time. But this old extraction tool suffered from several limitations: in particular, some Coq proofs were refused by it, whereas some others led to incorrect programs. In order to overcome these limitations, we built a completely new extraction tool for Coq, including both a new theory and a new implementation. Concerning theory, we developed new correctness proofs for this extraction mechanism. These new proofs are both complex and original. Concerning implementation, we focused on the generation of efficient and realistic code, which can be integrated in large-scale software developments, using modules and interfaces. Finally, we also present several case studies illustrating the capabilities of our new extraction. For example, we describe the certification of a modular library of finite set structures, and the production of programs about real exact arithmetic, starting from a formalization of constructive real analysis. These examples show the progress already achieved, even if the situation is not perfect yet, in particular in the last study.},
	titleaddon = {{ResearchGate}},
	author = {Letouzey, Pierre},
	urldate = {2019-02-01},
	langid = {english},
	file = {(8) (PDF) Certified functional programming  Progr.pdf:/Users/richardford/Zotero/storage/5IQA98EJ/(8) (PDF) Certified functional programming  Progr.pdf:application/pdf;Snapshot:/Users/richardford/Zotero/storage/V78NSVFJ/280790704_Certified_functional_programming_Program_extraction_within_Coq_proof_assistant.html:text/html}
}

@inproceedings{kang_crellvm:_2018,
	location = {New York, {NY}, {USA}},
	title = {Crellvm: Verified Credible Compilation for {LLVM}},
	isbn = {978-1-4503-5698-5},
	url = {http://doi.acm.org/10.1145/3192366.3192377},
	doi = {10.1145/3192366.3192377},
	series = {{PLDI} 2018},
	shorttitle = {Crellvm},
	abstract = {Production compilers such as {GCC} and {LLVM} are large complex software systems, for which achieving a high level of reliability is hard. Although testing is an effective method for finding bugs, it alone cannot guarantee a high level of reliability. To provide a higher level of reliability, many approaches that examine compilers' internal logics have been proposed. However, none of them have been successfully applied to major optimizations of production compilers. This paper presents Crellvm: a verified credible compilation framework for {LLVM}, which can be used as a systematic way of providing a high level of reliability for major optimizations in {LLVM}. Specifically, we augment an {LLVM} optimizer to generate translation results together with their correctness proofs, which can then be checked by a proof checker formally verified in Coq. As case studies, we applied our approach to two major optimizations of {LLVM}: register promotion mem2reg and global value numbering gvn, having found four new miscompilation bugs (two in each).},
	pages = {631--645},
	booktitle = {Proceedings of the 39th {ACM} {SIGPLAN} Conference on Programming Language Design and Implementation},
	publisher = {{ACM}},
	author = {Kang, Jeehoon and Kim, Yoonseung and Song, Youngju and Lee, Juneyoung and Park, Sanghoon and Shin, Mark Dongyeon and Kim, Yonghyun and Cho, Sungkeun and Choi, Joonwon and Hur, Chung-Kil and Yi, Kwangkeun},
	urldate = {2019-02-01},
	date = {2018},
	keywords = {Coq, compiler verification, credible compilation, {LLVM}, relational Hoare logic, translation validation},
	file = {ACM Full Text PDF:/Users/richardford/Zotero/storage/9BFDP4D4/Kang et al. - 2018 - Crellvm Verified Credible Compilation for LLVM.pdf:application/pdf}
}

@online{luo_extended_nodate,
	title = {An Extended Calculus of Constructions},
	url = {http://www.lfcs.inf.ed.ac.uk/reports/90/ECS-LFCS-90-118/},
	author = {Luo, Zhaohui},
	urldate = {2019-02-01},
	file = {Snapshot:/Users/richardford/Zotero/storage/7C9DFE56/ECS-LFCS-90-118.html:text/html;Zhaohui Luo - An Extended Calculus of Constructions.pdf:/Users/richardford/Zotero/storage/LXDDMBKD/Zhaohui Luo - An Extended Calculus of Constructions.pdf:application/pdf}
}

@online{patterson_compositional_nodate,
	title = {On Compositional Compiler Correctness and Fully Abstract Compilation - {POPL} 2018},
	url = {https://popl18.sigplan.org/event/prisc-2018-on-compositional-compiler-correctness-and-fully-abstract-compilation},
	author = {Patterson, Daniel and Ahmed, Amal},
	urldate = {2019-02-01},
	file = {On Compositional Compiler Correctness and Fully Abstract Compilation - POPL 2018:/Users/richardford/Zotero/storage/3WP6IYAC/prisc-2018-on-compositional-compiler-correctness-and-fully-abstract-compilation.html:text/html}
}

@article{patterson_compositional_nodate-1,
	title = {On Compositional Compiler Correctness and Fully Abstract Compilation},
	url = {https://popl18.sigplan.org/event/prisc-2018-on-compositional-compiler-correctness-and-fully-abstract-compilation},
	pages = {3},
	author = {Patterson, Daniel and Ahmed, Amal},
	langid = {english},
	file = {Garillot2009_Chapter_PackagingMathematicalStructure.pdf:/Users/richardford/Zotero/storage/XFXC4QGZ/Garillot2009_Chapter_PackagingMathematicalStructure.pdf:application/pdf;Patterson and Ahmed - On Compositional Compiler Correctness and Fully Ab.pdf:/Users/richardford/Zotero/storage/4BK4I6T7/Patterson and Ahmed - On Compositional Compiler Correctness and Fully Ab.pdf:application/pdf}
}

@book{gasser_building_1988,
	location = {New York},
	title = {Building a secure computer system},
	isbn = {978-0-442-23022-7},
	pagetotal = {288},
	publisher = {Van Nostrand Reinhold Co},
	author = {Gasser, Morrie},
	date = {1988},
	keywords = {Computer security, System design},
	file = {Gasser - 1988 - Building a secure computer system.pdf:/Users/richardford/Zotero/storage/DRV4KDU6/Gasser - 1988 - Building a secure computer system.pdf:application/pdf}
}

@inproceedings{costan_sanctum:_2016,
	title = {Sanctum: Minimal Hardware Extensions for Strong Software Isolation},
	url = {https://www.usenix.org/conference/usenixsecurity16/technical-sessions/presentation/costan},
	shorttitle = {Sanctum},
	eventtitle = {25th \{{USENIX}\} Security Symposium (\{{USENIX}\} Security 16)},
	pages = {857--874},
	author = {Costan, Victor and Lebedev, Ilia and Devadas, Srinivas},
	urldate = {2019-02-01},
	date = {2016},
	langid = {english},
	file = {Full Text PDF:/Users/richardford/Zotero/storage/XM5L2QXN/Costan et al. - 2016 - Sanctum Minimal Hardware Extensions for Strong So.pdf:application/pdf}
}

@article{costan_secure_2017,
	title = {Secure Processors Part I: Background, Taxonomy for Secure Enclaves and Intel {SGX} Architecture},
	volume = {11},
	issn = {1551-3939, 1551-3947},
	url = {http://www.nowpublishers.com/article/Details/EDA-051},
	doi = {10.1561/1000000051},
	shorttitle = {Secure Processors Part I},
	pages = {1--248},
	number = {1},
	journaltitle = {Foundations and Trends® in Electronic Design Automation},
	author = {Costan, Victor and Lebedev, Ilia and Devadas, Srinivas},
	urldate = {2019-02-01},
	date = {2017},
	langid = {english},
	file = {Costan et al. - 2017 - Secure Processors Part I Background, Taxonomy for.pdf:/Users/richardford/Zotero/storage/2ZB798A8/Costan et al. - 2017 - Secure Processors Part I Background, Taxonomy for.pdf:application/pdf}
}

@article{costan_secure_2017-1,
	title = {Secure Processors Part {II}: Intel {SGX} Security Analysis and {MIT} Sanctum Architecture},
	volume = {11},
	issn = {1551-3939, 1551-3947},
	url = {http://www.nowpublishers.com/article/Details/EDA-052},
	doi = {10.1561/1000000052},
	shorttitle = {Secure Processors Part {II}},
	pages = {249--361},
	number = {3},
	journaltitle = {Foundations and Trends® in Electronic Design Automation},
	author = {Costan, Victor and Lebedev, Ilia and Devadas, Srinivas},
	urldate = {2019-02-01},
	date = {2017},
	langid = {english},
	file = {Costan et al. - 2017 - Secure Processors Part II Intel SGX Security Anal.pdf:/Users/richardford/Zotero/storage/64GE2MA5/Costan et al. - 2017 - Secure Processors Part II Intel SGX Security Anal.pdf:application/pdf}
}

@online{pottier_menhir_nodate,
	title = {Menhir Reference Manual (version 20181113)},
	url = {http://gallium.inria.fr/~fpottier/menhir/manual.html},
	author = {Pottier, Francois and {REgis}-Gianas, Yan},
	urldate = {2019-02-01},
	file = {Menhir Reference Manual (version 20181113):/Users/richardford/Zotero/storage/P8JV42LL/manual.html:text/html;Menhir Reference Manual (version 20181113).pdf:/Users/richardford/Zotero/storage/P7ZHFCWM/Menhir Reference Manual (version 20181113).pdf:application/pdf}
}

@software{jacobs_verifast/verifast:_2019,
	title = {verifast/verifast: Research prototype tool for modular formal verification of C and Java programs},
	rights = {View license},
	url = {https://github.com/verifast/verifast},
	shorttitle = {Research prototype tool for modular formal verification of C and Java programs},
	publisher = {verifast},
	author = {Jacobs, Bart},
	urldate = {2019-02-01},
	date = {2019-01-25},
	note = {original-date: 2013-11-19T08:57:02Z}
}

@article{jacobs_featherweight_2015,
	title = {Featherweight {VeriFast}},
	volume = {11},
	issn = {18605974},
	url = {http://arxiv.org/abs/1507.07697},
	doi = {10.2168/LMCS-11(3:19)2015},
	abstract = {{VeriFast} is a leading research prototype tool for the sound modular verification of safety and correctness properties of single-threaded and multithreaded C and Java programs. It has been used as a vehicle for exploration and validation of novel program verification techniques and for industrial case studies; it has served well at a number of program verification competitions; and it has been used for teaching by multiple teachers independent of the authors. However, until now, while {VeriFast}'s operation has been described informally in a number of publications, and specific verification techniques have been formalized, a clear and precise exposition of how {VeriFast} works has not yet appeared. In this article we present for the first time a formal definition and soundness proof of a core subset of the {VeriFast} program verification approach. The exposition aims to be both accessible and rigorous: the text is based on lecture notes for a graduate course on program verification, and it is backed by an executable machine-readable definition and machine-checked soundness proof in Coq.},
	number = {3},
	journaltitle = {Logical Methods in Computer Science},
	author = {Jacobs, Bart and Vogels, Frédéric and Piessens, Frank},
	urldate = {2019-02-01},
	date = {2015-09-22},
	eprinttype = {arxiv},
	eprint = {1507.07697},
	keywords = {Computer Science - Logic in Computer Science},
	file = {arXiv\:1507.07697 PDF:/Users/richardford/Zotero/storage/6M9VGQ6K/Jacobs et al. - 2015 - Featherweight VeriFast.pdf:application/pdf;arXiv.org Snapshot:/Users/richardford/Zotero/storage/DVD7VF44/1507.html:text/html}
}

@report{jacobs_verifast_2008,
	title = {The {VeriFast} program verifier},
	abstract = {This note describes a separation-logic-based approach for the spec-ification and verification of safety properties of pointer-manipulating imperative programs. We describe the approach for the C language. The safety properties to be verified are specified as annotations in the source code, in the form of function preconditions and post-conditions expressed as separation logic assertions. To enable rich specifications, the user may include additional annotations that de-fine inductive datatypes, primitive recursive pure functions over these datatypes, and abstract predicates (i.e. named, parameterized assertions). A restricted form of existential quantification is sup-ported in assertions in the form of pattern matching. Verification is based on forward symbolic execution, where memory is represented as a separate conjunction of points-to as-sertions and abstract predicate assertions, and data values are rep-},
	author = {Jacobs, Bart and Piessens, Frank},
	date = {2008},
	file = {Citeseer - Full Text PDF:/Users/richardford/Zotero/storage/92SEBWLL/Jacobs and Piessens - 2008 - The VeriFast program verifier.pdf:application/pdf;Citeseer - Snapshot:/Users/richardford/Zotero/storage/5AS6HTW6/summary.html:text/html}
}

@article{jacobs_verifast_2017,
	title = {The {VeriFast} Program Veriﬁer: A Tutorial},
	pages = {102},
	author = {Jacobs, Bart and Smans, Jan and Piessens, Frank},
	date = {2017-11-28},
	langid = {english},
	file = {Jacobs et al. - The VeriFast Program Veriﬁer A Tutorial.pdf:/Users/richardford/Zotero/storage/EUBUNUXD/Jacobs et al. - The VeriFast Program Veriﬁer A Tutorial.pdf:application/pdf}
}

@online{leroy_ocaml_nodate,
	title = {{OCaml} Home Page},
	url = {https://ocaml.org/},
	author = {Leroy, Xavier},
	urldate = {2019-02-01},
	file = {OCaml – OCaml:/Users/richardford/Zotero/storage/GH352N3D/ocaml.org.html:text/html}
}

@online{minsky_real_nodate,
	title = {Real World {OCaml}},
	url = {http://dev.realworldocaml.org/},
	author = {Minsky, Yaron and Madhavapeddy, Anil and Hickey, Jason},
	urldate = {2019-02-01},
	file = {Real World OCaml:/Users/richardford/Zotero/storage/H2TNKC6U/dev.realworldocaml.org.html:text/html}
}

@inproceedings{lampson_abcds_2001,
	location = {New York, {NY}, {USA}},
	title = {The {ABCD}'s of Paxos},
	isbn = {978-1-58113-383-7},
	url = {http://doi.acm.org/10.1145/383962.383969},
	doi = {10.1145/383962.383969},
	series = {{PODC} '01},
	abstract = {We explain how consensus is used to implement replicated state machines, the general mechanism for fault-tolerance. We describe an abstract version of Lamport's Paxos algorithm for asynchronous consensus. Then we derive the Byzantine, classic, and disk versions of Paxos from the abstract one, show how they are related to each other, and discuss the safety, liveness, and performance of each one.},
	pages = {13--},
	booktitle = {Proceedings of the Twentieth Annual {ACM} Symposium on Principles of Distributed Computing},
	publisher = {{ACM}},
	author = {Lampson, Butler},
	urldate = {2019-02-01},
	date = {2001},
	file = {ACM Full Text PDF:/Users/richardford/Zotero/storage/RSUUAANU/Lampson - 2001 - The ABCD's of Paxos.pdf:application/pdf}
}

@article{van_renesse_paxos_2015,
	title = {Paxos Made Moderately Complex},
	volume = {47},
	issn = {0360-0300},
	url = {http://doi.acm.org/10.1145/2673577},
	doi = {10.1145/2673577},
	abstract = {This article explains the full reconfigurable multidecree Paxos (or multi-Paxos) protocol. Paxos is by no means a simple protocol, even though it is based on relatively simple invariants. We provide pseudocode and explain it guided by invariants. We initially avoid optimizations that complicate comprehension. Next we discuss liveness, list various optimizations that make the protocol practical, and present variants of the protocol.},
	pages = {42:1--42:36},
	number = {3},
	journaltitle = {{ACM} Comput. Surv.},
	author = {Van Renesse, Robbert and Altinbuken, Deniz},
	urldate = {2019-02-01},
	date = {2015-02},
	keywords = {consensus, Replicated state machines, voting},
	file = {ACM Full Text PDF:/Users/richardford/Zotero/storage/WITY9Q45/Van Renesse and Altinbuken - 2015 - Paxos Made Moderately Complex.pdf:application/pdf}
}

@incollection{hutchison_improving_2012,
	location = {Berlin, Heidelberg},
	title = {Improving Real Analysis in Coq: A User-Friendly Approach to Integrals and Derivatives},
	volume = {7679},
	isbn = {978-3-642-35307-9 978-3-642-35308-6},
	url = {http://link.springer.com/10.1007/978-3-642-35308-6_22},
	shorttitle = {Improving Real Analysis in Coq},
	abstract = {Veriﬁcation of numerical analysis programs requires dealing with derivatives and integrals. High conﬁdence in this process can be achieved using a formal proof checker, such as Coq. Its standard library provides an axiomatization of real numbers and various lemmas about real analysis, which may be used for this purpose. Unfortunately, its deﬁnitions of derivative and integral are unpractical as they are partial functions that demand a proof term. This proof term makes the handling of mathematical formulas cumbersome and does not conform to traditional analysis. Other proof assistants usually do not suﬀer from this issue; for instance, they may rely on Hilbert’s epsilon to get total operators. In this paper, we propose a way to deﬁne total operators for derivative and integral without having to extend Coq’s standard axiomatization of real numbers. We proved the compatibility of our deﬁnitions with the standard library’s in order to leverage existing results. We also greatly improved automation for real analysis proofs that use Coq standard deﬁnitions. We exercised our approach on lemmas involving iterated partial derivatives and diﬀerentiation under the integral sign, that were missing from the formal proof of a numerical program solving the wave equation.},
	pages = {289--304},
	booktitle = {Certified Programs and Proofs},
	publisher = {Springer Berlin Heidelberg},
	author = {Boldo, Sylvie and Lelay, Catherine and Melquiond, Guillaume},
	editor = {Hawblitzel, Chris and Miller, Dale},
	editorb = {Hutchison, David and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M. and Mattern, Friedemann and Mitchell, John C. and Naor, Moni and Nierstrasz, Oscar and Pandu Rangan, C. and Steffen, Bernhard and Sudan, Madhu and Terzopoulos, Demetri and Tygar, Doug and Vardi, Moshe Y. and Weikum, Gerhard},
	editorbtype = {redactor},
	urldate = {2019-02-01},
	date = {2012},
	langid = {english},
	doi = {10.1007/978-3-642-35308-6_22},
	file = {Boldo et al. - 2012 - Improving Real Analysis in Coq A User-Friendly Ap.pdf:/Users/richardford/Zotero/storage/4BBRWC9Y/Boldo et al. - 2012 - Improving Real Analysis in Coq A User-Friendly Ap.pdf:application/pdf}
}

@article{martin-dorel_proving_2016,
	title = {Proving Tight Bounds on Univariate Expressions with Elementary Functions in Coq},
	volume = {57},
	issn = {1573-0670},
	url = {https://doi.org/10.1007/s10817-015-9350-4},
	doi = {10.1007/s10817-015-9350-4},
	abstract = {The verification of floating-point mathematical libraries requires computing numerical bounds on approximation errors. Due to the tightness of these bounds and the peculiar structure of approximation errors, such a verification is out of the reach of generic tools such as computer algebra systems. In fact, the inherent difficulty of computing such bounds often mandates a formal proof of them. In this paper, we present a tactic for the Coq proof assistant that is designed to automatically and formally prove bounds on univariate expressions. It is based on a formalization of floating-point and interval arithmetic, associated with an on-the-fly computation of Taylor expansions. All the computations are performed inside Coq’s logic, in a reflexive setting. This paper also compares our tactic with various existing tools on a large set of examples.},
	pages = {187--217},
	number = {3},
	journaltitle = {J Autom Reasoning},
	author = {Martin-Dorel, Érik and Melquiond, Guillaume},
	urldate = {2019-02-01},
	date = {2016-10-01},
	langid = {english},
	keywords = {Coq proof assistant, Decision procedure, Floating-point arithmetic, Formal proof, Interval arithmetic, Nonlinear arithmetic},
	file = {Submitted Version:/Users/richardford/Zotero/storage/VKBLSM3J/Martin-Dorel and Melquiond - 2016 - Proving Tight Bounds on Univariate Expressions wit.pdf:application/pdf}
}

@inproceedings{boldo_round-off_2017,
	location = {London, United Kingdom},
	title = {Round-off Error Analysis of Explicit One-Step Numerical Integration Methods},
	url = {https://hal.archives-ouvertes.fr/hal-01581794},
	doi = {10.1109/ARITH.2017.22},
	abstract = {Ordinary differential equations are ubiquitous in scientific computing. Solving exactly these equations is usually not possible, except for special cases, hence the use of numerical schemes to get a discretized solution. We are interested in such numerical integration methods, for instance Euler's method or the Runge-Kutta methods. As they are implemented using floating-point arithmetic, round-off errors occur. In order to guarantee their accuracy, we aim at providing bounds on the round-off errors of explicit one-step numerical integration methods. Our methodology is to apply a fine-grained analysis to these numerical algorithms. Our originality is that our floating-point analysis takes advantage of the linear stability of the scheme, a mathematical property that vouches the scheme is well-behaved.},
	booktitle = {24th {IEEE} Symposium on Computer Arithmetic},
	author = {Boldo, Sylvie and Faissole, Florian and Chapoutot, Alexandre},
	urldate = {2019-02-01},
	date = {2017-07},
	keywords = {Floating-Point, Numerical Integration, Ordinary Differential Equation, Round-Off Error, Runge-Kutta Methods, Stability},
	file = {HAL PDF Full Text:/Users/richardford/Zotero/storage/T6FAQZYN/Boldo et al. - 2017 - Round-off Error Analysis of Explicit One-Step Nume.pdf:application/pdf}
}

@unpublished{boldo_round-off_2018,
	title = {Round-off error and exceptional behavior analysis of explicit Runge-Kutta methods},
	url = {https://hal.archives-ouvertes.fr/hal-01883843},
	abstract = {Numerical integration schemes are mandatory to understand complex behaviors of dynamical systems described by ordinary differential equations. Implementation of these numerical methods involve floating-point computations and propagation of round-off errors. This paper presents a new fine-grained analysis of round-off errors in explicit Runge-Kutta integration methods, taking into account exceptional behaviors, such as underflow and overflow. Linear stability properties play a central role in the proposed approach. For a large class of Runge-Kutta methods applied on linear problems, a tight bound of the round-off errors is provided. A simple test is defined and ensures the absence of underflow and a tighter round-off error bound. The absence of overflow is guaranteed as linear stability properties imply that (computed) solutions are non-increasing.},
	author = {Boldo, Sylvie and Faissole, Florian and Chapoutot, Alexandre},
	urldate = {2019-02-01},
	date = {2018-09},
	keywords = {Linear stability, Numerical integration, Overflow, Round-off error, Runge-Kutta method, Underflow},
	file = {HAL PDF Full Text:/Users/richardford/Zotero/storage/STNM4VEB/Boldo et al. - 2018 - Round-off error and exceptional behavior analysis .pdf:application/pdf}
}

@article{immler_verified_2018,
	title = {A Verified {ODE} Solver and the Lorenz Attractor},
	volume = {61},
	issn = {1573-0670},
	url = {https://doi.org/10.1007/s10817-017-9448-y},
	doi = {10.1007/s10817-017-9448-y},
	abstract = {A rigorous numerical algorithm, formally verified with Isabelle/{HOL}, is used to certify the computations that Tucker used to prove chaos for the Lorenz attractor. The verification is based on a formalization of a diverse variety of mathematics and algorithms. Formalized mathematics include ordinary differential equations and Poincaré maps. Algorithms include low level approximation schemes based on Runge–Kutta methods and affine arithmetic. On a high level, reachability analysis is guided by static hybridization and adaptive step-size control and splitting. The algorithms are systematically refined towards an implementation that can be executed on Tucker’s original input data.},
	pages = {73--111},
	number = {1},
	journaltitle = {J Autom Reasoning},
	author = {Immler, Fabian},
	urldate = {2019-02-01},
	date = {2018-06-01},
	langid = {english},
	keywords = {Isabelle/{HOL}, Lorenz attractor, Ordinary differential equation, Poincaré map, Rigorous numerics},
	file = {Springer Full Text PDF:/Users/richardford/Zotero/storage/9487Y7HE/Immler - 2018 - A Verified ODE Solver and the Lorenz Attractor.pdf:application/pdf}
}

@misc{boldo_coquelicot:_2013,
	title = {Coquelicot: A User-Friendly Library of Real Analysis for Coq},
	url = {https://hal.inria.fr/hal-00860648/document},
	shorttitle = {Coquelicot},
	abstract = {Real analysis is pervasive to many applications, if only because it is a suitable tool for modeling physical or socio-economical systems. As such, its support is warranted in proof assistants, so that the users have a way to formally verify mathematical theorems and correctness of critical systems. The Coq system comes with an axiomatization of standard real numbers and a library of theorems on real analysis. Unfortunately, this standard library is lacking some widely used results. For instance, power series are not developed further than their definition. Moreover, the definitions of integrals and derivatives are based on dependent types, which make them especially cumbersome to use in practice. To palliate these inadequacies, we have designed a user-friendly library: Coquelicot. An easier way of writing formulas and theorem statements is achieved by relying on total functions in place of dependent types for limits, derivatives, integrals, power series, and so on. To help with the proof process, the library comes with a comprehensive set of theorems that cover not only these notions, but also some extensions such as parametric integrals, two-dimensional differentiability, asymptotic behaviors. It also offers some automations for performing differentiability proofs. Moreover, Coquelicot is a conservative extension of Coq's standard library and we provide correspondence theorems between the two libraries. We have exercised the library on several use cases: in an exam at university entry level, for the definitions and properties of Bessel functions, and for the solution of the one-dimensional wave equation.},
	author = {Boldo, Sylvie and Lelay, Catherine and Melquiond, Guillaume},
	urldate = {2019-02-01},
	date = {2013-09-10},
	langid = {english},
	file = {Full Text PDF:/Users/richardford/Zotero/storage/WYXEI9GV/Boldo et al. - 2013 - Coquelicot A User-Friendly Library of Real Analys.pdf:application/pdf;Snapshot:/Users/richardford/Zotero/storage/FSB8NLLY/hal-00860648v1.html:text/html}
}

@article{boldo_formalization_2016,
	title = {Formalization of Real Analysis: A Survey of Proof Assistants and Libraries},
	volume = {26},
	url = {https://hal.inria.fr/hal-00806920/document},
	doi = {10.1017/S0960129514000437},
	shorttitle = {Formalization of Real Analysis},
	abstract = {In the recent years, numerous proof systems have improved enough to be used for formally verifying non-trivial mathematical results. They, however, have different purposes and it is not always easy to choose which one is adapted to undertake a formalization effort. In this survey, we focus on properties related to real analysis: real numbers, arithmetic operators, limits, differentiability, integrability, and so on. We have chosen to look into the formalizations provided in standard by the following systems: Coq, {HOL}4, {HOL} Light, Isabelle/{HOL}, Mizar, {ProofPower}-{HOL}, and {PVS}. We have also accounted for large developments that play a similar role or extend standard libraries: {ACL}2(r) for {ACL}2, C-{CoRN}/{MathClasses} for Coq, and the {NASA} {PVS} library. This survey presents how real numbers have been defined in these various provers and how the notions of real analysis described above have been formalized. We also look at the methods of automation these systems provide for real analysis.},
	pages = {1196--1233},
	number = {7},
	journaltitle = {Mathematical Structures in Computer Science},
	author = {Boldo, Sylvie and Lelay, Catherine and Melquiond, Guillaume},
	urldate = {2019-02-01},
	date = {2016-10},
	langid = {english},
	file = {Full Text PDF:/Users/richardford/Zotero/storage/LKG9S93Z/Boldo et al. - 2016 - Formalization of Real Analysis A Survey of Proof .pdf:application/pdf;Snapshot:/Users/richardford/Zotero/storage/6E5738FR/hal-00806920v2.html:text/html}
}

@inproceedings{holzl_type_2013,
	title = {Type Classes and Filters for Mathematical Analysis in Isabelle/{HOL}},
	isbn = {978-3-642-39634-2},
	series = {Lecture Notes in Computer Science},
	abstract = {The theory of analysis in Isabelle/{HOL} derives from earlier formalizations that were limited to specific concrete types: ℝ, ℂ and ℝ n . Isabelle’s new analysis theory unifies and generalizes these earlier efforts. The improvements are centered on two primary contributions: a generic theory of limits based on filters, and a new hierarchy of type classes that includes various topological, metric, vector, and algebraic spaces. These let us apply many results in multivariate analysis to types which are not Euclidean spaces, such as the extended real numbers, bounded continuous functions, or finite maps.},
	pages = {279--294},
	booktitle = {Interactive Theorem Proving},
	publisher = {Springer Berlin Heidelberg},
	author = {Hölzl, Johannes and Immler, Fabian and Huffman, Brian},
	editor = {Blazy, Sandrine and Paulin-Mohring, Christine and Pichardie, David},
	date = {2013},
	langid = {english},
	keywords = {Isabelle/{HOL}, Euclidean vector spaces, Filters, Limits, Mathematical analysis, Topology, Type classes},
	file = {Hölzl et al. - 2013 - Type Classes and Filters for Mathematical Analysis.pdf:/Users/richardford/Zotero/storage/PAGHJGKC/Hölzl et al. - 2013 - Type Classes and Filters for Mathematical Analysis.pdf:application/pdf}
}

@article{krebbers_type_2011,
	title = {Type classes for efficient exact real arithmetic in Coq},
	url = {http://arxiv.org/abs/1106.3448},
	doi = {10.2168/LMCS-9(1:01)2013},
	abstract = {Floating point operations are fast, but require continuous effort on the part of the user in order to ensure that the results are correct. This burden can be shifted away from the user by providing a library of exact analysis in which the computer handles the error estimates. Previously, we [Krebbers/Spitters 2011] provided a fast implementation of the exact real numbers in the Coq proof assistant. Our implementation improved on an earlier implementation by O'Connor by using type classes to describe an abstract specification of the underlying dense set from which the real numbers are built. In particular, we used dyadic rationals built from Coq's machine integers to obtain a 100 times speed up of the basic operations already. This article is a substantially expanded version of [Krebbers/Spitters 2011] in which the implementation is extended in the various ways. First, we implement and verify the sine and cosine function. Secondly, we create an additional implementation of the dense set based on Coq's fast rational numbers. Thirdly, we extend the hierarchy to capture order on undecidable structures, while it was limited to decidable structures before. This hierarchy, based on type classes, allows us to share theory on the naturals, integers, rationals, dyadics, and reals in a convenient way. Finally, we obtain another dramatic speed-up by avoiding evaluation of termination proofs at runtime.},
	journaltitle = {{arXiv}:1106.3448 [cs, math]},
	author = {Krebbers, Robbert and Spitters, Bas},
	urldate = {2019-02-01},
	date = {2011-06-17},
	eprinttype = {arxiv},
	eprint = {1106.3448},
	keywords = {Computer Science - Logic in Computer Science, D.2.4, F.4.1, G.1, Mathematics - Numerical Analysis},
	file = {arXiv\:1106.3448 PDF:/Users/richardford/Zotero/storage/2LLH7TZN/Krebbers and Spitters - 2011 - Type classes for efficient exact real arithmetic i.pdf:application/pdf;arXiv.org Snapshot:/Users/richardford/Zotero/storage/489A4YCS/1106.html:text/html}
}

@article{shrobe_trust-management_2009,
	title = {Trust-Management, Intrusion-Tolerance, Accountability, and Reconstitution Architecture ({TIARA})},
	url = {https://apps.dtic.mil/dtic/tr/fulltext/u2/a511350.pdf},
	abstract = {This report describes the Trust-management, Intrusion-tolerance, Accountability, and Reconstitution Architecture ({TIARA}) system,
a broad design effort including novel computer architecture, operating system and application middleware. {TIARA} illustrates that a
highly secure computer system can be designed without sacrificing performance. {TIARA} involves three major sub-efforts: A
hardware security tagged architecture ({STA}) that tags each word of the computer’s memory with metadata such as the data type and
compartment of the data. The {STA} hardware enforces access rules controlling which principals are allowed to perform which
operations on which data. This allows the construction of a novel Zero-kernel Operating System ({ZKOS}) that has no single all
privileged kernel and that provides strong guarantees against penetration. Finally {TIARA} provides a level of application middleware
that enforces architectural level constraints and maintains the provenance of application data. All common exploits are preventable
by the {TIARA} architecture and this incurs only a minor increase in chip area.},
	pages = {133},
	issue = {{AFRL}-{RI}-{RS}-{TR}-2009-271},
	author = {Shrobe, Howard and {DeHon}, Andre and Knight, Thomas},
	date = {2009-12},
	langid = {english},
	file = {Trust-Management, Intrusion-Tolerance, Accountabil.pdf:/Users/richardford/Zotero/storage/QA4ZCYDJ/Trust-Management, Intrusion-Tolerance, Accountabil.pdf:application/pdf}
}

@inproceedings{azevedo_de_amorim_verified_2014,
	location = {New York, {NY}, {USA}},
	title = {A Verified Information-flow Architecture},
	isbn = {978-1-4503-2544-8},
	url = {http://doi.acm.org/10.1145/2535838.2535839},
	doi = {10.1145/2535838.2535839},
	series = {{POPL} '14},
	abstract = {{SAFE} is a clean-slate design for a highly secure computer system, with pervasive mechanisms for tracking and limiting information flows. At the lowest level, the {SAFE} hardware supports fine-grained programmable tags, with efficient and flexible propagation and combination of tags as instructions are executed. The operating system virtualizes these generic facilities to present an information-flow abstract machine that allows user programs to label sensitive data with rich confidentiality policies. We present a formal, machine-checked model of the key hardware and software mechanisms used to control information flow in {SAFE} and an end-to-end proof of noninterference for this model.},
	pages = {165--178},
	booktitle = {Proceedings of the 41st {ACM} {SIGPLAN}-{SIGACT} Symposium on Principles of Programming Languages},
	publisher = {{ACM}},
	author = {Azevedo de Amorim, Arthur and Collins, Nathan and {DeHon}, André and Demange, Delphine and Hriţcu, Cătălin and Pichardie, David and Pierce, Benjamin C. and Pollack, Randy and Tolmach, Andrew},
	urldate = {2019-02-01},
	date = {2014},
	keywords = {formal verification, clean-slate design, information-flow control, refinement, security, tagged architecture},
	file = {ACM Full Text PDF:/Users/richardford/Zotero/storage/9CDWT8UT/Azevedo de Amorim et al. - 2014 - A Verified Information-flow Architecture.pdf:application/pdf}
}

@book{amorim_verified_2013,
	title = {A Verified Information-Flow Architecture (Long version)},
	abstract = {{SAFE} is a clean-slate effort to build a highly secure computer system, including pervasive mechanisms for tracking and limiting information flows. At the lowest level, the {SAFE} hardware supports fine-grained programmable tags, with efficient and flexible propagation and combination of tags as instructions are executed. The operating system virtualizes these generic facilities to present an information-flow abstract machine, on which user programs can label sensitive data with rich confidentiality and integrity policies. We present a formal, machine-checked model of the key information-flow mechanisms of the {SAFE} hardware and software, together with an end-to-end proof of noninterference for this model.},
	author = {Amorim, Arthur Azevedo de and Collins, Nathan and {DeHon}, André and Demange, Delphine and Hritcu, Cătălin and Pichardie, David and Pierce, Benjamin C. and Pollack, Randy and Tolmach, Andrew},
	date = {2013},
	file = {Citeseer - Full Text PDF:/Users/richardford/Zotero/storage/2YMYHR23/Amorim et al. - 2013 - A Verified Information-Flow Architecture (Long ver.pdf:application/pdf;Citeseer - Snapshot:/Users/richardford/Zotero/storage/M7W2QFG9/summary.html:text/html}
}

@book{andrew_oracle_2008,
	title = {Oracle Semantics Aquinas Hobor},
	abstract = {We define a Concurrent Separation Logic with first-class locks and threads for the C language, and prove its soundness in Coq with re-spect to a compilable operataional semantics. We define the language Concurrent C minor, an extension of the C minor language of Leroy. C minor was designed as the highest-level intermediate language in the {CompCert} certified {ANSI} C compiler, and we add to it lock, unlock, and fork statements to make Concurrent C minor, giving it a standard Pthreads style of concurrency. We define a Concurrent Separation Logic for Concurrent C minor, which extends the original Concurrent Separation Logic of O’Hearn to handle first-class locks and threads. We then prove the soundness of the logic with respect to the opera-tional semantics of the language. First, we define an erased concurrent operational semantics for Concurrent C minor that is a reasonable ab-},
	author = {Andrew, Advisor},
	date = {2008},
	file = {Citeseer - Full Text PDF:/Users/richardford/Zotero/storage/KI5U9GHB/Andrew - 2008 - Oracle Semantics Aquinas Hobor.pdf:application/pdf;Citeseer - Snapshot:/Users/richardford/Zotero/storage/G77WVBCV/summary.html:text/html}
}

@inproceedings{berdine_smallfoot:_2006,
	title = {Smallfoot: Modular Automatic Assertion Checking with Separation Logic},
	isbn = {978-3-540-36750-5},
	series = {Lecture Notes in Computer Science},
	shorttitle = {Smallfoot},
	abstract = {Separation logic is a program logic for reasoning about programs that manipulate pointer data structures. We describe Smallfoot, a tool for checking certain lightweight separation logic specifications. The assertions describe the shapes of data structures rather than their detailed contents, and this allows reasoning to be fully automatic. The presentation in the paper is tutorial in style. We illustrate what the tool can do via examples which are oriented toward novel aspects of separation logic, namely: avoidance of frame axioms (which say what a procedure does not change); embracement of “dirty” features such as memory disposal and address arithmetic; information hiding in the presence of pointers; and modular reasoning about concurrent programs.},
	pages = {115--137},
	booktitle = {Formal Methods for Components and Objects},
	publisher = {Springer Berlin Heidelberg},
	author = {Berdine, Josh and Calcagno, Cristiano and O’Hearn, Peter W.},
	editor = {de Boer, Frank S. and Bonsangue, Marcello M. and Graf, Susanne and de Roever, Willem-Paul},
	date = {2006},
	langid = {english},
	keywords = {Separation Logic, Symbolic Execution, Free List, Information Hiding, Tree Predicate},
	file = {Berdine et al. - 2006 - Smallfoot Modular Automatic Assertion Checking wi.pdf:/Users/richardford/Zotero/storage/RU9SZ96Q/Berdine et al. - 2006 - Smallfoot Modular Automatic Assertion Checking wi.pdf:application/pdf}
}

@incollection{ohearn_local_2001,
	title = {Local Reasoning about Programs that Alter Data Structures},
	isbn = {978-3-540-44802-0},
	series = {Lecture Notes in Computer Science},
	abstract = {We describe an extension of Hoare’s logic for reasoning about programs that alter data structures. We consider a low-level storage model based on a heap with associated lookup, update, allocation and deallocation operations, and unrestricted address arithmetic. The assertion language is based on a possible worlds model of the logic of bunched implications, and includes spatial conjunction and implication connectives alongside those of classical logic. Heap operations are axiomatized using what we call the “small axioms”, each of which mentions only those cells accessed by a particular command. Through these and a number of examples we show that the formalism supports local reasoning: A specification and proof can concentrate on only those cells in memory that a program accesses.This paper builds on earlier work by Burstall, Reynolds, Ishtiaq and O’Hearn on reasoning about data structures.},
	pages = {1--19},
	booktitle = {Computer Science Logic},
	publisher = {Springer Berlin Heidelberg},
	author = {O’Hearn, Peter and Reynolds, John and Yang, Hongseok},
	editor = {Fribourg, Laurent},
	date = {2001},
	langid = {english},
	keywords = {Hoare Logic, Frame Problem, Local Reasoning, Memory Fault, Weak Precondition},
	file = {O’Hearn et al. - 2001 - Local Reasoning about Programs that Alter Data Str.pdf:/Users/richardford/Zotero/storage/DSQLQ2IN/O’Hearn et al. - 2001 - Local Reasoning about Programs that Alter Data Str.pdf:application/pdf;O’Hearn et al. - 2001 - Local Reasoning about Programs that Alter Data Str.pdf:/Users/richardford/Zotero/storage/EFFA7GBR/O’Hearn et al. - 2001 - Local Reasoning about Programs that Alter Data Str.pdf:application/pdf}
}

@incollection{hermanns_local_2006,
	location = {Berlin, Heidelberg},
	title = {A Local Shape Analysis Based on Separation Logic},
	volume = {3920},
	isbn = {978-3-540-33056-1 978-3-540-33057-8},
	url = {http://link.springer.com/10.1007/11691372_19},
	abstract = {We describe a program analysis for linked list programs where the abstract domain uses formulae from separation logic.},
	pages = {287--302},
	booktitle = {Tools and Algorithms for the Construction and Analysis of Systems},
	publisher = {Springer Berlin Heidelberg},
	author = {Distefano, Dino and O’Hearn, Peter W. and Yang, Hongseok},
	editor = {Hermanns, Holger and Palsberg, Jens},
	urldate = {2019-02-01},
	date = {2006},
	langid = {english},
	doi = {10.1007/11691372_19},
	file = {Distefano et al. - 2006 - A Local Shape Analysis Based on Separation Logic.pdf:/Users/richardford/Zotero/storage/SYDSVSRA/Distefano et al. - 2006 - A Local Shape Analysis Based on Separation Logic.pdf:application/pdf}
}

@online{calcagno_moving_nodate,
	title = {Moving Fast with Software Verification},
	url = {https://research.fb.com/publications/moving-fast-with-software-verification},
	abstract = {For organisations like Facebook, high quality software is important. However, the pace of change and increasing complexity of modern code makes it difficult to produce error free software. Available tools are often lacking in helping programmers develop more reliable and secure applications.},
	titleaddon = {Facebook Research},
	author = {Calcagno, Cristiano and Distefano, Dino and Dubreil, Jeremy and O'Hearn, Peter},
	urldate = {2019-02-01},
	langid = {american},
	file = {Moving Fast with Software Verification.pdf:/Users/richardford/Zotero/storage/5FPGIE6K/Moving Fast with Software Verification.pdf:application/pdf;Snapshot:/Users/richardford/Zotero/storage/FFZ2PSBG/moving-fast-with-software-verification.html:text/html}
}

@book{sozeau_first-class_2008,
	title = {First-class type classes},
	abstract = {Abstract. Type Classes have met a large success in Haskell and Isabelle, as a solution for sharing notations by overloading and for specifying with abstract structures by quantification on contexts. However, both systems are limited by second-class implementations of these constructs, and these limitations are only overcomed by ad-hoc extensions to the respective systems. We propose an embedding of type classes into a dependent type theory that is first-class and supports some of the most popular extensions right away. The implementation is correspondingly cheap, general and integrates well inside the system, as we have experimented in Coq. We show how it can be used to help structured programming and proving by way of examples. 1},
	author = {Sozeau, Matthieu and Oury, Nicolas},
	date = {2008},
	file = {Citeseer - Full Text PDF:/Users/richardford/Zotero/storage/378JZIWP/Sozeau and Oury - 2008 - First-class type classes.pdf:application/pdf;Citeseer - Snapshot:/Users/richardford/Zotero/storage/UEWAJUHF/summary.html:text/html}
}

@incollection{mohamed_first-class_2008,
	location = {Berlin, Heidelberg},
	title = {First-Class Type Classes - {TPHOLs} Talk},
	volume = {5170},
	isbn = {978-3-540-71065-3 978-3-540-71067-7},
	url = {http://link.springer.com/10.1007/978-3-540-71067-7_23},
	pages = {278--293},
	booktitle = {Theorem Proving in Higher Order Logics},
	publisher = {Springer Berlin Heidelberg},
	author = {Sozeau, Matthieu and Oury, Nicolas},
	editor = {Mohamed, Otmane Ait and Muñoz, César and Tahar, Sofiène},
	urldate = {2019-02-01},
	date = {2008},
	langid = {english},
	doi = {10.1007/978-3-540-71067-7_23},
	file = {Sozeau and Oury - 2008 - First-Class Type Classes.pdf:/Users/richardford/Zotero/storage/ZNXCN3GH/Sozeau and Oury - 2008 - First-Class Type Classes.pdf:application/pdf}
}

@article{sozeau_subset_nodate,
	title = {Subset coercions in Coq},
	abstract = {Abstract. We propose a new language for writing programs with de-pendent types on top of the Coq proof assistant. This language permits to establish a phase distinction between writing and proving algorithms in the Coq environment. Concretely, this means allowing to write al-gorithms as easily as in a practical functional programming language whilst giving them as rich a specification as desired and proving that the code meets the specification using the whole Coq proof apparatus. This is achieved by extending conversion to an equivalence which re-lates types and subsets based on them, a technique originating from the “Predicate subtyping ” feature of {PVS} and following mathematical con-vention. The typing judgements can be translated to the Calculus of (Co-)Inductive Constructions (Cic) by means of an interpretation which inserts coercions at the appropriate places. These coercions can con-tain existential variables representing the propositional parts of the final term, corresponding to proof obligations (or {PVS} type-checking condi-tions). A prototype implementation of this process is integrated with the Coq environment. 1},
	pages = {237--252},
	journaltitle = {Springer-Verlag {LNCS}},
	author = {Sozeau, Matthieu},
	file = {Citeseer - Full Text PDF:/Users/richardford/Zotero/storage/XLS49AVP/Sozeau - Subset coercions in Coq.pdf:application/pdf;Citeseer - Snapshot:/Users/richardford/Zotero/storage/MNYEZ764/summary.html:text/html}
}

@report{gonthier_small_2015,
	title = {A Small Scale Reflection Extension for the Coq system},
	url = {https://hal.inria.fr/inria-00258384/document},
	abstract = {This is the user manual of Ssreflect, a set of extensions to the proof scripting language of the Coq proof assistant. While these extensions were developed to support a particular proof methodology - small-scale reflection - most of them actually are of a quite general nature, improving the functionality of Coq in basic areas such as script layout and structuring, proof context management, and rewriting. Consequently, and in spite of the title of this document, most of the extensions described here should be of interest for all Coq users, whether they embrace small-scale reflection or not.},
	institution = {Inria Saclay Ile de France},
	type = {report},
	author = {Gonthier, Georges and Mahboubi, Assia and Tassi, Enrico},
	urldate = {2019-02-05},
	date = {2015},
	langid = {english},
	file = {Full Text PDF:/Users/richardford/Zotero/storage/KDEK8FJA/Gonthier et al. - 2015 - A Small Scale Reflection Extension for the Coq sys.pdf:application/pdf;Snapshot:/Users/richardford/Zotero/storage/WAP8HJ4N/inria-00258384v16.html:text/html}
}

@inproceedings{ye_verified_2019,
	location = {New York, {NY}, {USA}},
	title = {A Verified Protocol Buffer Compiler},
	isbn = {978-1-4503-6222-1},
	url = {http://doi.acm.org/10.1145/3293880.3294105},
	doi = {10.1145/3293880.3294105},
	series = {{CPP} 2019},
	pages = {222--233},
	booktitle = {Proceedings of the 8th {ACM} {SIGPLAN} International Conference on Certified Programs and Proofs},
	publisher = {{ACM}},
	author = {Ye, Qianchuan and Delaware, Benjamin},
	date = {2019},
	note = {https://www.cs.purdue.edu/homes/bendy/Narcissus/{VerifiedProtoBuff}.html},
	keywords = {Program verification, Coq, Serialization},
	file = {Ye and Delaware - 2019 - A Verified Protocol Buffer Compiler.pdf:/Users/richardford/Zotero/storage/RSBG9JMH/Ye and Delaware - 2019 - A Verified Protocol Buffer Compiler.pdf:application/pdf}
}

@online{noauthor_lean_nodate,
	title = {Lean Forward: Usable Computer-Checked Proofs and Computations},
	url = {https://lean-forward.github.io/},
	urldate = {2019-02-08},
	file = {Lean Forward:/Users/richardford/Zotero/storage/7M6VIYMY/lean-forward.github.io.html:text/html}
}

@incollection{urban_roscoq:_2015,
	location = {Cham},
	title = {{ROSCoq}: Robots Powered by Constructive Reals},
	volume = {9236},
	isbn = {978-3-319-22101-4 978-3-319-22102-1},
	url = {http://link.springer.com/10.1007/978-3-319-22102-1_3},
	shorttitle = {{ROSCoq}},
	pages = {34--50},
	booktitle = {Interactive Theorem Proving},
	publisher = {Springer International Publishing},
	author = {Anand, Abhishek and Knepper, Ross},
	editor = {Urban, Christian and Zhang, Xingyuan},
	urldate = {2019-02-08},
	date = {2015},
	doi = {10.1007/978-3-319-22102-1_3},
	file = {Anand and Knepper - 2015 - ROSCoq Robots Powered by Constructive Reals.pdf:/Users/richardford/Zotero/storage/NZKLDCG7/Anand and Knepper - 2015 - ROSCoq Robots Powered by Constructive Reals.pdf:application/pdf}
}

@article{lamport_if_2018,
	title = {If You’re Not Writing a Program, Don’t Use a Programming Language},
	volume = {2},
	rights = {Authors who publish with this journal agree to the following terms:    Authors retain copyright and grant the journal right of first publication with the work simultaneously licensed under a Creative Commons Attribution License that allows others to share the work with an acknowledgement of the work's authorship and initial publication in this journal.       Authors are able to enter into separate, additional contractual arrangements for the non-exclusive distribution of the journal's published version of the work (e.g., post it to an institutional repository or publish it in a book), with an acknowledgement of its initial publication in this journal.},
	url = {http://eatcs.org/beatcs/index.php/beatcs/article/view},
	abstract = {The need to handle large programs and to produce ecient compiled codeadds complexity to programming languages and limits their expressiveness.Algorithms are not programs, and they can be expressed in a simpler and more expressive language. That language is the one used by almost every branch of science and engineering to precisely describe and reason about the objects they study: the language of mathematics. Math is useful for describing a more general class of algorithms than are studied in algorithmcourses.},
	number = {125},
	journaltitle = {Bulletin of {EATCS}},
	author = {Lamport, Leslie and Distributed Computing {\textbackslash}\& Education Column by Juraj Hromkovic, Stefan Schmid},
	urldate = {2019-02-08},
	date = {2018-06-12},
	langid = {english},
	file = {Lamport and Distributed Computing & Education Column by Juraj Hromkovic - 2018 - If You’re Not Writing a Program, Don’t Use a Progr.pdf:/Users/richardford/Zotero/storage/VSCKQ5W2/Lamport and Distributed Computing & Education Column by Juraj Hromkovic - 2018 - If You’re Not Writing a Program, Don’t Use a Progr.pdf:application/pdf;Snapshot:/Users/richardford/Zotero/storage/XYAISFI9/539.html:text/html}
}

@online{sewell_rems_nodate,
	title = {{REMS} - Rigorous Engineering of Mainstream Systems},
	url = {https://www.cl.cam.ac.uk/~pes20/rems/index.html},
	author = {Sewell, Peter},
	urldate = {2019-02-28},
	file = {REMS:/Users/richardford/Zotero/storage/RKHJKH69/index.html:text/html;report-2019-web.pdf:/Users/richardford/Zotero/storage/5EYFKN44/report-2019-web.pdf:application/pdf}
}

@article{bishop_engineering_2018,
	title = {Engineering with Logic: Rigorous Test-Oracle Specification and Validation for {TCP}/{IP} and the Sockets {API}},
	volume = {66},
	issn = {0004-5411},
	url = {http://doi.acm.org/10.1145/3243650},
	doi = {10.1145/3243650},
	shorttitle = {Engineering with Logic},
	abstract = {Conventional computer engineering relies on test-and-debug development processes, with the behavior of common interfaces described (at best) with prose specification documents. But prose specifications cannot be used in test-and-debug development in any automated way, and prose is a poor medium for expressing complex (and loose) specifications. The {TCP}/{IP} protocols and Sockets {API} are a good example of this: they play a vital role in modern communication and computation, and interoperability between implementations is essential. But what exactly they are is surprisingly obscure: their original development focused on “rough consensus and running code,” augmented by prose {RFC} specifications that do not precisely define what it means for an implementation to be correct. Ultimately, the actual standard is the de facto one of the common implementations, including, for example, the 15 000 to 20 000 lines of the {BSD} implementation—optimized and multithreaded C code, time dependent, with asynchronous event handlers, intertwined with the operating system, and security critical. This article reports on work done in the Netsem project to develop lightweight mathematically rigorous techniques that can be applied to such systems: to specify their behavior precisely (but loosely enough to permit the required implementation variation) and to test whether these specifications and the implementations correspond with specifications that are executable as test oracles. We developed post hoc specifications of {TCP}, {UDP}, and the Sockets {API}, both of the service that they provide to applications (in terms of {TCP} bidirectional stream connections) and of the internal operation of the protocol (in terms of {TCP} segments and {UDP} datagrams), together with a testable abstraction function relating the two. These specifications are rigorous, detailed, readable, with broad coverage, and rather accurate. Working within a general-purpose proof assistant ({HOL}4), we developed language idioms (within higher-order logic) in which to write the specifications: operational semantics with nondeterminism, time, system calls, monadic relational programming, and so forth. We followed an experimental semantics approach, validating the specifications against several thousand traces captured from three implementations ({FreeBSD}, Linux, and {WinXP}). Many differences between these were identified, as were a number of bugs. Validation was done using a special-purpose symbolic model checker programmed above {HOL}4. Having demonstrated that our logic-based engineering techniques suffice for handling real-world protocols, we argue that similar techniques could be applied to future critical software infrastructure at design time, leading to cleaner designs and (via specification-based testing) more robust and predictable implementations. In cases where specification looseness can be controlled, this should be possible with lightweight techniques, without the need for a general-purpose proof assistant, at relatively little cost.},
	pages = {1:1--1:77},
	number = {1},
	journaltitle = {J. {ACM}},
	author = {Bishop, Steve and Fairbairn, Matthew and Mehnert, Hannes and Norrish, Michael and Ridge, Tom and Sewell, Peter and Smith, Michael and Wansbrough, Keith},
	urldate = {2019-02-28},
	date = {2018-12},
	keywords = {network protocols, Rigorous engineering, specification},
	file = {ACM Full Text PDF:/Users/richardford/Zotero/storage/CSYHL8HP/Bishop et al. - 2018 - Engineering with Logic Rigorous Test-Oracle Speci.pdf:application/pdf}
}

@article{memarian_exploring_2019,
	title = {Exploring C Semantics and Pointer Provenance},
	volume = {3},
	issn = {2475-1421},
	url = {http://doi.acm.org/10.1145/3290380},
	doi = {10.1145/3290380},
	abstract = {The semantics of pointers and memory objects in C has been a vexed question for many years. C values cannot be treated as either purely abstract or purely concrete entities: the language exposes their representations, but compiler optimisations rely on analyses that reason about provenance and initialisation status, not just runtime representations. The {ISO} {WG}14 standard leaves much of this unclear, and in some respects differs with de facto standard usage --- which itself is difficult to investigate.   In this paper we explore the possible source-language semantics for memory objects and pointers, in {ISO} C and in C as it is used and implemented in practice, focussing especially on pointer provenance. We aim to, as far as possible, reconcile the {ISO} C standard, mainstream compiler behaviour, and the semantics relied on by the corpus of existing C code. We present two coherent proposals, tracking provenance via integers and not; both address many design questions. We highlight some pros and cons and open questions, and illustrate the discussion with a library of test cases. We make our semantics executable as a test oracle, integrating it with the Cerberus semantics for much of the rest of C, which we have made substantially more complete and robust, and equipped with a web-interface {GUI}. This allows us to experimentally assess our proposals on those test cases. To assess their viability with respect to larger bodies of C code, we analyse the changes required and the resulting behaviour for a port of {FreeBSD} to {CHERI}, a research architecture supporting hardware capabilities, which (roughly speaking) traps on the memory safety violations which our proposals deem undefined behaviour. We also develop a new runtime instrumentation tool to detect possible provenance violations in normal C code, and apply it to some of the {SPEC} benchmarks. We compare our proposal with a source-language variant of the twin-allocation {LLVM} semantics proposal of Lee et al. Finally, we describe ongoing interactions with {WG}14, exploring how our proposals could be incorporated into the {ISO} standard.},
	pages = {67:1--67:32},
	issue = {{POPL}},
	journaltitle = {Proc. {ACM} Program. Lang.},
	author = {Memarian, Kayvan and Gomes, Victor B. F. and Davis, Brooks and Kell, Stephen and Richardson, Alexander and Watson, Robert N. M. and Sewell, Peter},
	urldate = {2019-02-28},
	date = {2019-01},
	keywords = {C},
	file = {ACM Full Text PDF:/Users/richardford/Zotero/storage/B37CZ7YU/Memarian et al. - 2019 - Exploring C Semantics and Pointer Provenance.pdf:application/pdf}
}

@article{armstrong_isa_2019,
	title = {{ISA} Semantics for {ARMv}8-a, {RISC}-v, and {CHERI}-{MIPS}},
	volume = {3},
	issn = {2475-1421},
	url = {http://doi.acm.org/10.1145/3290384},
	doi = {10.1145/3290384},
	abstract = {Architecture specifications notionally define the fundamental interface between hardware and software: the envelope of allowed behaviour for processor implementations, and the basic assumptions for software development and verification. But in practice, they are typically prose and pseudocode documents, not rigorous or executable artifacts, leaving software and verification on shaky ground.   In this paper, we present rigorous semantic models for the sequential behaviour of large parts of the mainstream {ARMv}8-A, {RISC}-V, and {MIPS} architectures, and the research {CHERI}-{MIPS} architecture, that are complete enough to boot operating systems, variously Linux, {FreeBSD}, or {seL}4. Our {ARMv}8-A models are automatically translated from authoritative {ARM}-internal definitions, and (in one variant) tested against the {ARM} Architecture Validation Suite.   We do this using a custom language for {ISA} semantics, Sail, with a lightweight dependent type system, that supports automatic generation of emulator code in C and {OCaml}, and automatic generation of proof-assistant definitions for Isabelle, {HOL}4, and (currently only for {MIPS}) Coq. We use the former for validation, and to assess specification coverage. To demonstrate the usability of the latter, we prove (in Isabelle) correctness of a purely functional characterisation of {ARMv}8-A address translation. We moreover integrate the {RISC}-V model into the {RMEM} tool for (user-mode) relaxed-memory concurrency exploration. We prove (on paper) the soundness of the core Sail type system.   We thereby take a big step towards making the architectural abstraction actually well-defined, establishing foundations for verification and reasoning.},
	pages = {71:1--71:31},
	issue = {{POPL}},
	journaltitle = {Proc. {ACM} Program. Lang.},
	author = {Armstrong, Alasdair and Bauereiss, Thomas and Campbell, Brian and Reid, Alastair and Gray, Kathryn E. and Norton, Robert M. and Mundkur, Prashanth and Wassell, Mark and French, Jon and Pulte, Christopher and Flur, Shaked and Stark, Ian and Krishnaswami, Neel and Sewell, Peter},
	urldate = {2019-02-28},
	date = {2019-01},
	keywords = {Semantics, Instruction Set Architectures, Theorem Proving},
	file = {ACM Full Text PDF:/Users/richardford/Zotero/storage/E4ASQ97S/Armstrong et al. - 2019 - ISA Semantics for ARMv8-a, RISC-v, and CHERI-MIPS.pdf:application/pdf}
}

@article{pulte_simplifying_2017,
	title = {Simplifying {ARM} Concurrency: Multicopy-atomic Axiomatic and Operational Models for {ARMv}8},
	volume = {2},
	issn = {2475-1421},
	url = {http://doi.acm.org/10.1145/3158107},
	doi = {10.1145/3158107},
	shorttitle = {Simplifying {ARM} Concurrency},
	abstract = {{ARM} has a relaxed memory model, previously specified in informal prose for {ARMv}7 and {ARMv}8. Over time, and partly due to work building formal semantics for {ARM} concurrency, it has become clear that some of the complexity of the model is not justified by the potential benefits. In particular, the model was originally non-multicopy-atomic: writes could become visible to some other threads before becoming visible to all — but this has not been exploited in production implementations, the corresponding potential hardware optimisations are thought to have insufficient benefits in the {ARM} context, and it gives rise to subtle complications when combined with other {ARMv}8 features. The {ARMv}8 architecture has therefore been revised: it now has a multicopy-atomic model. It has also been simplified in other respects, including more straightforward notions of dependency, and the architecture now includes a formal concurrency model.  In this paper we detail these changes and discuss their motivation. We define two formal concurrency models: an operational one, simplifying the Flowing model of Flur et al., and the axiomatic model of the revised {ARMv}8 specification. The models were developed by an academic group and by {ARM} staff, respectively, and this extended collaboration partly motivated the above changes. We prove the equivalence of the two models. The operational model is integrated into an executable exploration tool with new web interface, demonstrated by exhaustively checking the possible behaviours of a loop-unrolled version of a Linux kernel lock implementation, a previously known bug due to unprevented speculation, and a fixed version.},
	pages = {19:1--19:29},
	issue = {{POPL}},
	journaltitle = {Proc. {ACM} Program. Lang.},
	author = {Pulte, Christopher and Flur, Shaked and Deacon, Will and French, Jon and Sarkar, Susmit and Sewell, Peter},
	urldate = {2019-02-28},
	date = {2017-12},
	keywords = {Semantics, Axiomatic, Operational, Relaxed Memory Models},
	file = {ACM Full Text PDF:/Users/richardford/Zotero/storage/6BGU9SUM/Pulte et al. - 2017 - Simplifying ARM Concurrency Multicopy-atomic Axio.pdf:application/pdf}
}

@inproceedings{nienhuis_operational_2016,
	location = {New York, {NY}, {USA}},
	title = {An Operational Semantics for C/C++11 Concurrency},
	isbn = {978-1-4503-4444-9},
	url = {http://doi.acm.org/10.1145/2983990.2983997},
	doi = {10.1145/2983990.2983997},
	series = {{OOPSLA} 2016},
	abstract = {The C/C++11 concurrency model balances two goals: it is relaxed enough to be efficiently implementable and (leaving aside the ``thin-air'' problem) it is strong enough to give useful guarantees to programmers. It is mathematically precise and has been used in verification research and compiler testing. However, the model is expressed in an axiomatic style, as predicates on complete candidate executions. This suffices for computing the set of allowed executions of a small litmus test, but it does not directly support the incremental construction of executions of larger programs. It is also at odds with conventional operational semantics, as used implicitly in the rest of the C/C++ standards.   Our main contribution is the development of an operational model for C/C++11 concurrency. This covers all the features of the previous formalised axiomatic model, and we have a mechanised proof that the two are equivalent, in Isabelle/{HOL}. We also integrate this semantics with an operational semantics for sequential C (described elsewhere); the combined semantics can incrementally execute programs in a small fragment of C.   Doing this uncovered several new aspects of the C/C++11 model: we show that one cannot build an equivalent operational model that simply follows program order, sequential consistent order, or the synchronises-with order. The first negative result is forced by hardware-observable behaviour, but the latter two are not, and so might be ameliorated by changing C/C++11. More generally, we hope that this work, with its focus on incremental construction of executions, will inform the future design of new concurrency models.},
	pages = {111--128},
	booktitle = {Proceedings of the 2016 {ACM} {SIGPLAN} International Conference on Object-Oriented Programming, Systems, Languages, and Applications},
	publisher = {{ACM}},
	author = {Nienhuis, Kyndylan and Memarian, Kayvan and Sewell, Peter},
	urldate = {2019-02-28},
	date = {2016},
	note = {event-place: Amsterdam, Netherlands},
	keywords = {C/C++, Concurrency},
	file = {ACM Full Text PDF:/Users/richardford/Zotero/storage/CHY6KVGP/Nienhuis et al. - 2016 - An Operational Semantics for CC++11 Concurrency.pdf:application/pdf}
}

@inproceedings{kell_missing_2016,
	location = {New York, {NY}, {USA}},
	title = {The Missing Link: Explaining {ELF} Static Linking, Semantically},
	isbn = {978-1-4503-4444-9},
	url = {http://doi.acm.org/10.1145/2983990.2983996},
	doi = {10.1145/2983990.2983996},
	series = {{OOPSLA} 2016},
	shorttitle = {The Missing Link},
	abstract = {Beneath the surface, software usually depends on complex linker behaviour to work as intended. Even linking {\textless}pre{\textgreater}hello\_world.c{\textless}/pre{\textgreater} is surprisingly involved, and systems software such as {\textless}pre{\textgreater}libc{\textless}/pre{\textgreater} and operating system kernels rely on a host of linker features. But linking is poorly understood by working programmers and has largely been neglected by language researchers.  In this paper we survey the many use-cases that linkers support and the poorly specified linker speak by which they are controlled: metadata in object files, command-line options, and linker-script language. We provide the first validated formalisation of a realistic executable and linkable format ({ELF}), and capture aspects of the Application Binary Interfaces for four mainstream platforms ({AArch}64, {AMD}64, Power64, and {IA}32). Using these, we develop an executable specification of static linking, covering (among other things) enough to link small C programs (we use the example of bzip2) into a correctly running executable. We provide our specification in Lem and Isabelle/{HOL} forms. This is the first formal specification of mainstream linking. We have used the Isabelle/{HOL} version to prove a sample correctness property for one case of {AMD}64 {ABI} relocation, demonstrating that the specification supports formal proof, and as a first step towards the much more ambitious goal of verified linking. Our work should enable several novel strands of research, including linker-aware verified compilation and program analysis, and better languages for controlling linking.},
	pages = {607--623},
	booktitle = {Proceedings of the 2016 {ACM} {SIGPLAN} International Conference on Object-Oriented Programming, Systems, Languages, and Applications},
	publisher = {{ACM}},
	author = {Kell, Stephen and Mulligan, Dominic P. and Sewell, Peter},
	urldate = {2019-02-28},
	date = {2016},
	note = {event-place: Amsterdam, Netherlands},
	keywords = {Executable and Linkable Format ({ELF}), formal specification, Linking, theorem-proving},
	file = {ACM Full Text PDF:/Users/richardford/Zotero/storage/GN92372Y/Kell et al. - 2016 - The Missing Link Explaining ELF Static Linking, S.pdf:application/pdf}
}

@inproceedings{mulligan_lem:_2014,
	location = {New York, {NY}, {USA}},
	title = {Lem: Reusable Engineering of Real-world Semantics},
	isbn = {978-1-4503-2873-9},
	url = {http://doi.acm.org/10.1145/2628136.2628143},
	doi = {10.1145/2628136.2628143},
	series = {{ICFP} '14},
	shorttitle = {Lem},
	abstract = {Recent years have seen remarkable successes in rigorous engineering: using mathematically rigorous semantic models (not just idealised calculi) of real-world processors, programming languages, protocols, and security mechanisms, for testing, proof, analysis, and design. Building these models is challenging, requiring experimentation, dialogue with vendors or standards bodies, and validation; their scale adds engineering issues akin to those of programming to the task of writing clear and usable mathematics. But language and tool support for specification is lacking. Proof assistants can be used but bring their own difficulties, and a model produced in one, perhaps requiring many person-years effort and maintained over an extended period, cannot be used by those familiar with another. We introduce Lem, a language for engineering reusable large-scale semantic models. The Lem design takes inspiration both from functional programming languages and from proof assistants, and Lem definitions are translatable into {OCaml} for testing, Coq, {HOL}4, and Isabelle/{HOL} for proof, and {LaTeX} and {HTML} for presentation. This requires a delicate balance of expressiveness, careful library design, and implementation of transformations - akin to compilation, but subject to the constraint of producing usable and human-readable code for each target. Lem's effectiveness is demonstrated by its use in practice.},
	pages = {175--188},
	booktitle = {Proceedings of the 19th {ACM} {SIGPLAN} International Conference on Functional Programming},
	publisher = {{ACM}},
	author = {Mulligan, Dominic P. and Owens, Scott and Gray, Kathryn E. and Ridge, Tom and Sewell, Peter},
	urldate = {2019-02-28},
	date = {2014},
	note = {event-place: Gothenburg, Sweden},
	keywords = {proof assistants, lem, real-world semantics, specification languages},
	file = {ACM Full Text PDF:/Users/richardford/Zotero/storage/FAGX7FNA/Mulligan et al. - 2014 - Lem Reusable Engineering of Real-world Semantics.pdf:application/pdf}
}

@software{noauthor_lem_2019,
	title = {Lem semantic definition language.},
	url = {https://github.com/rems-project/lem},
	publisher = {{REMS}},
	urldate = {2019-02-28},
	date = {2019-02-11},
	note = {original-date: 2018-01-31T15:35:24Z}
}

@software{sewell_ott_2019,
	title = {The Ott tool for writing definitions of programming languages and calculi: ott-lang/ott},
	rights = {View license},
	url = {https://github.com/ott-lang/ott},
	shorttitle = {The Ott tool for writing definitions of programming languages and calculi},
	publisher = {ott-lang},
	author = {Sewell, Peter},
	urldate = {2019-02-28},
	date = {2019-01-17},
	note = {original-date: 2016-10-27T15:44:41Z}
}

@software{noauthor_formalization_2019,
	title = {Formalization of the Interaction Tree Datatype in Coq: {DeepSpec}/{InteractionTrees}},
	rights = {{MIT}},
	url = {https://github.com/DeepSpec/InteractionTrees},
	shorttitle = {Formalization of the Interaction Tree Datatype in Coq},
	publisher = {{DeepSpec}},
	urldate = {2019-02-28},
	date = {2019-02-27},
	note = {original-date: 2018-06-21T18:53:18Z}
}

@online{stewart_verified_nodate,
	title = {Verified Separate Compilation for C {\textbar} Computer Science Department at Princeton University},
	url = {https://www.cs.princeton.edu/research/techreps/TR-980-15},
	author = {Stewart, Gordon},
	urldate = {2019-03-03},
	file = {Verified Separate Compilation for C  Computer Sci.pdf:/Users/richardford/Zotero/storage/U6MLH23P/Verified Separate Compilation for C  Computer Sci.pdf:application/pdf;Verified Separate Compilation for C | Computer Science Department at Princeton University:/Users/richardford/Zotero/storage/S255C77P/TR-980-15.html:text/html}
}

@inproceedings{mckinna_why_2006,
	location = {New York, {NY}, {USA}},
	title = {Why Dependent Types Matter},
	isbn = {978-1-59593-027-9},
	url = {http://doi.acm.org/10.1145/1111037.1111038},
	doi = {10.1145/1111037.1111038},
	series = {{POPL} '06},
	abstract = {Language designers have in recent years proposed a wealth of richer type systems for programming which seek to extend the range of statically enforced guarantees on data and code. Most such proposals have been evolutionary extensions of {ML} or Haskell, offering programmers a balanced compromise between expressive strength and existing well-understood technology. Typically they revolve around type- or kind-indexed types such as {GADTs}, supported by limited equality reasoning at the type-checking level, thus separating the dynamic behaviour of programs from the (simpler) static behaviour of indexing information occurring in their types.I want to argue in this talk for a more radical departure from such practice by examining full spectrum type dependency, lifting such restrictions on the data upon which types may depend. Conor {McBride} and I designed the language {EPIGRAM} for experiments in programming with inductive families of data (of which {GADTs} are a special case). Using it for illustration, I will explore some of the possibilities and challenges afforded by full spectrum type dependency at the static and dynamic level: types directly support modelling complex invariants in terms of other data (rather than their types), with a Curry-Howard flavour of data-as-evidence; such complexity is on a 'pay-as-you-go' basis, while keeping type annotations and other syntactic overheads to a minimum; data decomposition steps, e.g. case analysis, furnish more informative interactions between types and values during typechecking; such steps may moreover be abstractly specified by their types, and thus user definable; this supports a style of programming embracing 'learning by testing', views, and Burstall's 'hand simulation plus a little induction'; the absence of a rigid phase distinction need not lead to type-passing or excessive run-time overhead; effectful computation, in particular partiality, can be incorporated via variations on existing ideas such as monads.This talk is based on joint work with Conor {McBride}, Edwin Brady and Thorsten Altenkirch.},
	pages = {1--1},
	booktitle = {Conference Record of the 33rd {ACM} {SIGPLAN}-{SIGACT} Symposium on Principles of Programming Languages},
	publisher = {{ACM}},
	author = {{McKinna}, James},
	urldate = {2019-03-22},
	date = {2006},
	note = {event-place: Charleston, South Carolina, {USA}},
	file = {ACM Full Text PDF:/Users/richardford/Zotero/storage/IR878C3R/McKinna - 2006 - Why Dependent Types Matter.pdf:application/pdf}
}

@article{altenkirch_why_nodate,
	title = {Why Dependent Types Matter},
	abstract = {We exhibit the rationale behind the design of Epigram, a dependently typed programming language and interactive program development system, using reﬁnements of a well known program—merge sort—as a running example. We discuss its relationship with other proposals to introduce aspects of dependent types into functional programming languages and sketch some topics for further work in this area.},
	pages = {21},
	author = {Altenkirch, Thorsten and {McBride}, Conor and {McKinna}, James},
	langid = {english},
	file = {Altenkirch et al. - Why Dependent Types Matter.pdf:/Users/richardford/Zotero/storage/MMP37DYK/Altenkirch et al. - Why Dependent Types Matter.pdf:application/pdf}
}

@video{strange_loop_proof_nodate,
	title = {"Proof Theory Impressionism: Blurring the Curry-Howard Line" by Dan Pittman},
	url = {https://www.youtube.com/watch?v=jrVPB-Ad5Gc&t=31s},
	shorttitle = {"Proof Theory Impressionism},
	author = {{Strange Loop}},
	urldate = {2019-03-22}
}

@article{bansal_holist:_2019,
	title = {{HOList}: An Environment for Machine Learning of Higher-Order Theorem Proving (extended version)},
	url = {http://arxiv.org/abs/1904.03241},
	shorttitle = {{HOList}},
	abstract = {We present an environment, benchmark, and deep learning driven automated theorem prover for higher-order logic. Higher-order interactive theorem provers enable the formalization of arbitrary mathematical theories and thereby present an interesting, open-ended challenge for deep learning. We provide an open-source framework based on the {HOL} Light theorem prover that can be used as a reinforcement learning environment. {HOL} Light comes with a broad coverage of basic mathematical theorems on calculus and the formal proof of the Kepler conjecture, from which we derive a challenging benchmark for automated reasoning. We also present a deep reinforcement learning driven automated theorem prover, {DeepHOL}, with strong initial results on this benchmark.},
	journaltitle = {{arXiv}:1904.03241 [cs]},
	author = {Bansal, Kshitij and Loos, Sarah M. and Rabe, Markus N. and Szegedy, Christian and Wilcox, Stewart},
	urldate = {2019-05-26},
	date = {2019-04-05},
	eprinttype = {arxiv},
	eprint = {1904.03241},
	keywords = {Computer Science - Logic in Computer Science, Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
	file = {arXiv\:1904.03241 PDF:/Users/richardford/Zotero/storage/6KEIAT9S/Bansal et al. - 2019 - HOList An Environment for Machine Learning of Hig.pdf:application/pdf;arXiv.org Snapshot:/Users/richardford/Zotero/storage/JANLZQ2R/1904.html:text/html}
}

@article{yang_learning_2019,
	title = {Learning to Prove Theorems via Interacting with Proof Assistants},
	url = {http://arxiv.org/abs/1905.09381},
	abstract = {Humans prove theorems by relying on substantial high-level reasoning and problem-specific insights. Proof assistants offer a formalism that resembles human mathematical reasoning, representing theorems in higher-order logic and proofs as high-level tactics. However, human experts have to construct proofs manually by entering tactics into the proof assistant. In this paper, we study the problem of using machine learning to automate the interaction with proof assistants. We construct {CoqGym}, a large-scale dataset and learning environment containing 71K human-written proofs from 123 projects developed with the Coq proof assistant. We develop {ASTactic}, a deep learning-based model that generates tactics as programs in the form of abstract syntax trees ({ASTs}). Experiments show that {ASTactic} trained on {CoqGym} can generate effective tactics and can be used to prove new theorems not previously provable by automated methods. Code is available at https://github.com/princeton-vl/{CoqGym}.},
	journaltitle = {{arXiv}:1905.09381 [cs, stat]},
	author = {Yang, Kaiyu and Deng, Jia},
	urldate = {2019-05-26},
	date = {2019-05-21},
	eprinttype = {arxiv},
	eprint = {1905.09381},
	keywords = {Computer Science - Logic in Computer Science, Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Statistics - Machine Learning},
	file = {arXiv\:1905.09381 PDF:/Users/richardford/Zotero/storage/A6VG6AAK/Yang and Deng - 2019 - Learning to Prove Theorems via Interacting with Pr.pdf:application/pdf;arXiv.org Snapshot:/Users/richardford/Zotero/storage/R3L7GILT/1905.html:text/html}
}

@software{noauthor_learning_2019,
	title = {A Learning Environment for Theorem Proving with the Coq proof assistant: princeton-vl/{CoqGym}},
	rights = {{BSD}-2-Clause},
	url = {https://github.com/princeton-vl/CoqGym},
	shorttitle = {A Learning Environment for Theorem Proving with the Coq proof assistant},
	publisher = {Princeton Vision \& Learning Lab},
	urldate = {2019-05-26},
	date = {2019-05-26},
	note = {original-date: 2019-05-24T22:31:20Z}
}

@article{sozeau_metacoq_nodate,
	title = {The {MetaCoq} Project},
	abstract = {The {MetaCoq} project1 aims to provide a certiﬁed meta-programming environment in Coq. It builds on Template-Coq, a plugin for Coq originally implemented by Malecha (2014), which provided a reiﬁer for Coq terms and global declarations, as represented in the Coq kernel, as well as a denotation command. Recently, it was used in the {CertiCoq} certiﬁed compiler project (Anand et al., 2017), as its front-end language, to derive parametricity properties (Anand and Morrisett, 2018). However, the syntax lacked semantics, be it typing semantics or operational semantics, which should reﬂect, as formal speciﬁcations in Coq, the semantics of Coq’s type theory itself. The tool was also rather bare bones, providing only rudimentary quoting and unquoting commands. We generalize it to handle the entire Polymorphic Calculus of Cumulative Inductive Constructions ({pCUIC}), as implemented by Coq, including the kernel’s declaration structures for deﬁnitions and inductives, and implement a monad for general manipulation of Coq’s logical environment. We demonstrate how this setup allows Coq users to deﬁne many kinds of general purpose plugins, whose correctness can be readily proved in the system itself, and that can be run eﬃciently after extraction. We give a few examples of implemented plugins, including a parametricity translation and a certifying extraction to call-by-value λ-calculus. We also advocate the use of {MetaCoq} as a foundation for higher-level tools.},
	pages = {39},
	author = {Sozeau, Matthieu},
	langid = {english},
	file = {Sozeau - The MetaCoq Project.pdf:/Users/richardford/Zotero/storage/PXHZCWEL/Sozeau - The MetaCoq Project.pdf:application/pdf}
}

@article{gilbert_definitional_2019,
	title = {Definitional Proof-irrelevance Without K},
	volume = {3},
	issn = {2475-1421},
	url = {http://doi.acm.org/10.1145/3290316},
	doi = {10.1145/3290316},
	abstract = {Definitional equality—or conversion—for a type theory with a decidable type checking is the simplest tool to prove that two objects are the same, letting the system decide just using computation. Therefore, the more things are equal by conversion, the simpler it is to use a language based on type theory. Proof-irrelevance, stating that any two proofs of the same proposition are equal, is a possible way to extend conversion to make a type theory more powerful. However, this new power comes at a price if we integrate it naively, either by making type checking undecidable or by realizing new axioms—such as uniqueness of identity proofs ({UIP})—that are incompatible with other extensions, such as univalence. In this paper, taking inspiration from homotopy type theory, we propose a general way to extend a type theory with definitional proof irrelevance, in a way that keeps type checking decidable and is compatible with univalence. We provide a new criterion to decide whether a proposition can be eliminated over a type (correcting and improving the so-called singleton elimination of Coq) by using techniques coming from recent development on dependent pattern matching without {UIP}. We show the generality of our approach by providing implementations for both Coq and Agda, both of which are planned to be integrated in future versions of those proof assistants.},
	pages = {3:1--3:28},
	issue = {{POPL}},
	journaltitle = {Proc. {ACM} Program. Lang.},
	author = {Gilbert, Gaëtan and Cockx, Jesper and Sozeau, Matthieu and Tabareau, Nicolas},
	urldate = {2019-05-26},
	date = {2019-01},
	keywords = {proof assistants, proof irrelevance, type theory},
	file = {ACM Full Text PDF:/Users/richardford/Zotero/storage/KN2LAI29/Gilbert et al. - 2019 - Definitional Proof-irrelevance Without K.pdf:application/pdf}
}

@inproceedings{timany_cumulative_2018,
	title = {Cumulative Inductive Types In Coq},
	doi = {10.4230/LIPIcs.FSCD.2018.29},
	abstract = {In order to avoid well-known paradoxes associated with self-referential definitions, higher-order dependent type theories stratify the theory using a countably infinite hierarchy of universes (also known as sorts), Type0 : Type1 : · · · . Such type systems are called cumulative if for any type A we have that A : Typei implies A : Typei+1. The Predicative Calculus of Inductive Constructions ({pCIC}) which forms the basis of the Coq proof assistant, is one such system. In this paper we present the Predicative Calculus of Cumulative Inductive Constructions ({pCuIC}) which extends the cumulativity relation to inductive types. We discuss cumulative inductive types as present in Coq 8.7 and their application to formalization and definitional translations. 2012 {ACM} Subject Classification Theory of computation → Type theory, Theory of computation → Lambda calculus},
	booktitle = {{FSCD}},
	author = {Timany, Amin and Sozeau, Matthieu},
	date = {2018},
	keywords = {Calculi, Calculus of constructions, Coq (software), Dependent type, Inductive type, Proof assistant, Type system},
	file = {Full Text PDF:/Users/richardford/Zotero/storage/BQY5D9QX/Timany and Sozeau - 2018 - Cumulative Inductive Types In Coq.pdf:application/pdf}
}

@article{gueneau_formal_nodate,
	title = {Formal Proof and Analysis of an Incremental Cycle Detection Algorithm},
	pages = {23},
	author = {Guéneau, Armaël and Jourdan, Jacques-Henri and Charguéraud, Arthur and Pottier, François},
	langid = {english},
	file = {Guéneau et al. - Formal Proof and Analysis of an Incremental Cycle .pdf:/Users/richardford/Zotero/storage/DGK59PVM/Guéneau et al. - Formal Proof and Analysis of an Incremental Cycle .pdf:application/pdf}
}

@article{breitner_ready_2018,
	title = {Ready, Set, Verify! Applying Hs-to-coq to Real-world Haskell Code (Experience Report)},
	volume = {2},
	issn = {2475-1421},
	url = {http://doi.acm.org/10.1145/3236784},
	doi = {10.1145/3236784},
	abstract = {Good tools can bring mechanical verification to programs written in mainstream functional languages. We use {\textless}pre{\textgreater}hs-to-coq{\textless}/pre{\textgreater} to translate significant portions of Haskell’s {\textless}pre{\textgreater}containers{\textless}/pre{\textgreater} library into Coq, and verify it against specifications that we derive from a variety of sources including type class laws, the library’s test suite, and interfaces from Coq’s standard library. Our work shows that it is feasible to verify mature, widely-used, highly optimized, and unmodified Haskell code. We also learn more about the theory of weight-balanced trees, extend {\textless}pre{\textgreater}hs-to-coq{\textless}/pre{\textgreater} to handle partiality, and – since we found no bugs – attest to the superb quality of well-tested functional code.},
	pages = {89:1--89:16},
	issue = {{ICFP}},
	journaltitle = {Proc. {ACM} Program. Lang.},
	author = {Breitner, Joachim and Spector-Zabusky, Antal and Li, Yao and Rizkallah, Christine and Wiegley, John and Weirich, Stephanie},
	urldate = {2019-05-26},
	date = {2018-07},
	keywords = {Coq, verification, Haskell},
	file = {ACM Full Text PDF:/Users/richardford/Zotero/storage/T6BANJL6/Breitner et al. - 2018 - Ready, Set, Verify! Applying Hs-to-coq to Real-wor.pdf:application/pdf}
}

@thesis{casinghino_combining_2014,
	location = {Philadelphia, {PA}, {USA}},
	title = {Combining Proofs and Programs},
	url = {https://www.seas.upenn.edu/~sweirich/papers/casinghino-thesis.pdf},
	institution = {University of Pennsylvania},
	type = {phdthesis},
	author = {Casinghino, Chris},
	urldate = {2019-05-26},
	date = {2014},
	langid = {english},
	file = {Weirich - 2011 - Combining Proofs and Programs.pdf:/Users/richardford/Zotero/storage/A8VI99N7/Weirich - 2011 - Combining Proofs and Programs.pdf:application/pdf}
}

@inproceedings{casinghino_combining_2014-1,
	location = {New York, {NY}, {USA}},
	title = {Combining Proofs and Programs in a Dependently Typed Language},
	isbn = {978-1-4503-2544-8},
	url = {http://doi.acm.org/10.1145/2535838.2535883},
	doi = {10.1145/2535838.2535883},
	series = {{POPL} '14},
	abstract = {Most dependently-typed programming languages either require that all expressions terminate (e.g. Coq, Agda, and Epigram), or allow infinite loops but are inconsistent when viewed as logics (e.g. Haskell, {ATS}, Ωmega. Here, we combine these two approaches into a single dependently-typed core language. The language is composed of two fragments that share a common syntax and overlapping semantics: a logic that guarantees total correctness, and a call-by-value programming language that guarantees type safety but not termination. The two fragments may interact: logical expressions may be used as programs; the logic may soundly reason about potentially nonterminating programs; programs can require logical proofs as arguments; and "mobile" program values, including proofs computed at runtime, may be used as evidence by the logic. This language allows programmers to work with total and partial functions uniformly, providing a smooth path from functional programming to dependently-typed programming.},
	pages = {33--45},
	booktitle = {Proceedings of the 41st {ACM} {SIGPLAN}-{SIGACT} Symposium on Principles of Programming Languages},
	publisher = {{ACM}},
	author = {Casinghino, Chris and Sjöberg, Vilhelm and Weirich, Stephanie},
	urldate = {2019-05-26},
	date = {2014},
	note = {event-place: San Diego, California, {USA}},
	keywords = {termination, dependent types, general recursion},
	file = {ACM Full Text PDF:/Users/richardford/Zotero/storage/28LRMA7M/Casinghino et al. - 2014 - Combining Proofs and Programs in a Dependently Typ.pdf:application/pdf}
}

@thesis{eisenberg_dependent_2016,
	location = {Philadelphia, {PA}, {USA}},
	title = {{DEPENDENT} {TYPES} {IN} {HASKELL}: {THEORY} {AND} {PRACTICE}},
	pagetotal = {351},
	institution = {Pennsylvania},
	type = {phdthesis},
	author = {Eisenberg, Richard A},
	date = {2016},
	langid = {english},
	file = {Eisenberg - DEPENDENT TYPES IN HASKELL THEORY AND PRACTICE.pdf:/Users/richardford/Zotero/storage/6XMQQ2G5/Eisenberg - DEPENDENT TYPES IN HASKELL THEORY AND PRACTICE.pdf:application/pdf}
}

@article{weirich_specification_2017,
	title = {A Specification for Dependent Types in Haskell},
	volume = {1},
	issn = {2475-1421},
	url = {http://doi.acm.org/10.1145/3110275},
	doi = {10.1145/3110275},
	abstract = {We propose a core semantics for Dependent Haskell, an extension of Haskell with full-spectrum dependent types. Our semantics consists of two related languages. The first is a Curry-style dependently-typed language with nontermination, irrelevant arguments, and equality abstraction. The second, inspired by the Glasgow Haskell Compiler's core language {FC}, is its explicitly-typed analogue, suitable for implementation in {GHC}. All of our results---chiefly, type safety, along with theorems that relate these two languages---have been formalized using the Coq proof assistant. Because our work is backwards compatible with Haskell, our type safety proof holds in the presence of nonterminating computation. However, unlike other full-spectrum dependently-typed languages, such as Coq, Agda or Idris, because of this nontermination, Haskell's term language does not correspond to a consistent logic.},
	pages = {31:1--31:29},
	issue = {{ICFP}},
	journaltitle = {Proc. {ACM} Program. Lang.},
	author = {Weirich, Stephanie and Voizard, Antoine and de Amorim, Pedro Henrique Azevedo and Eisenberg, Richard A.},
	urldate = {2019-05-26},
	date = {2017-08},
	keywords = {Haskell, Dependent Types},
	file = {ACM Full Text PDF:/Users/richardford/Zotero/storage/G2TIF5IX/Weirich et al. - 2017 - A Specification for Dependent Types in Haskell.pdf:application/pdf}
}

@article{de_millo_social_1979,
	title = {Social Processes and Proofs of Theorems and Programs},
	volume = {22},
	issn = {0001-0782},
	url = {http://doi.acm.org/10.1145/359104.359106},
	doi = {10.1145/359104.359106},
	abstract = {It is argued that formal verifications of programs, no matter how obtained, will not play the same key role in the development of computer science and software engineering as proofs do in mathematics. Furthermore the absence of continuity, the inevitability of change, and the complexity of specification of significantly many real programs make the formal verification process difficult to justify and manage. It is felt that ease of formal verification should not dominate program language design.},
	pages = {271--280},
	number = {5},
	journaltitle = {Commun. {ACM}},
	author = {De Millo, Richard A. and Lipton, Richard J. and Perlis, Alan J.},
	urldate = {2019-05-26},
	date = {1979-05},
	keywords = {program verification, formal mathematics, mathematical proofs, program specification},
	file = {ACM Full Text PDF:/Users/richardford/Zotero/storage/29EX5NRG/De Millo et al. - 1979 - Social Processes and Proofs of Theorems and Progra.pdf:application/pdf}
}

@article{dijkstra_political_1978,
	title = {On a Political Pamphlet from the Middle Ages},
	volume = {3},
	issn = {0163-5948},
	url = {http://doi.acm.org/10.1145/1005888.1005890},
	doi = {10.1145/1005888.1005890},
	pages = {14--16},
	number = {2},
	journaltitle = {{SIGSOFT} Softw. Eng. Notes},
	author = {Dijkstra, Edsger W. and {DeMillo}, R. A. and Lipton, R. J. and Perlis, A J.},
	urldate = {2019-05-26},
	date = {1978-04},
	file = {ACM Full Text PDF:/Users/richardford/Zotero/storage/NL8ZHB8J/Dijkstra et al. - 1978 - On a Political Pamphlet from the Middle Ages.pdf:application/pdf}
}

@article{hedin_perspective_nodate,
	title = {A Perspective on Information-Flow Control},
	abstract = {Information-ﬂow control tracks how information propagates through the program during execution to make sure that the program handles the information securely. Secure information ﬂow is comprised of two related aspects: information conﬁdentiality and information integrity — intuitively pertaining to the reading and writing of the information. The prevailing basic semantic notion of secure information ﬂow is noninterference, demanding independence of public (or, in the case of integrity, trusted) output from secret (or, in the case of integrity, untrusted) input. This document gives an account of the state-of-the-art in conﬁdentiality and integrity policies and their enforcement with a systematic formalization of four dominant formulations of noninterference: termination-insensitive, termination-sensitive, progress-insensitive, and progress-sensitive, cast in the setting of two minimal while languages.},
	pages = {29},
	author = {Hedin, Daniel and Sabelfeld, Andrei},
	langid = {english},
	file = {Hedin and Sabelfeld - A Perspective on Information-Flow Control.pdf:/Users/richardford/Zotero/storage/6KCTTWF6/Hedin and Sabelfeld - A Perspective on Information-Flow Control.pdf:application/pdf}
}

@inproceedings{chiricescu_safe:_2013,
	location = {Waltham, {MA}, {USA}},
	title = {{SAFE}: A clean-slate architecture for secure systems},
	isbn = {978-1-4799-1535-4 978-1-4799-3963-3},
	url = {http://ieeexplore.ieee.org/document/6699066/},
	doi = {10.1109/THS.2013.6699066},
	shorttitle = {{SAFE}},
	abstract = {{SAFE} is a large-scale, clean-slate co-design project encompassing hardware architecture, programming languages, and operating systems. Funded by {DARPA}, the goal of {SAFE} is to create a secure computing system from the ground up. {SAFE} hardware provides memory safety, dynamic type checking, and native support for dynamic information ﬂow control. The Breeze programming language leverages the security features of the underlying machine, and the “zero kernel” operating system avoids relying on any single privileged component for overall system security. The {SAFE} project is working towards formally verifying security properties of the runtime software. The {SAFE} system sets a new high-water mark for system security, allowing secure applications to be built on a solid foundation rather than on the inherently vulnerable conventional platforms available today.},
	eventtitle = {2013 {IEEE} International Conference on Technologies for Homeland Security ({HST})},
	pages = {570--576},
	booktitle = {2013 {IEEE} International Conference on Technologies for Homeland Security ({HST})},
	publisher = {{IEEE}},
	author = {Chiricescu, Silviu and {DeHon}, Andre and Demange, Delphine and Iyer, Suraj and Kliger, Aleksey and Morrisett, Greg and Pierce, Benjamin C. and Reubenstein, Howard and Smith, Jonathan M. and Sullivan, Gregory T. and Thomas, Arun and Tov, Jesse and White, Christopher M. and Wittenberg, David},
	urldate = {2019-05-26},
	date = {2013-11},
	langid = {english},
	file = {Chiricescu et al. - 2013 - SAFE A clean-slate architecture for secure system.pdf:/Users/richardford/Zotero/storage/MZKE6TJN/Chiricescu et al. - 2013 - SAFE A clean-slate architecture for secure system.pdf:application/pdf}
}

@inproceedings{sjosten_information_2018,
	title = {Information Flow Tracking for Side-Effectful Libraries},
	isbn = {978-3-319-92612-4},
	series = {Lecture Notes in Computer Science},
	abstract = {Dynamic information flow control is a promising technique for ensuring confidentiality and integrity of applications that manipulate sensitive information. While much progress has been made on increasingly powerful programming languages ranging from low-level machine languages to high-level languages for distributed systems, surprisingly little attention has been devoted to libraries and {APIs}. The state of the art is largely an all-or-nothing choice: either a shallow or deep library modeling approach. Seeking to break out of this restrictive choice, we formalize a general mechanism that tracks information flow for a language that includes higher-order functions, structured data types and references. A key feature of our approach is the model heap, a part of the memory, where security information is kept to enable the interaction between the labeled program and the unlabeled library. We provide a proof-of-concept implementation and report on experiments with a file system library. The system has been proved correct using Coq.},
	pages = {141--160},
	booktitle = {Formal Techniques for Distributed Objects, Components, and Systems},
	publisher = {Springer International Publishing},
	author = {Sjösten, Alexander and Hedin, Daniel and Sabelfeld, Andrei},
	editor = {Baier, Christel and Caires, Luís},
	date = {2018},
	langid = {english},
	file = {Sjösten et al. - 2018 - Information Flow Tracking for Side-Effectful Libra.pdf:/Users/richardford/Zotero/storage/IEF5SLLA/Sjösten et al. - 2018 - Information Flow Tracking for Side-Effectful Libra.pdf:application/pdf}
}

@incollection{jajodia_termination-insensitive_2008,
	location = {Berlin, Heidelberg},
	title = {Termination-Insensitive Noninterference Leaks More Than Just a Bit},
	volume = {5283},
	isbn = {978-3-540-88312-8 978-3-540-88313-5},
	url = {http://link.springer.com/10.1007/978-3-540-88313-5_22},
	abstract = {Current tools for analysing information ﬂow in programs build upon ideas going back to Denning’s work from the 70’s. These systems enforce an imperfect notion of information ﬂow which has become known as terminationinsensitive noninterference. Under this version of noninterference, information leaks are permitted if they are transmitted purely by the program’s termination behaviour (i.e., whether it terminates or not). This imperfection is the price to pay for having a security condition which is relatively liberal (e.g. allowing whileloops whose termination may depend on the value of a secret) and easy to check. But what is the price exactly? We argue that, in the presence of output, the price is higher than the “one bit” often claimed informally in the literature, and effectively such programs can leak all of their secrets. In this paper we develop a deﬁnition of termination-insensitive noninterference suitable for reasoning about programs with outputs. We show that the deﬁnition generalises “batch-job” style deﬁnitions from the literature and that it is indeed satisﬁed by a Denning-style program analysis with output. Although more than a bit of information can be leaked by programs satisfying this condition, we show that the best an attacker can do is a brute-force attack, which means that the attacker cannot reliably (in a technical sense) learn the secret in polynomial time in the size of the secret. If we further assume that secrets are uniformly distributed, we show that the advantage the attacker gains when guessing the secret after observing a polynomial amount of output is negligible in the size of the secret.},
	pages = {333--348},
	booktitle = {Computer Security - {ESORICS} 2008},
	publisher = {Springer Berlin Heidelberg},
	author = {Askarov, Aslan and Hunt, Sebastian and Sabelfeld, Andrei and Sands, David},
	editor = {Jajodia, Sushil and Lopez, Javier},
	urldate = {2019-05-26},
	date = {2008},
	langid = {english},
	doi = {10.1007/978-3-540-88313-5_22},
	file = {Askarov et al. - 2008 - Termination-Insensitive Noninterference Leaks More.pdf:/Users/richardford/Zotero/storage/WPIGF9BJ/Askarov et al. - 2008 - Termination-Insensitive Noninterference Leaks More.pdf:application/pdf}
}

@inproceedings{goguen_unwinding_1984,
	location = {Oakland, {CA}, {USA}},
	title = {Unwinding and Inference Control},
	isbn = {978-0-8186-0532-1},
	url = {http://ieeexplore.ieee.org/document/6234812/},
	doi = {10.1109/SP.1984.10019},
	eventtitle = {1984 {IEEE} Symposium on Security and Privacy},
	pages = {75--75},
	booktitle = {1984 {IEEE} Symposium on Security and Privacy},
	publisher = {{IEEE}},
	author = {Goguen, Joseph A. and Meseguer, Jose},
	urldate = {2019-05-26},
	date = {1984-04},
	langid = {english},
	file = {Goguen and Meseguer - 1984 - Unwinding and Inference Control.pdf:/Users/richardford/Zotero/storage/4GBIR6L2/Goguen and Meseguer - 1984 - Unwinding and Inference Control.pdf:application/pdf}
}

@article{lescuyer_provencore:_nodate,
	title = {{ProvenCore}: Towards a Verified Isolation Micro-Kernel},
	pages = {69},
	author = {Lescuyer, Stéphane},
	langid = {english},
	file = {Lescuyer - ProvenCore Towards a Verified Isolation Micro-Ker.pdf:/Users/richardford/Zotero/storage/IVKJ3U5P/Lescuyer - ProvenCore Towards a Verified Isolation Micro-Ker.pdf:application/pdf}
}

@unpublished{lescuyer_provencore:_2015,
	title = {{ProvenCore}: Towards a Verified Isolation Micro-Kernel},
	url = {https://zenodo.org/record/47990#.XOrmF-tKi24},
	shorttitle = {{ProvenCore}},
	abstract = {We report on an ongoing project aiming at a fully secure micro-kernel named {ProvenCore}. This operating system is both developed and specified in a single specification language called Smart. The Smart models are used to generate efficient C code and express low- and high-level properties of the implementation, and first among them guarantees of integrity and confidentiality for the various processes running on the kernel. {ProvenCore} is designed to be used as a secure world operating system in mobile devices, beneath a professional application platform or a Trusted Execution Environment.},
	author = {Lescuyer, Stéphane},
	urldate = {2019-05-26},
	date = {2015-01-20},
	keywords = {Certification Toolchain, Formal Proof, Isolation, Separation Kernel,},
	file = {Zenodo Full Text PDF:/Users/richardford/Zotero/storage/QQ2KC8RM/Lescuyer - 2015 - ProvenCore Towards a Verified Isolation Micro-Ker.pdf:application/pdf}
}

@inproceedings{montagu_theory_2013,
	title = {A Theory of Information-Flow Labels},
	doi = {10.1109/CSF.2013.8},
	abstract = {The security literature offers a multitude of calculi, languages, and systems for information-flow control, each with some set of labels encoding security policies that can be attached to data and computations. The exact form of these labels varies widely, with different systems offering many different combinations of features addressing issues such as confidentiality, integrity, and policy ownership. This variation makes it difficult to compare the expressive power of different information-flow frameworks. To enable such comparisons, we introduce label algebras, an abstract interface for information-flow labels equipped with a notion of authority, and study several notions of embedding between them. The simplest is a straightforward notion of injection between label algebras, but this lacks a clear computational motivation and rejects some reasonable encodings between label models. We obtain a more refined account by defining a space of encodings parameterized by an interpretation of labels and authorities, thus giving a semantic flavor to the definition of encoding. We study the theory of semantic encodings and consider two specific instances, one based on the possible observations of boolean values and one based on the behavior of programs in a small lambda-calculus parameterized over an arbitrary label algebra. We use this framework to define and compare a number of concrete label algebras, including realizations of the familiar taint, endorsement, readers, and distrust models, as well as label algebras based on several existing programming languages and operating systems.},
	eventtitle = {2013 {IEEE} 26th Computer Security Foundations Symposium},
	pages = {3--17},
	booktitle = {2013 {IEEE} 26th Computer Security Foundations Symposium},
	author = {Montagu, B. and Pierce, B. C. and Pollack, R.},
	date = {2013-06},
	keywords = {Semantics, programming languages, information-flow control, Algebra, Asbestos, Boolean algebra, Boolean values, calculus, computational motivation, decentralized label model ({DLM}), Design, {DIFC}, disjunction category model, encoding, Encoding, Flume, {HiStar}, Information flow control ({IFC}), information-flow frameworks, information-flow labels, {JIF}, label algebras, label models, labels encoding security policies, lambda-calculus, Languages, Lattices, {LIO}, Observers, operating systems, Security, semantic encodings theory, Syntactics, telecommunication security, Theory},
	file = {IEEE Xplore Abstract Record:/Users/richardford/Zotero/storage/RBVYSQD8/6595817.html:text/html;IEEE Xplore Full Text PDF:/Users/richardford/Zotero/storage/82XHQZSG/Montagu et al. - 2013 - A Theory of Information-Flow Labels.pdf:application/pdf}
}

@inproceedings{menon_shakti-t:_2017,
	location = {New York, {NY}, {USA}},
	title = {Shakti-T: A {RISC}-V Processor with Light Weight Security Extensions},
	isbn = {978-1-4503-5266-6},
	url = {http://doi.acm.org/10.1145/3092627.3092629},
	doi = {10.1145/3092627.3092629},
	series = {{HASP} '17},
	shorttitle = {Shakti-T},
	abstract = {With increased usage of compute cores for sensitive applications, including e-commerce, there is a need to provide additional hardware support for securing information from memory based attacks. This work presents a unified hardware framework for handling spatial and temporal memory attacks. The paper integrates the proposed hardware framework with a {RISC}-V based micro-architecture with an enhanced application binary interface that enables software layers to use these features to protect sensitive data. We demonstrate the effectiveness of the proposed scheme through practical case studies in addition to taking the design through a {VLSI} {CAD} design flow. The proposed processor reduces the metadata storage overhead up to 4 x in comparison with the existing solutions, while incurring an area overhead of just 1914 {LUTs} and 2197 flip flops on an {FPGA}, without affecting the critical path delay of the processor.},
	pages = {2:1--2:8},
	booktitle = {Proceedings of the Hardware and Architectural Support for Security and Privacy},
	publisher = {{ACM}},
	author = {Menon, Arjun and Murugan, Subadra and Rebeiro, Chester and Gala, Neel and Veezhinathan, Kamakoti},
	urldate = {2019-05-26},
	date = {2017},
	note = {event-place: Toronto, {ON}, Canada},
	keywords = {Buffer Overflow, Memory Security, Secure Processor Architecture, Spatial Attacks, Tagged Architecture, Temporal Attacks},
	file = {ACM Full Text PDF:/Users/richardford/Zotero/storage/R3FUM3FC/Menon et al. - 2017 - Shakti-T A RISC-V Processor with Light Weight Sec.pdf:application/pdf}
}

@article{jung_iris_2018-1,
	title = {Iris from the ground up: A modular foundation for higher-order concurrent separation logic},
	volume = {28},
	issn = {0956-7968, 1469-7653},
	url = {https://www.cambridge.org/core/product/identifier/S0956796818000151/type/journal_article},
	doi = {10.1017/S0956796818000151},
	shorttitle = {Iris from the ground up},
	abstract = {Iris is a framework for higher-order concurrent separation logic, which has been implemented in the Coq proof assistant and deployed very effectively in a wide variety of veriﬁcation projects. Iris was designed with the express goal of simplifying and consolidating the foundations of modern separation logics, but it has evolved over time, and the design and semantic foundations of Iris itself have yet to be fully written down and explained together properly in one place. Here, we attempt to ﬁll this gap, presenting a reasonably complete picture of the latest version of Iris (version 3.1), from ﬁrst principles and in one coherent narrative.},
	journaltitle = {Journal of Functional Programming},
	author = {Jung, Ralf and Krebbers, Robbert and Jourdan, Jacques-Henri and Bizjak, Aleš and Birkedal, Lars and Dreyer, Derek},
	urldate = {2019-05-26},
	date = {2018},
	langid = {english},
	file = {Jung et al. - 2018 - Iris from the ground up A modular foundation for .pdf:/Users/richardford/Zotero/storage/F8IP6QRI/Jung et al. - 2018 - Iris from the ground up A modular foundation for .pdf:application/pdf}
}

@online{noauthor_ghc_nodate,
	title = {{GHC} User’s Guide — Glasgow Haskell Compiler 8.6.5 User's Guide},
	url = {https://downloads.haskell.org/~ghc/latest/docs/html/users_guide/index.html},
	urldate = {2019-05-26},
	file = {Welcome to the GHC User’s Guide — Glasgow Haskell Compiler 8.6.5 User's Guide:/Users/richardford/Zotero/storage/F8SX6JFV/index.html:text/html}
}

@online{noauthor_algebraic_nodate,
	title = {Algebraic Specification of Stack Effects for Forth Programs},
	url = {https://www.researchgate.net/publication/269399251_Algebraic_Specification_of_Stack_Effects_for_Forth_Programs},
	abstract = {{ResearchGate} is a network dedicated to science and research. Connect, collaborate and discover scientific publications, jobs and conferences. All for free.},
	titleaddon = {{ResearchGate}},
	urldate = {2019-05-26},
	langid = {english}
}

@article{poial_forth_nodate,
	title = {Forth and Formal Language Theory},
	abstract = {Forth is an excellent programming paradigm, but it is also an interesting object of investigation for formal language theory. With its clear interface based on stacks Forth programs are easily generated by some formal system (e.g. syntax directed translation scheme). Usually it is possible to make such a formal system to generate only "useful" programs, but this subset of programs is often very small and does not cover interesting features of the Forth language itself.},
	pages = {6},
	author = {Poial, Jaanus},
	langid = {english},
	file = {Poial - Forth and Formal Language Theory.pdf:/Users/richardford/Zotero/storage/BBWF7DFT/Poial - Forth and Formal Language Theory.pdf:application/pdf}
}

@book{power_formal_nodate,
	title = {A Formal Model of Forth Control Words in the Pi-Calculus},
	abstract = {Abstract: In this paper we develop a formal specification of aspects of the Forth programming language. We describe the operation of the Forth compiler as it translates Forth control words, dealing in particular with the interpretation of immediate words during compilation. Our goal here is to provide a basis for the study of safety properties of embedded systems, many of which are constructed using Forth or Forth-like languages. To this end we construct a model of the Forth compiler in the π-calculus, and have simulated its execution by animating this model using the Pict programming language.},
	author = {Power, James F. and Sinclair, David},
	file = {Citeseer - Full Text PDF:/Users/richardford/Zotero/storage/RXSMBBXT/Power and Sinclair - A Formal Model of Forth Control Words in the Pi-Ca.pdf:application/pdf;Citeseer - Snapshot:/Users/richardford/Zotero/storage/PB52X8ZE/summary.html:text/html}
}

@article{braibant_formal_2013,
	title = {Formal Verification of Hardware Synthesis},
	volume = {8044},
	url = {http://arxiv.org/abs/1301.4779},
	doi = {10.1007/978-3-642-39799-8_14},
	abstract = {We report on the implementation of a certified compiler for a high-level hardware description language ({HDL}) called Fe-Si ({FEatherweight} {SynthesIs}). Fe-Si is a simplified version of Bluespec, an {HDL} based on a notion of guarded atomic actions. Fe-Si is defined as a dependently typed deep embedding in Coq. The target language of the compiler corresponds to a synthesisable subset of Verilog or {VHDL}. A key aspect of our approach is that input programs to the compiler can be defined and proved correct inside Coq. Then, we use extraction and a Verilog back-end (written in {OCaml}) to get a certified version of a hardware design.},
	pages = {213--228},
	journaltitle = {{arXiv}:1301.4779 [cs]},
	author = {Braibant, Thomas and Chlipala, Adam},
	urldate = {2019-05-26},
	date = {2013},
	eprinttype = {arxiv},
	eprint = {1301.4779},
	keywords = {Computer Science - Programming Languages},
	file = {arXiv\:1301.4779 PDF:/Users/richardford/Zotero/storage/M6XE2T6F/Braibant and Chlipala - 2013 - Formal Verification of Hardware Synthesis.pdf:application/pdf;arXiv.org Snapshot:/Users/richardford/Zotero/storage/BAK6PZ7I/1301.html:text/html}
}

@inproceedings{bidmeshki_vericoq:_2015,
	location = {Lisbon, Portugal},
	title = {{VeriCoq}: A Verilog-to-Coq converter for proof-carrying hardware automation},
	isbn = {978-1-4799-8391-9},
	url = {http://ieeexplore.ieee.org/document/7168562/},
	doi = {10.1109/ISCAS.2015.7168562},
	shorttitle = {{VeriCoq}},
	abstract = {Proof carrying hardware intellectual property ({PCHIP}) introduces a new framework in which a hardware (semiconductor) Intellectual Property ({IP}) is accompanied by formal proofs of certain security-related properties, ensuring that the acquired {IP} is trustworthy and free from hardware Trojans. In the {PCHIP} framework, conversion of the design from a hardware description language ({HDL}) to a formal representation is an essential step. Towards automating this process, herein we introduce {VeriCoq}, a converter of designs described in Register Transfer Level ({RTL}) Verilog to their corresponding representation in the Coq theorem proving language, based on the rules deﬁned in the {PCHIP} framework. {VeriCoq} supports most of the synthesizable Verilog constructs and is the ﬁrst step towards automating the entire framework, in order to simplify adoption of {PCHIP} by hardware {IP} developers and consumers and, thereby, increase {IP} trustworthiness.},
	eventtitle = {2015 {IEEE} International Symposium on Circuits and Systems ({ISCAS})},
	pages = {29--32},
	booktitle = {2015 {IEEE} International Symposium on Circuits and Systems ({ISCAS})},
	publisher = {{IEEE}},
	author = {Bidmeshki, Mohammad-Mahdi and Makris, Yiorgos},
	urldate = {2019-05-26},
	date = {2015-05},
	langid = {english},
	file = {Bidmeshki and Makris - 2015 - VeriCoq A Verilog-to-Coq converter for proof-carr.pdf:/Users/richardford/Zotero/storage/3CDKTVGC/Bidmeshki and Makris - 2015 - VeriCoq A Verilog-to-Coq converter for proof-carr.pdf:application/pdf}
}

@book{chailloux_developing_2000,
	location = {Paris},
	title = {Developing Applications with Objective Caml},
	isbn = {978-2-84177-121-9},
	publisher = {O'Reilly},
	author = {Chailloux, Emmanuel and Manoury, Pascal and Pagano, Bruno},
	date = {2000},
	langid = {english},
	note = {{OCLC}: 803160552},
	file = {Chailloux et al. - 2000 - Développement d'applications avec objective caml.pdf:/Users/richardford/Zotero/storage/MUB2AMXF/Chailloux et al. - 2000 - Développement d'applications avec objective caml.pdf:application/pdf}
}

@online{noauthor_handbook_nodate,
	title = {Handbook Of Floating Point Arithmetic Download {eBook} for Free},
	url = {http://ebook4scaricare.com/gratis/handbook-of-floating-point-arithmetic/},
	abstract = {Download handbook of floating point arithmetic ebook free in {PDF} and {EPUB} Format. handbook of floating point arithmetic also available in docx and mobi. Read handbook of floating point arithmetic online, read in mobile or Kindle.},
	urldate = {2019-05-26},
	langid = {american},
	file = {Handbook Of Floating Point Arithmetic Download eBo.pdf:/Users/richardford/Zotero/storage/F24UXIX3/Handbook Of Floating Point Arithmetic Download eBo.pdf:application/pdf}
}

@article{noauthor_ieee_nodate,
	title = {{IEEE} Std 1800™-2012 (Revision of {IEEE} Std 1800-2009) {IEEE} Standard for {SystemVerilog}—Unified Hardware Design, Specification, and Verification Language},
	abstract = {Abstract: The definition of the language syntax and semantics for {SystemVerilog}, which is a unified hardware design, specification, and verification language, is provided. This standard includes support for modeling hardware at the behavioral, register transfer level ({RTL}), and gate-level abstraction levels, and for writing testbenches using coverage, assertions, object-oriented programming, and constrained random verification. The standard also provides application programming interfaces ({APIs}) to foreign programming languages.},
	pages = {1315},
	langid = {english},
	file = {IEEE Std 1800™-2012 (Revision of IEEE Std 1800-200.pdf:/Users/richardford/Zotero/storage/88A583HL/IEEE Std 1800™-2012 (Revision of IEEE Std 1800-200.pdf:application/pdf}
}

@report{noauthor_ieee_nodate-1,
	title = {{IEEE} Standard for Universal Verification Methodology Language Reference Manual},
	url = {http://ieeexplore.ieee.org/document/7932212/},
	abstract = {The Universal Verification Methodology ({UVM}) that can improve interoperability, reduce the cost of using intellectual property ({IP}) for new projects or electronic design automation ({EDA}) tools, and make it easier to reuse verification components is provided. Overall, using this standard will lower verification costs and improve design quality throughout the industry. The primary audiences for this standard are the implementors of the {UVM} base class library, the implementors of tools supporting the {UVM} base class library, and the users of the {UVM} base class library.},
	institution = {{IEEE}},
	urldate = {2019-05-26},
	langid = {english},
	doi = {10.1109/IEEESTD.2017.7932212},
	file = {IEEE Standard for Universal Verification Methodolo.pdf:/Users/richardford/Zotero/storage/6F8A2Z6Y/IEEE Standard for Universal Verification Methodolo.pdf:application/pdf}
}

@article{noauthor_ieee_nodate-2,
	title = {{IEEE} Std 754™-2008 (Revision of {IEEE} Std 754-1985), {IEEE} Standard for Floating-Point Arithmetic},
	abstract = {Abstract: This standard specifies interchange and arithmetic formats and methods for binary and decimal floating-point arithmetic in computer programming environments. This standard specifies exception conditions and their default handling. An implementation of a floating-point system conforming to this standard may be realized entirely in software, entirely in hardware, or in any combination of software and hardware. For operations specified in the normative part of this standard, numerical results and exceptions are uniquely determined by the values of the input data, sequence of operations, and destination formats, all under user control.},
	pages = {70},
	langid = {english},
	file = {IEEE Std 754™-2008 (Revision of IEEE Std 754-1985).pdf:/Users/richardford/Zotero/storage/MT5IUVF8/IEEE Std 754™-2008 (Revision of IEEE Std 754-1985).pdf:application/pdf}
}

@article{hughes_why_1989,
	title = {Why Functional Programming Matters},
	volume = {32},
	issn = {0010-4620, 1460-2067},
	url = {https://academic.oup.com/comjnl/article-lookup/doi/10.1093/comjnl/32.2.98},
	doi = {10.1093/comjnl/32.2.98},
	abstract = {As software becomes more and more complex, it is more and more important to structure it well. Well-structured software is easy to write and to debug, and provides a collection of modules that can be reused to reduce future programming costs. In this paper we show that two features of functional languages in particular, higher-order functions and lazy evaluation, can contribute signiﬁcantly to modularity. As examples, we manipulate lists and trees, program several numerical algorithms, and implement the alpha-beta heuristic (an algorithm from Artiﬁcial Intelligence used in game-playing programs). We conclude that since modularity is the key to successful programming, functional programming oﬀers important advantages for software development.},
	pages = {98--107},
	number = {2},
	journaltitle = {The Computer Journal},
	author = {Hughes, J.},
	urldate = {2019-05-26},
	date = {1989-02-01},
	langid = {english},
	file = {Hughes - 1989 - Why Functional Programming Matters.pdf:/Users/richardford/Zotero/storage/3LZ6DT3E/Hughes - 1989 - Why Functional Programming Matters.pdf:application/pdf}
}

@article{williams_interactive_nodate,
	title = {An Interactive Plotting Program},
	pages = {259},
	author = {Williams, Thomas and Kelley, Colin},
	langid = {english},
	file = {Williams and Kelley - An Interactive Plotting Program.pdf:/Users/richardford/Zotero/storage/EJ58MWQ4/Williams and Kelley - An Interactive Plotting Program.pdf:application/pdf}
}

@inproceedings{da_rocha_pinto_tada:_2014,
	title = {{TaDA}: A Logic for Time and Data Abstraction},
	isbn = {978-3-662-44202-9},
	series = {Lecture Notes in Computer Science},
	shorttitle = {{TaDA}},
	abstract = {To avoid data races, concurrent operations should either be at distinct times or on distinct data. Atomicity is the abstraction that an operation takes effect at a single, discrete instant in time, with linearisability being a well-known correctness condition which asserts that concurrent operations appear to behave atomically. Disjointness is the abstraction that operations act on distinct data resource, with concurrent separation logics enabling reasoning about threads that appear to operate independently on disjoint resources.We present {TaDA}, a program logic that combines the benefits of abstract atomicity and abstract disjointness. Our key contribution is the introduction of atomic triples, which offer an expressive approach to specifying program modules. By building up examples, we show that {TaDA} supports elegant modular reasoning in a way that was not previously possible.},
	pages = {207--231},
	booktitle = {{ECOOP} 2014 – Object-Oriented Programming},
	publisher = {Springer Berlin Heidelberg},
	author = {da Rocha Pinto, Pedro and Dinsdale-Young, Thomas and Gardner, Philippa},
	editor = {Jones, Richard},
	date = {2014},
	langid = {english},
	keywords = {Abstract State, Data Abstraction, Label Transition System, Proof Rule, Shared Region},
	file = {da Rocha Pinto et al. - 2014 - TaDA A Logic for Time and Data Abstraction.pdf:/Users/richardford/Zotero/storage/YXE6B83X/da Rocha Pinto et al. - 2014 - TaDA A Logic for Time and Data Abstraction.pdf:application/pdf}
}

@inproceedings{koh_c_2019,
	location = {New York, {NY}, {USA}},
	title = {From C to Interaction Trees: Specifying, Verifying, and Testing a Networked Server},
	isbn = {978-1-4503-6222-1},
	url = {http://doi.acm.org/10.1145/3293880.3294106},
	doi = {10.1145/3293880.3294106},
	series = {{CPP} 2019},
	shorttitle = {From C to Interaction Trees},
	abstract = {We present the first formal verification of a networked server implemented in C. Interaction trees, a general structure for representing reactive computations, are used to tie together disparate verification and testing tools (Coq, {VST}, and {QuickChick}) and to axiomatize the behavior of the operating system on which the server runs ({CertiKOS}). The main theorem connects a specification of acceptable server behaviors, written in a straightforward “one client at a time” style, with the {CompCert} semantics of the C program. The variability introduced by low-level buffering of messages and interleaving of multiple {TCP} connections is captured using network refinement, a variant of observational refinement.},
	pages = {234--248},
	booktitle = {Proceedings of the 8th {ACM} {SIGPLAN} International Conference on Certified Programs and Proofs},
	publisher = {{ACM}},
	author = {Koh, Nicolas and Li, Yao and Li, Yishuai and Xia, Li-yao and Beringer, Lennart and Honoré, Wolf and Mansky, William and Pierce, Benjamin C. and Zdancewic, Steve},
	urldate = {2019-05-26},
	date = {2019},
	note = {event-place: Cascais, Portugal},
	keywords = {formal verification, interaction trees, network refinement, {QuickChick}, {TCP}, testing, {VST}},
	file = {ACM Full Text PDF:/Users/richardford/Zotero/storage/G7MPS9TF/Koh et al. - 2019 - From C to Interaction Trees Specifying, Verifying.pdf:application/pdf}
}

@article{mansky_verifying_nodate,
	title = {Verifying Concurrent Programs with {VST}},
	pages = {15},
	author = {Mansky, William},
	langid = {english},
	file = {Mansky - Verifying Concurrent Programs with VST.pdf:/Users/richardford/Zotero/storage/FZQ3YMV8/Mansky - Verifying Concurrent Programs with VST.pdf:application/pdf}
}

@article{rand_formally_nodate,
	title = {Formally Verified Quantum Programming},
	pages = {222},
	author = {Rand, Robert},
	langid = {english},
	file = {Rand - Formally Verified Quantum Programming.pdf:/Users/richardford/Zotero/storage/RLFBPD4Y/Rand - Formally Verified Quantum Programming.pdf:application/pdf}
}

@incollection{davenport_computer_2011,
	location = {Berlin, Heidelberg},
	title = {Computer Certified Efficient Exact Reals in Coq},
	volume = {6824},
	isbn = {978-3-642-22672-4 978-3-642-22673-1},
	url = {http://link.springer.com/10.1007/978-3-642-22673-1_7},
	abstract = {Floating point operations are fast, but require continuous effort on the part of the user in order to ensure that the results are correct. This burden can be shifted away from the user by providing a library of exact analysis in which the computer handles the error estimates. We provide an implementation of the exact real numbers in the Coq proof assistant. This improves on the earlier Coq-implementation by O’Connor in two ways: we use dyadic rationals built from the machine integers and we optimize computation of power series by using approximate division. Moreover, we use type classes for clean mathematical interfaces. This appears to be the ﬁrst time that type classes are used in heavy computation. We obtain over a 100 times speed up of the basic operations and indications for improving the Coq system.},
	pages = {90--106},
	booktitle = {Intelligent Computer Mathematics},
	publisher = {Springer Berlin Heidelberg},
	author = {Krebbers, Robbert and Spitters, Bas},
	editor = {Davenport, James H. and Farmer, William M. and Urban, Josef and Rabe, Florian},
	urldate = {2019-05-26},
	date = {2011},
	langid = {english},
	doi = {10.1007/978-3-642-22673-1_7},
	file = {Krebbers and Spitters - 2011 - Computer Certified Efficient Exact Reals in Coq.pdf:/Users/richardford/Zotero/storage/LEETDCJM/Krebbers and Spitters - 2011 - Computer Certified Efficient Exact Reals in Coq.pdf:application/pdf}
}

@incollection{hutchison_picard_2013,
	location = {Berlin, Heidelberg},
	title = {The Picard Algorithm for Ordinary Differential Equations in Coq},
	volume = {7998},
	isbn = {978-3-642-39633-5 978-3-642-39634-2},
	url = {http://link.springer.com/10.1007/978-3-642-39634-2_34},
	abstract = {Ordinary Diﬀerential Equations ({ODEs}) are ubiquitous in physical applications of mathematics. The Picard-Lindelo¨f theorem is the ﬁrst fundamental theorem in the theory of {ODEs}. It allows one to solve diﬀerential equations numerically. We provide a constructive development of the Picard-Lindelo¨f theorem which includes a program together with suﬃcient conditions for its correctness. The proof/program is written in the Coq proof assistant and uses the implementation of eﬃcient real numbers from the {CoRN} library and the {MathClasses} library. Our proof makes heavy use of operators and functionals, functions on spaces of functions. This is faithful to the usual mathematical description, but a novel level of abstraction for certiﬁed exact real computation.},
	pages = {463--468},
	booktitle = {Interactive Theorem Proving},
	publisher = {Springer Berlin Heidelberg},
	author = {Makarov, Evgeny and Spitters, Bas},
	editor = {Blazy, Sandrine and Paulin-Mohring, Christine and Pichardie, David},
	editorb = {Hutchison, David and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M. and Mattern, Friedemann and Mitchell, John C. and Naor, Moni and Nierstrasz, Oscar and Pandu Rangan, C. and Steffen, Bernhard and Sudan, Madhu and Terzopoulos, Demetri and Tygar, Doug and Vardi, Moshe Y. and Weikum, Gerhard},
	editorbtype = {redactor},
	urldate = {2019-05-26},
	date = {2013},
	langid = {english},
	doi = {10.1007/978-3-642-39634-2_34},
	file = {Makarov and Spitters - 2013 - The Picard Algorithm for Ordinary Differential Equ.pdf:/Users/richardford/Zotero/storage/6J3Y858E/Makarov and Spitters - 2013 - The Picard Algorithm for Ordinary Differential Equ.pdf:application/pdf}
}

@book{nelson_computer_1980,
	location = {Boston, {MA}},
	title = {Computer Techniques in Radiation Transport and Dosimetry},
	isbn = {978-1-4684-3608-2},
	url = {http://public.eblib.com/choice/publicfullrecord.aspx?p=3083212},
	abstract = {In October 1978, a group of 41 scientists from 14 countries met in Erice, Sicily to attend the Second Course of the Interna tional School of Radiation Damage and Protection "Ettore Majorana", the proceedings of which are contained in this book. The countries represented at the School were: Brazil, Canada, Federal Republic of Germany, Finland, German Democratic Republic, Hungary, India, Italy, Japan, Spain, Sweden, Switzerland, United States of America, and Yugoslavia. The School was officially sponsored by the Italian Health Physics Association, the Italian Ministry of Public Education, the Italian Ministry of Scientific and Technological Research, and the Sicilian Regional Government. In addition, administrative and tech nical support was received from the Stanford Linear Accelerator Center and from {CERN}. The past 15 or so years have witnessed a significant develop ment of computer methods in the science of radiation protection. The radiation transport codes associated with hadronic and electro magnetic cascades, reactor shielding, unfolding techniques, and gamma ray spectrum analysis have reached the state-of-the-art level, and the Erice Course aimed at presenting as comprehensive an over view of these programs as was possible within the allotted time span.},
	publisher = {Springer {US}},
	author = {Nelson, Walter R and Jenkins, T. M},
	urldate = {2019-05-27},
	date = {1980},
	langid = {english},
	note = {{OCLC}: 851841483},
	file = {Nelson and Jenkins - 1980 - Computer Techniques in Radiation Transport and Dos.pdf:/Users/richardford/Zotero/storage/IFUB94ZN/Nelson and Jenkins - 1980 - Computer Techniques in Radiation Transport and Dos.pdf:application/pdf}
}

@inproceedings{stoddart_forth_2012,
	title = {Forth Semantics for Compiler Verification},
	abstract = {Here we are interested in the semantics of Forth from the point of view of using Forth as a target language for a formally verified compiler for Ruth-R, a reversible sequential programming language we are currently developing. We limit out attention to those Forth operations and constructs which will be targetted by the Ruth-R compiler. To facilitate the comparison of meanings of source and target languages, we represent the semantics of Forth code by translation into a form which can be described using the ”prospective value” semantics we use for Ruth-R.},
	author = {Stoddart, Bill and Ritchie, C. and Dunne, Steve},
	date = {2012},
	keywords = {Compiler, Concurrent computing, Formal verification, Foundations, {HL}7PublishingSubSection {\textless}operations{\textgreater}, Programming language, Prospective search, Verification of Theories},
	file = {Full Text PDF:/Users/richardford/Zotero/storage/9HJDEX34/Stoddart et al. - 2012 - Forth Semantics for Compiler Verification.pdf:application/pdf}
}

@inproceedings{knaggs_practical_1993,
	title = {Practical and theoretical aspects of {FORTH} software development},
	abstract = {This is an investigation into the use of the Forth programming environment. The main areas of enquiry were: interfacing Forth to other languages; interfacing Forth and local area networks; and the use of {RISC} processors with stack based architecture such as the {NC}4000 and Harris {RTX} series. We describe how t o i n terface Forth a n d C. W e also provide a system with a multi-tasking interrupt driven interface to the Ibm {NetBios} networking software and a simple, generic, method of task activation through message passing. Many aspects of the investigation proved to be dependent on a more thorough theoretical underpinning for the Forth language. The use of a typeless parameter stack means that a programmer must concern himself with the intellectual burden of managing the parameter stack. The mismatching of stack elements can be the cause of subtle logic errors. We therefore investigated the possibility o f d e v eloping a type algebra" that would allow u s t o d e v elop a typed version of Forth. This thesis includes a theory for a type signature algebra" for the stack based argument passing method used by Forth. To support the use of multi-tasking we provide a simple, but formal, theory of concurrent tasks based on state machines that synchronise on events. This has a graphical notation for people who are not familiar with formal notations. We also looked at how formalisms might be used to deene a semantic model for the Forth language and how formalisms can help to deene the relationship between Forth's stack based virtual machine and register based target processors.},
	author = {Knaggs, Peter J.},
	date = {1993},
	keywords = {Central processing unit, Computer multitasking, Forth, Graphical user interface, Harris affine region detector, Integrated development environment, Message passing, {NetBIOS}, Programmer, Software development, Type signature, Virtual machine},
	file = {Full Text PDF:/Users/richardford/Zotero/storage/2YVPZMA2/Knaggs - 1993 - Practical and theoretical aspects of FORTH softwar.pdf:application/pdf}
}

@incollection{badger_towards_2019,
	location = {Cham},
	title = {Towards Full Proof Automation in Frama-C Using Auto-active Verification},
	volume = {11460},
	isbn = {978-3-030-20651-2 978-3-030-20652-9},
	url = {http://link.springer.com/10.1007/978-3-030-20652-9_6},
	abstract = {While deductive veriﬁcation is increasingly used on real-life code, making it fully automatic remains difﬁcult. The development of powerful {SMT} solvers has improved the situation, but some proofs still require interactive theorem provers in order to achieve full formal veriﬁcation. Auto-active veriﬁcation relies on additional guiding annotations (assertions, ghost code, lemma functions, etc.) and provides an important step towards a greater automation of the proof. However, the support of this methodology often remains partial and depends on the veriﬁcation tool. This paper presents an experience report on a complete functional veriﬁcation of several C programs from the literature and real-life code using auto-active veriﬁcation with the C software analysis platform {FRAMA}-C and its deductive veriﬁcation plugin {WP}. The goal is to use automatic solvers to verify properties that are classically veriﬁed with interactive provers. Based on our experience, we discuss the beneﬁts of this methodology and the current limitations of the tool, as well as proposals of new features to overcome them.},
	pages = {88--105},
	booktitle = {{NASA} Formal Methods},
	publisher = {Springer International Publishing},
	author = {Blanchard, Allan and Loulergue, Frédéric and Kosmatov, Nikolai},
	editor = {Badger, Julia M. and Rozier, Kristin Yvonne},
	urldate = {2019-06-07},
	date = {2019},
	langid = {english},
	doi = {10.1007/978-3-030-20652-9_6},
	file = {Blanchard et al. - 2019 - Towards Full Proof Automation in Frama-C Using Aut.pdf:/Users/richardford/Zotero/storage/446GURGV/Blanchard et al. - 2019 - Towards Full Proof Automation in Frama-C Using Aut.pdf:application/pdf}
}

@incollection{badger_extracting_2019,
	location = {Cham},
	title = {Extracting and Optimizing Formally Verified Code for Systems Programming},
	volume = {11460},
	isbn = {978-3-030-20651-2 978-3-030-20652-9},
	url = {http://link.springer.com/10.1007/978-3-030-20652-9_15},
	abstract = {{MCQC} is a compiler for extracting veriﬁed systems programs to low-level assembly, with no runtime or garbage collection requirements and an emphasis on performance. {MCQC} targets the Gallina functional language used in the Coq proof assistant. {MCQC} translates pure and recursive functions into C++17, while compiling monadic eﬀectful functions to imperative C++ system calls. With a few memory and performance optimizations, {MCQC} combines veriﬁability with memory and runtime performance. By handling eﬀectful and pure functions separately {MCQC} can generate executable veriﬁed code directly from Gallina, reducing the eﬀort of implementing and executing veriﬁed systems.},
	pages = {228--236},
	booktitle = {{NASA} Formal Methods},
	publisher = {Springer International Publishing},
	author = {Ioannidis, Eleftherios and Kaashoek, Frans and Zeldovich, Nickolai},
	editor = {Badger, Julia M. and Rozier, Kristin Yvonne},
	urldate = {2019-06-07},
	date = {2019},
	langid = {english},
	doi = {10.1007/978-3-030-20652-9_15},
	file = {Ioannidis et al. - 2019 - Extracting and Optimizing Formally Verified Code f.pdf:/Users/richardford/Zotero/storage/2F9TQKXK/Ioannidis et al. - 2019 - Extracting and Optimizing Formally Verified Code f.pdf:application/pdf}
}

@inproceedings{fleury_optimizing_2019,
	title = {Optimizing a Verified {SAT} Solver},
	isbn = {978-3-030-20652-9},
	series = {Lecture Notes in Computer Science},
	abstract = {In previous work, I verified a {SAT} solver with dedicated imperative data structures, including the two-watched-literal scheme. In this paper, I extend this formalization with four additional optimizations. The approach is still based on refining an abstract calculus to a deterministic program. In turn, an imperative version is synthesized from the latter, which is then exported to Standard {ML}. The first optimization is the extension with blocking literals. Then, the memory management is improved in order to implement the heuristics necessary to implement search restart and forget, which were subsequently implemented. This required changes to the abstract calculus. Finally, the solver uses machine words until they overflow before switching to unbounded integers. Performance has improved and is now closer to {MiniSAT} without preprocessing.},
	pages = {148--165},
	booktitle = {{NASA} Formal Methods},
	publisher = {Springer International Publishing},
	author = {Fleury, Mathias},
	editor = {Badger, Julia M. and Rozier, Kristin Yvonne},
	date = {2019},
	langid = {english}
}

@inproceedings{ortiz_$$textsf_2019,
	title = {\$\${\textbackslash}textsf \{{ML}\}\_\{{\textbackslash}nu \}\$\$: A Distributed Real-Time Modal Logic},
	isbn = {978-3-030-20652-9},
	series = {Lecture Notes in Computer Science},
	shorttitle = {\$\${\textbackslash}textsf \{{ML}\}\_\{{\textbackslash}nu \}\$\$},
	abstract = {Distributed Real-Time Systems ({DRTS}) can be characterized by several communicating components whose behavior depends on a large number of timing constraints and such components can basically be located at several computers spread over a communication network. Extensions of Timed Modal Logics ({TML}) such as, Timed Propositional Modal Logic ({TPML}), Timed Modal {\textbackslash}({\textbackslash}mu {\textbackslash})-calculus and {\textbackslash}({\textbackslash}textsf \{L\}\_\{{\textbackslash}nu \}{\textbackslash}) have been proposed to capture timed and temporal properties in real-time systems. However, these logics rely on a so-called mono-timed semantics for the underlying Timed Labelled Transition Systems ({TLTS}). This semantics does not capture complex interactions between components with their associated local clocks, thus missing possible action sequences. Based on Multi-Timed Labelled Transition Systems ({MLTS}), which are an extension of {TLTS} in order to cope with the notion of distributed clocks, we propose {\textbackslash}({\textbackslash}textsf \{{ML}\}\_\{{\textbackslash}nu \}{\textbackslash}), an extension of {\textbackslash}({\textbackslash}textsf \{L\}\_\{{\textbackslash}nu \}{\textbackslash}) that relies on a distributed semantics for Timed Automata ({TA}) instead of considering uniform clocks over the distributed systems, we let time vary independently in each {TA}. We define the syntax and the semantics of {\textbackslash}({\textbackslash}textsf \{{ML}\}\_\{{\textbackslash}nu \}{\textbackslash}) over executions of {MLTS} with such a semantics and we show that its model checking problem against {\textbackslash}({\textbackslash}textsf \{{ML}\}\_\{{\textbackslash}nu \}{\textbackslash}) is {EXPTIME}-complete.},
	pages = {19--35},
	booktitle = {{NASA} Formal Methods},
	publisher = {Springer International Publishing},
	author = {Ortiz, James and Amrani, Moussa and Schobbens, Pierre-Yves},
	editor = {Badger, Julia M. and Rozier, Kristin Yvonne},
	date = {2019},
	langid = {english}
}

@inproceedings{salvia_mixed_2019,
	title = {A Mixed Real and Floating-Point Solver},
	isbn = {978-3-030-20652-9},
	series = {Lecture Notes in Computer Science},
	abstract = {Reasoning about mixed real and floating-point constraints is essential for developing accurate analysis tools for floating-point programs. This paper presents {FPRoCK}, a prototype tool for solving mixed real and floating-point formulas. {FPRoCK} transforms a mixed formula into an equisatisfiable one over the reals. This formula is then solved using an off-the-shelf {SMT} solver. {FPRoCK} is also integrated with the {PRECiSA} static analyzer, which computes a sound estimation of the round-off error of a floating-point program. It is used to detect infeasible computational paths, thereby improving the accuracy of {PRECiSA}.},
	pages = {363--370},
	booktitle = {{NASA} Formal Methods},
	publisher = {Springer International Publishing},
	author = {Salvia, Rocco and Titolo, Laura and Feliú, Marco A. and Moscato, Mariano M. and Muñoz, César A. and Rakamarić, Zvonimir},
	editor = {Badger, Julia M. and Rozier, Kristin Yvonne},
	date = {2019},
	langid = {english}
}

@article{hoang_spark_2015,
	title = {{SPARK} 2014 and {GNATprove}},
	volume = {17},
	issn = {1433-2787},
	url = {https://doi.org/10.1007/s10009-014-0322-5},
	doi = {10.1007/s10009-014-0322-5},
	abstract = {Extensive and expensive testing is the method most widely used for gaining confidence in safety-critical software. With a few exceptions, such as {SPARK}, formal verification is rarely used in industry due to its high cost and level of skill required. The grand challenge of building a verifying compiler for static formal verification of programs aims at bringing formal verification to non-expert users of powerful programming languages. This challenge has nurtured competition and collaboration among verification tool builders; an example is the {VerifyThis} competition Huisman et al. (http://digbib.ubka.uni-karlsruhe.de/volltexte/1000034373, 2013). In this paper, we describe our approach to popularising formal verification in the design of the {SPARK} 2014 language and the associated formal verification tool {GNATprove}. In particular, we present our solution to combining tests and proofs, which provides a cost-competitive way to develop software to standards such as do-178. At the heart of our technique are executable contracts, and the ability to both test and prove those. We use running examples from the {VerifyThis} 2012 competition and discuss the results of using our tools on those problems.},
	pages = {695--707},
	number = {6},
	journaltitle = {Int J Softw Tools Technol Transfer},
	author = {Hoang, Duc and Moy, Yannick and Wallenburg, Angela and Chapman, Roderick},
	urldate = {2019-06-11},
	date = {2015-11-01},
	langid = {english},
	keywords = {Program verification, {SPARK}, Deductive verification, Ada, Static analysis, Verifying compiler},
	file = {Hoang et al. - 2015 - SPARK 2014 and GNATprove.pdf:/Users/richardford/Zotero/storage/XPLCF9EM/Hoang et al. - 2015 - SPARK 2014 and GNATprove.pdf:application/pdf}
}

@online{chapman_fumble_nodate,
	title = {The Fumble Programmer},
	url = {https://proteancode.com/wp-content/uploads/2018/02/the_fumble_programmer.pdf},
	abstract = {This paper reflects on the need for formality, discipline and humility in
programming. Starting with the work of Turing, Dijkstra and Humphrey, this paper
goes on to cover our experience with the Personal Software Process, formal pro-
gramming with {SPARK}, and the impact of putting the two together.},
	author = {Chapman, Roderick}
}

@inproceedings{salvia_mixed_2019-1,
	title = {A Mixed Real and Floating-Point Solver},
	isbn = {978-3-030-20652-9},
	series = {Lecture Notes in Computer Science},
	abstract = {Reasoning about mixed real and floating-point constraints is essential for developing accurate analysis tools for floating-point programs. This paper presents {FPRoCK}, a prototype tool for solving mixed real and floating-point formulas. {FPRoCK} transforms a mixed formula into an equisatisfiable one over the reals. This formula is then solved using an off-the-shelf {SMT} solver. {FPRoCK} is also integrated with the {PRECiSA} static analyzer, which computes a sound estimation of the round-off error of a floating-point program. It is used to detect infeasible computational paths, thereby improving the accuracy of {PRECiSA}.},
	pages = {363--370},
	booktitle = {{NASA} Formal Methods},
	publisher = {Springer International Publishing},
	author = {Salvia, Rocco and Titolo, Laura and Feliú, Marco A. and Moscato, Mariano M. and Muñoz, César A. and Rakamarić, Zvonimir},
	editor = {Badger, Julia M. and Rozier, Kristin Yvonne},
	date = {2019},
	langid = {english},
	file = {nfm2019-stfmmr.pdf:/Users/richardford/Zotero/storage/HWBDNTMV/nfm2019-stfmmr.pdf:application/pdf}
}

@inproceedings{erosa_taming_1994,
	title = {Taming control flow: a structured approach to eliminating goto statements},
	doi = {10.1109/ICCL.1994.288377},
	shorttitle = {Taming control flow},
	abstract = {In designing optimizing and parallelizing compilers, it is often simpler and more efficient to deal with programs that have structured control flow. Although most programmers naturally program in a structured fashion, there remain many important programs and benchmarks that include some number of goto statements, thus rendering the entire program unstructured. Such unstructured programs cannot be handled with compilers built with analyses and transformations for structured programs. In this paper we present a straight-forward algorithm to structure C programs by eliminating all goto statements. The method works directly on a high-level abstract syntax tree ({AST}) representation of the program and could easily be integrated into any compiler that uses an {AST}-based intermediate representation. The actual algorithm proceeds by eliminating each goto by first applying a sequence of goto-movement transformations followed by the appropriate goto-elimination transformation. We have implemented the method in the {McCAT} ({McGill} Compiler Architecture Testbed) optimizing/parallelizing C compiler and we present experimental results that demonstrate that the method is both efficient and effective.{\textless}{\textgreater}},
	eventtitle = {Proceedings of 1994 {IEEE} International Conference on Computer Languages ({ICCL}'94)},
	pages = {229--240},
	booktitle = {Proceedings of 1994 {IEEE} International Conference on Computer Languages ({ICCL}'94)},
	author = {Erosa, A. M. and Hendren, L. J.},
	date = {1994-05},
	keywords = {{AST} representation, C language, C programs, Computer science, control flow, Design optimization, Flow graphs, goto statements, goto-elimination, goto-movement transformations, high-level abstract syntax tree, Information analysis, intermediate representation, {McCAT}, {McGill} Compiler Architecture Testbed, optimizing compilers, Optimizing compilers, parallel programming, parallelizing compilers, program compilers, Program processors, Programming profession, Software engineering, Software testing, Switches},
	file = {Erosa and Hendren - 1994 - Taming control flow a structured approach to elim.pdf:/Users/richardford/Zotero/storage/P6UHYZ9B/Erosa and Hendren - 1994 - Taming control flow a structured approach to elim.pdf:application/pdf;IEEE Xplore Abstract Record:/Users/richardford/Zotero/storage/6LYT77BR/288377.html:text/html}
}

@article{ammarguellat_control-flow_1992,
	title = {A control-flow normalization algorithm and its complexity},
	volume = {18},
	issn = {0098-5589},
	doi = {10.1109/32.126773},
	abstract = {A single method for normalizing the control-flow of programs to facilitate program transformations, program analysis, and automatic parallelization is presented. While previous methods result in programs whose control flowgraphs are reducible, programs normalized by this technique satisfy a stronger condition than reducibility and are therefore simpler in their syntax and structure than with previous methods. In particular, all control-flow cycles are normalized into single-entry, single-exit while loops and all {GOTOs} are eliminated. Furthermore, the method avoids problems of code replication that are characteristic of node-splitting techniques. This restructuring obviates the control dependence graph, since afterwards control dependence relations are manifest in the syntax tree of the program. Transformations that effect this normalization are presented, and the complexity of the method is studied.{\textless}{\textgreater}},
	pages = {237--251},
	number = {3},
	journaltitle = {{IEEE} Transactions on Software Engineering},
	author = {Ammarguellat, Z.},
	date = {1992-03},
	keywords = {graph theory, Program processors, Algorithm design and analysis, Automatic control, automatic parallelization, complexity, computational complexity, control dependence relations, control flowgraphs, control-flow cycles, control-flow normalization algorithm, Data analysis, {GOTOs}, node-splitting techniques, parallel algorithms, Pathology, Performance analysis, structured programming, syntax tree, Tree graphs},
	file = {Ammarguellat - 1992 - A control-flow normalization algorithm and its com.pdf:/Users/richardford/Zotero/storage/ZU9CD6QL/Ammarguellat - 1992 - A control-flow normalization algorithm and its com.pdf:application/pdf;IEEE Xplore Abstract Record:/Users/richardford/Zotero/storage/2W69UCHL/126773.html:text/html}
}

@inproceedings{harrison_can_1997,
	title = {Can abstract interpretation become a mainstream compiler technology?},
	isbn = {978-3-540-69576-9},
	series = {Lecture Notes in Computer Science},
	abstract = {Abstract interpretation has enormous promise and yet remains at the margins of compiler practice. In this talk I will argue that abstract interpretation cannot become a mainstream compiler technlogy until its computational, algorithmic aspects are as well-developed as its mathematical, foundational aspects have been to date. I will put the problem into perspective by comparing abstract interpretation to dataflow analysis, for which a well-developed body of compuational methods exists. This comparison reveals that abstract interpretation is most appropriately seen as a method for specifying problems (that is, equations to be solved), and not as a method for specifying solutions (that is, algorithms for solving equations). In particular, efficient solution methods for the equations that arise from abstract interpretations are seldom obvious from the surface of the equations themselves. In other words, the “algorithms” that are strongly suggested by an abstract interpretation, in which the semantic domains are viewed as “data structures, the semantic functions as procedures”, and a simple fixed point engine used to integrate these parts into a workable whole, is naive and is at best suitable for use in prototyping program analyzers. This point of view calls into question the casual dismissal of abstract interpretation as inefficient, by questioning what can be inferred about the complexity of an abstract interpretation problem by superficial examination of the domains and semantic functions involved.},
	pages = {395--395},
	booktitle = {Static Analysis},
	publisher = {Springer Berlin Heidelberg},
	author = {Harrison, Luddy},
	editor = {Van Hentenryck, Pascal},
	date = {1997},
	langid = {english}
}

@article{brady_idris_2013,
	title = {Idris, a general-purpose dependently typed programming language: Design and implementation},
	volume = {23},
	issn = {0956-7968, 1469-7653},
	url = {https://www.cambridge.org/core/product/identifier/S095679681300018X/type/journal_article},
	doi = {10.1017/S095679681300018X},
	shorttitle = {Idris, a general-purpose dependently typed programming language},
	abstract = {Many components of a dependently-typed programming language are by now well understood, for example the underlying type theory, type checking, uniﬁcation and evaluation. How to combine these components into a realistic and usable high-level language is, however, folklore, discovered anew by successive language implementators. In this paper, I describe the implementation of {IDRIS}, a new dependently-typed functional programming language. {IDRIS} is intended to be a general purpose programming language and as such provides high-level concepts such as implicit syntax, type classes and do notation. I describe the high-level language and the underlying type theory, and present a tactic-based method for elaborating concrete high-level syntax with implicit arguments and type classes into a fully explicit type theory. Furthermore, I show how this method facilitates the implementation of new high-level language constructs.},
	pages = {552--593},
	number = {5},
	journaltitle = {Journal of Functional Programming},
	author = {Brady, Edwin},
	urldate = {2019-06-30},
	date = {2013-09},
	langid = {english},
	file = {Brady - 2013 - Idris, a general-purpose dependently typed program.pdf:/Users/richardford/Zotero/storage/BUP9HMTA/Brady - 2013 - Idris, a general-purpose dependently typed program.pdf:application/pdf}
}

@inproceedings{fogarty_concoqtion:_2007,
	location = {New York, {NY}, {USA}},
	title = {Concoqtion: Indexed Types Now!},
	isbn = {978-1-59593-620-2},
	url = {http://doi.acm.org/10.1145/1244381.1244400},
	doi = {10.1145/1244381.1244400},
	series = {{PEPM} '07},
	shorttitle = {Concoqtion},
	abstract = {Almost twenty years after the pioneering efforts of Cardelli, the programming languages community is vigorously pursuing ways to incorporate Fω-style indexed types into programming languages. This paper advocates Concoqtion, a practical approach to adding such highly expressive types to full-fledged programming languages. The approach is applied to {MetaOCaml} using the Coq proof checker to conservatively extend Hindley-Milner type inference. The implementation of {MetaOCaml} Concoqtion requires minimal modifications to the syntax, the type checker, and the compiler; and yields a language comparable in notation to the leading proposals. The resulting language provides unlimited expressiveness in the type system while maintaining decidability. Furthermore, programmers can take advantage of a wide range of libraries not only for the programming language but also for the indexed types. Programming in {MetaOCaml} Concoqtion is illustrated with small examples and a case study implementing a statically-typed domain-specific language.},
	pages = {112--121},
	booktitle = {Proceedings of the 2007 {ACM} {SIGPLAN} Symposium on Partial Evaluation and Semantics-based Program Manipulation},
	publisher = {{ACM}},
	author = {Fogarty, Seth and Pasalic, Emir and Siek, Jeremy and Taha, Walid},
	urldate = {2019-07-07},
	date = {2007},
	note = {event-place: Nice, France},
	file = {ACM Full Text PDF:/Users/richardford/Zotero/storage/W3TQFYD3/Fogarty et al. - 2007 - Concoqtion Indexed Types Now!.pdf:application/pdf}
}

@article{barras_semantical_nodate,
	title = {Semantical Investigations in Intuitionistic Set Theory and Type Theories with Inductive Families},
	pages = {170},
	author = {Barras, Bruno},
	langid = {english},
	file = {Barras - Semantical Investigations in Intuitionistic Set Th.pdf:/Users/richardford/Zotero/storage/SRHR58S6/Barras - Semantical Investigations in Intuitionistic Set Th.pdf:application/pdf}
}

@article{timany_consistency_2017,
	title = {Consistency of the Predicative Calculus of Cumulative Inductive Constructions ({pCuIC})},
	url = {http://arxiv.org/abs/1710.03912},
	abstract = {In order to avoid well-know paradoxes associated with self-referential definitions, higher-order dependent type theories stratify the theory using a countably infinite hierarchy of universes (also known as sorts), Type\$\_0\$ : Type\$\_1\$ : \${\textbackslash}cdots\$ . Such type systems are called cumulative if for any type \$A\$ we have that \$A\$ : Type\$\_\{i\}\$ implies \$A\$ : Type\$\_\{i+1\}\$. The predicative calculus of inductive constructions ({pCIC}) which forms the basis of the Coq proof assistant, is one such system. In this paper we present and establish the soundness of the predicative calculus of cumulative inductive constructions ({pCuIC}) which extends the cumulativity relation to inductive types.},
	journaltitle = {{arXiv}:1710.03912 [cs]},
	author = {Timany, Amin and Sozeau, Matthieu},
	urldate = {2019-07-21},
	date = {2017-10-11},
	eprinttype = {arxiv},
	eprint = {1710.03912},
	keywords = {Computer Science - Programming Languages},
	file = {arXiv\:1710.03912 PDF:/Users/richardford/Zotero/storage/WJNTCXG7/Timany and Sozeau - 2017 - Consistency of the Predicative Calculus of Cumulat.pdf:application/pdf;arXiv.org Snapshot:/Users/richardford/Zotero/storage/MEM7S2RD/1710.html:text/html}
}

@article{gueneau_procrastination_nodate,
	title = {Procrastination},
	abstract = {We present a small Coq library for collecting side conditions and deferring their proof.},
	pages = {7},
	author = {Guéneau, Armaël},
	langid = {english},
	file = {Procrastination.pdf:/Users/richardford/Zotero/storage/JHZQEC2E/Procrastination.pdf:application/pdf}
}

@online{noauthor_mezzo_nodate,
	title = {The Mezzo programming language},
	url = {http://protz.github.io/mezzo/},
	urldate = {2019-08-05},
	file = {protzenko-phd-final.pdf:/Users/richardford/Zotero/storage/W4X3TH6D/protzenko-phd-final.pdf:application/pdf;The Mezzo programming language:/Users/richardford/Zotero/storage/VFGBN4CQ/mezzo.html:text/html}
}

@inproceedings{hoder_z_2011,
	title = {μZ– An Efficient Engine for Fixed Points with Constraints},
	isbn = {978-3-642-22110-1},
	series = {Lecture Notes in Computer Science},
	abstract = {The μZ tool is a scalable, efficient engine for fixed points with constraints. It supports high-level declarative fixed point constraints over a combination of built-in and plugin domains. The built-in domains include formulas presented to the {SMT} solver Z3 and domains known from abstract interpretation. We present the interface to μZ, a number of the domains, and a set of examples illustrating the use of μZ.},
	pages = {457--462},
	booktitle = {Computer Aided Verification},
	publisher = {Springer Berlin Heidelberg},
	author = {Hoder, Kryštof and Bjørner, Nikolaj and de Moura, Leonardo},
	editor = {Gopalakrishnan, Ganesh and Qadeer, Shaz},
	date = {2011},
	langid = {english},
	keywords = {Abstract Interpretation, Abstract Machine, Default Representation, Hash Table, Relational Algebra},
	file = {Springer Full Text PDF:/Users/richardford/Zotero/storage/BJ3ZGIBR/Hoder et al. - 2011 - μZ– An Efficient Engine for Fixed Points with Cons.pdf:application/pdf}
}

@inproceedings{selsam_guiding_2019,
	title = {Guiding High-Performance {SAT} Solvers with Unsat-Core Predictions},
	isbn = {978-3-030-24258-9},
	series = {Lecture Notes in Computer Science},
	abstract = {The {NeuroSAT} neural network architecture was introduced in [37] for predicting properties of propositional formulae. When trained to predict the satisfiability of toy problems, it was shown to find solutions and unsatisfiable cores on its own. However, the authors saw “no obvious path” to using the architecture to improve the state-of-the-art. In this work, we train a simplified {NeuroSAT} architecture to directly predict the unsatisfiable cores of real problems. We modify several state-of-the-art {SAT} solvers to periodically replace their variable activity scores with {NeuroSAT}’s prediction of how likely the variables are to appear in an unsatisfiable core. The modified {MiniSat} solves 10\% more problems on {SATCOMP}-2018 within the standard 5,000 second timeout than the original does. The modified Glucose solves 11\% more problems than the original, while the modified Z3 solves 6\% more. The gains are even greater when the training is specialized for a specific distribution of problems; on a benchmark of hard problems from a scheduling domain, the modified Glucose solves 20\% more problems than the original does within a one-hour timeout. Our results demonstrate that {NeuroSAT} can provide effective guidance to high-performance {SAT} solvers on real problems.},
	pages = {336--353},
	booktitle = {Theory and Applications of Satisfiability Testing – {SAT} 2019},
	publisher = {Springer International Publishing},
	author = {Selsam, Daniel and Bjørner, Nikolaj},
	editor = {Janota, Mikoláš and Lynce, Inês},
	date = {2019},
	langid = {english}
}

@article{bardin_bringing_2019,
	title = {Bringing {CP}, {SAT} and {SMT} together: Next Challenges in Constraint Solving (Dagstuhl Seminar 19062)},
	volume = {9},
	issn = {2192-5283},
	url = {http://drops.dagstuhl.de/opus/volltexte/2019/10857},
	doi = {10.4230/DagRep.9.2.27},
	shorttitle = {Bringing {CP}, {SAT} and {SMT} together},
	pages = {27--47},
	number = {2},
	journaltitle = {Dagstuhl Reports},
	author = {Bardin, Sébastien and Bjørner, Nikolaj and Cadar, Cristian},
	editor = {Bardin, Sébastien and Bjørner, Nikolaj S. and Cadar, Cristian},
	urldate = {2019-08-23},
	date = {2019},
	keywords = {Automated Decision Procedures, Constraint Programming, {SAT}, {SMT}},
	file = {Full Text PDF:/Users/richardford/Zotero/storage/4YE7JBES/Bardin et al. - 2019 - Bringing CP, SAT and SMT together Next Challenges.pdf:application/pdf;Snapshot:/Users/richardford/Zotero/storage/SUY2UKQZ/10857.html:text/html}
}

@article{yurichev_sat/smt_nodate,
	title = {{SAT}/{SMT} by Example},
	pages = {555},
	author = {Yurichev, Dennis},
	langid = {english},
	file = {Yurichev - SATSMT by Example.pdf:/Users/richardford/Zotero/storage/K7ATB273/Yurichev - SATSMT by Example.pdf:application/pdf}
}

@misc{bjorner_programming_nodate,
	title = {Programming Z3},
	url = {http://theory.stanford.edu/~nikolaj/programmingz3.html},
	abstract = {This tutorial provides a programmer's introduction to the Satisfiability Modulo Theories Solver Z3. It describes how to use Z3 through scripts, provided in the Python scripting language, and it describes several of the algorithms underlying the decision procedures within Z3. It aims to broadly cover almost all available features of Z3 and the essence of the underlying algorithms.},
	author = {Bjørner, Nikolaj and de Moura, Leonardo and Nachmanson, lev and Wintersteiger, Christoph}
}

@article{feldman_inferring_2019,
	title = {Inferring Inductive Invariants from Phase Structures},
	url = {http://arxiv.org/abs/1905.07739},
	abstract = {Infinite-state systems such as distributed protocols are challenging to verify using interactive theorem provers or automatic verification tools. Of these techniques, deductive verification is highly expressive but requires the user to annotate the system with inductive invariants. To relieve the user from this labor-intensive and challenging task, invariant inference aims to find inductive invariants automatically. Unfortunately, when applied to infinite-state systems such as distributed protocols, existing inference techniques often diverge, which limits their applicability. This paper proposes user-guided invariant inference based on phase invariants, which capture the different logical phases of the protocol. Users conveys their intuition by specifying a phase structure, an automaton with edges labeled by program transitions; the tool automatically infers assertions that hold in the automaton's states, resulting in a full safety proof.The additional structure from phases guides the inference procedure towards finding an invariant. Our results show that user guidance by phase structures facilitates successful inference beyond the state of the art. We find that phase structures are pleasantly well matched to the intuitive reasoning routinely used by domain experts to understand why distributed protocols are correct, so that providing a phase structure reuses this existing intuition.},
	journaltitle = {{arXiv}:1905.07739 [cs]},
	author = {Feldman, Yotam M. Y. and Wilcox, James R. and Shoham, Sharon and Sagiv, Mooly},
	urldate = {2019-08-26},
	date = {2019-05-19},
	eprinttype = {arxiv},
	eprint = {1905.07739},
	keywords = {Computer Science - Programming Languages},
	file = {arXiv\:1905.07739 PDF:/Users/richardford/Zotero/storage/HK3TF24F/Feldman et al. - 2019 - Inferring Inductive Invariants from Phase Structur.pdf:application/pdf;arXiv.org Snapshot:/Users/richardford/Zotero/storage/BGNWGZEP/1905.html:text/html}
}

@book{manna_temporal_1995,
	location = {New York},
	title = {Temporal Verification of Reactive Systems: Safety},
	isbn = {978-0-387-94459-3},
	url = {https://www.springer.com/gp/book/9780387944593},
	series = {Manna,Z.;Pnueli,A.:Temporal Logic of Reactive Systems},
	shorttitle = {Temporal Verification of Reactive Systems},
	abstract = {This book is about the verification of reactive systems. A reactive system is a system that maintains an ongoing interaction with its environment, as opposed to computing some final value on termination. The family of reactive systems includes many classes of programs whose correct and reliable construction is con­ sidered to be particularly challenging, including concurrent programs, embedded and process control programs, and operating systems. Typical examples of such systems are an air traffic control system, programs controlling mechanical devices such as a train, or perpetually ongoing processes such as a nuclear reactor. With the expanding use of computers in safety-critical areas, where failure is potentially disastrous, correctness is crucial. This has led to the introduction of formal verification techniques, which give both users and designers of software and hardware systems greater confidence that the systems they build meet the desired specifications. Framework The approach promoted in this book is based on the use of temporal logic for specifying properties of reactive systems, and develops an extensive verification methodology for proving that a system meets its temporal specification. Reactive programs must be specified in terms of their ongoing behavior, and temporal logic provides an expressive and natural language for specifying this behavior. Our framework for specifying and verifying temporal properties of reactive systems is based on the following four components: 1. A computational model to describe the behavior of reactive systems. The model adopted in this book is that of a Fair Transition System ({FTS}).},
	publisher = {Springer-Verlag},
	author = {Manna, Zohar and Pnueli, Amir},
	urldate = {2019-08-29},
	date = {1995},
	langid = {english},
	file = {Snapshot:/Users/richardford/Zotero/storage/JF92NIX9/9780387944593.html:text/html}
}

@inproceedings{mullen_oeuf:_2018,
	location = {New York, {NY}, {USA}},
	title = {ŒUf: Minimizing the Coq Extraction {TCB}},
	isbn = {978-1-4503-5586-5},
	url = {http://doi.acm.org/10.1145/3167089},
	doi = {10.1145/3167089},
	series = {{CPP} 2018},
	shorttitle = {ŒUf},
	abstract = {Verifying systems by implementing them in the programming language of a proof assistant (e.g., Gallina for Coq) lets us directly leverage the full power of the proof assistant for verifying the system. But, to execute such an implementation requires extraction, a large complicated process that is in the trusted computing base ({TCB}).  This paper presents Œuf, a verified compiler from a subset of Gallina to assembly. Œuf’s correctness theorem ensures that compilation preserves the semantics of the source Gallina program. We describe how Œuf’s specification can be used as a foreign function interface to reason about the interaction between compiled Gallina programs and surrounding shim code. Additionally, Œufmaintains a small {TCB} for its front-end by reflecting Gallina programs to Œufsource and automatically ensuring equivalence using computational denotation. This design enabled us to implement some early compiler passes (e.g., lambda lifting) in the untrusted reflection and ensure their correctness via translation validation. To evaluate Œuf, we compile Appel’s {SHA}256 specification from Gallina to x86 and write a shim for the generated code, yielding a verified sha256sum implementation with a small {TCB}.},
	pages = {172--185},
	booktitle = {Proceedings of the 7th {ACM} {SIGPLAN} International Conference on Certified Programs and Proofs},
	publisher = {{ACM}},
	author = {Mullen, Eric and Pernsteiner, Stuart and Wilcox, James R. and Tatlock, Zachary and Grossman, Dan},
	urldate = {2019-08-30},
	date = {2018},
	note = {event-place: Los Angeles, {CA}, {USA}},
	keywords = {Coq, Compilers, Formal Verification, Verified Systems},
	file = {ACM Full Text PDF:/Users/richardford/Zotero/storage/LRDLZB4D/Mullen et al. - 2018 - ŒUf Minimizing the Coq Extraction TCB.pdf:application/pdf}
}

@inproceedings{padon_ivy:_2016,
	location = {New York, {NY}, {USA}},
	title = {Ivy: Safety Verification by Interactive Generalization},
	isbn = {978-1-4503-4261-2},
	url = {http://doi.acm.org/10.1145/2908080.2908118},
	doi = {10.1145/2908080.2908118},
	series = {{PLDI} '16},
	shorttitle = {Ivy},
	abstract = {Despite several decades of research, the problem of formal verification of infinite-state systems has resisted effective automation. We describe a system --- Ivy --- for interactively verifying safety of infinite-state systems. Ivy's key principle is that whenever verification fails, Ivy graphically displays a concrete counterexample to induction. The user then interactively guides generalization from this counterexample. This process continues until an inductive invariant is found. Ivy searches for universally quantified invariants, and uses a restricted modeling language. This ensures that all verification conditions can be checked algorithmically. All user interactions are performed using graphical models, easing the user's task. We describe our initial experience with verifying several distributed protocols.},
	pages = {614--630},
	booktitle = {Proceedings of the 37th {ACM} {SIGPLAN} Conference on Programming Language Design and Implementation},
	publisher = {{ACM}},
	author = {Padon, Oded and {McMillan}, Kenneth L. and Panda, Aurojit and Sagiv, Mooly and Shoham, Sharon},
	urldate = {2019-08-30},
	date = {2016},
	note = {event-place: Santa Barbara, {CA}, {USA}},
	keywords = {counterexamples to induction, distributed systems, invariant inference, safety verification},
	file = {ACM Full Text PDF:/Users/richardford/Zotero/storage/IDEQDLZ7/Padon et al. - 2016 - Ivy Safety Verification by Interactive Generaliza.pdf:application/pdf}
}

@online{noauthor_hazel_nodate,
	title = {Hazel, a live functional programming environment featuring typed holes.},
	url = {http://hazel.org/},
	urldate = {2019-08-30},
	file = {Hazel, a live functional programming environment featuring typed holes.:/Users/richardford/Zotero/storage/THGUDSZA/hazel.org.html:text/html}
}

@software{noauthor_hazel_2019,
	title = {Hazel, a live functional programming environment with typed holes: hazelgrove/hazel},
	rights = {{MIT}},
	url = {https://github.com/hazelgrove/hazel},
	shorttitle = {Hazel, a live functional programming environment with typed holes},
	publisher = {hazelgrove},
	urldate = {2019-08-30},
	date = {2019-08-20},
	note = {original-date: 2017-01-27T02:14:05Z}
}

@article{ringer_qed_2019,
	title = {{QED} at Large: A Survey of Engineering of Formally Verified Software},
	volume = {5},
	issn = {2325-1107, 2325-1131},
	url = {https://www.nowpublishers.com/article/Details/PGL-045},
	doi = {10.1561/2500000045},
	shorttitle = {{QED} at Large},
	abstract = {{QED} at Large: A Survey of Engineering of Formally Verified Software},
	pages = {102--281},
	number = {2},
	journaltitle = {{PGL}},
	author = {Ringer, Talia and Palmskog, Karl and Sergey, Ilya and Gligoric, Milos and Tatlock, Zachary},
	urldate = {2019-09-10},
	date = {2019-09-03},
	file = {Full Text PDF:/Users/richardford/Zotero/storage/BNSN99RP/Ringer et al. - 2019 - QED at Large A Survey of Engineering of Formally .pdf:application/pdf;Snapshot:/Users/richardford/Zotero/storage/VLMVNE56/PGL-045.html:text/html}
}

@article{hoare_verifying_2003,
	title = {The Verifying Compiler: A Grand Challenge for Computing Research},
	volume = {50},
	issn = {0004-5411},
	url = {http://doi.acm.org/10.1145/602382.602403},
	doi = {10.1145/602382.602403},
	shorttitle = {The Verifying Compiler},
	abstract = {This contribution proposes a set of criteria that distinguish a grand challenge in science or engineering from the many other kinds of short-term or long-term research problems that engage the interest of scientists and engineers. As an example drawn from Computer Science, it revives an old challenge: the construction and application of a verifying compiler that guarantees correctness of a program before running it.},
	pages = {63--69},
	number = {1},
	journaltitle = {J. {ACM}},
	author = {Hoare, Tony},
	urldate = {2019-09-17},
	date = {2003-01},
	file = {ACM Full Text PDF:/Users/richardford/Zotero/storage/LN7AL2B6/Hoare - 2003 - The Verifying Compiler A Grand Challenge for Comp.pdf:application/pdf}
}

@article{cofer_formal_nodate,
	title = {Formal Methods Case Studies for {DO}-333},
	pages = {203},
	author = {Cofer, Darren and Miller, Steven P and Collins, Rockwell},
	langid = {english},
	file = {Cofer et al. - Formal Methods Case Studies for DO-333.pdf:/Users/richardford/Zotero/storage/VSAYJK4A/Cofer et al. - Formal Methods Case Studies for DO-333.pdf:application/pdf}
}

@incollection{hutchison_formal_2009,
	location = {Berlin, Heidelberg},
	title = {Formal Methods for Privacy},
	volume = {5850},
	isbn = {978-3-642-05088-6 978-3-642-05089-3},
	url = {http://link.springer.com/10.1007/978-3-642-05089-3_1},
	pages = {1--15},
	booktitle = {{FM} 2009: Formal Methods},
	publisher = {Springer Berlin Heidelberg},
	author = {Tschantz, Michael Carl and Wing, Jeannette M.},
	editor = {Cavalcanti, Ana and Dams, Dennis R.},
	editorb = {Hutchison, David and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M. and Mattern, Friedemann and Mitchell, John C. and Naor, Moni and Nierstrasz, Oscar and Pandu Rangan, C. and Steffen, Bernhard and Sudan, Madhu and Terzopoulos, Demetri and Tygar, Doug and Vardi, Moshe Y. and Weikum, Gerhard},
	editorbtype = {redactor},
	urldate = {2019-10-04},
	date = {2009},
	langid = {english},
	doi = {10.1007/978-3-642-05089-3_1},
	file = {Tschantz and Wing - 2009 - Formal Methods for Privacy.pdf:/Users/richardford/Zotero/storage/ZJ5VILLY/Tschantz and Wing - 2009 - Formal Methods for Privacy.pdf:application/pdf}
}

@article{collins_secure_nodate,
	title = {{SECURE} {MATHEMATICALLY}- {ASSURED} {COMPOSITION} {OF} {CONTROL} {MODELS}},
	pages = {134},
	author = {Collins, Rockwell},
	langid = {english},
	file = {Collins - SECURE MATHEMATICALLY- ASSURED COMPOSITION OF CONT.pdf:/Users/richardford/Zotero/storage/GMUEMDAE/Collins - SECURE MATHEMATICALLY- ASSURED COMPOSITION OF CONT.pdf:application/pdf}
}

@book{ringer_qed_2019-1,
	title = {{QED} at Large: A Survey of Engineering of Formally Verified Software},
	url = {http://ieeexplore.ieee.org/document/8824174},
	shorttitle = {{QED} at Large},
	abstract = {Development of formal proofs of correctness of programs can increase actual and perceived reliability and facilitate better understanding of program specifications and their underlying assumptions. Tools supporting such development have been available for over 40 years but have only recently seen wide practical use. Projects based on construction of machine-checked formal proofs are now reaching an unprecedented scale, comparable to large software projects, which leads to new challenges in proof development and maintenance. Despite its increasing importance, the field of proof engineering is seldom considered in its own right; related theories, techniques, and tools span many fields and venues. {QED} at Large covers the timeline and research literature concerning proof development for program verification, including theories, languages, and tools. It emphasizes challenges and breakthroughs at each stage in history and highlights challenges that are currently present due to the increasing scale of proof developments. This monograph is intended for use by researchers and students who are new to the field. It provides the reader with an insightful overview of the work that has led to modern-day techniques for formally verifying software. In times of increasing automation, this underpins many software systems so future trends are also highlighted.},
	publisher = {now},
	author = {Ringer, T. and Palmskog, K. and Sergey, I. and Gligoric, M. and Tatlock, Z.},
	urldate = {2019-09-26},
	date = {2019}
}

@inproceedings{tuch_types_2007,
	location = {New York, {NY}, {USA}},
	title = {Types, Bytes, and Separation Logic},
	isbn = {978-1-59593-575-5},
	url = {http://doi.acm.org/10.1145/1190216.1190234},
	doi = {10.1145/1190216.1190234},
	series = {{POPL} '07},
	abstract = {We present a formal model of memory that both captures the low-level features of C's pointers and memory, and that forms the basis for an expressive implementation of separation logic. At the low level, we do not commit common oversimplifications, but correctly deal with C's model of programming language values and the heap. At the level of separation logic, we are still able to reason abstractly and efficiently. We implement this framework in the theorem prover Isabelle/{HOL} and demonstrate it on two case studies. We show that the divide between detailed and abstract does not impose undue verification overhead, and that simple programs remain easy to verify. We also show that the framework is applicable to real, security- and safety-critical code by formally verifying the memory allocator of the L4 microkernel.},
	pages = {97--108},
	booktitle = {Proceedings of the 34th Annual {ACM} {SIGPLAN}-{SIGACT} Symposium on Principles of Programming Languages},
	publisher = {{ACM}},
	author = {Tuch, Harvey and Klein, Gerwin and Norrish, Michael},
	urldate = {2019-09-26},
	date = {2007},
	note = {event-place: Nice, France},
	keywords = {separation logic, interactive theorem proving, C},
	file = {ACM Full Text PDF:/Users/richardford/Zotero/storage/LM5767HX/Tuch et al. - 2007 - Types, Bytes, and Separation Logic.pdf:application/pdf}
}

@article{ross_exterminators_2005,
	title = {The exterminators [software bugs},
	volume = {42},
	issn = {0018-9235},
	url = {http://ieeexplore.ieee.org/document/1502527/},
	doi = {10.1109/MSPEC.2005.1502527},
	pages = {36--41},
	number = {9},
	journaltitle = {{IEEE} Spectr.},
	author = {Ross, P.E.},
	urldate = {2019-09-24},
	date = {2005-09},
	langid = {english},
	file = {Ross - 2005 - The exterminators [software bugs.pdf:/Users/richardford/Zotero/storage/J92P78QP/Ross - 2005 - The exterminators [software bugs.pdf:application/pdf}
}

@article{ross_exterminators_2005-1,
	title = {The exterminators [software bugs]},
	volume = {42},
	doi = {10.1109/MSPEC.2005.1502527},
	abstract = {This paper describes a sound methodology developed at Praxis High Integrity Systems for detecting and exterminating bugs during all stages of a software project. To develop software, the London-based software house uses mathematically based techniques, known as formal methods, which require that programmers begin their work not by writing code but rather by stringing together special symbols that represent the program's logic. Like a mathematical theorem, these symbol strings can be checked to verify that they form logically correct statements. Once the programmer has checked that the program doesn't have logical flaws, it's a relatively simple matter to convert those symbols into programming code. With an average of less than one error in every 10,000 lines of delivered code, Praxis claims a bug rate that is at least 50 times better than the industry standard.},
	pages = {36--41},
	number = {9},
	journaltitle = {{IEEE} Spectrum},
	author = {Ross, P. E.},
	date = {2005-09},
	keywords = {formal methods, software engineering, bug-free software, Computer bugs, formal logic, Logic, mathematical logic, Praxis High Integrity Systems, program debugging, software bugs, software development, software engineering methods, software experts, software project}
}

@article{furia_autoproof:_2017,
	title = {{AutoProof}: auto-active functional verification of object-oriented programs},
	volume = {19},
	issn = {1433-2787},
	url = {https://doi.org/10.1007/s10009-016-0419-0},
	doi = {10.1007/s10009-016-0419-0},
	shorttitle = {{AutoProof}},
	abstract = {Auto-active verifiers provide a level of automation intermediate between fully automatic and interactive: users supply code with annotations as input while benefiting from a high level of automation in the back-end. This paper presents {AutoProof}, a state-of-the-art auto-active verifier for object-oriented sequential programs with complex functional specifications. {AutoProof} fully supports advanced object-oriented features and a powerful methodology for framing and class invariants, which make it applicable in practice to idiomatic object-oriented patterns. The paper focuses on describing {AutoProof} ’s interface, design, and implementation features, and demonstrates {AutoProof} ’s performance on a rich collection of benchmark problems. The results attest {AutoProof} ’s competitiveness among tools in its league on cutting-edge functional verification of object-oriented programs.},
	pages = {697--716},
	number = {6},
	journaltitle = {Int J Softw Tools Technol Transfer},
	author = {Furia, Carlo A. and Nordio, Martin and Polikarpova, Nadia and Tschannen, Julian},
	urldate = {2019-09-23},
	date = {2017-11-01},
	langid = {english},
	keywords = {Auto-active verification, Functional verification, Object-oriented verification, Verification benchmarks},
	file = {Full Text:/Users/richardford/Zotero/storage/FD9CX7PQ/Furia et al. - 2017 - AutoProof auto-active functional verification of .pdf:application/pdf}
}

@article{bjorner_manifest_2017,
	title = {Manifest domains: analysis and description},
	volume = {29},
	issn = {1433-299X},
	url = {https://doi.org/10.1007/s00165-016-0385-z},
	doi = {10.1007/s00165-016-0385-z},
	shorttitle = {Manifest domains},
	abstract = {We show that manifest domains, an understanding of which are a prerequisite for software requirements prescriptions, can be precisely described: narrated and formalised. We show that such manifest domains can be understood as a collection of endurant, that is, basically spatial entities: parts, components and materials, and perdurant, that is, basically temporal entities: actions, events and behaviours. We show that parts can be modeled in terms of external qualities whether: atomic or composite parts, having internal qualities: unique identifications, mereologies, which model relations between parts, and attributes. We show that the manifest domain analysis endeavour can be supported by a calculus of manifest domain analysis prompts: is\_entity, is\_endurant, is\_perdurant, is\_part, is\_component, is\_material, is\_atomic, is\_composite, has\_components, has\_materials, has\_concrete\_type, attribute\_names, is\_stationary, etcetera; and show how the manifest domain description endeavour can be supported by a calculus of manifest domain description prompts: observe\_part\_sorts, observe\_part\_type, observe\_components, observe\_materials, observe\_unique\_identifier, observe\_mereology, observe\_attributes. We show how to model attributes, essentially following Michael Jackson (Software requirements \& specifications: a lexicon of practice, principles and prejudices. {ACM} Press, Addison-Wesley, Reading, 1995), but with a twist: The attribute model introduces the attribute analysis prompts is\_static\_attribute, is\_dynamic\_attribute, is\_inert\_attribute, is\_reactive\_attribute, is\_active\_attribute, is\_autonomous\_attribute, is\_biddable\_attribute and is\_programmable\_attribute. The twist suggests ways of modeling “access” to the values of these kinds of attributes: the static attributes by simply “copying” them, once, the reactive and programmable attributes by “carrying” them as function parameters whose values are kept always updated, and the remaining, the external\_attributes, by inquiring, when needed, as to their value, as if they were always offered on {CSP}-like channels (Hoare, Communicating sequential processes. C.A.R. Hoare series in computer science. Prentice-Hall International, London, 2004). We show how to model essential aspects of perdurants in terms of their signatures based on the concepts of endurants. And we show how one can “compile” descriptions of endurant parts into descriptions of perdurant behaviours. We do not show prompt calculi for perdurants. The above contributions express a method with principles, techniques and tools for constructing domain descriptions. It is important to realise that we do not wish to nor claim that the method can describe all that it is interesting to know about domains.},
	pages = {175--225},
	number = {2},
	journaltitle = {Form Asp Comp},
	author = {Bjørner, Dines},
	urldate = {2019-09-23},
	date = {2017-03-01},
	langid = {english},
	keywords = {Analysis \& description, Domain engineering, Manifest domains, Prompt calculi},
	file = {Submitted Version:/Users/richardford/Zotero/storage/KPC4Q6PV/Bjørner - 2017 - Manifest domains analysis and description.pdf:application/pdf}
}

@online{noauthor_dines_nodate,
	title = {Dines Bjorner},
	url = {http://www.imm.dtu.dk/~dibj/},
	urldate = {2019-09-23},
	file = {ae-db-research:/Users/richardford/Zotero/storage/AZAIJ4BU/~dibj.html:text/html}
}

@incollection{hutchison_40_2014,
	location = {Cham},
	title = {40 Years of Formal Methods: Some Obstacles and Some Possibilities?},
	volume = {8442},
	isbn = {978-3-319-06409-3 978-3-319-06410-9},
	url = {http://link.springer.com/10.1007/978-3-319-06410-9_4},
	shorttitle = {40 Years of Formal Methods},
	pages = {42--61},
	booktitle = {{FM} 2014: Formal Methods},
	publisher = {Springer International Publishing},
	author = {Bjørner, Dines and Havelund, Klaus},
	editor = {Jones, Cliff and Pihlajasaari, Pekka and Sun, Jun},
	editorb = {Hutchison, David and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M. and Kobsa, Alfred and Mattern, Friedemann and Mitchell, John C. and Naor, Moni and Nierstrasz, Oscar and Pandu Rangan, C. and Steffen, Bernhard and Terzopoulos, Demetri and Tygar, Doug and Weikum, Gerhard},
	editorbtype = {redactor},
	urldate = {2019-09-23},
	date = {2014},
	langid = {english},
	doi = {10.1007/978-3-319-06410-9_4},
	file = {Bjørner and Havelund - 2014 - 40 Years of Formal Methods Some Obstacles and Som.pdf:/Users/richardford/Zotero/storage/4H2GEJ6B/Bjørner and Havelund - 2014 - 40 Years of Formal Methods Some Obstacles and Som.pdf:application/pdf}
}

@inproceedings{mullen_oeuf:_2018-1,
	location = {New York, {NY}, {USA}},
	title = {ŒUf: Minimizing the Coq Extraction {TCB}},
	isbn = {978-1-4503-5586-5},
	url = {http://doi.acm.org/10.1145/3167089},
	doi = {10.1145/3167089},
	series = {{CPP} 2018},
	shorttitle = {ŒUf},
	abstract = {Verifying systems by implementing them in the programming language of a proof assistant (e.g., Gallina for Coq) lets us directly leverage the full power of the proof assistant for verifying the system. But, to execute such an implementation requires extraction, a large complicated process that is in the trusted computing base ({TCB}).  This paper presents Œuf, a verified compiler from a subset of Gallina to assembly. Œuf’s correctness theorem ensures that compilation preserves the semantics of the source Gallina program. We describe how Œuf’s specification can be used as a foreign function interface to reason about the interaction between compiled Gallina programs and surrounding shim code. Additionally, Œufmaintains a small {TCB} for its front-end by reflecting Gallina programs to Œufsource and automatically ensuring equivalence using computational denotation. This design enabled us to implement some early compiler passes (e.g., lambda lifting) in the untrusted reflection and ensure their correctness via translation validation. To evaluate Œuf, we compile Appel’s {SHA}256 specification from Gallina to x86 and write a shim for the generated code, yielding a verified sha256sum implementation with a small {TCB}.},
	pages = {172--185},
	booktitle = {Proceedings of the 7th {ACM} {SIGPLAN} International Conference on Certified Programs and Proofs},
	publisher = {{ACM}},
	author = {Mullen, Eric and Pernsteiner, Stuart and Wilcox, James R. and Tatlock, Zachary and Grossman, Dan},
	urldate = {2019-07-30},
	date = {2018},
	note = {event-place: Los Angeles, {CA}, {USA}},
	keywords = {Coq, Compilers, Formal Verification, Verified Systems},
	file = {poplws18cpp-id12.pdf:/Users/richardford/Zotero/storage/EFMYGWDQ/poplws18cpp-id12.pdf:application/pdf}
}

@article{farrell_robotics_2018,
	title = {Robotics and Integrated Formal Methods: Necessity meets Opportunity},
	volume = {11023},
	url = {http://arxiv.org/abs/1805.11996},
	doi = {10.1007/978-3-319-98938-9_10},
	shorttitle = {Robotics and Integrated Formal Methods},
	abstract = {Robotic systems are multi-dimensional entities, combining both hardware and software, that are heavily dependent on, and influenced by, interactions with the real world. They can be variously categorised as embedded, cyberphysical, real-time, hybrid, adaptive and even autonomous systems, with a typical robotic system being likely to contain all of these aspects. The techniques for developing and verifying each of these system varieties are often quite distinct. This, together with the sheer complexity of robotic systems, leads us to argue that diverse formal techniques must be integrated in order to develop, verify, and provide certification evidence for, robotic systems. Furthermore, we propose the fast evolving field of robotics as an ideal catalyst for the advancement of integrated formal methods research, helping to drive the field in new and exciting directions and shedding light on the development of large-scale, dynamic, complex systems.},
	pages = {161--171},
	journaltitle = {{arXiv}:1805.11996 [cs]},
	author = {Farrell, Marie and Luckcuck, Matt and Fisher, Michael},
	urldate = {2019-10-05},
	date = {2018},
	eprinttype = {arxiv},
	eprint = {1805.11996},
	keywords = {Computer Science - Software Engineering, Computer Science - Robotics},
	file = {arXiv\:1805.11996 PDF:/Users/richardford/Zotero/storage/PPGSYFJR/Farrell et al. - 2018 - Robotics and Integrated Formal Methods Necessity .pdf:application/pdf;arXiv.org Snapshot:/Users/richardford/Zotero/storage/UHPEFVBL/1805.html:text/html}
}

@article{gonthier_how_2013,
	title = {How to make ad hoc proof automation less ad hoc},
	volume = {23},
	issn = {0956-7968, 1469-7653},
	url = {https://www.cambridge.org/core/product/identifier/S0956796813000051/type/journal_article},
	doi = {10.1017/S0956796813000051},
	abstract = {Most interactive theorem provers provide support for some form of user-customizable proof automation. In a number of popular systems, such as Coq and Isabelle, this automation is achieved primarily through tactics, which are programmed in a separate language from that of the prover’s base logic. While tactics are clearly useful in practice, they can be difﬁcult to maintain and compose because, unlike lemmas, their behavior cannot be speciﬁed within the expressive type system of the prover itself.},
	pages = {357--401},
	number = {4},
	journaltitle = {J. Funct. Prog.},
	author = {Gonthier, Georges and Ziliani, Beta and Nanevski, Aleksandar and Dreyer, Derek},
	urldate = {2019-10-13},
	date = {2013-07},
	langid = {english},
	file = {Gonthier et al. - 2013 - How to make ad hoc proof automation less ad hoc.pdf:/Users/richardford/Zotero/storage/927PW954/Gonthier et al. - 2013 - How to make ad hoc proof automation less ad hoc.pdf:application/pdf}
}

@article{chihani_certication_nodate,
	title = {Certiﬁcation of First-order proofs in classical and intuitionistic logics},
	pages = {167},
	author = {Chihani, Zakaria},
	langid = {english},
	file = {Chihani - Certiﬁcation of First-order proofs in classical an.pdf:/Users/richardford/Zotero/storage/VQJPPM4J/Chihani - Certiﬁcation of First-order proofs in classical an.pdf:application/pdf}
}

@inproceedings{easterbrook_formal_1997,
	title = {Formal methods for V \& V of partial specifications: an experience report},
	doi = {10.1109/ISRE.1997.566865},
	shorttitle = {Formal methods for V amp;V of partial specifications},
	abstract = {This paper describes our work exploring the suitability of formal specification methods for independent verification and validation ({IV}\&V) of software specifications for large, safety critical systems. An {IV}\&V contractor often has to perform rapid analysis on incomplete specifications, with no control over how those specifications are represented. Lightweight formal methods show significant promise in this context, as they offer a way of uncovering major errors, without the burden of full proofs of correctness. We describe an experiment in the application of the method {SCR} to testing for consistency properties of a partial model of the requirements for fault detection isolation and recovery on the space station. We conclude that the insights gained from formalizing a specification is valuable, and it is the process of formalization, rather than the end product that is important. It was only necessary to build enough of the formal model to test the properties in which we were interested. Maintenance of fidelity between multiple representations of the same requirements (as they evolve) is still a problem, and deserves further study.},
	eventtitle = {Proceedings of {ISRE} '97: 3rd {IEEE} International Symposium on Requirements Engineering},
	pages = {160--168},
	booktitle = {Proceedings of {ISRE} '97: 3rd {IEEE} International Symposium on Requirements Engineering},
	author = {Easterbrook, S. and Callahan, J.},
	date = {1997-01},
	keywords = {program verification, formal methods, formal specification, testing, Performance analysis, aerospace computing, Aerospace safety, artificial satellites, consistency properties, Error correction, errors, fault detection isolation, fault diagnosis, fault recovery, formal specification methods, Formal specifications, incomplete specifications, independent verification, International Space Station, large safety critical systems, {NASA}, partial specification verification, program testing, safety-critical software, {SCR}, Software safety, space station, Space stations, Testing, Thyristors}
}

@article{easterbrook_formal_nodate,
	title = {Formal Methods for V\&V of partial specifications: An experience report},
	abstract = {This paper describes our work exploring the suitability of formal specification methods f o r independ e n t verification and validation ({IVi}3V) of software specifications for large, safety critical systems. An {IV}\&V contractor often has to perform rapid analysis on incomplete specifications, with no control over how those {speciJcations} are represented. Lightweight formal methods show significant promise in this context, as they offer a way of uncovering major errors, without the burden of full proofs of correctness. We describe an experiment in the application of the method {SCR} to testing for consistency properties of a partial model of th,e requirements for Fault Detection Isolation and Recovery o n th,e space station. We conclude that the insights gained from formalizing a specification is valuable, and it is the process of formalization, rather than the end product that is important. It was only necessary to build enough of the formal model to test the properties in which we were interested. Maintenance of fidelity between multiple representations of the same requirements (as they evolve) is still a problem,, and deserves further study.},
	pages = {9},
	author = {Easterbrook, Steve and Callahan, John},
	langid = {english},
	file = {Easterbrook and Callahan - Formal Methods for V&V of partial specifications .pdf:/Users/richardford/Zotero/storage/2NY7449P/Easterbrook and Callahan - Formal Methods for V&V of partial specifications .pdf:application/pdf}
}

@incollection{ter_beek_gospelproviding_2019,
	location = {Cham},
	title = {{GOSPEL}—Providing {OCaml} with a Formal Specification Language},
	volume = {11800},
	isbn = {978-3-030-30941-1 978-3-030-30942-8},
	url = {http://link.springer.com/10.1007/978-3-030-30942-8_29},
	abstract = {This paper introduces {GOSPEL}, a behavioral speciﬁcation language for {OCaml}. It is designed to enable modular veriﬁcation of data structures and algorithms. {GOSPEL} is a contract-based, strongly typed language, with a formal semantics deﬁned by means of translation into Separation Logic. Compared with writing speciﬁcations directly in Separation Logic, {GOSPEL} provides a high-level syntax that greatly improves conciseness and makes it accessible to programmers with no familiarity with Separation Logic. Although {GOSPEL} has been developed for specifying {OCaml} code, we believe that many aspects of its design could apply to other programming languages. This paper presents the design and semantics of {GOSPEL}, and reports on its application for the development of a formally veriﬁed library of general-purpose {OCaml} data structures.},
	pages = {484--501},
	booktitle = {Formal Methods – The Next 30 Years},
	publisher = {Springer International Publishing},
	author = {Charguéraud, Arthur and Filliâtre, Jean-Christophe and Lourenço, Cláudio and Pereira, Mário},
	editor = {ter Beek, Maurice H. and {McIver}, Annabelle and Oliveira, José N.},
	urldate = {2019-10-14},
	date = {2019},
	langid = {english},
	doi = {10.1007/978-3-030-30942-8_29},
	file = {Charguéraud et al. - 2019 - GOSPEL—Providing OCaml with a Formal Specification.pdf:/Users/richardford/Zotero/storage/P9ICM9G6/Charguéraud et al. - 2019 - GOSPEL—Providing OCaml with a Formal Specification.pdf:application/pdf}
}

@inproceedings{alana_reference_2018,
	location = {Madrid, Spain},
	title = {A reference architecture for space systems},
	isbn = {978-1-4503-6483-6},
	url = {http://dl.acm.org/citation.cfm?doid=3241403.3241416},
	doi = {10.1145/3241403.3241416},
	abstract = {The definition of a Reference Architecture for Space Systems is a noteworthy field to improve the development of embedded critical systems. The European Space Agency ({ESA}) and the European Commission ({EU}) are actively working on different initiatives to elaborate common and agreed architectures in different fields of the Space Domain. This abstract presents the results of some of these initiatives in which {GMV} takes part.},
	eventtitle = {the 12th European Conference},
	pages = {1--2},
	booktitle = {Proceedings of the 12th European Conference on Software Architecture Companion Proceedings - {ECSA} '18},
	publisher = {{ACM} Press},
	author = {Alaña, Elena and Herrero, Javier and Urueña, Santiago and Macioszek, Krystyna and Silveira, Daniel},
	urldate = {2019-10-14},
	date = {2018},
	langid = {english},
	file = {Alaña et al. - 2018 - A reference architecture for space systems.pdf:/Users/richardford/Zotero/storage/Y337HAFV/Alaña et al. - 2018 - A reference architecture for space systems.pdf:application/pdf}
}

@article{klein_formally_2018,
	title = {Formally verified software in the real world},
	volume = {61},
	issn = {00010782},
	url = {http://dl.acm.org/citation.cfm?doid=3281635.3230627},
	doi = {10.1145/3230627},
	pages = {68--77},
	number = {10},
	journaltitle = {Commun. {ACM}},
	author = {Klein, Gerwin and Andronick, June and Fernandez, Matthew and Kuz, Ihor and Murray, Toby and Heiser, Gernot},
	urldate = {2019-10-14},
	date = {2018-09-26},
	langid = {english},
	file = {Klein et al. - 2018 - Formally verified software in the real world.pdf:/Users/richardford/Zotero/storage/U4UV5PRH/Klein et al. - 2018 - Formally verified software in the real world.pdf:application/pdf}
}

@inproceedings{moscato_provably_2019,
	title = {Provably Correct Floating-Point Implementation of a Point-in-Polygon Algorithm},
	isbn = {978-3-030-30942-8},
	series = {Lecture Notes in Computer Science},
	abstract = {The problem of determining whether or not a point lies inside a given polygon occurs in many applications. In air traffic management concepts, a correct solution to the point-in-polygon problem is critical to geofencing systems for Unmanned Aerial Vehicles and in weather avoidance applications. Many mathematical methods can be used to solve the point-in-polygon problem. Unfortunately, a straightforward floating-point implementation of these methods can lead to incorrect results due to round-off errors. In particular, these errors may cause the control flow of the program to diverge with respect to the ideal real-number algorithm. This divergence potentially results in an incorrect point-in-polygon determination even when the point is far from the edges of the polygon. This paper presents a provably correct implementation of a point-in-polygon method that is based on the computation of the winding number. This implementation is mechanically generated from a source-to-source transformation of the ideal real-number specification of the algorithm. The correctness of this implementation is formally verified within the Frama-C analyzer, where the proof obligations are discharged using the Prototype Verification System ({PVS}).},
	pages = {21--37},
	booktitle = {Formal Methods – The Next 30 Years},
	publisher = {Springer International Publishing},
	author = {Moscato, Mariano M. and Titolo, Laura and Feliú, Marco A. and Muñoz, César A.},
	editor = {ter Beek, Maurice H. and {McIver}, Annabelle and Oliveira, José N.},
	date = {2019},
	langid = {english}
}

@online{noauthor_fm_nodate,
	title = {{FM} folks - richardlford@gmail.com - Gmail},
	url = {https://mail.google.com/mail/u/0/#inbox/FMfcgxwDrlVnZmDccTxHFBnzPRMfbmpn?projector=1&messagePartId=0.1},
	urldate = {2019-10-14},
	file = {FM folks - richardlford@gmail.com - Gmail:/Users/richardford/Zotero/storage/BJ2KFM5C/0.html:text/html}
}

@inproceedings{garillot_packaging_2009,
	title = {Packaging Mathematical Structures},
	isbn = {978-3-642-03359-9},
	series = {Lecture Notes in Computer Science},
	abstract = {This paper proposes generic design patterns to define and combine algebraic structures, using dependent records, coercions and type inference, inside the Coq system. This alternative to telescopes in particular supports multiple inheritance, maximal sharing of notations and theories, and automated structure inference. Our methodology is robust enough to handle a hierarchy comprising a broad variety of algebraic structures, from types with a choice operator to algebraically closed fields. Interfaces for the structures enjoy the convenience of a classical setting, without requiring any axiom. Finally, we present two applications of our proof techniques: a key lemma for characterising the discrete logarithm, and a matrix decomposition problem.},
	pages = {327--342},
	booktitle = {Theorem Proving in Higher Order Logics},
	publisher = {Springer Berlin Heidelberg},
	author = {Garillot, François and Gonthier, Georges and Mahboubi, Assia and Rideau, Laurence},
	editor = {Berghofer, Stefan and Nipkow, Tobias and Urban, Christian and Wenzel, Makarius},
	date = {2009},
	langid = {english},
	keywords = {Coq, Coercive subtyping, Formalization of Algebra, {SSReflect}, Type inference},
	file = {Garillot et al. - 2009 - Packaging Mathematical Structures.pdf:/Users/richardford/Zotero/storage/PFXDE3SD/Garillot et al. - 2009 - Packaging Mathematical Structures.pdf:application/pdf}
}

@incollection{hutchison_pragmatic_2013,
	location = {Berlin, Heidelberg},
	title = {Pragmatic Quotient Types in Coq},
	volume = {7998},
	isbn = {978-3-642-39633-5 978-3-642-39634-2},
	url = {http://link.springer.com/10.1007/978-3-642-39634-2_17},
	abstract = {In intensional type theory, it is not always possible to form the quotient of a type by an equivalence relation. However, quotients are extremely useful when formalizing mathematics, especially in algebra. We provide a Coq library with a pragmatic approach in two complementary components. First, we provide a framework to work with quotient types in an axiomatic manner. Second, we program construction mechanisms for some speciﬁc cases where it is possible to build a quotient type. This library was helpful in implementing the types of rational fractions, multivariate polynomials, ﬁeld extensions and real algebraic numbers.},
	pages = {213--228},
	booktitle = {Interactive Theorem Proving},
	publisher = {Springer Berlin Heidelberg},
	author = {Cohen, Cyril},
	editor = {Blazy, Sandrine and Paulin-Mohring, Christine and Pichardie, David},
	editorb = {Hutchison, David and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M. and Mattern, Friedemann and Mitchell, John C. and Naor, Moni and Nierstrasz, Oscar and Pandu Rangan, C. and Steffen, Bernhard and Sudan, Madhu and Terzopoulos, Demetri and Tygar, Doug and Vardi, Moshe Y. and Weikum, Gerhard},
	editorbtype = {redactor},
	urldate = {2019-10-18},
	date = {2013},
	langid = {english},
	doi = {10.1007/978-3-642-39634-2_17},
	file = {Cohen2013_Chapter_PragmaticQuotientTypesInCoq.pdf:/Users/richardford/Zotero/storage/SY5Z6DX3/Cohen2013_Chapter_PragmaticQuotientTypesInCoq.pdf:application/pdf}
}

@book{soare_turing_2016,
	location = {Berlin, Heidelberg},
	title = {Turing Computability},
	isbn = {978-3-642-31932-7 978-3-642-31933-4},
	url = {http://link.springer.com/10.1007/978-3-642-31933-4},
	series = {Theory and Applications of Computability},
	publisher = {Springer Berlin Heidelberg},
	author = {Soare, Robert I.},
	urldate = {2019-11-15},
	date = {2016},
	doi = {10.1007/978-3-642-31933-4},
	file = {Soare - 2016 - Turing Computability.pdf:/Users/richardford/Zotero/storage/YRCUVKEF/Soare - 2016 - Turing Computability.pdf:application/pdf}
}

@book{longley_higher-order_2015,
	location = {Berlin, Heidelberg},
	title = {Higher-Order Computability},
	isbn = {978-3-662-47991-9 978-3-662-47992-6},
	url = {http://link.springer.com/10.1007/978-3-662-47992-6},
	series = {Theory and Applications of Computability},
	publisher = {Springer Berlin Heidelberg},
	author = {Longley, John and Normann, Dag},
	urldate = {2019-11-15},
	date = {2015},
	doi = {10.1007/978-3-662-47992-6},
	file = {Longley and Normann - 2015 - Higher-Order Computability.pdf:/Users/richardford/Zotero/storage/UES9V7IJ/Longley and Normann - 2015 - Higher-Order Computability.pdf:application/pdf}
}

@book{downey_algorithmic_2010,
	location = {New York, {NY}},
	title = {Algorithmic Randomness and Complexity},
	isbn = {978-0-387-95567-4 978-0-387-68441-3},
	url = {http://link.springer.com/10.1007/978-0-387-68441-3},
	series = {Theory and Applications of Computability},
	publisher = {Springer New York},
	author = {Downey, Rodney G. and Hirschfeldt, Denis R.},
	urldate = {2019-11-15},
	date = {2010},
	doi = {10.1007/978-0-387-68441-3},
	file = {Downey and Hirschfeldt - 2010 - Algorithmic Randomness and Complexity.pdf:/Users/richardford/Zotero/storage/K4LMHPLX/Downey and Hirschfeldt - 2010 - Algorithmic Randomness and Complexity.pdf:application/pdf}
}

@book{bridges_apartness_2011,
	location = {Berlin, Heidelberg},
	title = {Apartness and Uniformity},
	isbn = {978-3-642-22414-0 978-3-642-22415-7},
	url = {http://link.springer.com/10.1007/978-3-642-22415-7},
	series = {Theory and Applications of Computability},
	publisher = {Springer Berlin Heidelberg},
	author = {Bridges, Douglas S. and Vîţă, Luminiţa Simona},
	urldate = {2019-11-15},
	date = {2011},
	doi = {10.1007/978-3-642-22415-7},
	file = {Bridges and Vîţă - 2011 - Apartness and Uniformity.pdf:/Users/richardford/Zotero/storage/HU52C494/Bridges and Vîţă - 2011 - Apartness and Uniformity.pdf:application/pdf}
}

@article{oconnor_computer-verified_2010,
	title = {A computer-verified monadic functional implementation of the integral},
	volume = {411},
	issn = {0304-3975},
	url = {http://www.sciencedirect.com/science/article/pii/S0304397510003233},
	doi = {10.1016/j.tcs.2010.05.031},
	abstract = {We provide a computer-verified exact monadic functional implementation of the Riemann integral in type theory. Together with previous work by O’Connor, this may be seen as the beginning of the realization of Bishop’s vision to use constructive mathematics as a programming language for exact analysis.},
	pages = {3386--3402},
	number = {37},
	journaltitle = {Theoretical Computer Science},
	author = {O’Connor, Russell and Spitters, Bas},
	urldate = {2019-11-06},
	date = {2010-08-07},
	langid = {english},
	keywords = {Type theory, Exact real analysis, Functional programming, Monads},
	file = {ScienceDirect Full Text PDF:/Users/richardford/Zotero/storage/9CBAVCVC/O’Connor and Spitters - 2010 - A computer-verified monadic functional implementat.pdf:application/pdf;ScienceDirect Snapshot:/Users/richardford/Zotero/storage/EH5KVJ6P/S0304397510003233.html:text/html}
}

@online{noauthor_coquelicot.coquelicot_nodate,
	title = {Coquelicot.Coquelicot},
	url = {http://coquelicot.saclay.inria.fr/html/Coquelicot.Coquelicot.html},
	urldate = {2019-11-03},
	file = {Coquelicot.Coquelicot:/Users/richardford/Zotero/storage/VLB33M7N/Coquelicot.Coquelicot.html:text/html}
}

@collection{cooper_incomputable_2017,
	location = {Cham},
	title = {The Incomputable},
	isbn = {978-3-319-43667-8 978-3-319-43669-2},
	url = {http://link.springer.com/10.1007/978-3-319-43669-2},
	series = {Theory and Applications of Computability},
	publisher = {Springer International Publishing},
	editor = {Cooper, S. Barry and Soskova, Mariya I.},
	urldate = {2019-11-15},
	date = {2017},
	doi = {10.1007/978-3-319-43669-2},
	file = {Cooper and Soskova - 2017 - The Incomputable.pdf:/Users/richardford/Zotero/storage/ZJSEKPHJ/Cooper and Soskova - 2017 - The Incomputable.pdf:application/pdf}
}

@article{dang_rustbelt_nodate,
	title = {{RustBelt} Meets Relaxed Memory},
	volume = {4},
	abstract = {The Rust programming language supports safe systems programming by means of a strong ownership-tracking type system. In their prior work on {RustBelt}, Jung et al. began the task of setting Rust’s safety claims on a more rigorous formal foundation. Specifically, they used Iris, a Coq-based separation logic framework, to build a machine-checked proof of semantic soundness for a λ-calculus model of Rust, as well as for a number of widely-used Rust libraries that internally employ unsafe language features. However, they also made the significant simplifying assumption that the language is sequentially consistent. In this paper, we adapt {RustBelt} to account for the relaxed-memory operations that concurrent Rust libraries actually use, in the process uncovering a data race in the Arc library. We focus on the most interesting technical problem: how to reason about resource reclamation under relaxed memory, using a logical construction we call synchronized ghost state. {CCS} Concepts: • Theory of computation → Separation logic; Operational semantics; Programming logic.},
	pages = {29},
	author = {Dang, Hoang-Hai and Jourdan, Jacques-Henri and Kaiser, Jan-Oliver and Dreyer, Derek},
	langid = {english},
	file = {Dang et al. - RustBelt Meets Relaxed Memory.pdf:/Users/richardford/Zotero/storage/9BZCWM3G/Dang et al. - RustBelt Meets Relaxed Memory.pdf:application/pdf}
}

@article{jones_function_2013,
	title = {Function Points As a Universal Software Metric},
	volume = {38},
	issn = {0163-5948},
	url = {http://doi.acm.org/10.1145/2492248.2492268},
	doi = {10.1145/2492248.2492268},
	abstract = {Function point metrics are the most accurate and effective metrics yet developed for software sizing and also for studying software productivity, quality, costs, risks, and economic value. Unlike the older "lines of code" metric function points can be used to study requirements, design, and in fact all software activities from development through maintenance. In the future function point metrics can easily become a universal metric used for all software applications and for all software contracts in all countries. The government of Brazil already requires function points for all software contracts, and South Korea and Italy may soon follow. However, there are some logistical problems with function point metrics that need to be understood and overcome in order for function point metrics to become the primary metric for software economic analysis. Manual function point counting is too slow and costly to be used on large software projects above 10,000 function points in size. Also, application size is not constant but grows at about 2\% per calendar month during development and 8\% or more per calendar year for as long as software is in active use. This paper discusses a method of high-speed function point counting that can size any application in less than two minutes, and which can predict application growth during development and for five years after release. This new method is based on pattern matching and is covered by U.S. utility patent application and hence is patent pending.},
	pages = {1--27},
	number = {4},
	journaltitle = {{SIGSOFT} Softw. Eng. Notes},
	author = {Jones, Capers},
	urldate = {2019-11-27},
	date = {2013-07},
	file = {ACM Full Text PDF:/Users/richardford/Zotero/storage/7JSFC92I/Jones - 2013 - Function Points As a Universal Software Metric.pdf:application/pdf}
}

@article{clark_instructors_2019,
	title = {The Instructor’s Guide to Real Induction},
	volume = {92},
	issn = {0025-570X, 1930-0980},
	url = {https://www.tandfonline.com/doi/full/10.1080/0025570X.2019.1549902},
	doi = {10.1080/0025570X.2019.1549902},
	pages = {136--150},
	number = {2},
	journaltitle = {Mathematics Magazine},
	author = {Clark, Pete L.},
	urldate = {2019-11-27},
	date = {2019-03-15},
	langid = {english},
	file = {Clark - 2019 - The Instructor’s Guide to Real Induction.pdf:/Users/richardford/Zotero/storage/F4QAXND8/Clark - 2019 - The Instructor’s Guide to Real Induction.pdf:application/pdf}
}

@inproceedings{malecha_towards_2016,
	title = {Towards foundational verification of cyber-physical systems},
	doi = {10.1109/SOSCYPS.2016.7580000},
	abstract = {The safety-critical aspects of cyber-physical systems motivate the need for rigorous analysis of these systems. In the literature this work is often done using idealized models of systems where the analysis can be carried out using high-level reasoning techniques such as Lyapunov functions and model checking. In this paper we present {VERIDRONE}, a foundational framework for reasoning about cyber-physical systems at all levels from high-level models to C code that implements the system. {VERIDRONE} is a library within the Coq proof assistant enabling us to build on its foundational implementation, its interactive development environments, and its wealth of libraries capturing interesting theories ranging from real numbers and differential equations to verified compilers and floating point numbers. These features make proof assistants in general, and Coq in particular, a powerful platform for unifying foundational results about safety-critical systems and ensuring interesting properties at all levels of the stack.},
	eventtitle = {2016 Science of Security for Cyber-Physical Systems Workshop ({SOSCYPS})},
	pages = {1--5},
	booktitle = {2016 Science of Security for Cyber-Physical Systems Workshop ({SOSCYPS})},
	author = {Malecha, Gregory and Ricketts, Daniel and Alvarez, Mario M. and Lerner, Sorin},
	date = {2016-04},
	note = {{ISSN}: null},
	keywords = {formal verification, Coq proof assistant, program compilers, safety-critical software, Biomedical monitoring, Cognition, cyber-physical systems, Cyber-physical systems, differential equations, floating point numbers, foundational framework, high-level models, idealized models, interactive development environments, Lyapunov functions, model checking, Monitoring, Robustness, safety-critical aspects, Software, Stability analysis, towards foundational verification, verified compilers}
}

@inproceedings{protzenko_formally_2019,
	location = {San Francisco, {CA}, {USA}},
	title = {Formally Verified Cryptographic Web Applications in {WebAssembly}},
	isbn = {978-1-5386-6660-9},
	url = {https://ieeexplore.ieee.org/document/8835291/},
	doi = {10.1109/SP.2019.00064},
	abstract = {After suffering decades of high-proﬁle attacks, the need for formal veriﬁcation of security-critical software has never been clearer. Veriﬁcation-oriented programming languages like F∗ are now being used to build high-assurance cryptographic libraries and implementations of standard protocols like {TLS}. In this paper, we seek to apply these veriﬁcation techniques to modern Web applications, like {WhatsApp}, that embed sophisticated custom cryptographic components. The problem is that these components are often implemented in {JavaScript}, a language that is both hostile to cryptographic code and hard to reason about. So we instead target {WebAssembly}, a new instruction set that is supported by all major {JavaScript} runtimes.},
	eventtitle = {2019 {IEEE} Symposium on Security and Privacy ({SP})},
	pages = {1256--1274},
	booktitle = {2019 {IEEE} Symposium on Security and Privacy ({SP})},
	publisher = {{IEEE}},
	author = {Protzenko, Jonathan and Beurdouche, Benjamin and Merigoux, Denis and Bhargavan, Karthikeyan},
	urldate = {2019-11-26},
	date = {2019-05},
	langid = {english},
	file = {Protzenko et al. - 2019 - Formally Verified Cryptographic Web Applications i.pdf:/Users/richardford/Zotero/storage/KL7T699C/Protzenko et al. - 2019 - Formally Verified Cryptographic Web Applications i.pdf:application/pdf}
}

@thesis{giuffrida_safe_2014,
	title = {Safe and automatic live update},
	type = {phdthesis},
	author = {Giuffrida, C},
	date = {2014},
	langid = {english},
	note = {{OCLC}: 876276706},
	file = {Giuffrida - 2014 - Safe and automatic live update.pdf:/Users/richardford/Zotero/storage/XDPPCG4E/Giuffrida - 2014 - Safe and automatic live update.pdf:application/pdf}
}

@article{giuffrida_safe_2013,
	title = {Safe and automatic live update for operating systems},
	volume = {41},
	issn = {0163-5964, 0362-1340},
	url = {http://dl.acm.org/citation.cfm?id=2451116.2451147},
	doi = {10.1145/2451116.2451147},
	pages = {279--292},
	number = {1},
	journaltitle = {{ACM} {SIGARCH} Computer Architecture News},
	author = {Giuffrida, Cristiano and Kuijsten, Anton and Tanenbaum, Andrew S. and Giuffrida, Cristiano and Kuijsten, Anton and Tanenbaum, Andrew S. and Giuffrida, Cristiano and Kuijsten, Anton and Tanenbaum, Andrew S.},
	urldate = {2019-12-04},
	date = {2013-03-16},
	file = {Full Text PDF:/Users/richardford/Zotero/storage/IJHI7NRV/Giuffrida et al. - 2013 - Safe and automatic live update for operating syste.pdf:application/pdf;Snapshot:/Users/richardford/Zotero/storage/D4ZCW5XH/citation.html:text/html}
}

@book{bourque_guide_2014,
	title = {Guide to the software engineering body of knowledge},
	isbn = {978-0-7695-5166-1},
	author = {{IEEE Computer Society}},
	editor = {Bourque, Pierre and Fairley, R. E},
	date = {2014},
	langid = {english},
	note = {{OCLC}: 973217192},
	file = {Bourque et al. - 2014 - Guide to the software engineering body of knowledg.pdf:/Users/richardford/Zotero/storage/43FIHMET/Bourque et al. - 2014 - Guide to the software engineering body of knowledg.pdf:application/pdf}
}

@online{noauthor_rems:_nodate,
	title = {{REMS}: Rigorous Engineering of Mainsteam Systems, Papers},
	url = {https://www.cl.cam.ac.uk/~pes20/rems/rems-all.html},
	urldate = {2019-12-27},
	file = {rems-all:/Users/richardford/Zotero/storage/TZ3CQF6C/rems-all.html:text/html}
}

@inproceedings{ford_specification-based_1997,
	title = {The specification-based testing of a trusted kernel: {MK}++},
	doi = {10.1109/ICFEM.1997.630422},
	shorttitle = {The specification-based testing of a trusted kernel},
	abstract = {The {MK}++ kernel, a descendant of Mach, was designed and implemented at the Open Group Research Institute. Independently, Computational Logic Inc. had developed a formal specification for the Mach kernel interface. We report on the adaptation of this specification to {MK}++, and its use in the derivation of a testing strategy for the {MK}++ implementation. The results and utility of the tests are discussed.},
	eventtitle = {First {IEEE} International Conference on Formal Engineering Methods},
	pages = {151--160},
	booktitle = {First {IEEE} International Conference on Formal Engineering Methods},
	author = {Ford, R.L. and Simon, R.T. and Bevier, W.R. and Smith, L.M.},
	date = {1997-11},
	note = {{ISSN}: null},
	keywords = {formal specification, Computer bugs, Logic, Formal specifications, program testing, Atomic layer deposition, Kernel, Law, Legal factors, Mach kernel interface, {MK}++ implementation, {MK}++ kernel, operating system kernels, Performance evaluation, software reliability, specification based testing, System testing, testing strategy, trusted kernel, Yarn},
	file = {Ford et al. - 1997 - The specification-based testing of a trusted kerne.pdf:/Users/richardford/Zotero/storage/TM9VUD7S/Ford et al. - 1997 - The specification-based testing of a trusted kerne.pdf:application/pdf;IEEE Xplore Abstract Record:/Users/richardford/Zotero/storage/KASH6I92/630422.html:text/html}
}

@online{lamport_pretending_2005,
	title = {Pretending Atomicity, Digital Systems Research Center: Report 44},
	url = {https://web.archive.org/web/20051227134748/http://gatekeeper.research.compaq.com/pub/DEC/SRC/research-reports/abstracts/src-rr-044.html},
	shorttitle = {Pretending Atomicity},
	abstract = {We present a theorem for deriving properties of a concurrent program by reasoning about a simpler, coarser-grained version. The theorem generalizes a result that Lipton proved for partial correctness and deadlock-freedom. Our theorem applies to all safety properties.},
	author = {Lamport, Leslie and Schneider, Fred B},
	urldate = {2019-12-30},
	date = {2005-12-27},
	file = {Pretending Atomicity:/Users/richardford/Zotero/storage/D58RFPMM/pretending.pdf:application/pdf;Snapshot:/Users/richardford/Zotero/storage/HZ5GATYJ/src-rr-044.html:text/html}
}

@article{liu_virtual_2019,
	title = {Virtual timeline: a formal abstraction for verifying preemptive schedulers with temporal isolation},
	volume = {4},
	issn = {24751421},
	url = {http://dl.acm.org/citation.cfm?doid=3377388.3371088},
	doi = {10.1145/3371088},
	shorttitle = {Virtual timeline},
	pages = {1--31},
	issue = {{POPL}},
	journaltitle = {Proceedings of the {ACM} on Programming Languages},
	author = {Liu, Mengqi and Rieg, Lionel and Shao, Zhong and Gu, Ronghui and Costanzo, David and Kim, Jung-Eun and Yoon, Man-Ki},
	urldate = {2019-12-31},
	date = {2019-12-20},
	langid = {english},
	file = {Liu et al. - 2019 - Virtual timeline a formal abstraction for verifyi.pdf:/Users/richardford/Zotero/storage/FLN4HKK6/Liu et al. - 2019 - Virtual timeline a formal abstraction for verifyi.pdf:application/pdf}
}

@inproceedings{shin_wormspace:_2019,
	location = {Santa Cruz, {CA}, {USA}},
	title = {{WormSpace}: A Modular Foundation for Simple, Verifiable Distributed Systems},
	isbn = {978-1-4503-6973-2},
	url = {http://dl.acm.org/citation.cfm?doid=3357223.3362739},
	doi = {10.1145/3357223.3362739},
	shorttitle = {{WormSpace}},
	abstract = {We propose the Write-Once Register ({WOR}) as an abstraction for building and verifying distributed systems. A {WOR} exposes a simple, data-centric {API}: clients can capture, write, and read it. Applications can use a sequence or a set of {WORs} to obtain properties such as durability, concurrency control, and failure atomicity. By hiding the logic for distributed coordination underneath a data-centric {API}, the {WOR} abstraction enables easy, incremental, and extensible implementation and verification of applications built above it. We present the design, implementation, and verification of a system called {WormSpace} that provides developers with an address space of {WORs}, implementing each {WOR} via a Paxos instance. We describe three applications built over {WormSpace}: a flexible, efficient Multi-Paxos implementation; a shared log implementation with lower append latency than the state-of-the-art; and a faulttolerant transaction coordinator that uses an optimal number of round-trips. We show that these applications are simple, easy to verify, and match the performance of unverified monolithic implementations. We use a modular layered verification approach to link the proofs for {WormSpace}, its applications, and a verified operating system to produce the first verified distributed system stack from the application to the operating system.},
	eventtitle = {the {ACM} Symposium},
	pages = {299--311},
	booktitle = {Proceedings of the {ACM} Symposium on Cloud Computing  - {SoCC} '19},
	publisher = {{ACM} Press},
	author = {Shin, Ji-Yong and Kim, Jieung and Honoré, Wolf and Vanzetto, Hernán and Radhakrishnan, Srihari and Balakrishnan, Mahesh and Shao, Zhong},
	urldate = {2019-12-31},
	date = {2019},
	langid = {english},
	file = {Shin et al. - 2019 - WormSpace A Modular Foundation for Simple, Verifi.pdf:/Users/richardford/Zotero/storage/KPL5EXSL/Shin et al. - 2019 - WormSpace A Modular Foundation for Simple, Verifi.pdf:application/pdf}
}

@incollection{kennedy_types_2010,
	location = {Berlin, Heidelberg},
	title = {Types for Units-of-Measure: Theory and Practice},
	isbn = {978-3-642-17685-2},
	url = {https://doi.org/10.1007/978-3-642-17685-2_8},
	series = {Lecture Notes in Computer Science},
	shorttitle = {Types for Units-of-Measure},
	abstract = {Units-of-measure are to science what types are to programming. In science and engineering, dimensional and unit consistency provides a first check on the correctness of an equation or formula, just as in programming the validation of a program by the type-checker eliminates one possible reason for failure.},
	pages = {268--305},
	booktitle = {Central European Functional Programming School: Third Summer School, {CEFP} 2009, Budapest, Hungary, May 21-23, 2009 and Komárno, Slovakia, May 25-30, 2009, Revised Selected Lectures},
	publisher = {Springer},
	author = {Kennedy, Andrew},
	editor = {Horváth, Zoltán and Plasmeijer, Rinus and Zsók, Viktória},
	urldate = {2020-01-01},
	date = {2010},
	langid = {english},
	doi = {10.1007/978-3-642-17685-2_8},
	keywords = {Equational Theory, Inference Algorithm, Type Inference, Type Scheme, Type System},
	file = {Kennedy - 2010 - Types for Units-of-Measure Theory and Practice.pdf:/Users/richardford/Zotero/storage/MDYN5WIW/Kennedy - 2010 - Types for Units-of-Measure Theory and Practice.pdf:application/pdf}
}

@online{noauthor_acsl_nodate,
	title = {{ACSL} by Example},
	url = {https://github.com/fraunhoferfokus/acsl-by-example},
	abstract = {Public snapshots of "{ACSL} by Example". Contribute to fraunhoferfokus/acsl-by-example development by creating an account on {GitHub}.},
	titleaddon = {{GitHub}},
	urldate = {2020-01-10},
	langid = {english},
	file = {Snapshot:/Users/richardford/Zotero/storage/XJL9QPWX/ACSL-by-Example.html:text/html}
}

@online{noauthor_iris_nodate,
	title = {Iris / stdpp},
	url = {https://gitlab.mpi-sws.org/iris/stdpp},
	abstract = {An extended "Standard Library" for Coq. [[coqdoc]](https://plv.mpi-sws.org/coqdoc/stdpp/)},
	titleaddon = {{GitLab}},
	urldate = {2020-01-10},
	langid = {english},
	file = {Snapshot:/Users/richardford/Zotero/storage/9RJK2RNR/stdpp.html:text/html}
}

@software{noauthor_coqeal_2020,
	title = {{CoqEAL}},
	url = {https://github.com/CoqEAL/CoqEAL},
	abstract = {{CoqEAL} -- The Coq Effective Algebra Library. Contribute to {CoqEAL}/{CoqEAL} development by creating an account on {GitHub}.},
	publisher = {{CoqEAL}},
	urldate = {2020-01-10},
	date = {2020-01-08},
	note = {original-date: 2014-02-10T12:35:29Z}
}

@online{noauthor_event-b_nodate,
	title = {Event-B and the Rodin Platform},
	url = {http://www.event-b.org/},
	urldate = {2020-01-10},
	file = {Event-B.org:/Users/richardford/Zotero/storage/3FA6KM7N/www.event-b.org.html:text/html}
}

@online{noauthor_theorem_nodate,
	title = {Theorem Proving in Lean — Theorem Proving in Lean 3.4.0 documentation},
	url = {https://leanprover.github.io/theorem_proving_in_lean/index.html},
	urldate = {2020-01-10},
	file = {Theorem Proving in Lean — Theorem Proving in Lean .pdf:/Users/richardford/Zotero/storage/CZUXXKHS/Theorem Proving in Lean — Theorem Proving in Lean .pdf:application/pdf;Theorem Proving in Lean — Theorem Proving in Lean 3.4.0 documentation:/Users/richardford/Zotero/storage/MK7SN4IG/index.html:text/html}
}

@article{shafiq_integrating_2014,
	title = {Integrating Formal Methods in {XP}—A Conceptual Solution},
	volume = {07},
	issn = {1945-3116, 1945-3124},
	url = {http://www.scirp.org/journal/doi.aspx?DOI=10.4236/jsea.2014.74029},
	doi = {10.4236/jsea.2014.74029},
	pages = {299--310},
	number = {4},
	journaltitle = {Journal of Software Engineering and Applications},
	author = {Shafiq, Shagufta and Minhas, Nasir Mehmood},
	urldate = {2020-01-10},
	date = {2014},
	file = {Full Text:/Users/richardford/Zotero/storage/IPQVKICE/Shafiq and Minhas - 2014 - Integrating Formal Methods in XP—A Conceptual Solu.pdf:application/pdf}
}

@article{ullrich_counting_2019,
	title = {Counting Immutable Beans: Reference Counting Optimized for Purely Functional Programming},
	url = {http://arxiv.org/abs/1908.05647},
	shorttitle = {Counting Immutable Beans},
	abstract = {Most functional languages rely on some garbage collection for automatic memory management. They usually eschew reference counting in favor of a tracing garbage collector, which has less bookkeeping overhead at runtime. On the other hand, having an exact reference count of each value can enable optimizations, such as destructive updates. We explore these optimization opportunities in the context of an eager, purely functional programming language. We propose a new mechanism for efficiently reclaiming memory used by nonshared values, reducing stress on the global memory allocator. We describe an approach for minimizing the number of reference counts updates using borrowed references and a heuristic for automatically inferring borrow annotations. We implemented all these techniques in a new compiler for an eager and purely functional programming language with support for multi-threading. Our preliminary experimental results demonstrate our approach is competitive and often outperforms state-of-the-art compilers.},
	journaltitle = {{arXiv}:1908.05647 [cs]},
	author = {Ullrich, Sebastian and de Moura, Leonardo},
	urldate = {2020-01-10},
	date = {2019-09-03},
	eprinttype = {arxiv},
	eprint = {1908.05647},
	keywords = {Computer Science - Programming Languages},
	file = {arXiv Fulltext PDF:/Users/richardford/Zotero/storage/7DG57YQ9/Ullrich and de Moura - 2019 - Counting Immutable Beans Reference Counting Optim.pdf:application/pdf;arXiv.org Snapshot:/Users/richardford/Zotero/storage/7MNP545U/1908.html:text/html}
}

@software{carneiro_metamath_2020,
	title = {Metamath Zero},
	rights = {{CC}0-1.0},
	url = {https://github.com/digama0/mm0},
	abstract = {Metamath Zero specification language. Contribute to digama0/mm0 development by creating an account on {GitHub}.},
	author = {Carneiro, Mario},
	urldate = {2020-01-10},
	date = {2020-01-10},
	note = {original-date: 2019-02-25T07:34:19Z}
}

@article{carneiro_type_2019,
	title = {The Type Theory of Lean},
	url = {https://github.com/digama0/lean-type-theory/releases/download/v1.0/main.pdf},
	author = {Carneiro, Mario},
	date = {2019-04-16},
	file = {Carneiro - 2019 - The Type Theory of Lean.pdf:/Users/richardford/Zotero/storage/3KWG8UY5/Carneiro - 2019 - The Type Theory of Lean.pdf:application/pdf}
}

@article{carneiro_specifying_2019,
	title = {Specifying verified x86 software from scratch},
	url = {http://arxiv.org/abs/1907.01283},
	abstract = {We present a simple framework for specifying and proving facts about the input/output behavior of {ELF} binary files on the x86-64 architecture. A strong emphasis has been placed on simplicity at all levels: the specification says only what it needs to about the target executable, the specification is performed inside a simple logic (equivalent to first-order Peano Arithmetic), and the verification language and proof checker are custom-designed to have only what is necessary to perform efficient general purpose verification. This forms a part of the Metamath Zero project, to build a minimal verifier that is capable of verifying its own binary. In this paper, we will present the specification of the dynamic semantics of x86 machine code, together with enough information about Linux system calls to perform simple {IO}.},
	journaltitle = {{arXiv}:1907.01283 [cs]},
	author = {Carneiro, Mario},
	urldate = {2020-01-10},
	date = {2019-07-02},
	eprinttype = {arxiv},
	eprint = {1907.01283},
	keywords = {Computer Science - Logic in Computer Science, 68Q60 (Primary) 68N30 (Secondary)},
	file = {arXiv Fulltext PDF:/Users/richardford/Zotero/storage/2MU53N8P/Carneiro - 2019 - Specifying verified x86 software from scratch.pdf:application/pdf;arXiv.org Snapshot:/Users/richardford/Zotero/storage/9X7GGN9W/1907.html:text/html}
}

@article{avigad_data_2019,
	title = {Data Types as Quotients of Polynomial Functors},
	url = {http://drops.dagstuhl.de/opus/volltexte/2019/11061/},
	doi = {10.4230/lipics.itp.2019.6},
	abstract = {A broad class of data types, including arbitrary nestings of inductive types, coinductive types, and quotients, can be represented as quotients of polynomial functors. This provides perspicuous ways of constructing them and reasoning about them in an interactive theorem prover.},
	journaltitle = {Schloss Dagstuhl - Leibniz-Zentrum fuer Informatik {GmbH}, Wadern/Saarbruecken, Germany},
	author = {Avigad, Jeremy and Carneiro, Mario and Hudon, Simon},
	urldate = {2020-01-10},
	date = {2019},
	langid = {english},
	file = {Avigad et al. - 2019 - Data Types as Quotients of Polynomial Functors.pdf:/Users/richardford/Zotero/storage/AKHGETSH/Avigad et al. - 2019 - Data Types as Quotients of Polynomial Functors.pdf:application/pdf}
}

@article{bolignano_proven_2016,
	title = {Proven Security for the Internet of Things},
	abstract = {The large-scale deployment of the Internet of Things will not be possible without resolving current security issues and challenges. We believe this can be addressed using a few key security software components and will illustrate this using representative examples drawn mainly from the connected car use case.},
	pages = {11},
	author = {Bolignano, Dominique},
	date = {2016},
	langid = {english},
	file = {Bolignano - 2016 - Proven Security for the Internet of Things.pdf:/Users/richardford/Zotero/storage/GY5L9S2K/Bolignano - 2016 - Proven Security for the Internet of Things.pdf:application/pdf}
}

@online{noauthor_xetex_nodate,
	title = {{XeTeX} - {TeX} Users Group},
	url = {https://tug.org/xetex/},
	urldate = {2020-01-10},
	file = {XeTeX - TeX Users Group:/Users/richardford/Zotero/storage/IMRU2KSM/xetex.html:text/html}
}

@incollection{kennedy_types_2010-1,
	location = {Berlin, Heidelberg},
	title = {Types for Units-of-Measure: Theory and Practice},
	isbn = {978-3-642-17685-2},
	url = {https://doi.org/10.1007/978-3-642-17685-2_8},
	series = {Lecture Notes in Computer Science},
	shorttitle = {Types for Units-of-Measure},
	abstract = {Units-of-measure are to science what types are to programming. In science and engineering, dimensional and unit consistency provides a first check on the correctness of an equation or formula, just as in programming the validation of a program by the type-checker eliminates one possible reason for failure.},
	pages = {268--305},
	booktitle = {Central European Functional Programming School: Third Summer School, {CEFP} 2009, Budapest, Hungary, May 21-23, 2009 and Komárno, Slovakia, May 25-30, 2009, Revised Selected Lectures},
	publisher = {Springer},
	author = {Kennedy, Andrew},
	editor = {Horváth, Zoltán and Plasmeijer, Rinus and Zsók, Viktória},
	urldate = {2020-01-10},
	date = {2010},
	langid = {english},
	doi = {10.1007/978-3-642-17685-2_8},
	keywords = {Equational Theory, Inference Algorithm, Type Inference, Type Scheme, Type System}
}

@article{goossens_xetex_nodate,
	title = {The {XeTeX} Companion: {TeX} meets {OpenType} and Unicode},
	pages = {112},
	author = {Goossens, Michel},
	langid = {english},
	file = {Goossens - Work in progress. Version January 11,2010.pdf:/Users/richardford/Zotero/storage/ZPY9VYWE/Goossens - Work in progress. Version January 11,2010.pdf:application/pdf}
}

@online{noauthor_texmaker_nodate,
	title = {Texmaker (free cross-platform latex editor)},
	url = {https://www.xm1math.net/texmaker/doc.html},
	urldate = {2020-01-10},
	file = {Texmaker (free cross-platform latex editor):/Users/richardford/Zotero/storage/383674TZ/doc.html:text/html}
}

@video{noauthor_galois_nodate,
	title = {Galois, Inc. Tech Talk: {JaVerT}: a {JavaScript} Verification Toolchain (Dr. Philippa Gardner)},
	url = {https://www.youtube.com/watch?v=uNVAmCYL1Jo},
	shorttitle = {Galois, Inc. Tech Talk},
	abstract = {Abstract:

The dynamic nature of {JavaScript} and its complex semantics make it a difficult target for logic-based verification. In this talk, I will describe {JaVerT}, a semi-automatic {JavaScript} Verification Toolchain
based on separation logic. {JaVerT} is aimed at the specialist developer wanting rich, mechanically verified specifications of critical {JavaScript} code. The specification challenge is to design specifications that are readable by developers. The verification challenge is to handle the complex, dynamic nature of {JavaScript}
without simplification. The validation challenge is to understand what it means for the verification to be trusted.

Bio:

Philippa Gardner is a professor in the Department of Computing at Imperial College London and leader of the research group working on Verified Trustworthy Software Specification. Her current research focusses on reasoning about web programs ({JavaScript} and {DOM}); and reasoning about concurrent programs. 
She completed her {PhD} thesis, supervised by Professor Gordon Plotkin {FRS} at Edinburgh in 1992. She moved to Cambridge in 1998 on an {EPSRC} Advanced Fellowship, hosted by Professor Robin Milner {FRS}. She obtained a lectureship at Imperial in 2001, and became professor in 2009. She held a Microsoft Research Cambridge/Royal Academy of Engineering Senior Fellowship from 2005 to 2010 at Imperial.

Philippa directs the Research Institute on Verified Trustworthy Software Systems ({VeTSS}), funded by {EPSRC}, from 2017 to 2022. She also chairs the {BCS} awards committee, which decides the Lovelace medal (senior) and Roger Needham award (mid-career) for computer science and engineering.},
	urldate = {2020-01-10}
}

@inproceedings{devai_embedding_2009,
	title = {Embedding a Proof System in Haskell},
	url = {http://link.springer.com/chapter/10.1007/978-3-642-17685-2_10},
	doi = {10.1007/978-3-642-17685-2_10},
	abstract = {This article reports about a work-in-progress project that aims at embedding a proof system [4] in the Haskellprogramming language. The goal of the system is to create formally verified software...},
	eventtitle = {Central European Functional Programming School},
	pages = {354--371},
	booktitle = {Central European Functional Programming School},
	publisher = {Springer, Berlin, Heidelberg},
	author = {Dévai, Gergely},
	urldate = {2020-01-10},
	date = {2009-05-21},
	langid = {english},
	file = {Dévai - 2009 - Embedding a Proof System in Haskell.pdf:/Users/richardford/Zotero/storage/CFRETGP9/Dévai - 2009 - Embedding a Proof System in Haskell.pdf:application/pdf}
}

@online{noauthor_etaps_nodate,
	title = {{ETAPS} 2020},
	url = {https://www.etaps.org/},
	urldate = {2020-01-10},
	file = {ETAPS 2020:/Users/richardford/Zotero/storage/57T6QQQM/www.etaps.org.html:text/html}
}

@article{lombardi_commutative_2015,
	title = {Commutative algebra: Constructive methods. Finite projective modules},
	volume = {20},
	url = {http://arxiv.org/abs/1605.04832},
	doi = {10.1007/978-94-017-9944-7},
	shorttitle = {Commutative algebra},
	abstract = {This book is an introductory course to basic commutative algebra with a particular emphasis on finitely generated projective modules. We adopt the constructive point of view, with which all existence theorems have an explicit algorithmic content content. In particular, when a theorem affirms the existence of an object -- the solution of a problem -- a construction algorithm of the object can always be extracted from the given proof. We revisit with a new and often simplifying eye several abstract classical theories. In particular, we review theories which did not have any algorithmic content in their general natural framework, such as Galois theory, the Dedekind domains, the finitely generated projective modules or the Krull dimension.},
	journaltitle = {{arXiv}:1605.04832 [math]},
	author = {Lombardi, Henri and Quitté, Claude},
	urldate = {2020-01-10},
	date = {2015},
	eprinttype = {arxiv},
	eprint = {1605.04832},
	keywords = {13-02 (13C10), Mathematics - Commutative Algebra},
	file = {arXiv Fulltext PDF:/Users/richardford/Zotero/storage/ZM8CL6MF/Lombardi and Quitté - 2015 - Commutative algebra Constructive methods. Finite .pdf:application/pdf;arXiv.org Snapshot:/Users/richardford/Zotero/storage/JGCJRI88/1605.html:text/html}
}

@online{noauthor_eacsl_nodate,
	title = {{EACSL} – European Association for Computer Science Logic},
	url = {https://www.eacsl.org/},
	urldate = {2020-01-10},
	langid = {american},
	file = {Snapshot:/Users/richardford/Zotero/storage/NPX39JTM/www.eacsl.org.html:text/html}
}

@online{leslie-hurd_joe_nodate,
	title = {Joe Leslie-Hurd - Gilith},
	url = {http://www.gilith.com/},
	abstract = {Has Opentheory, Metis, and Chess as well as other links.},
	author = {Leslie-Hurd, Joe},
	urldate = {2020-01-10},
	file = {Joe Leslie-Hurd - Gilith:/Users/richardford/Zotero/storage/KH3YB3LB/www.gilith.com.html:text/html}
}

@online{noauthor_opentheory_nodate,
	title = {{OpenTheory} Project - Gilith},
	url = {http://www.gilith.com/opentheory/},
	urldate = {2020-01-10},
	file = {OpenTheory Project - Gilith:/Users/richardford/Zotero/storage/DUMQW9F5/opentheory.html:text/html}
}

@online{noauthor_metis_nodate,
	title = {Metis Theorem Prover - Gilith},
	url = {http://www.gilith.com/metis/},
	urldate = {2020-01-10},
	file = {Metis Theorem Prover - Gilith:/Users/richardford/Zotero/storage/QTVYNGV4/metis.html:text/html}
}

@incollection{bobaru_opentheory_2011,
	location = {Berlin, Heidelberg},
	title = {The {OpenTheory} Standard Theory Library},
	volume = {6617},
	isbn = {978-3-642-20397-8 978-3-642-20398-5},
	url = {http://link.springer.com/10.1007/978-3-642-20398-5_14},
	abstract = {Interactive theorem proving is tackling ever larger formalization and veriﬁcation projects, and there is a critical need for theory engineering techniques to support these eﬀorts. One such technique is cross-prover package management, which has the potential to simplify the development of logical theories and eﬀectively share theories between diﬀerent theorem prover implementations. The {OpenTheory} project has developed standards for packaging theories of the higher order logic implemented by the {HOL} family of theorem provers. What is currently missing is a standard theory library that can serve as a published contract of interoperability and contain proofs of basic properties that would otherwise appear in many theory packages. The core contribution of this paper is the presentation of a standard theory library for higher order logic represented as an {OpenTheory} package. We identify the core theory set of the {HOL} family of theorem provers, and describe the process of instrumenting the {HOL} Light theorem prover to extract a standardized version of its core theory development. We proﬁle the axioms and theorems of our standard theory library and investigate the performance cost of separating the standard theory library into coherent hierarchical theory packages.},
	pages = {177--191},
	booktitle = {{NASA} Formal Methods},
	publisher = {Springer Berlin Heidelberg},
	author = {Hurd, Joe},
	editor = {Bobaru, Mihaela and Havelund, Klaus and Holzmann, Gerard J. and Joshi, Rajeev},
	urldate = {2020-01-10},
	date = {2011},
	langid = {english},
	doi = {10.1007/978-3-642-20398-5_14},
	file = {Hurd - 2011 - The OpenTheory Standard Theory Library.pdf:/Users/richardford/Zotero/storage/IWLYWVQY/Hurd - 2011 - The OpenTheory Standard Theory Library.pdf:application/pdf}
}

@online{noauthor_proofpower_nodate,
	title = {The {ProofPower} Web Pages},
	url = {http://www.lemma-one.com/ProofPower/index/},
	urldate = {2020-01-10},
	file = {The ProofPower Web Pages:/Users/richardford/Zotero/storage/NJ5Q9DBQ/index.html:text/html}
}

@online{joe_leslie-hurd_slowest_2015,
	title = {The Slowest Software Development Methodology in the World},
	url = {https://gilith.wordpress.com/2015/07/19/the-slowest-software-development-methodology-in-the-world/},
	abstract = {For some time now I’ve been practicing what can only be described as the slowest software development methodology in the world: a three step waltz of Prototyping, Verification and Export. Pro…},
	titleaddon = {The Robot Mathematician},
	author = {{Joe Leslie-Hurd}},
	urldate = {2020-01-10},
	date = {2015-07-19},
	langid = {english},
	file = {Snapshot:/Users/richardford/Zotero/storage/WPXZIPZ3/the-slowest-software-development-methodology-in-the-world.html:text/html}
}

@online{noauthor_ats_nodate,
	title = {The {ATS} Programming Language},
	url = {http://www.ats-lang.org/},
	urldate = {2020-01-10},
	file = {ATS-PL-SYS:/Users/richardford/Zotero/storage/UWKPQ2PR/www.ats-lang.org.html:text/html}
}

@article{xi_applied_2017,
	title = {Applied Type System: An Approach to Practical Programming with Theorem-Proving},
	url = {http://arxiv.org/abs/1703.08683},
	shorttitle = {Applied Type System},
	abstract = {The framework Pure Type System ({PTS}) offers a simple and general approach to designing and formalizing type systems. However, in the presence of dependent types, there often exist certain acute problems that make it difficult for {PTS} to directly accommodate many common realistic programming features such as general recursion, recursive types, effects (e.g., exceptions, references, input/output), etc. In this paper, Applied Type System ({ATS}) is presented as a framework for designing and formalizing type systems in support of practical programming with advanced types (including dependent types). In particular, it is demonstrated that {ATS} can readily accommodate a paradigm referred to as programming with theorem-proving ({PwTP}) in which programs and proofs are constructed in a syntactically intertwined manner, yielding a practical approach to internalizing constraint-solving needed during type-checking. The key salient feature of {ATS} lies in a complete separation between statics, where types are formed and reasoned about, and dynamics, where programs are constructed and evaluated. With this separation, it is no longer possible for a program to occur in a type as is otherwise allowed in {PTS}. The paper contains not only a formal development of {ATS} but also some examples taken from ats-lang.org, a programming language with a type system rooted in {ATS}, in support of employing {ATS} as a framework to formulate advanced type systems for practical programming.},
	journaltitle = {{arXiv}:1703.08683 [cs]},
	author = {Xi, Hongwei},
	urldate = {2020-01-10},
	date = {2017-03-25},
	eprinttype = {arxiv},
	eprint = {1703.08683},
	keywords = {Computer Science - Logic in Computer Science, Computer Science - Programming Languages},
	file = {arXiv Fulltext PDF:/Users/richardford/Zotero/storage/65F5XPI9/Xi - 2017 - Applied Type System An Approach to Practical Prog.pdf:application/pdf;arXiv.org Snapshot:/Users/richardford/Zotero/storage/SVKPK6CW/1703.html:text/html}
}

@article{xi_introduction_nodate,
	title = {Introduction to Programming in {ATS}},
	pages = {252},
	author = {Xi, Hongwei},
	langid = {english},
	file = {Xi - Introduction to Programming in ATS.pdf:/Users/richardford/Zotero/storage/RHKEDKY6/Xi - Introduction to Programming in ATS.pdf:application/pdf}
}

@online{noauthor_hongwei_nodate,
	title = {Hongwei Xi},
	url = {http://www.cs.bu.edu/~hwxi/},
	abstract = {Author of {ATS}},
	urldate = {2020-01-10},
	file = {Hongwei Xi:/Users/richardford/Zotero/storage/DNZPPL2V/~hwxi.html:text/html}
}

@software{noauthor_deducteamholide_2019,
	title = {Deducteam/Holide},
	url = {https://github.com/Deducteam/Holide},
	abstract = {A translator from {OpenTheory} to Dedukti. Contribute to Deducteam/Holide development by creating an account on {GitHub}.},
	publisher = {Deducteam},
	urldate = {2020-01-10},
	date = {2019-11-05},
	note = {original-date: 2018-02-08T13:18:34Z}
}

@software{noauthor_deducteamdedukti_2019,
	title = {Deducteam/Dedukti},
	url = {https://github.com/Deducteam/Dedukti},
	abstract = {Implementation of the λΠ-calculus modulo rewriting},
	publisher = {Deducteam},
	urldate = {2020-01-10},
	date = {2019-12-22},
	note = {original-date: 2017-11-16T15:34:07Z}
}

@online{noauthor_dedukti_nodate,
	title = {Dedukti - a Logical Framework},
	url = {https://deducteam.github.io/},
	urldate = {2020-01-10},
	file = {Dedukti - a Logical Framework:/Users/richardford/Zotero/storage/6C4KAPKJ/deducteam.github.io.html:text/html}
}

@article{assaf_dedukti_nodate,
	title = {Dedukti: a Logical Framework based on the λΠ-Calculus Modulo Theory},
	abstract = {Dedukti is a Logical Framework based on the λΠ-Calculus Modulo Theory. We show that many theories can be expressed in Dedukti: constructive and classical predicate logic, Simple type theory, programming languages, Pure type systems, the Calculus of inductive constructions with universes, etc. and that permits to used it to check large libraries of proofs developed in other proof systems: Zenon, {iProver}, {FoCaLiZe}, {HOL} Light, and Matita.},
	pages = {36},
	author = {Assaf, Ali and Burel, Guillaume and Cauderlier, Raphaël and Dowek, Gilles and Dubois, Catherine and Gilbert, Frédéric and Halmagrand, Pierre and Hermant, Olivier and Saillard, Ronan},
	langid = {english},
	file = {Assaf et al. - Dedukti a Logical Framework based on the λΠ-Calcu.pdf:/Users/richardford/Zotero/storage/6MS7VU63/Assaf et al. - Dedukti a Logical Framework based on the λΠ-Calcu.pdf:application/pdf}
}

@online{noauthor_qemu_nodate,
	title = {{QEMU}},
	url = {https://wiki.qemu.org/Main_Page},
	urldate = {2020-01-10},
	file = {QEMU:/Users/richardford/Zotero/storage/FR9JLQMB/Main_Page.html:text/html}
}

@online{noauthor_qemu_nodate-1,
	title = {{QEMU} version 4.1.0 User Documentation},
	url = {https://qemu.weilnetz.de/doc/qemu-doc.html},
	urldate = {2020-01-10},
	file = {QEMU version 4.1.0 User Documentation:/Users/richardford/Zotero/storage/F4G5M6Z6/qemu-doc.html:text/html}
}

@online{scott_continuous_nodate,
	title = {Continuous lattices},
	url = {https://www.researchgate.net/publication/251394986_Continuous_lattices},
	abstract = {Starting from the topological point of view a certain wide class of To-spaces is introduced having a very strong extension property for continuous functions with values in these spaces. It is then shown that all such spaces are complete lattices whose lattice structure determines the topology — these are the continuous lattices — and every such lattice has the extension property. With this foundation the lattices are studied in detail with respect to projections, subspaces, embeddings, and constructions such as products, sums, function spaces, and inverse limits. The main result of the paper is a proof that every topological space can be embedded in a continuous lattice which is homeomorphic (and isomorphic) to its own function space. The function algebra of such spaces provides mathematical models for the Church-Curry λ-calculus.},
	titleaddon = {{ResearchGate}},
	author = {Scott, Dana},
	urldate = {2020-01-12},
	langid = {english},
	file = {Scott - Continuous lattices.pdf:/Users/richardford/Zotero/storage/DF7MHLVE/Scott - Continuous lattices.pdf:application/pdf;Snapshot:/Users/richardford/Zotero/storage/8EFC6RBA/251394986_Continuous_lattices.html:text/html}
}

@online{weisstein_mathworld_nodate,
	title = {Mathworld Classroom},
	rights = {Copyright 1999-2014 Wolfram Research, Inc.  See http://mathworld.wolfram.com/about/terms.html for a full terms of use statement.},
	url = {http://mathworld.wolfram.com/classroom/},
	abstract = {Course List},
	type = {Text},
	author = {Weisstein, Eric W.},
	urldate = {2020-01-12},
	langid = {english},
	file = {Snapshot:/Users/richardford/Zotero/storage/Q6MBNLGT/classroom.html:text/html}
}

@article{aydemir_engineering_nodate,
	title = {Engineering Formal Metatheory},
	abstract = {Machine-checked proofs of properties of programming languages have become a critical need, both for increased conﬁdence in large and complex designs and as a foundation for technologies such as proof-carrying code. However, constructing these proofs remains a black art, involving many choices in the formulation of deﬁnitions and theorems that make a huge cumulative difference in the difﬁculty of carrying out large formal developments. The representation and manipulation of terms with variable binding is a key issue.},
	pages = {13},
	author = {Aydemir, Brian and Chargueraud, Arthur and Pierce, Benjamin C and Pollack, Randy and Weirich, Stephanie},
	langid = {english},
	file = {Aydemir et al. - Engineering Formal Metatheory.pdf:/Users/richardford/Zotero/storage/94I3EC6C/Aydemir et al. - Engineering Formal Metatheory.pdf:application/pdf}
}

@article{gross_experience_2014,
	title = {Experience Implementing a Performant Category-Theory Library in Coq},
	url = {http://arxiv.org/abs/1401.7694},
	abstract = {We describe our experience implementing a broad categorytheory library in Coq. Category theory and computational performance are not usually mentioned in the same breath, but we have needed substantial engineering effort to teach Coq to cope with large categorical constructions without slowing proof script processing unacceptably. In this paper, we share the lessons we have learned about how to represent very abstract mathematical objects and arguments in Coq and how future proof assistants might be designed to better support such reasoning. One particular encoding trick to which we draw attention allows category-theoretic arguments involving duality to be internalized in Coq’s logic with definitional equality. Ours may be the largest Coq development to date that uses the relatively new Coq version developed by homotopy type theorists, and we reflect on which new features were especially helpful.},
	journaltitle = {{arXiv}:1401.7694 [cs, math]},
	author = {Gross, Jason and Chlipala, Adam and Spivak, David I.},
	urldate = {2020-01-13},
	date = {2014-04-17},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {1401.7694},
	keywords = {Computer Science - Logic in Computer Science, Mathematics - Category Theory},
	file = {Gross et al. - 2014 - Experience Implementing a Performant Category-Theo.pdf:/Users/richardford/Zotero/storage/LERST232/Gross et al. - 2014 - Experience Implementing a Performant Category-Theo.pdf:application/pdf}
}

@online{noauthor_welcome_nodate,
	title = {Welcome to dune’s documentation! — dune documentation},
	url = {https://dune.readthedocs.io/en/stable/},
	urldate = {2020-01-13},
	file = {Welcome to dune’s documentation! — dune documentation:/Users/richardford/Zotero/storage/48JPPLEG/stable.html:text/html}
}

@article{birkedal_taste_nodate,
	title = {A Taste of Categorical Logic — Tutorial Notes},
	pages = {41},
	author = {Birkedal, Lars},
	langid = {english},
	file = {Birkedal - A Taste of Categorical Logic — Tutorial Notes.pdf:/Users/richardford/Zotero/storage/Q7H9YWPZ/Birkedal - A Taste of Categorical Logic — Tutorial Notes.pdf:application/pdf}
}

@software{noauthor_lambdapi_2020,
	title = {Lambdapi, a proof assistant based on the λΠ-calculus modulo rewriting},
	url = {https://github.com/Deducteam/lambdapi},
	abstract = {Proof assistant based on the λΠ-calculus modulo rewriting},
	publisher = {Deducteam},
	urldate = {2020-01-13},
	date = {2020-01-10},
	note = {original-date: 2017-09-10T20:32:16Z},
	keywords = {dependent-types, logical-framework, proof-assistant, proof-checker, rewriting}
}

@online{noauthor_matita_nodate,
	title = {Matita - Interactive Theorem Prover},
	url = {http://matita.cs.unibo.it/},
	abstract = {Matita (that means pencil in italian) is an experimental, interactive theorem prover under development at the Computer Science Department of the University of Bologna.},
	urldate = {2020-01-13},
	file = {Matita - Home Page:/Users/richardford/Zotero/storage/7U4SV46Z/matita.cs.unibo.it.html:text/html}
}

@online{noauthor_cerco_nodate,
	title = {{CerCo} - Certified Complexity},
	url = {http://cerco.cs.unibo.it/},
	abstract = {{CerCo} (Certified Complexity) is a European research project in the ​7th Research Framework Programme ({FP}7) of the ​European Commission (project number 243381). The project is situated in the {FP}7 theme ​Information \& Communication Technologies ({ICT}) in the topic Future and Emerging Technologies ({FET} Open). The project has started February 1st, 2010, and will have a duration of 3 years.

The project aims to the construction of a formally verified complexity preserving compiler from a large subset of C to some typical microcontroller assembly, of the kind traditionally used in embedded systems. The work comprise the definition of cost models for the input and target languages, and the machine-checked proof of preservation of complexity (concrete, not asymptotic) along compilation. The compiler will also return tight and certified cost annotations for the source program, providing a reliable infrastructure to draw temporal assertions on the executable code while reasoning on the source. The compiler will be open source, and all proofs will be public domain.},
	urldate = {2020-01-13},
	file = {CerCo:/Users/richardford/Zotero/storage/FVM747ZK/cerco.cs.unibo.it.html:text/html}
}

@thesis{saillard_typechecking_2015,
	title = {Typechecking in the lambda-Pi-Calculus Modulo : Theory and Practice},
	url = {https://pastel.archives-ouvertes.fr/tel-01299180},
	shorttitle = {Typechecking in the lambda-Pi-Calculus Modulo},
	abstract = {Automatic proof checking is about using a computer to check the validity of proofs of mathematical statements. Since this verification is purely computational, it offers a high degree of confidence. Therefore, it is particularly useful for checking that a critical software, i.e., a software that when malfunctioning may result in death or serious injury to people, loss or severe damage to equipment or environmental harm, corresponds to its specification. {DEDUKTI} is such a proof checker. It implements a type system, the lambda-Pi-Calculus Modulo, that is an extension of the dependently-typed lambda-calculus with first-order rewrite rules. Through the Curry-Howard correspondence, {DEDUKTI} implements both a powerful programming language and an expressive logical system. Furthermore, this language is particularly well suited for encoding other proof systems. For instance, we can import in {DEDUKTI} theorems proved using other tools such as {COQ}, {HOL} or {ZENON}, a first step towards creating interoperability between these systems.The lambda-Pi-Calculus Modulo is a very expressive language. On the other hand, some fundamental properties such as subject reduction (i.e., the stability of typing by reduction) and uniqueness of types are not guaranteed in general and depend on the rewrite rules considered. Yet, these properties are necessary for guaranteeing the coherence of the proof system, but also for provingthe soundness and completeness of the type-checking algorithms implemented in {DEDUKTI}. Unfortunately, these properties are undecidable. In this thesis, we design new criteria for subject reduction and uniqueness of types that are decidable in order to be implemented in {DEDUKTI}.For this purpose, we give a new definition of the lambda-Pi-Calculus Modulo that takes into account the iterative aspect of the addition of rewrite rules in the typing context. A detailed study of this new system shows that the problems of subject reduction and uniqueness of types can be reduced to two simpler properties that we call product compatibility and well-typedness of rewrite rules.Hence, we study these two properties separately and give effective sufficient conditions for them to hold.These ideas have been implemented in {DEDUKTI}, increasing its generality and reliability.},
	institution = {Ecole Nationale Supérieure des Mines de Paris},
	type = {phdthesis},
	author = {Saillard, Ronan},
	urldate = {2020-01-13},
	date = {2015-09-25},
	langid = {english},
	file = {Full Text PDF:/Users/richardford/Zotero/storage/2HPMRHNE/Saillard - 2015 - Typechecking in the lambda-Pi-Calculus Modulo  Th.pdf:application/pdf;Snapshot:/Users/richardford/Zotero/storage/CKUULC6W/tel-01299180.html:text/html}
}

@article{krebbers_mosel_2018,
	title = {{MoSeL}: a general, extensible modal framework for interactive proofs in separation logic},
	volume = {2},
	issn = {24751421},
	url = {http://dl.acm.org/citation.cfm?doid=3243631.3236772},
	doi = {10.1145/3236772},
	shorttitle = {{MoSeL}},
	pages = {1--30},
	issue = {{ICFP}},
	journaltitle = {Proceedings of the {ACM} on Programming Languages},
	author = {Krebbers, Robbert and Jourdan, Jacques-Henri and Jung, Ralf and Tassarotti, Joseph and Kaiser, Jan-Oliver and Timany, Amin and Charguéraud, Arthur and Dreyer, Derek},
	urldate = {2020-01-13},
	date = {2018-07-30},
	langid = {english},
	file = {Krebbers et al. - 2018 - MoSeL a general, extensible modal framework for i.pdf:/Users/richardford/Zotero/storage/YAMP778J/Krebbers et al. - 2018 - MoSeL a general, extensible modal framework for i.pdf:application/pdf}
}

@incollection{hutchison_embedding_2007,
	location = {Berlin, Heidelberg},
	title = {Embedding Pure Type Systems in the Lambda-Pi-Calculus Modulo},
	volume = {4583},
	isbn = {978-3-540-73227-3 978-3-540-73228-0},
	url = {http://link.springer.com/10.1007/978-3-540-73228-0_9},
	abstract = {The lambda-Pi-calculus allows to express proofs of minimal predicate logic. It can be extended, in a very simple way, by adding computation rules. This leads to the lambda-Pi-calculus modulo. We show in this paper that this simple extension is surprisingly expressive and, in particular, that all functional Pure Type Systems, such as the system F, or the Calculus of Constructions, can be embedded in it. And, moreover, that this embedding is conservative under termination hypothesis.},
	pages = {102--117},
	booktitle = {Typed Lambda Calculi and Applications},
	publisher = {Springer Berlin Heidelberg},
	author = {Cousineau, Denis and Dowek, Gilles},
	editor = {Della Rocca, Simona Ronchi},
	editorb = {Hutchison, David and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M. and Mattern, Friedemann and Mitchell, John C. and Naor, Moni and Nierstrasz, Oscar and Rangan, C. Pandu and Steffen, Bernhard and Sudan, Madhu and Terzopoulos, Demetri and Tygar, Doug and Vardi, Moshe Y. and Weikum, Gerhard},
	editorbtype = {redactor},
	urldate = {2020-01-13},
	date = {2007},
	langid = {english},
	doi = {10.1007/978-3-540-73228-0_9},
	file = {Cousineau and Dowek - 2007 - Embedding Pure Type Systems in the Lambda-Pi-Calcu.pdf:/Users/richardford/Zotero/storage/X92R9WSL/Cousineau and Dowek - 2007 - Embedding Pure Type Systems in the Lambda-Pi-Calcu.pdf:application/pdf}
}

@online{noauthor_introduction_nodate,
	title = {Introduction to Domain Theory},
	url = {http://www.cs.nott.ac.uk/~pszgmh/domains.html},
	urldate = {2020-01-13},
	file = {Introduction to Domain Theory:/Users/richardford/Zotero/storage/2TARLBQN/domains.html:text/html}
}

@incollection{di_cosmo_linear_2019,
	edition = {Summer 2019},
	title = {Linear Logic},
	url = {https://plato.stanford.edu/archives/sum2019/entries/logic-linear/},
	abstract = {Linear logic is a refinement of classical and intuitionistic logic.Instead of emphasizing truth, as in classical logic, orproof, as in intuitionistic logic, linear logic emphasizes therole of formulas as resources. To achieve this focus, linearlogic does not allow the usual structural rules of contraction andweakening to apply to all formulas but only those formulas marked withcertain modals. Linear logic contains a fully involutive negation whilemaintaining a strong constructive interpretation. Linear logic alsoprovides new insights into the nature of proofs in both classical andintuitionistic logic. Given its focus on resources, linear logic hasfound many applications in Computer Science.},
	booktitle = {The Stanford Encyclopedia of Philosophy},
	publisher = {Metaphysics Research Lab, Stanford University},
	author = {Di Cosmo, Roberto and Miller, Dale},
	editor = {Zalta, Edward N.},
	urldate = {2020-01-13},
	date = {2019},
	keywords = {logic: and games, logic: classical, logic: dialogical, logic: intuitionistic, logic: substructural, proof theory},
	file = {SEP - Snapshot:/Users/richardford/Zotero/storage/F2F4YKGP/logic-linear.html:text/html}
}

@incollection{girard_linear_1995,
	location = {Cambridge},
	title = {Linear Logic: its syntax and semantics},
	isbn = {978-0-511-62915-0},
	url = {https://www.cambridge.org/core/product/identifier/CBO9780511629150A008/type/book_part},
	shorttitle = {Linear Logic},
	pages = {1--42},
	booktitle = {Advances in Linear Logic},
	publisher = {Cambridge University Press},
	author = {Girard, J.-Y.},
	editor = {Girard, Jean-Yves and Lafont, Yves and Regnier, Laurent},
	urldate = {2020-01-13},
	date = {1995},
	langid = {english},
	doi = {10.1017/CBO9780511629150.002},
	file = {Girard - 1995 - Linear Logic its syntax and semantics.pdf:/Users/richardford/Zotero/storage/AYG62SL5/Girard - 1995 - Linear Logic its syntax and semantics.pdf:application/pdf}
}

@online{noauthor_formal_nodate,
	title = {Formal Versus Agile: Survival of the Fittest},
	url = {https://www.researchgate.net/publication/224587383_Formal_Versus_Agile_Survival_of_the_Fittest},
	shorttitle = {(17) ({PDF}) Formal Versus Agile},
	abstract = {{ResearchGate} is a network dedicated to science and research. Connect, collaborate and discover scientific publications, jobs and conferences. All for free.},
	titleaddon = {{ResearchGate}},
	urldate = {2020-01-14},
	langid = {english},
	file = {Formal Versus Agile Survival of the Fittest.pdf:/Users/richardford/Zotero/storage/T7SMMH8N/Formal Versus Agile Survival of the Fittest.pdf:application/pdf;Snapshot:/Users/richardford/Zotero/storage/MEGWY5FF/224587383_Formal_Versus_Agile_Survival_of_the_Fittest.html:text/html}
}

@article{birkedal_lecture_nodate,
	title = {Lecture Notes on Iris: Higher-Order Concurrent Separation Logic},
	pages = {138},
	author = {Birkedal, Lars and Bizjak, Aleš},
	langid = {english},
	file = {Birkedal and Bizjak - Lecture Notes on Iris Higher-Order Concurrent Sep.pdf:/Users/richardford/Zotero/storage/G2TQDRZA/Birkedal and Bizjak - Lecture Notes on Iris Higher-Order Concurrent Sep.pdf:application/pdf}
}

@article{bizjak_iron_2019,
	title = {Iron: managing obligations in higher-order concurrent separation logic},
	volume = {3},
	issn = {24751421},
	url = {http://dl.acm.org/citation.cfm?doid=3302515.3290378},
	doi = {10.1145/3290378},
	shorttitle = {Iron},
	pages = {1--30},
	issue = {{POPL}},
	journaltitle = {Proceedings of the {ACM} on Programming Languages},
	author = {Bizjak, Aleš and Gratzer, Daniel and Krebbers, Robbert and Birkedal, Lars},
	urldate = {2020-01-14},
	date = {2019-01-02},
	langid = {english},
	file = {Bizjak et al. - 2019 - Iron managing obligations in higher-order concurr.pdf:/Users/richardford/Zotero/storage/VKCEUYVS/Bizjak et al. - 2019 - Iron managing obligations in higher-order concurr.pdf:application/pdf}
}

@online{noauthor_iron_nodate,
	title = {Iron: Managing Obligations in Higher-Order Concurrent Separation Logic ({POPL} 2019)},
	url = {https://iris-project.org/iron/},
	urldate = {2020-01-14},
	file = {Iron\: Managing Obligations in Higher-Order Concurrent Separation Logic (POPL 2019):/Users/richardford/Zotero/storage/LCDYTTVM/iron.html:text/html}
}

@online{noauthor_alloy_nodate,
	title = {Alloy - software modeling},
	url = {http://alloytools.org/},
	abstract = {Alloy is an open source language and analyzer for software modeling. It has been used in a wide range of applications, from finding holes in security mechanisms to designing telephone switching networks. This site provides language documentation, tool downloads, and a repository of links to case studies and applications. As the open source community grows, this site will also provide access to extensions of the Alloy Analyzer, and tools built on top of it and on top of Kodkod, its model finding engine.},
	urldate = {2020-01-15},
	file = {:/Users/richardford/Zotero/storage/P6XWRH3W/alloytools.org.html:text/html}
}

@article{adamek_abstract_2004,
	title = {Abstract and Concrete Categories - The Joy of Cats},
	url = {http://katmat.math.uni-bremen.de/acc/acc.pdf},
	abstract = {Abstract and Concrete Categories was published by John Wiley and Sons, Inc, in 1990, and after several reprints, the book has been sold out and unavailable for several years. We now present an improved and corrected version as an open access file. This was made possible due to the return of copyright to the authors, and due to many hours of hard work and the exceptional skill of Christoph Schubert, to whom we wish to express our profound gratitude. The illustrations of Edward Gorey are unfortunately missing in the current version (for copyright reasons), but fortunately additional original illustrations by Marcel Erné, to whom additional special thanks of the authors belong, counterbalance the loss.
Open access includes the right of any reader to copy, store or distribute the book or parts of it freely. (See the {GNU} Free Documentation License at the end of the text.) Besides the acknowledgements appearing at the end of the original preface (below), we wish to thank all those who have helped to eliminate mistakes that survived the first printing of the text, particularly H. Bargenda, J. Jürjens W. Meyer, L. Schröder A. M. Torkabud, and O. Wyler.
January 12, 2004},
	pages = {524},
	author = {Adamek, Jiri and Herrlich, Horst and Strecker, George E and Schubert, Christoph},
	date = {2004-01-12},
	langid = {english},
	file = {Schubert - Abstract and Concrete Categories - The Joy of Cats.pdf:/Users/richardford/Zotero/storage/QQ75DYII/Schubert - Abstract and Concrete Categories - The Joy of Cats.pdf:application/pdf}
}

@book{riehl_category_2017,
	title = {Category Theory in Context},
	abstract = {Category theory has provided the foundations for many of the twentieth century's greatest advances in pure mathematics. This concise, original text for a one-semester course on the subject is derived from courses that author Emily Riehl taught at Harvard and Johns Hopkins Universities. The treatment introduces the essential concepts of category theory: categories, functors, natural transformations, the Yoneda lemma, limits and colimits, adjunctions, monads, and other topics. Suitable for advanced undergraduates and graduate students in mathematics, the text provides tools for understanding and attacking difficult problems in algebra, number theory, algebraic geometry, and algebraic topology. Drawing upon a broad range of mathematical examples from the categorical perspective, the author illustrates how the concepts and constructions of category theory arise from and illuminate more basic mathematical ideas. Prerequisites are limited to familiarity with some basic set theory and logic.},
	pagetotal = {272},
	publisher = {Dover Publications},
	author = {Riehl, Emily},
	date = {2017-03-09}
}

@book{appel_program_2014,
	edition = {1 edition},
	title = {Program Logics for Certified Compilers},
	abstract = {Separation logic is the twenty-first-century variant of Hoare logic that permits verification of pointer-manipulating programs. This book covers practical and theoretical aspects of separation logic at a level accessible to beginning graduate students interested in software verification. On the practical side it offers an introduction to verification in Hoare and separation logics, simple case studies for toy languages, and the Verifiable C program logic for the C programming language. On the theoretical side it presents separation algebras as models of separation logics; step-indexed models of higher-order logical features for higher-order programs; indirection theory for constructing step-indexed separation algebras; tree-shares as models for shared ownership; and the semantic construction (and soundness proof) of Verifiable C. In addition, the book covers several aspects of the {CompCert} verified C compiler, and its connection to foundationally verified software analysis tools. All constructions and proofs are made rigorous and accessible in the Coq developments of the open-source Verified Software Toolchain.},
	pagetotal = {472},
	publisher = {Cambridge University Press},
	author = {Appel, Andrew W. and Dockins, Robert and Hobor, Aquinas and Beringer, Lennart and Dodds, Josiah and Stewart, Gordon and Blazy, Sandrine and Leroy, Xavier},
	date = {2014-04-21}
}

@article{leinster_higher_2003,
	title = {Higher Operads, Higher Categories},
	url = {http://arxiv.org/abs/math/0305049},
	abstract = {Higher-dimensional category theory is the study of n-categories, operads, braided monoidal categories, and other such exotic structures. It draws its inspiration from areas as diverse as topology, quantum algebra, mathematical physics, logic, and theoretical computer science. This is the first book on the subject and lays its foundations. Many examples are given throughout. There is also an introductory chapter motivating the subject for topologists.},
	journaltitle = {{arXiv}:math/0305049},
	author = {Leinster, Tom},
	urldate = {2020-01-15},
	date = {2003-05-02},
	eprinttype = {arxiv},
	eprint = {math/0305049},
	keywords = {Mathematics - Category Theory, Mathematics - Algebraic Geometry, Mathematics - Algebraic Topology, Mathematics - Quantum Algebra},
	file = {arXiv Fulltext PDF:/Users/richardford/Zotero/storage/QS8ULIWD/Leinster - 2003 - Higher Operads, Higher Categories.pdf:application/pdf;arXiv.org Snapshot:/Users/richardford/Zotero/storage/AYETAAVU/0305049.html:text/html}
}

@article{friedman_elementary_2016,
	title = {An elementary illustrated introduction to simplicial sets},
	url = {http://arxiv.org/abs/0809.4221},
	abstract = {This is an expository introduction to simplicial sets and simplicial homotopy theory with particular focus on relating the combinatorial aspects of the theory to their geometric/topological origins. It is intended to be accessible to students familiar with just the fundamentals of algebraic topology.},
	journaltitle = {{arXiv}:0809.4221 [math]},
	author = {Friedman, Greg},
	urldate = {2020-01-15},
	date = {2016-10-03},
	eprinttype = {arxiv},
	eprint = {0809.4221},
	keywords = {Mathematics - Category Theory, Mathematics - Algebraic Topology, 18G30, 55U10, Mathematics - Geometric Topology},
	file = {arXiv Fulltext PDF:/Users/richardford/Zotero/storage/V7AHEHJZ/Friedman - 2016 - An elementary illustrated introduction to simplici.pdf:application/pdf;arXiv.org Snapshot:/Users/richardford/Zotero/storage/IRT624MN/0809.html:text/html}
}

@incollection{hutchison_impredicative_2014,
	location = {Berlin, Heidelberg},
	title = {Impredicative Concurrent Abstract Predicates},
	volume = {8410},
	isbn = {978-3-642-54832-1 978-3-642-54833-8},
	url = {http://link.springer.com/10.1007/978-3-642-54833-8_9},
	abstract = {We present impredicative concurrent abstract predicates –{iCAP} – a program logic for modular reasoning about concurrent, higherorder, reentrant, imperative code. Building on earlier work, {iCAP} uses protocols to reason about shared mutable state. A key novel feature of {iCAP} is the ability to deﬁne impredicative protocols; protocols that are parameterized on arbitrary predicates, including predicates that themselves refer to protocols. We demonstrate the utility of impredicative protocols through a series of examples, including the speciﬁcation and veriﬁcation, in the logic, of a spin-lock, a reentrant event loop, and a concurrent bag implemented using cooperation, against modular speciﬁcations.},
	pages = {149--168},
	booktitle = {Programming Languages and Systems},
	publisher = {Springer Berlin Heidelberg},
	author = {Svendsen, Kasper and Birkedal, Lars},
	editor = {Shao, Zhong},
	editorb = {Hutchison, David and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M. and Mattern, Friedemann and Mitchell, John C. and Naor, Moni and Nierstrasz, Oscar and Pandu Rangan, C. and Steffen, Bernhard and Sudan, Madhu and Terzopoulos, Demetri and Tygar, Doug and Vardi, Moshe Y. and Weikum, Gerhard},
	editorbtype = {redactor},
	urldate = {2020-01-15},
	date = {2014},
	langid = {english},
	doi = {10.1007/978-3-642-54833-8_9},
	file = {Svendsen and Birkedal - 2014 - Impredicative Concurrent Abstract Predicates.pdf:/Users/richardford/Zotero/storage/Q8CWH7QI/Svendsen and Birkedal - 2014 - Impredicative Concurrent Abstract Predicates.pdf:application/pdf}
}

@incollection{hutchison_modular_2013,
	location = {Berlin, Heidelberg},
	title = {Modular Reasoning about Separation of Concurrent Data Structures},
	volume = {7792},
	isbn = {978-3-642-37035-9 978-3-642-37036-6},
	url = {http://link.springer.com/10.1007/978-3-642-37036-6_11},
	abstract = {In a concurrent setting, the usage protocol of standard separation logic speciﬁcations are not reﬁnable by clients, because standard speciﬁcations abstract all information about potential interleavings. This breaks modularity, as libraries cannot be veriﬁed in isolation, since the appropriate speciﬁcation depends on how clients intend to use the library. In this paper we propose a new logic and a new style of speciﬁcation for thread-safe concurrent data structures. Our speciﬁcations allow clients to reﬁne usage protocols and associate ownership of additional resources with instances of these data structures.},
	pages = {169--188},
	booktitle = {Programming Languages and Systems},
	publisher = {Springer Berlin Heidelberg},
	author = {Svendsen, Kasper and Birkedal, Lars and Parkinson, Matthew},
	editor = {Felleisen, Matthias and Gardner, Philippa},
	editorb = {Hutchison, David and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M. and Mattern, Friedemann and Mitchell, John C. and Naor, Moni and Nierstrasz, Oscar and Pandu Rangan, C. and Steffen, Bernhard and Sudan, Madhu and Terzopoulos, Demetri and Tygar, Doug and Vardi, Moshe Y. and Weikum, Gerhard},
	editorbtype = {redactor},
	urldate = {2020-01-15},
	date = {2013},
	langid = {english},
	doi = {10.1007/978-3-642-37036-6_11},
	file = {Svendsen et al. - 2013 - Modular Reasoning about Separation of Concurrent D.pdf:/Users/richardford/Zotero/storage/Q4D8UYKL/Svendsen et al. - 2013 - Modular Reasoning about Separation of Concurrent D.pdf:application/pdf}
}

@book{epstein_computability_1989,
	location = {Pacific Grove, Calif},
	edition = {1 edition},
	title = {Computability: Computable Functions Logic and the Foundations of Math},
	isbn = {978-0-534-10356-9},
	shorttitle = {Computability},
	abstract = {This book should be of interest to intermediate mathematics undergraduates; postgraduates in theoretical computer science/philosophy of mathematics.},
	pagetotal = {320},
	publisher = {Chapman and Hall/{CRC}},
	author = {Epstein, Richard L. and Carnielli, Walter Alexandr},
	date = {1989-11-09}
}

@inproceedings{celik_mutation_2019,
	location = {San Diego, {CA}, {USA}},
	title = {Mutation Analysis for Coq},
	isbn = {978-1-72812-508-4},
	url = {https://ieeexplore.ieee.org/document/8952421/},
	doi = {10.1109/ASE.2019.00057},
	abstract = {Mutation analysis, which introduces artiﬁcial defects into software systems, is the basis of mutation testing, a technique widely applied to evaluate and enhance the quality of test suites. However, despite the deep analogy between tests and formal proofs, mutation analysis has seldom been considered in the context of deductive veriﬁcation. We propose mutation proving, a technique for analyzing veriﬁcation projects that use proof assistants. We implemented our technique for the Coq proof assistant in a tool dubbed {MCOQ}. {MCOQ} applies a set of mutation operators to Coq deﬁnitions of functions and datatypes, inspired by operators previously proposed for functional programming languages. {MCOQ} then checks proofs of lemmas affected by operator application. To make our technique feasible in practice, we implemented several optimizations in {MCOQ} such as parallel proof checking. We applied {MCOQ} to several medium and large scale Coq projects, and recorded whether proofs passed or failed when applying different mutation operators. We then qualitatively analyzed the mutants, ﬁnding many instances of incomplete speciﬁcations. For our evaluation, we made several improvements to serialization of Coq ﬁles and even discovered a notable bug in Coq itself, all acknowledged by developers. We believe {MCOQ} can be useful both to proof engineers for improving the quality of their veriﬁcation projects and to researchers for evaluating proof engineering techniques.},
	eventtitle = {2019 34th {IEEE}/{ACM} International Conference on Automated Software Engineering ({ASE})},
	pages = {539--551},
	booktitle = {2019 34th {IEEE}/{ACM} International Conference on Automated Software Engineering ({ASE})},
	publisher = {{IEEE}},
	author = {Celik, Ahmet and Palmskog, Karl and Parovic, Marinela and Jesus Gallego Arias, Emilio and Gligoric, Milos},
	urldate = {2020-01-20},
	date = {2019-11},
	langid = {english},
	file = {Celik et al. - 2019 - Mutation Analysis for Coq.pdf:/Users/richardford/Zotero/storage/MUVES2QN/Celik et al. - 2019 - Mutation Analysis for Coq.pdf:application/pdf}
}