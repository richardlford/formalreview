
@article{lehmann_storm_2021,
	title = {{STORM}: Reﬁnement Types for Secure Web Applications},
	abstract = {We present {STORM}, a web framework that allows developers to build {MVC} applications with compile-time enforcement of centrally speciﬁed data-dependent security policies. {STORM} ensures security using a Security Typed {ORM} that reﬁnes the (type) abstractions of each layer of the {MVC} {API} with logical assertions that describe the data produced and consumed by the underlying operation and the users allowed access to that data. To evaluate the security guarantees of {STORM}, we build a formally veriﬁed reference implementation using the Labeled {IO} ({LIO}) {IFC} framework. We present case studies and end-toend applications that show how {STORM} lets developers specify diverse policies while centralizing the trusted code to under 1\% of the application, and statically enforces security with modest type annotation overhead, and no run-time cost.},
	pages = {19},
	journaltitle = {Proceedings of Symposium on Operating Systems Design and Implementation ({OSDI})},
	author = {Lehmann, Nico and Kunkel, Rose and Brown, Jordan and Yang, Jean and Vazou, Niki and Polikarpova, Nadia and Stefan, Deian and Jhala, Ranjit},
	date = {2021-07},
	langid = {english},
	file = {Lehmann et al. - STORM Reﬁnement Types for Secure Web Applications.pdf:/home/fordrl/Zotero/storage/HTTJC33N/Lehmann et al. - STORM Reﬁnement Types for Secure Web Applications.pdf:application/pdf},
}

@inproceedings{algehed_dynamic_nodate,
	title = {Dynamic {IFC} Theorems for Free!},
	isbn = {978-1-72817-607-9},
	url = {https://www.computer.org/csdl/proceedings-article/csf/2021/760700a001/1pmB5edaFk4},
	doi = {10.1109/CSF51468.2021.00005},
	abstract = {We show that noninterference and transparency, 
the key soundness theorems for dynamic {IFC} libraries, can be 
obtained “for free”, as direct consequences of the more general 
parametricity theorem of type abstraction. This allows us to give 
very short soundness proofs for dynamic {IFC} libraries such as 
faceted values and {LIO}. Our proofs stay short even when fully 
mechanized for Agda implementations of the libraries in terms of type abstraction.},
	eventtitle = {2021 {IEEE} 34th Computer Security Foundations Symposium ({CSF})},
	pages = {1--14},
	publisher = {{IEEE} Computer Society},
	author = {Algehed, Maximilian and Bernardy, Jean-Philippe and Hritcu, Catalin},
	urldate = {2021-06-11},
	note = {{ISSN}: 2374-8303},
	file = {Algehed and Bernardy - Dynamic IFC Theorems for Free!.pdf:/home/fordrl/Zotero/storage/RY4EVV8A/Algehed and Bernardy - Dynamic IFC Theorems for Free!.pdf:application/pdf;Snapshot:/home/fordrl/Zotero/storage/4RW2LCIB/1pmB5edaFk4.html:text/html},
}

@inproceedings{tsampas_capableptrs_2021,
	title = {{CapablePtrs}: Securely Compiling Partial Programs Using the Pointers-as-Capabilities Principle},
	abstract = {Capability machines such as {CHERI} provide mem- to implement ﬁne-grained memory protection, and has the ory capabilities that can be used by compilers to provide security beneﬁts for compiled code (e.g., memory safety). The existing C to {CHERI} compiler, for example, achieves memory safety by following a principle called “pointers as capabilities” ({PAC} ). Informally, {PAC} says that a compiler should represent a source potential to provide protection against many software bugs.},
	eventtitle = {34th {IEEE} Computer Security Foundations Symposium},
	pages = {16},
	author = {Tsampas, Akram El-Korashy Stelios and Patrignani, Marco and Devriese, Dominique and Piessens, Deepak Garg Frank},
	date = {2021-06-21},
	langid = {english},
	file = {Tsampas et al. - CapablePtrs Securely Compiling Partial Programs U.pdf:/home/fordrl/Zotero/storage/KQWMGD5D/Tsampas et al. - CapablePtrs Securely Compiling Partial Programs U.pdf:application/pdf},
}

@inproceedings{busi_brief_2019,
	location = {Pisa, Italy},
	title = {A Brief Tour of Formally Secure Compilation},
	url = {http://ceur-ws.org/Vol-2315/paper03.pdf},
	abstract = {Modern programming languages provide helpful high-level abstractions and mechanisms (e.g. types, module, automatic memory management) that enforce good programming practices and are crucial when writing correct and secure code. However, the security guarantees provided by such abstractions are not preserved when a compiler translates a source program into object code. Formally secure compilation is an emerging research ﬁeld concerned with the design and the implementation of compilers that preserve source-level security properties at the object level. This paper presents a short guided tour of the relevant literature on secure compilation. Our goal is to help newcomers to grasp the basic concepts of this ﬁeld and, for this reason, we rephrase and present the most relevant results in the literature in a common setting.},
	eventtitle = {Third Italian Conference on Cyber Security},
	pages = {13},
	booktitle = {Proceedings of the Third Italian Conference on Cyber Security},
	publisher = {{CEUR}-{WS}.org},
	author = {Busi, Matteo and Galletta, Letterio},
	date = {2019-02-13},
	langid = {english},
	file = {Busi and Galletta - A Brief Tour of Formally Secure Compilation.pdf:/home/fordrl/Zotero/storage/DWYVCL28/Busi and Galletta - A Brief Tour of Formally Secure Compilation.pdf:application/pdf},
}

@inproceedings{clarkson_hyperproperties_2008,
	title = {Hyperproperties},
	doi = {10.1109/CSF.2008.7},
	abstract = {Properties, which have long been used for reasoning about systems, are sets of traces. Hyperproperties, introduced here, are sets of properties. Hyperproperties can express security policies, such as secure information flow, that properties cannot. Safety and liveness are generalized to hyperproperties, and every hyperproperty is shown to be the intersection of a safety hyperproperty and a liveness hyperproperty. A verification technique for safety hyperproperties is given and is shown to generalize prior techniques for verifying secure information flow. Refinement is shown to be valid for safety hyperproperties. A topological characterization of hyperproperties is given.},
	eventtitle = {2008 21st {IEEE} Computer Security Foundations Symposium},
	pages = {51--65},
	booktitle = {2008 21st {IEEE} Computer Security Foundations Symposium},
	author = {Clarkson, Michael R. and Schneider, Fred B.},
	date = {2008-06},
	note = {{ISSN}: 2377-5459},
	keywords = {Computer science, Computer security, Delay effects, Information security, liveness, safety, Safety, Security policies, Topology, Writing},
	file = {Hyperproperties.JCS.pdf:/home/fordrl/Zotero/storage/3YDH8YT6/Hyperproperties.JCS.pdf:application/pdf;IEEE Xplore Abstract Record:/home/fordrl/Zotero/storage/9PPVH3HV/4556678.html:text/html},
}

@article{juglaret_towards_2015,
	title = {Towards a Fully Abstract Compiler Using Micro-Policies: Secure Compilation for Mutually Distrustful Components},
	url = {http://arxiv.org/abs/1510.00697},
	shorttitle = {Towards a Fully Abstract Compiler Using Micro-Policies},
	abstract = {Secure compilation prevents all low-level attacks on compiled code and allows for sound reasoning about security in the source language. In this work we propose a new attacker model for secure compilation that extends the well-known notion of full abstraction to ensure protection for mutually distrustful components. We devise a compiler chain (compiler, linker, and loader) and a novel security monitor that together defend against this strong attacker model. The monitor is implemented using a recently proposed, generic tag-based protection framework called micro-policies, which comes with hardware support for efficient caching and with a formal verification methodology. Our monitor protects the abstractions of a simple object-oriented language---class isolation, the method call discipline, and type safety---against arbitrary low-level attackers.},
	journaltitle = {{arXiv}:1510.00697 [cs]},
	author = {Juglaret, Yannis and Hritcu, Catalin and de Amorim, Arthur Azevedo and Pierce, Benjamin C. and Spector-Zabusky, Antal and Tolmach, Andrew},
	urldate = {2021-06-07},
	date = {2015-10-02},
	eprinttype = {arxiv},
	eprint = {1510.00697},
	keywords = {Computer Science - Cryptography and Security, Computer Science - Programming Languages},
	file = {arXiv.org Snapshot:/home/fordrl/Zotero/storage/J22GTPI9/1510.html:text/html;arXiv Fulltext PDF:/home/fordrl/Zotero/storage/Q5WTENYV/Juglaret et al. - 2015 - Towards a Fully Abstract Compiler Using Micro-Poli.pdf:application/pdf},
}

@article{abate_journey_2019,
	title = {Journey Beyond Full Abstraction: Exploring Robust Property Preservation for Secure Compilation},
	url = {http://arxiv.org/abs/1807.04603},
	doi = {10.1109/CSF.2019.00025},
	shorttitle = {Journey Beyond Full Abstraction},
	abstract = {({CROPPED} {TO} {FIT} {IN} {ARXIV}'S {SILLY} {LIMIT}. {SEE} {PDF} {FOR} {COMPLETE} {ABSTRACT}.) We are the first to thoroughly explore a large space of formal secure compilation criteria based on robust property preservation, i.e., the preservation of properties satisfied against arbitrary adversarial contexts. We study robustly preserving various classes of trace properties such as safety, of hyperproperties such as noninterference, and of relational hyperproperties such as trace equivalence. This leads to many new secure compilation criteria, some of which are easier to practically achieve and prove than full abstraction, and some of which provide strictly stronger security guarantees. For each of the studied criteria we propose an equivalent "property-free" characterization that clarifies which proof techniques apply. For relational properties and hyperproperties, which relate the behaviors of multiple programs, our formal definitions of the property classes themselves are novel. We order our criteria by their relative strength and show several collapses and separation results. Finally, we adapt existing proof techniques to show that even the strongest of our secure compilation criteria, the robust preservation of all relational hyperproperties, is achievable for a simple translation from a statically typed to a dynamically typed language.},
	pages = {256--25615},
	journaltitle = {2019 {IEEE} 32nd Computer Security Foundations Symposium ({CSF})},
	author = {Abate, Carmine and Blanco, Roberto and Garg, Deepak and Hritcu, Catalin and Patrignani, Marco and Thibault, Jérémy},
	urldate = {2021-06-07},
	date = {2019-06},
	eprinttype = {arxiv},
	eprint = {1807.04603},
	keywords = {Computer Science - Cryptography and Security, Computer Science - Programming Languages},
	file = {arXiv.org Snapshot:/home/fordrl/Zotero/storage/XH8LF764/1807.html:text/html;arXiv Fulltext PDF:/home/fordrl/Zotero/storage/8RTHN9K8/Abate et al. - 2019 - Journey Beyond Full Abstraction Exploring Robust .pdf:application/pdf},
}

@article{abate_when_2019,
	title = {When Good Components Go Bad: Formally Secure Compilation Despite Dynamic Compromise},
	url = {http://arxiv.org/abs/1802.00588},
	shorttitle = {When Good Components Go Bad},
	abstract = {We propose a new formal criterion for evaluating secure compilation schemes for unsafe languages, expressing end-to-end security guarantees for software components that may become compromised after encountering undefined behavior---for example, by accessing an array out of bounds. Our criterion is the first to model dynamic compromise in a system of mutually distrustful components with clearly specified privileges. It articulates how each component should be protected from all the others---in particular, from components that have encountered undefined behavior and become compromised. Each component receives secure compilation guarantees---in particular, its internal invariants are protected from compromised components---up to the point when this component itself becomes compromised, after which we assume an attacker can take complete control and use this component's privileges to attack other components. More precisely, a secure compilation chain must ensure that a dynamically compromised component cannot break the safety properties of the system at the target level any more than an arbitrary attacker-controlled component (with the same interface and privileges, but without undefined behaviors) already could at the source level. To illustrate the model, we construct a secure compilation chain for a small unsafe language with buffers, procedures, and components, targeting a simple abstract machine with built-in compartmentalization. We give a machine-checked proof in Coq that this compiler satisfies our secure compilation criterion. Finally, we show that the protection guarantees offered by the compartmentalized abstract machine can be achieved at the machine-code level using either software fault isolation or a tag-based reference monitor.},
	journaltitle = {{arXiv}:1802.00588 [cs]},
	author = {Abate, Carmine and de Amorim, Arthur Azevedo and Blanco, Roberto and Evans, Ana Nora and Fachini, Guglielmo and Hritcu, Catalin and Laurent, Théo and Pierce, Benjamin C. and Stronati, Marco and Thibault, Jérémy and Tolmach, Andrew},
	urldate = {2021-06-07},
	date = {2019-11-29},
	eprinttype = {arxiv},
	eprint = {1802.00588},
	keywords = {Computer Science - Cryptography and Security, Computer Science - Programming Languages},
	file = {arXiv.org Snapshot:/home/fordrl/Zotero/storage/HZ6QL7N7/1802.html:text/html;arXiv Fulltext PDF:/home/fordrl/Zotero/storage/HKGK2R88/Abate et al. - 2019 - When Good Components Go Bad Formally Secure Compi.pdf:application/pdf},
}

@article{juglaret_beyond_2017,
	title = {Beyond Good and Evil: Formalizing the Security Guarantees of Compartmentalizing Compilation},
	url = {http://arxiv.org/abs/1602.04503},
	shorttitle = {Beyond Good and Evil},
	abstract = {Compartmentalization is good security-engineering practice. By breaking a large software system into mutually distrustful components that run with minimal privileges, restricting their interactions to conform to well-defined interfaces, we can limit the damage caused by low-level attacks such as control-flow hijacking. When used to defend against such attacks, compartmentalization is often implemented cooperatively by a compiler and a low-level compartmentalization mechanism. However, the formal guarantees provided by such compartmentalizing compilation have seen surprisingly little investigation. We propose a new security property, secure compartmentalizing compilation ({SCC}), that formally characterizes the guarantees provided by compartmentalizing compilation and clarifies its attacker model. We reconstruct our property by starting from the well-established notion of fully abstract compilation, then identifying and lifting three important limitations that make standard full abstraction unsuitable for compartmentalization. The connection to full abstraction allows us to prove {SCC} by adapting established proof techniques; we illustrate this with a compiler from a simple unsafe imperative language with procedures to a compartmentalized abstract machine.},
	journaltitle = {{arXiv}:1602.04503 [cs]},
	author = {Juglaret, Yannis and Hritcu, Catalin and de Amorim, Arthur Azevedo and Eng, Boris and Pierce, Benjamin C.},
	urldate = {2021-06-07},
	date = {2017-04-15},
	eprinttype = {arxiv},
	eprint = {1602.04503},
	keywords = {Computer Science - Cryptography and Security, Computer Science - Programming Languages},
	file = {arXiv.org Snapshot:/home/fordrl/Zotero/storage/CJ9IG6ZE/1602.html:text/html;arXiv Fulltext PDF:/home/fordrl/Zotero/storage/U2L9Z3J4/Juglaret et al. - 2017 - Beyond Good and Evil Formalizing the Security Gua.pdf:application/pdf},
}

@article{chhak_towards_2020,
	title = {Towards Formally Verified Compilation of Tag-Based Policy Enforcement},
	url = {http://arxiv.org/abs/2012.10313},
	abstract = {Hardware-assisted reference monitoring is receiving increasing attention as a way to improve the security of existing software. One example is the {PIPE} architecture extension, which attaches metadata tags to register and memory values and executes tag-based rules at each machine instruction to enforce a software-defined security policy. To use {PIPE} effectively, engineers should be able to write security policies in terms of source-level concepts like functions, local variables, and structured control operators, which are not visible at machine level. It is the job of the compiler to generate {PIPE}-aware machine code that enforces these source-level policies. The compiler thus becomes part of the monitored system's trusted computing base -- and hence a prime candidate for verification. To formalize compiler correctness in this setting, we extend the source language semantics with its own form of user-specified tag-based monitoring, and show that the compiler preserves that monitoring behavior. The challenges of compilation include mapping source-level monitoring policies to instruction-level tag rules, preserving fail-stop behaviors, and satisfying the surprisingly complex preconditions for conventional optimizations. In this paper, we describe the design and verification of Tagine, a small prototype compiler that translates a simple tagged {WHILE} language to a tagged register transfer language and performs simple optimizations. Tagine is based on the {RTLgen} and Deadcode phases of the {CompCert} compiler, and hence is written and verified in Coq. This work is a first step toward verification of a full-scale compiler for a realistic tagged source language.},
	journaltitle = {{arXiv}:2012.10313 [cs]},
	author = {Chhak, C. H. R. and Tolmach, Andrew and Anderson, Sean},
	urldate = {2021-06-07},
	date = {2020-12-18},
	eprinttype = {arxiv},
	eprint = {2012.10313},
	keywords = {Computer Science - Cryptography and Security},
	file = {arXiv.org Snapshot:/home/fordrl/Zotero/storage/GWFC6JDS/2012.html:text/html;arXiv Fulltext PDF:/home/fordrl/Zotero/storage/VH5ZATM6/Chhak et al. - 2020 - Towards Formally Verified Compilation of Tag-Based.pdf:application/pdf},
}

@article{oak_language_nodate,
	title = {Language Support for Secure Software Development with Enclaves},
	abstract = {Conﬁdential computing is a promising technology for securing code and data-in-use on untrusted host machines, e.g., the cloud. Many hardware vendors offer different implementations of Trusted Execution Environments ({TEEs}). A {TEE} is a hardware protected execution environment that allows performing conﬁdential computations over sensitive data on untrusted hosts. Despite the appeal of achieving strong security guarantees against low-level attackers, two challenges hinder the adoption of {TEEs}. First, developing software in high-level managed languages, e.g., Java or Scala, taking advantage of existing {TEEs} is complex and error-prone. Second, partitioning an application into components that run inside and outside a {TEE} may break application-level security policies, resulting in an insecure application when facing a realistic attacker.},
	pages = {16},
	author = {Oak, Aditya and Ahmadian, Amir M and Balliu, Musard and Salvaneschi, Guido},
	langid = {english},
	file = {Oak et al. - Language Support for Secure Software Development w.pdf:/home/fordrl/Zotero/storage/NWIYUYQQ/Oak et al. - Language Support for Secure Software Development w.pdf:application/pdf},
}

@article{plotkin_lcf_1977,
	title = {{LCF} considered as a programming language},
	volume = {5},
	issn = {0304-3975},
	url = {https://www.sciencedirect.com/science/article/pii/0304397577900445},
	doi = {10.1016/0304-3975(77)90044-5},
	abstract = {The paper studies connections between denotational and operational semantics for a simple programming language based on {LCF}. It begins with the connection between the behaviour of a program and its denotation. It turns out that a program denotes ⊥ in any of several possible semantics if it does not terminate. From this it follows that if two terms have the same denotation in one of these semantics, they have the same behaviour in all contexts. The converse fails for all the semantics. If, however, the language is extended to allow certain parallel facilities behavioural equivalence does coincide with denotational equivalence in one of the semantics considered, which may therefore be called “fully abstract”. Next a connection is given which actually determines the semantics up to isomorphism from the behaviour alone. Conversely, by allowing further parallel facilities, every r.e. element of the fully abstract semantics becomes definable, thus characterising the programming language, up to interdefinability, from the set of r.e. elements of the domains of the semantics.},
	pages = {223--255},
	number = {3},
	journaltitle = {Theoretical Computer Science},
	shortjournal = {Theoretical Computer Science},
	author = {Plotkin, G. D.},
	urldate = {2021-05-28},
	date = {1977-12-01},
	langid = {english},
	file = {LCF considered as a programming language:/home/fordrl/Zotero/storage/BSRBY3B4/main.pdf:application/pdf;ScienceDirect Snapshot:/home/fordrl/Zotero/storage/IDCA9U8A/0304397577900445.html:text/html},
}

@online{sidhpurwala_security_2019,
	title = {Security flaws caused by compiler optimizations},
	url = {https://www.redhat.com/en/blog/security-flaws-caused-compiler-optimizations},
	abstract = {An optimizing compiler is one that tries to maximize some attribute(s) of an executable program at the expense of other attribute(s). Usually the goal is to improve performance or code size at the expense of compiler time and the possibility to debug the program at a later stage. Most modern compilers support some sort of optimization. Normally code optimized for performance is the usual preference. In cases where space is a constraint like embedded systems, developers also prefer code optimized for size.},
	author = {Sidhpurwala, Huzaifa},
	urldate = {2021-05-28},
	date = {2019-08-21},
	langid = {english},
	file = {Snapshot:/home/fordrl/Zotero/storage/Z9LRKND4/security-flaws-caused-compiler-optimizations.html:text/html},
}

@article{guarnieri_contract-aware_2020,
	title = {Contract-Aware Secure Compilation},
	url = {http://arxiv.org/abs/2012.14205},
	abstract = {Microarchitectural attacks exploit the abstraction gap between the Instruction Set Architecture ({ISA}) and how instructions are actually executed by processors to compromise the confidentiality and integrity of a system. To secure systems against microarchitectural attacks, programmers need to reason about and program against these microarchitectural side-effects. However, we cannot -- and should not -- expect programmers to manually tailor programs for specific processors and their security guarantees. Instead, we could rely on compilers (and the secure compilation community), as they can play a prominent role in bridging this gap: compilers should target specific processors microarchitectural security guarantees and they should leverage these guarantees to produce secure code. To achieve this, we outline the idea of Contract-Aware Secure {COmpilation} ({CASCO}) where compilers are parametric with respect to a hardware/software security-contract, an abstraction capturing a processor's security guarantees. That is, compilers will automatically leverage the guarantees formalized in the contract to ensure that program-level security properties are preserved at microarchitectural level.},
	journaltitle = {{arXiv}:2012.14205 [cs]},
	author = {Guarnieri, Marco and Patrignani, Marco},
	urldate = {2021-05-27},
	date = {2020-12-28},
	eprinttype = {arxiv},
	eprint = {2012.14205},
	keywords = {Computer Science - Cryptography and Security, Computer Science - Programming Languages},
	file = {arXiv.org Snapshot:/home/fordrl/Zotero/storage/W9R3LGUW/2012.html:text/html;arXiv Fulltext PDF:/home/fordrl/Zotero/storage/KMAYRTDV/Guarnieri and Patrignani - 2020 - Contract-Aware Secure Compilation.pdf:application/pdf},
}

@article{sison_verified_2020,
	title = {Verified Secure Compilation for Mixed-Sensitivity Concurrent Programs},
	url = {http://arxiv.org/abs/2010.14032},
	abstract = {Proving only over source code that programs do not leak sensitive data leaves a gap between reasoning and reality that can only be filled by accounting for the behaviour of the compiler. Furthermore, software does not always have the luxury of limiting itself to single-threaded computation with resources statically dedicated to each user to ensure the confidentiality of their data. This results in mixed-sensitivity concurrent programs, which might reuse memory shared between their threads to hold data of different sensitivity levels at different times; for such programs, a compiler must preserve the value-dependent coordination of such mixed-sensitivity reuse despite the impact of concurrency. Here we demonstrate, using Isabelle/{HOL}, that it is feasible to verify that a compiler preserves noninterference, the strictest kind of confidentiality property, for mixed-sensitivity concurrent programs. First, we present notions of refinement that preserve a concurrent value-dependent notion of noninterference that we have designed to support such programs. As proving noninterference-preserving refinement can be considerably more complex than the standard refinements typically used to verify semantics -- preserving compilation, our notions include a decomposition principle that separates the semantics -- from the security-preservation concerns. Second, we demonstrate that these refinement notions are applicable to verified secure compilation, by exercising them on a single-pass compiler for mixed-sensitivity concurrent programs that synchronise using mutex locks, from a generic imperative language to a generic {RISC}-style assembly language. Finally, we execute our compiler on a nontrivial mixed-sensitivity concurrent program modelling a real-world use case, thus preserving its source-level noninterference properties down to an assembly-level model automatically. (See paper for complete abstract.)},
	journaltitle = {{arXiv}:2010.14032 [cs]},
	author = {Sison, Robert and Murray, Toby},
	urldate = {2021-05-27},
	date = {2020-10-26},
	eprinttype = {arxiv},
	eprint = {2010.14032},
	keywords = {Computer Science - Cryptography and Security, Computer Science - Programming Languages, Computer Science - Logic in Computer Science, D.2.4, D.1.3, D.3.4, F.3.1},
	file = {arXiv.org Snapshot:/home/fordrl/Zotero/storage/EGRLBF8N/2010.html:text/html;arXiv Fulltext PDF:/home/fordrl/Zotero/storage/9ZD627GR/Sison and Murray - 2020 - Verified Secure Compilation for Mixed-Sensitivity .pdf:application/pdf},
}

@article{namjoshi_witnessing_2019,
	title = {Witnessing Secure Compilation},
	url = {http://arxiv.org/abs/1911.05866},
	abstract = {Compiler optimizations are designed to improve run-time performance while preserving input-output behavior. Correctness in this sense does not necessarily preserve security: it is known that standard optimizations may break or weaken security properties that hold of the source program. This work develops a translation validation method for secure compilation. Security (hyper-)properties are expressed using automata operating over a bundle of program traces. A flexible, automaton-based refinement scheme, generalizing existing refinement methods, guarantees that the associated security property is preserved by a program transformation. In practice, the refinement relations ("security witnesses") can be generated during compilation and validated independently with a refinement checker. This process is illustrated for common optimizations. Crucially, it is not necessary to verify the compiler implementation itself, which is infeasible in practice for production compilers.},
	journaltitle = {{arXiv}:1911.05866 [cs]},
	author = {Namjoshi, Kedar S. and Tabajara, Lucas M.},
	urldate = {2021-05-27},
	date = {2019-11-13},
	eprinttype = {arxiv},
	eprint = {1911.05866},
	keywords = {Computer Science - Formal Languages and Automata Theory},
	file = {arXiv.org Snapshot:/home/fordrl/Zotero/storage/GN8BCBWC/1911.html:text/html;arXiv Fulltext PDF:/home/fordrl/Zotero/storage/7N5YNXF5/Namjoshi and Tabajara - 2019 - Witnessing Secure Compilation.pdf:application/pdf},
}

@article{tsampas_categorical_2020,
	title = {A categorical approach to secure compilation},
	url = {http://arxiv.org/abs/2004.03557},
	abstract = {We introduce a novel approach to secure compilation based on maps of distributive laws. We demonstrate through four examples that the coherence criterion for maps of distributive laws can potentially be a viable alternative for compiler security instead of full abstraction, which is the preservation and reflection of contextual equivalence. To that end, we also make use of the well-behavedness properties of distributive laws to construct a categorical argument for the contextual connotations of bisimilarity.},
	journaltitle = {{arXiv}:2004.03557 [cs]},
	author = {Tsampas, Stelios and Nuyts, Andreas and Devriese, Dominique and Piessens, Frank},
	urldate = {2021-05-27},
	date = {2020-04-07},
	eprinttype = {arxiv},
	eprint = {2004.03557},
	keywords = {Computer Science - Programming Languages, Computer Science - Logic in Computer Science},
	file = {arXiv.org Snapshot:/home/fordrl/Zotero/storage/58XAAWNR/2004.html:text/html;arXiv Fulltext PDF:/home/fordrl/Zotero/storage/HETK4AS7/Tsampas et al. - 2020 - A categorical approach to secure compilation.pdf:application/pdf},
}

@article{abadi_protection_1998,
	title = {Protection in programming-language translations},
	pages = {16},
	journaltitle = {{DECSRC}},
	author = {Abadi, Martin},
	date = {1998},
	langid = {english},
	file = {Abadi - Protection in programming-language translations.pdf:/home/fordrl/Zotero/storage/Z5QYCSJG/Abadi - Protection in programming-language translations.pdf:application/pdf},
}

@inproceedings{agten_secure_2012,
	location = {Cambridge, {MA}, {USA}},
	title = {Secure Compilation to Modern Processors},
	isbn = {978-1-4673-1918-8 978-0-7695-4718-3},
	url = {http://ieeexplore.ieee.org/document/6266159/},
	doi = {10.1109/CSF.2012.12},
	abstract = {We present a secure (fully abstract) compilation scheme to compile an object-based high-level language to lowlevel machine code. Full abstraction is achieved by relying on a ﬁne-grained program counter-based memory access protection scheme, which is part of our low-level target language. We discuss why standard compilers fail to provide full abstraction and introduce enhancements needed to achieve this goal. We prove that our enhanced compilation scheme provides full abstraction from our high-level source language to our lowlevel target language. Lastly, we show by means of a prototype implementation that our low-level language with ﬁne-grained memory access control can be realized efﬁciently on modern commodity platforms.},
	eventtitle = {2012 {IEEE} 25th Computer Security Foundations Symposium ({CSF})},
	pages = {171--185},
	booktitle = {2012 {IEEE} 25th Computer Security Foundations Symposium},
	publisher = {{IEEE}},
	author = {Agten, Pieter and Strackx, Raoul and Jacobs, Bart and Piessens, Frank},
	urldate = {2021-05-26},
	date = {2012-06},
	langid = {english},
	file = {Agten et al. - 2012 - Secure Compilation to Modern Processors.pdf:/home/fordrl/Zotero/storage/3CAGUP6Y/Agten et al. - 2012 - Secure Compilation to Modern Processors.pdf:application/pdf},
}

@article{patrignani_formal_2019,
	title = {Formal Approaches to Secure Compilation: A Survey of Fully Abstract Compilation and Related Work},
	volume = {51},
	issn = {0360-0300},
	url = {https://doi.org/10.1145/3280984},
	doi = {10.1145/3280984},
	shorttitle = {Formal Approaches to Secure Compilation},
	abstract = {Secure compilation is a discipline aimed at developing compilers that preserve the security properties of the source programs they take as input in the target programs they produce as output. This discipline is broad in scope, targeting languages with a variety of features (including objects, higher-order functions, dynamic memory allocation, call/cc, concurrency) and employing a range of different techniques to ensure that source-level security is preserved at the target level. This article provides a survey of the existing literature on formal approaches to secure compilation with a focus on those that prove fully abstract compilation, which has been the criterion adopted by much of the literature thus far. This article then describes the formal techniques employed to prove secure compilation in existing work, introducing relevant terminology, and discussing the merits and limitations of each work. Finally, this article discusses open challenges and possible directions for future work in secure compilation.},
	pages = {125:1--125:36},
	number = {6},
	journaltitle = {{ACM} Computing Surveys},
	shortjournal = {{ACM} Comput. Surv.},
	author = {Patrignani, Marco and Ahmed, Amal and Clarke, Dave},
	urldate = {2021-05-26},
	date = {2019-02-04},
	keywords = {contextual equivalence, fully abstract compilation, program equivalence, Secure compilation, type preserving compilation},
	file = {Full Text PDF:/home/fordrl/Zotero/storage/ASCDJFDA/Patrignani et al. - 2019 - Formal Approaches to Secure Compilation A Survey .pdf:application/pdf},
}

@article{yousefi-azar_mutual_2021,
	title = {Mutual Information and Feature Importance Gradient Boosting: Automatic byte n‐gram feature reranking for Android malware detection},
	doi = {10.1002/spe.2971},
	shorttitle = {Mutual Information and Feature Importance Gradient Boosting},
	abstract = {The fast pace evolving of Android malware demands for highly efficient strategy. That is, for a range of malware types, a malware detection scheme needs to be resilient and with minimum computation performs efficient and precise. In this paper, we propose Mutual Information and Feature Importance Gradient Boosting ({MIFIBoost}) tool that uses byte n‐gram frequency. {MIFIBoost} consists of four steps in the model construction phase and two steps in the prediction phase. For training, first, n‐grams of both the classes.dex and {AndroidManifest}.xml binary files are obtained. Then, {MIFIBoost} uses Mutual Information ({MI}) to determine the top most informative items from the entire n‐gram vocabulary. In the third phase, {MIFIBoost} utilizes the Gradient Boosting algorithm to re‐rank these top n‐grams. For testing, {MIFIBoost} uses the learned vocabulary of byte n‐grams term‐frequency (tf) to feed into the classifier for prediction. Thus, {MIFIBoost} does not require reverse engineering. A key insight from this work is that filtering using {XGBoost} helps us to address the hard problem of detecting obfuscated malware better while having a negligible impact on nonobfuscated malware. We have conducted a wide range of experiments on four different datasets one of which is obfuscated, and {MIFIBoost} outperforms state‐of‐the‐art tools. {MIFIBoost}'s f1‐score for Drebin, {DexShare}, and {AMD} datasets is 99.1\%, 98.87\%, and 99.62\%, respectively, a False Positive Rate of 0.41\% using {AMD} dataset. On average, the False Negative Rate of {MIFIBoost} is 2.1\% for the {PRAGuard} dataset in which seven different obfuscation techniques are implemented. In addition to fast run‐time performance and resiliency against obfuscated malware, the experiments show that {MIFIBoost} performs quite efficiently for five zero‐day families with 99.78\% {AUC}.},
	journaltitle = {Software: Practice and Experience},
	shortjournal = {Software: Practice and Experience},
	author = {Yousefi-Azar, Mahmood and Varadharajan, Vijay and Hamey, Len and Chen, Shiping},
	date = {2021-04-05},
}

@report{schoolderman_efficient_2021,
	title = {Efficient Verification of Optimized Code: Correct High-speed X25519},
	url = {https://eprint.iacr.org/2021/415},
	shorttitle = {Efficient Verification of Optimized Code},
	abstract = {Code that is highly optimized poses a problem for program-level verification: programmers can employ various clever tricks that are non-trivial to reason about. For cryptography on low-power devices, it is nonetheless crucial that implementations be functionally correct, secure, and efficient. These are usually crafted in hand-optimized machine code that eschew conventional control flow as much as possible.



We have formally verified such code: a library which implements elliptic curve cryptography on 8-bit {AVR} microcontrollers. The chosen implementation is the most efficient currently known for this microarchitecture. It consists of over 3000 lines of assembly instructions. Building on earlier work, we use the Why3 platform to model the code and prove verification conditions, using automated provers. We expect the approach to be re-usable and adaptable, and it allows for validation. Furthermore, an error in the original implementation was found and corrected, at the same time reducing its memory footprint. This shows that practical verification of cutting-edge code is not only possible, but can in fact add to its efficiency—and is clearly necessary.},
	number = {415},
	author = {Schoolderman, Marc and Moerman, Jonathan and Smetsers, Sjaak and Eekelen, Marko van},
	urldate = {2021-05-26},
	date = {2021},
	keywords = {formal verification, elliptic curve cryptosystem, implementation},
	file = {ePrint IACR Snapshot:/home/fordrl/Zotero/storage/B8LXIMJB/415.html:text/html;ePrint IACR Full Text PDF:/home/fordrl/Zotero/storage/PKX87MVU/Schoolderman et al. - 2021 - Efficient Verification of Optimized Code Correct .pdf:application/pdf},
}

@report{poettering_sok_2021,
	title = {{SoK}: Game-based Security Models for Group Key Exchange},
	url = {https://eprint.iacr.org/2021/305},
	shorttitle = {{SoK}},
	abstract = {Group key exchange ({GKE}) protocols let a group of users jointly establish fresh and secure key material. Many flavors of {GKE} have been proposed, differentiated by, among others, whether group membership is static or dynamic, whether a single key or a continuous stream of keys is established, and whether security is provided in the presence of state corruptions (forward and post-compromise security). In all cases, an indispensable ingredient to the rigorous analysis of a candidate solution is a corresponding formal security model. We observe, however, that most {GKE}-related publications are more focused on building new constructions that have more functionality or are more efficient than prior proposals, while leaving the job of identifying and working out the details of adequate security models a subordinate task.



In this systematization of knowledge we bring the formal modeling of {GKE} security to the fore by revisiting the intuitive goals of {GKE}, critically evaluating how these goals are reflected (or not) in the established models, and how they would be best considered in new models. We classify and compare characteristics of a large selection of game-based {GKE} models that appear in the academic literature, including those proposed for {GKE} with post-compromise security. We observe a range of shortcomings in some of the studied models, such as dependencies on overly restrictive syntactical constrains, unrealistic adversarial capabilities, or simply incomplete definitions. Our systematization enables us to identify a coherent suite of desirable characteristics that we believe should be represented in all general purpose {GKE} models. To demonstrate the feasibility of covering all these desirable characteristics simultaneously in one concise definition, we conclude with proposing a new generic reference model for {GKE}.},
	number = {305},
	author = {Poettering, Bertram and Rösler, Paul and Schwenk, Jörg and Stebila, Douglas},
	urldate = {2021-05-21},
	date = {2021},
	keywords = {cryptographic protocols, Group key exchange, key agreement, key establishment, multi-user protocol, security model, systematization of knowledge},
	file = {ePrint IACR Snapshot:/home/fordrl/Zotero/storage/BKAWF8B2/305.html:text/html;ePrint IACR Full Text PDF:/home/fordrl/Zotero/storage/YDD5Q2BP/Poettering et al. - 2021 - SoK Game-based Security Models for Group Key Exch.pdf:application/pdf},
}

@article{cauligi_sok_2021,
	title = {{SoK}: Practical Foundations for Spectre Defenses},
	url = {http://arxiv.org/abs/2105.05801},
	shorttitle = {{SoK}},
	abstract = {Spectre vulnerabilities violate our fundamental assumptions about architectural abstractions, allowing attackers to steal sensitive data despite previously state-of-the-art countermeasures. To defend against Spectre, developers of verification tools and compiler-based mitigations are forced to reason about microarchitectural details such as speculative execution. In order to aid developers with these attacks in a principled way, the research community has sought formal foundations for speculative execution upon which to rebuild provable security guarantees. This paper systematizes the community's current knowledge about software verification and mitigation for Spectre. We study state-of-the-art software defenses, both with and without associated formal models, and use a cohesive framework to compare the security properties each defense provides. We explore a wide variety of tradeoffs in the complexity of formal frameworks, the performance of defense tools, and the resulting security guarantees. As a result of our analysis, we suggest practical choices for developers of analysis and mitigation tools, and we identify several open problems in this area to guide future work on grounded software defenses.},
	journaltitle = {{arXiv}:2105.05801 [cs]},
	author = {Cauligi, Sunjay and Disselkoen, Craig and Moghimi, Daniel and Barthe, Gilles and Stefan, Deian},
	urldate = {2021-05-19},
	date = {2021-05-12},
	eprinttype = {arxiv},
	eprint = {2105.05801},
	keywords = {Computer Science - Cryptography and Security, Computer Science - Programming Languages},
	file = {arXiv.org Snapshot:/home/fordrl/Zotero/storage/UQB2GXV6/2105.html:text/html;arXiv Fulltext PDF:/home/fordrl/Zotero/storage/VGHRI892/Cauligi et al. - 2021 - SoK Practical Foundations for Spectre Defenses.pdf:application/pdf},
}

@article{kruger_crysl_2019,
	title = {{CrySL}: An Extensible Approach to Validating the Correct Usage of Cryptographic {APIs}},
	issn = {1939-3520},
	doi = {10.1109/TSE.2019.2948910},
	shorttitle = {{CrySL}},
	abstract = {Various studies have empirically shown that the majority of Java and Android applications misuse cryptographic libraries, causing devastating breaches of data security. It is crucial to detect such misuses early in the development process. To detect cryptography misuses, one must define secure uses first, a process mastered primarily by cryptography experts but not by developers. In this paper, we present {CrySL}, a specification language for bridging the cognitive gap between cryptography experts and developers. {CrySL} enables cryptography experts to specify the secure usage of the cryptographic libraries they provide. We have implemented a compiler that translates such {CrySL} specification into a context-sensitive and flow-sensitive demand-driven static analysis. The analysis then helps developers by automatically checking a given Java or Android app for compliance with the {CrySL}-encoded rules. We have designed an extensive {CrySL} rule set for the Java Cryptography Architecture ({JCA}), and empirically evaluated it by analyzing 10,000 current Android apps and all 204,788 current Java software artefacts on Maven Central. Our results show that misuse of cryptographic {APIs} is still widespread, with 95\% of apps and 63\% of Maven artefacts containing at least one misuse. Our easily extensible {CrySL} rule set covers more violations than previous special-purpose tools that contain hard-coded rules, while still offering a more precise analysis.},
	pages = {1--1},
	journaltitle = {{IEEE} Transactions on Software Engineering},
	author = {Krüger, Stefan and Späth, Johannes and Ali, Karim and Bodden, Eric and Mezini, Mira},
	date = {2019},
	note = {Conference Name: {IEEE} Transactions on Software Engineering},
	keywords = {static analysis, Ciphers, cryptography, domain-specific language, Encryption, Java, Semantics, Static analysis, Tools},
	file = {IEEE Xplore Abstract Record:/home/fordrl/Zotero/storage/CVHBRFEF/8880510.html:text/html;Full Text:/home/fordrl/Zotero/storage/AX2XZFSQ/Krüger et al. - 2019 - CrySL An Extensible Approach to Validating the Co.pdf:application/pdf},
}

@article{bonifacio_dealing_2021,
	title = {Dealing with Variability in {API} Misuse Specification},
	url = {http://arxiv.org/abs/2105.04950},
	abstract = {{APIs} are the primary mechanism for developers to gain access to externally defined services and tools. However, previous research has revealed {API} misuses that violate the contract of {APIs} to be prevalent. Such misuses can have harmful consequences, especially in the context of cryptographic libraries. Various {API} misuse detectors have been proposed to address this issue including {CogniCrypt}, one of the most versatile of such detectors and that uses a language {CrySL} to specify cryptographic {API} usage contracts. Nonetheless, existing approaches to detect {API} misuse had not been designed for systematic reuse, ignoring the fact that different versions of a library, different versions of a platform, and different recommendations or guidelines might introduce variability in the correct usage of an {API}. Yet, little is known about how such variability impacts the specification of the correct {API} usage. This paper investigates this question by analyzing the impact of various sources of variability on widely used Java cryptographic libraries including {JCA}, Bouncy Castle, and Google Tink. The results of our investigation show that sources of variability like new versions of the {API} and security standards significantly impact the specifications. We then use the insights gained from our investigation to motivate an extension to the {CrySL} language named {MetaCrySL}, which builds on meta programming concepts. We evaluate {MetaCrySL} by specifying usage rules for a family of Android versions and illustrate that {MetaCrySL} can model all forms of variability we identified and drastically reduce the size of a family of specifications for the correct usage of cryptographic {APIs}},
	journaltitle = {{arXiv}:2105.04950 [cs]},
	author = {Bonifacio, Rodrigo and Krüger, Stefan and Narasimhan, Krishna and Bodden, Eric and Mezini, Mira},
	urldate = {2021-05-19},
	date = {2021-05-17},
	eprinttype = {arxiv},
	eprint = {2105.04950},
	keywords = {Computer Science - Cryptography and Security, Computer Science - Software Engineering, 68N19, D.2.1, D.3.3},
	file = {arXiv.org Snapshot:/home/fordrl/Zotero/storage/8846WXX6/2105.html:text/html;arXiv Fulltext PDF:/home/fordrl/Zotero/storage/HCFDM4JN/Bonifacio et al. - 2021 - Dealing with Variability in API Misuse Specificati.pdf:application/pdf},
}

@inproceedings{barthe_secure_2021,
	location = {Dubrovnik, Croatia},
	title = {Secure Compilation of Constant-Resource Programs},
	url = {https://hal.archives-ouvertes.fr/hal-03221440},
	abstract = {Observational non-interference ({ONI}) is a generic information-flow policy for side-channel leakage. Informally, a program is {ONI}-secure if observing program leakage during execution does not reveal any information about secrets. Formally, {ONI} is parametrized by a leakage function , and different instances of {ONI} can be recovered through different instantiations of. One popular instance of {ONI} is the cryptographic constant-time ({CCT}) policy, which is widely used in cryptographic libraries to protect against timing and cache attacks. Informally, a program is {CCT}-secure if it does not branch on secrets and does not perform secret-dependent memory accesses. Another instance of {ONI} is the constant-resource ({CR}) policy, a relaxation of the {CCT} policy which is used in Amazon's s2n implementation of {TLS} and in several other security applications. Informally, a program is {CR}-secure if its cost (modelled by a tick operator over an arbitrary semi-group) does not depend on secrets. In this paper, we consider the problem of preserving {ONI} by compilation. Prior work on the preservation of the {CCT} policy develops proof techniques for showing that main compiler optimisations preserve the {CCT} policy. However, these proof techniques critically rely on the fact that the semi-group used for modelling leakage satisfies the property:},
	booktitle = {{IEEE} 34th Computer Security Foundations Symposium ({CSF})},
	author = {Barthe, Gilles and Blazy, Sandrine and Hutin, Rémi and Pichardie, David},
	urldate = {2021-05-17},
	date = {2021-06},
	file = {HAL PDF Full Text:/home/fordrl/Zotero/storage/K6B56V2F/Barthe et al. - 2021 - Secure Compilation of Constant-Resource Programs.pdf:application/pdf},
}

@article{dietz_understanding_nodate,
	title = {Understanding Integer Overﬂow in C/C++},
	abstract = {Integer overﬂow bugs in C and C++ programs are difﬁcult to track down and may lead to fatal errors or exploitable vulnerabilities. Although a number of tools for ﬁnding these bugs exist, the situation is complicated because not all overﬂows are bugs. Better tools need to be constructed—but a thorough understanding of the issues behind these errors does not yet exist. We developed {IOC}, a dynamic checking tool for integer overﬂows, and used it to conduct the ﬁrst detailed empirical study of the prevalence and patterns of occurrence of integer overﬂows in C and C++ code. Our results show that intentional uses of wraparound behaviors are more common than is widely believed; for example, there are over 200 distinct locations in the {SPEC} {CINT}2000 benchmarks where overﬂow occurs. Although many overﬂows are intentional, a large number of accidental overﬂows also occur. Orthogonal to programmers’ intent, overﬂows are found in both welldeﬁned and undeﬁned ﬂavors. Applications executing undeﬁned operations can be, and have been, broken by improvements in compiler optimizations. Looking beyond {SPEC}, we found and reported undeﬁned integer overﬂows in {SQLite}, {PostgreSQL}, {SafeInt}, {GNU} {MPC} and {GMP}, Firefox, {GCC}, {LLVM}, Python, {BIND}, and {OpenSSL}; many of these have since been ﬁxed. Our results show that integer overﬂow issues in C and C++ are subtle and complex, that they are common even in mature, widely used programs, and that they are widely misunderstood by developers.},
	pages = {11},
	author = {Dietz, Will and Li, Peng and Regehr, John and Adve, Vikram},
	langid = {english},
	file = {Dietz et al. - Understanding Integer Overﬂow in CC++.pdf:/home/fordrl/Zotero/storage/PHA29A8Y/Dietz et al. - Understanding Integer Overﬂow in CC++.pdf:application/pdf},
}

@article{zou_intdroid_2021,
	title = {{IntDroid}: Android Malware Detection Based on {API} Intimacy Analysis},
	volume = {30},
	issn = {1049-331X},
	url = {https://doi.org/10.1145/3442588},
	doi = {10.1145/3442588},
	shorttitle = {{IntDroid}},
	abstract = {Android, the most popular mobile operating system, has attracted millions of users around the world. Meanwhile, the number of new Android malware instances has grown exponentially in recent years. On the one hand, existing Android malware detection systems have shown that distilling the program semantics into a graph representation and detecting malicious programs by conducting graph matching are able to achieve high accuracy on detecting Android malware. However, these traditional graph-based approaches always perform expensive program analysis and suffer from low scalability on malware detection. On the other hand, because of the high scalability of social network analysis, it has been applied to complete large-scale malware detection. However, the social-network-analysis-based method only considers simple semantic information (i.e., centrality) for achieving market-wide mobile malware scanning, which may limit the detection effectiveness when benign apps show some similar behaviors as malware. In this article, we aim to combine the high accuracy of traditional graph-based method with the high scalability of social-network-analysis--based method for Android malware detection. Instead of using traditional heavyweight static analysis, we treat function call graphs of apps as complex social networks and apply social-network--based centrality analysis to unearth the central nodes within call graphs. After obtaining the central nodes, the average intimacies between sensitive {API} calls and central nodes are computed to represent the semantic features of the graphs. We implement our approach in a tool called {IntDroid} and evaluate it on a dataset of 3,988 benign samples and 4,265 malicious samples. Experimental results show that {IntDroid} is capable of detecting Android malware with an F-measure of 97.1\% while maintaining a True-positive Rate of 99.1\%. Although the scalability is not as fast as a social-network-analysis--based method (i.e., {MalScan}), compared to a traditional graph-based method, {IntDroid} is more than six times faster than {MaMaDroid}. Moreover, in a corpus of apps collected from {GooglePlay} market, {IntDroid} is able to identify 28 zero-day malware that can evade detection of existing tools, one of which has been downloaded and installed by more than ten million users. This app has also been flagged as malware by six anti-virus scanners in {VirusTotal}, one of which is Symantec Mobile Insight.},
	pages = {39:1--39:32},
	number = {3},
	journaltitle = {{ACM} Transactions on Software Engineering and Methodology},
	shortjournal = {{ACM} Trans. Softw. Eng. Methodol.},
	author = {Zou, Deqing and Wu, Yueming and Yang, Siru and Chauhan, Anki and Yang, Wei and Zhong, Jiangying and Dou, Shihan and Jin, Hai},
	urldate = {2021-05-13},
	date = {2021-05-08},
	keywords = {Android malware, {API} intimacy, centrality, social network},
	file = {Full Text PDF:/home/fordrl/Zotero/storage/XERQVJ7A/Zou et al. - 2021 - IntDroid Android Malware Detection Based on API I.pdf:application/pdf},
}

@article{palit_dynpta_nodate,
	title = {{DynPTA}: Combining Static and Dynamic Analysis for Practical Selective Data Protection},
	abstract = {As control ﬂow hijacking attacks become more challenging due to the deployment of various exploit mitigation technologies, the leakage of sensitive process data through the exploitation of memory disclosure vulnerabilities is becoming an increasingly important threat. To make matters worse, recently introduced transient execution attacks provide a new avenue for leaking conﬁdential process data. As a response, various approaches for selectively protecting subsets of critical in-memory data have been proposed, which though either require a signiﬁcant code refactoring effort, or do not scale for large applications. In this paper we present {DynPTA}, a selective data protection approach that combines static analysis with scoped dynamic data ﬂow tracking ({DFT}) to keep a subset of manually annotated sensitive data always encrypted in memory. {DynPTA} ameliorates the inherent overapproximation of pointer analysis—a signiﬁcant challenge that has prevented previous approaches from supporting large applications—by relying on lightweight label lookups to determine if potentially sensitive data is actually sensitive. Labeled objects are tracked only within the subset of value ﬂows that may carry potentially sensitive data, requiring only a fraction of the program’s code to be instrumented for {DFT}. We experimentally evaluated {DynPTA} with real-world applications and demonstrate that it can prevent memory disclosure (Heartbleed) and transient execution (Spectre) attacks from leaking the protected data, while incurring a modest runtime overhead of up to 19.2\% when protecting the private {TLS} key of Nginx with {OpenSSL}.},
	pages = {19},
	author = {Palit, Tapti and Moon, Jarin Firose and Monrose, Fabian and Polychronakis, Michalis},
	langid = {english},
	file = {Palit et al. - DynPTA Combining Static and Dynamic Analysis for .pdf:/home/fordrl/Zotero/storage/NFR6JVWI/Palit et al. - DynPTA Combining Static and Dynamic Analysis for .pdf:application/pdf},
}

@incollection{degano_secure_2009,
	location = {Berlin, Heidelberg},
	title = {Secure Information Flow as a Safety Property},
	volume = {5491},
	isbn = {978-3-642-01464-2 978-3-642-01465-9},
	url = {http://link.springer.com/10.1007/978-3-642-01465-9_2},
	pages = {20--34},
	booktitle = {Formal Aspects in Security and Trust},
	publisher = {Springer Berlin Heidelberg},
	author = {Boudol, Gérard},
	editor = {Degano, Pierpaolo and Guttman, Joshua and Martinelli, Fabio},
	urldate = {2021-02-17},
	date = {2009},
	doi = {10.1007/978-3-642-01465-9_2},
	note = {Series Title: Lecture Notes in Computer Science},
}

@article{bengtson_refinement_2011,
	title = {Refinement types for secure implementations},
	volume = {33},
	issn = {0164-0925, 1558-4593},
	url = {https://dl.acm.org/doi/10.1145/1890028.1890031},
	doi = {10.1145/1890028.1890031},
	pages = {1--45},
	number = {2},
	journaltitle = {{ACM} Transactions on Programming Languages and Systems},
	shortjournal = {{ACM} Trans. Program. Lang. Syst.},
	author = {Bengtson, Jesper and Bhargavan, Karthikeyan and Fournet, Cédric and Gordon, Andrew D. and Maffeis, Sergio},
	urldate = {2021-02-17},
	date = {2011-01},
	langid = {english},
	file = {Full Text:/home/fordrl/Zotero/storage/V24D6F3I/Bengtson et al. - 2011 - Refinement types for secure implementations.pdf:application/pdf},
}

@inproceedings{barthe_secure_2018,
	location = {Oxford},
	title = {Secure Compilation of Side-Channel Countermeasures: The Case of Cryptographic “Constant-Time”},
	isbn = {978-1-5386-6680-7},
	url = {https://ieeexplore.ieee.org/document/8429315/},
	doi = {10.1109/CSF.2018.00031},
	shorttitle = {Secure Compilation of Side-Channel Countermeasures},
	eventtitle = {2018 {IEEE} 31st Computer Security Foundations Symposium ({CSF})},
	pages = {328--343},
	booktitle = {2018 {IEEE} 31st Computer Security Foundations Symposium ({CSF})},
	publisher = {{IEEE}},
	author = {Barthe, Gilles and Gregoire, Benjamin and Laporte, Vincent},
	urldate = {2021-02-17},
	date = {2018-07},
	file = {Full Text:/home/fordrl/Zotero/storage/5WEX9YJ4/Barthe et al. - 2018 - Secure Compilation of Side-Channel Countermeasures.pdf:application/pdf},
}

@article{alpern_defining_1985,
	title = {Defining liveness},
	volume = {21},
	issn = {00200190},
	url = {https://linkinghub.elsevier.com/retrieve/pii/0020019085900560},
	doi = {10.1016/0020-0190(85)90056-0},
	pages = {181--185},
	number = {4},
	journaltitle = {Information Processing Letters},
	shortjournal = {Information Processing Letters},
	author = {Alpern, Bowen and Schneider, Fred B.},
	urldate = {2021-02-17},
	date = {1985-10},
	langid = {english},
}

@article{abadi_secure_2002,
	title = {Secure Implementation of Channel Abstractions},
	volume = {174},
	issn = {08905401},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0890540102930865},
	doi = {10.1006/inco.2002.3086},
	pages = {37--83},
	number = {1},
	journaltitle = {Information and Computation},
	shortjournal = {Information and Computation},
	author = {Abadi, Martı́n and Fournet, Cédric and Gonthier, Georges},
	urldate = {2021-02-17},
	date = {2002-04},
	langid = {english},
	file = {Submitted Version:/home/fordrl/Zotero/storage/J9MWNCZK/Abadi et al. - 2002 - Secure Implementation of Channel Abstractions.pdf:application/pdf},
}

@inproceedings{bugliesi_secure_2007,
	location = {Nice, France},
	title = {Secure implementations of typed channel abstractions},
	isbn = {978-1-59593-575-5},
	url = {http://portal.acm.org/citation.cfm?doid=1190216.1190253},
	doi = {10.1145/1190216.1190253},
	eventtitle = {the 34th annual {ACM} {SIGPLAN}-{SIGACT} symposium},
	pages = {251},
	booktitle = {Proceedings of the 34th annual {ACM} {SIGPLAN}-{SIGACT} symposium on Principles of programming languages  - {POPL} '07},
	publisher = {{ACM} Press},
	author = {Bugliesi, Michele and Giunti, Marco},
	urldate = {2021-02-17},
	date = {2007},
	langid = {english},
}

@article{abadi_secrecy_1999,
	title = {Secrecy by typing in security protocols},
	volume = {46},
	issn = {0004-5411, 1557-735X},
	url = {https://dl.acm.org/doi/10.1145/324133.324266},
	doi = {10.1145/324133.324266},
	pages = {749--786},
	number = {5},
	journaltitle = {Journal of the {ACM}},
	shortjournal = {J. {ACM}},
	author = {Abadi, Martín},
	urldate = {2021-02-17},
	date = {1999-09},
	langid = {english},
}

@article{patrignani_robustly_2021,
	title = {Robustly Safe Compilation, an Efficient Form of Secure Compilation},
	volume = {43},
	issn = {0164-0925, 1558-4593},
	url = {https://dl.acm.org/doi/10.1145/3436809},
	doi = {10.1145/3436809},
	abstract = {Security-preserving compilers generate compiled code that withstands target-level attacks such as alteration of control flow, data leaks, or memory corruption. Many existing security-preserving compilers are proven to be fully abstract, meaning that they reflect and preserve observational equivalence. Fully abstract compilation is strong and useful but, in certain cases, comes at the cost of requiring expensive runtime constructs in compiled code. These constructs may have no relevance for security, but are needed to accommodate differences between the source and target languages that fully abstract compilation necessarily needs.
            
              As an alternative to fully abstract compilation, this article explores a different criterion for secure compilation called robustly safe compilation or
              {RSC}
              . Briefly, this criterion means that the compiled code preserves relevant safety properties of the source program against all adversarial contexts interacting with the compiled program. We show that
              {RSC}
              can be proved more easily than fully abstract compilation and also often results in more efficient code. We also present two different proof techniques for establishing that a compiler attains
              {RSC}
              and, to illustrate them, develop three illustrative robustly safe compilers that rely on different target-level protection mechanisms. We then proceed to turn one of our compilers into a fully abstract one and through this example argue that proving
              {RSC}
              can be simpler than proving full abstraction.
            
            
              To better explain and clarify notions, this article uses syntax highlighting in a way that colourblind and black-8-white readers can benefit from Reference [58]. For a better experience, please print or view this article in colour
              .
              1},
	pages = {1--41},
	number = {1},
	journaltitle = {{ACM} Transactions on Programming Languages and Systems},
	shortjournal = {{ACM} Trans. Program. Lang. Syst.},
	author = {Patrignani, Marco and Garg, Deepak},
	urldate = {2021-02-17},
	date = {2021-02},
	langid = {english},
	file = {Full Text:/home/fordrl/Zotero/storage/L6WEN5DW/Patrignani and Garg - 2021 - Robustly Safe Compilation, an Efficient Form of Se.pdf:application/pdf},
}

@thesis{habib_learning_2021,
	location = {Darmstadt},
	title = {Learning to Find Bugs in Programs and their Documentation},
	rights = {{CC}-{BY}-{SA} 4.0 International - Creative Commons, Attribution Share-alike},
	url = {https://tuprints.ulb.tu-darmstadt.de/17377/},
	abstract = {Although software is pervasive, almost all programs suffer from bugs and errors. To detect software bugs, developers use various techniques such as static analysis, dynamic analysis, and model checking. However, none of these techniques is bulletproof.

This dissertation argues that learning from programs and their documentation provides an effective means to prevent and detect software bugs. The main observation that motivates our work is that software documentation is often under-utilized by traditional bug detection techniques. Leveraging the documentation together with the program itself, whether its source code or runtime behavior, enables us to build unconventional bug detectors that benefit from the richness of natural language documentation and the formal algorithm of a program. More concretely, we present techniques that utilize the documentation of a program and the program itself to: (i) Improve the documentation by inferring missing information and detecting inconsistencies, and (ii) Find bugs in the source code or runtime behavior of the program. A key insight we build on is that machine learning provides a powerful means to deal with the fuzziness and nuances of natural language in software documentation and that source code is repetitive enough to also allow statistical learning from it. Therefore, several of the techniques proposed in this dissertation employ a learning component whether from documentation, source code, runtime behavior, and their combinations.

We envision the impact of our work to be two-fold. First, we provide developers with novel bug detection techniques that complement traditional ones. Our approaches learn bug detectors end-to-end from data and hence, do not require complex analysis frameworks. Second, we hope that our work will open the door for more research on automatically utilizing natural language in software development. Future work should explore more ideas on how to extract richer information from natural language to automate software engineering tasks, and how to utilize the programs themselves to enhance the state-of-the-practice in software documentation.},
	institution = {Technische Universität},
	type = {phdthesis},
	author = {Habib, Andrew},
	urldate = {2021-02-17},
	date = {2021},
	langid = {english},
	doi = {10.26083/tuprints-00017377},
	file = {Snapshot:/home/fordrl/Zotero/storage/ZSZ4JGDX/17377.html:text/html;Full Text PDF:/home/fordrl/Zotero/storage/C74JSEL3/Habib - 2021 - Learning to Find Bugs in Programs and their Docume.pdf:application/pdf},
}

@article{anderson_comparison_2020,
	title = {A Comparison of Fuzzing Dynamic Analysis and Static Code Analysis},
	pages = {13},
	author = {Anderson, Sean and Hood, Jonathan and Jones, Erica},
	date = {2020-11-16},
	langid = {english},
	file = {A Comparison of Fuzzing Dynamic Analysis and Stati.pdf:/home/fordrl/Zotero/storage/9U7GVJN7/A Comparison of Fuzzing Dynamic Analysis and Stati.pdf:application/pdf},
}

@inproceedings{dsilva_correctness-security_2015,
	title = {The Correctness-Security Gap in Compiler Optimization},
	doi = {10.1109/SPW.2015.33},
	abstract = {There is a significant body of work devoted to testing, verifying, and certifying the correctness of optimizing compilers. The focus of such work is to determine if source code and optimized code have the same functional semantics. In this paper, we introduce the correctness-security gap, which arises when a compiler optimization preserves the functionality of but violates a security guarantee made by source code. We show with concrete code examples that several standard optimizations, which have been formally proved correct, in-habit this correctness-security gap. We analyze this gap and conclude that it arises due to techniques that model the state of the program but not the state of the underlying machine. We propose a broad research programme whose goal is to identify, understand, and mitigate the impact of security errors introduced by compiler optimizations. Our proposal includes research in testing, program analysis, theorem proving, and the development of new, accurate machine models for reasoning about the impact of compiler optimizations on security.},
	eventtitle = {2015 {IEEE} Security and Privacy Workshops},
	pages = {73--87},
	booktitle = {2015 {IEEE} Security and Privacy Workshops},
	author = {D'Silva, V. and Payer, M. and Song, D.},
	date = {2015-05},
	keywords = {Optimization, Semantics, compiler optimization, correctness certification, correctness testing, correctness verification, correctness-security gap, Cryptography, formal correctness, functional semantics, machine model, optimising compilers, optimized code, optimizing compiler, Optimizing compilers, program analysis, program diagnostics, program state, program testing, reasoning, reasoning about programs, security, security error, security guarantee, security of data, source code, Standards, Syntactics, theorem proving},
	file = {IEEE Xplore Abstract Record:/home/fordrl/Zotero/storage/6HHJWZMH/7163211.html:text/html;Submitted Version:/home/fordrl/Zotero/storage/DLA9HJ9G/D'Silva et al. - 2015 - The Correctness-Security Gap in Compiler Optimizat.pdf:application/pdf},
}

@article{van_schaik_sgaxe_nodate,
	title = {{SGAxe}: How {SGX} Fails in Practice},
	abstract = {Intel’s Software Guard Extensions ({SGX}) promises an isolated execution environment, protected from all software running on the machine. A signiﬁcant limitation of {SGX} is its lack of protection against side-channel attacks. In particular, recent works have shown that transient-execution attacks can leak arbitrary data from {SGX}, breaching {SGX}’s conﬁdentiality. However, less work has been done on the implications of such attacks on the {SGX} ecosystems.},
	pages = {14},
	author = {van Schaik, Stephan and Kwong, Andrew and Genkin, Daniel and Yarom, Yuval},
	langid = {english},
	file = {van Schaik et al. - SGAxe How SGX Fails in Practice.pdf:/home/fordrl/Zotero/storage/FESLI3G5/van Schaik et al. - SGAxe How SGX Fails in Practice.pdf:application/pdf},
}

@article{schwarz_improving_2021,
	title = {Improving Thread-Modular Abstract Interpretation},
	url = {http://arxiv.org/abs/2108.07613},
	abstract = {We give thread-modular non-relational value analyses as abstractions of a local trace semantics. The semantics as well as the analyses are formulated by means of global invariants and side-effecting constraint systems. We show that a generalization of the analysis provided by the static analyzer Goblint as well as a natural improvement of Antoine Min{\textbackslash}'e's approach can be obtained as instances of this general scheme. We show that these two analyses are incomparable w.r.t. precision and provide a refinement which improves on both precision-wise. We also report on a preliminary experimental comparison of the given analyses on a meaningful suite of benchmarks.},
	journaltitle = {{arXiv}:2108.07613 [cs]},
	author = {Schwarz, Michael and Saan, Simmo and Seidl, Helmut and Apinis, Kalmer and Erhard, Julian and Vojdani, Vesal},
	urldate = {2021-08-26},
	date = {2021-08-17},
	eprinttype = {arxiv},
	eprint = {2108.07613},
	keywords = {Computer Science - Programming Languages},
	file = {arXiv.org Snapshot:/home/fordrl/Zotero/storage/FR2MC5N9/2108.html:text/html;arXiv Fulltext PDF:/home/fordrl/Zotero/storage/F9S7KNNE/Schwarz et al. - 2021 - Improving Thread-Modular Abstract Interpretation.pdf:application/pdf},
}

@inproceedings{singh_multi-view_2021,
	location = {New York, {NY}, {USA}},
	title = {Multi-View Learning for Repackaged Malware Detection},
	isbn = {978-1-4503-9051-4},
	url = {https://doi.org/10.1145/3465481.3470040},
	doi = {10.1145/3465481.3470040},
	series = {{ARES} 2021},
	abstract = {Repackaging refers to the core process of unpacking a software package, then repackaging it after a probable modification to the decompiled code and/or to other resource files. In the case of repackaged malware, benign apps are injected with a malicious payload. Repackaged malware pose a serious threat to the Android ecosystem. Moreover, repackaged malware and benign apps share more than 80\% of their features, which makes detection a challenging problem. This paper presents a novel technique based on multi-view learning to address this challenge of detecting repackaged malware. Multi-View Learning is a technique where data from multiple distinct feature groups, referred to as views, are fused to improve the model’s generalization performance. In the context of Android, we define views as different components of the app, such as permissions, {APIs}, sensor usage, etc. We analyzed 15,297 repackaged app pairs and extracted seven different views to represent an app. We perform an ablation study to identify which view(s) contribute more to the classification. The model was trained end-to-end to jointly learn appropriate features and to perform the classification. We show that our approach achieves accuracy and an F1-score of 97.46\% and 0.98, respectively.},
	pages = {1--9},
	booktitle = {The 16th International Conference on Availability, Reliability and Security},
	publisher = {Association for Computing Machinery},
	author = {Singh, Shirish and Chaturvedy, Kushagra and Mishra, Bharavi},
	urldate = {2021-08-26},
	date = {2021-08-17},
	keywords = {Malware detection, Mobile apps, Multi-view learning, Repackaged malware},
	file = {Full Text PDF:/home/fordrl/Zotero/storage/BQ2P8E2I/Singh et al. - 2021 - Multi-View Learning for Repackaged Malware Detecti.pdf:application/pdf},
}

@inproceedings{yu_detecting_2021,
	location = {New York, {NY}, {USA}},
	title = {Detecting concurrency vulnerabilities based on partial orders of memory and thread events},
	isbn = {978-1-4503-8562-6},
	url = {https://doi.org/10.1145/3468264.3468572},
	doi = {10.1145/3468264.3468572},
	series = {{ESEC}/{FSE} 2021},
	abstract = {Memory vulnerabilities are the main causes of software security problems. However, detecting vulnerabilities in multi-threaded programs is challenging because many vulnerabilities occur under specific executions, and it is hard to explore all possible executions of a multi-threaded program. Existing approaches are either computationally intensive or likely to miss some vulnerabilities due to the complex thread interleaving. This paper introduces a novel approach to detect concurrency memory vulnerabilities based on partial orders of events. A partial order on a set of events represents the definite execution orders of events. It allows constructing feasible traces exposing specific vulnerabilities by exchanging the execution orders of vulnerability-potential events. It also reduces the search space of possible executions and thus improves computational efficiency. We propose new algorithms to extract vulnerability-potential event pairs for three kinds of memory vulnerabilities. We also design a novel algorithm to compute a potential event pair's feasible set, which contains the relevant events required by a feasible trace. Our method extends existing approaches for data race detection by considering that two events are protected by the same lock. We implement a prototype of our approach and conduct experiments to evaluate its performance. Experimental results show that our tool exhibits superiority over state-of-the-art algorithms in both effectiveness and efficiency.},
	pages = {280--291},
	booktitle = {Proceedings of the 29th {ACM} Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
	publisher = {Association for Computing Machinery},
	author = {Yu, Kunpeng and Wang, Chenxu and Cai, Yan and Luo, Xiapu and Yang, Zijiang},
	urldate = {2021-08-26},
	date = {2021-08-20},
	keywords = {concurrency vulnerability, multi-threaded programs, partial orders},
	file = {Full Text PDF:/home/fordrl/Zotero/storage/HTZ6IPJP/Yu et al. - 2021 - Detecting concurrency vulnerabilities based on par.pdf:application/pdf},
}

@inproceedings{cai_sound_2021,
	location = {New York, {NY}, {USA}},
	title = {Sound and efficient concurrency bug prediction},
	isbn = {978-1-4503-8562-6},
	url = {https://doi.org/10.1145/3468264.3468549},
	doi = {10.1145/3468264.3468549},
	series = {{ESEC}/{FSE} 2021},
	abstract = {Concurrency bugs are extremely difficult to detect. Recently, several dynamic techniques achieve sound analysis. M2 is even complete for two threads. It is designed to decide whether two events can occur consecutively. However, real-world concurrency bugs can involve more events and threads. Some can occur when the order of two or more events can be exchanged even if they occur not consecutively. We propose a new technique {SeqCheck} to soundly decide whether a sequence of events can occur in a specified order. The ordered sequence represents a potential concurrency bug. And several known forms of concurrency bugs can be easily encoded into event sequences where each represents a way that the bug can occur. To achieve it, {SeqCheck} explicitly analyzes branch events and includes a set of efficient algorithms. We show that {SeqCheck} is sound; and it is also complete on traces of two threads. We have implemented {SeqCheck} to detect three types of concurrency bugs and evaluated it on 51 Java benchmarks producing up to billions of events. Compared with M2 and other three recent sound race detectors, {SeqCheck} detected 333 races in {\textasciitilde}30 minutes; while others detected from 130 to 285 races in {\textasciitilde}6 to {\textasciitilde}12 hours. {SeqCheck} detected 20 deadlocks in {\textasciitilde}6 seconds. This is only one less than Dirk; but Dirk spent more than one hour. {SeqCheck} also detected 30 atomicity violations in {\textasciitilde}20 minutes. The evaluation shows {SeqCheck} can significantly outperform existing concurrency bug detectors.},
	pages = {255--267},
	booktitle = {Proceedings of the 29th {ACM} Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
	publisher = {Association for Computing Machinery},
	author = {Cai, Yan and Yun, Hao and Wang, Jinqiu and Qiao, Lei and Palsberg, Jens},
	urldate = {2021-08-26},
	date = {2021-08-20},
	keywords = {atomicity violations, Concurrency bugs, data races, deadlocks},
	file = {Full Text PDF:/home/fordrl/Zotero/storage/3HPYZJ8Z/Cai et al. - 2021 - Sound and efficient concurrency bug prediction.pdf:application/pdf},
}

@article{han_precise_2021,
	title = {Precise and Scalable Detection of Use-after-Compacting-Garbage-Collection Bugs},
	abstract = {Compacting garbage collection (compact-gc) is a method that improves memory utilization and reduces memory fragmentation by rearranging live objects and updating their references using an address table. A critical use-after-free bug may exist if an object reference that is not registered in the address table is used after compact-gc, as the live object may be moved but the reference will not be updated after compact-gc. We refer to this as a use-after-compact-gc (use-after-cgc) bug. Prior tools have attempted to statically detect these bugs with targetspeciﬁc heuristics. However, due to their path-insensitive analysis and imprecise target-speciﬁc heuristics, they have high false-positives and false-negatives. In this paper, we present a precise and scalable static analyzer, named {CGSan}, for ﬁnding use-after-cgc bugs. {CGSan} detects use-after-cgc bug candidates by intra-procedural static symbolic taint analysis and checks their feasibility by underconstrained directed symbolic execution. To mitigate the incompleteness of intra-procedural analysis, we employ a typebased taint policy. For scalability, we propose using directed inter-procedural control-ﬂow graphs, which reduce search spaces by excluding paths irrelevant to checking feasibility, and directed scheduling, which prioritizes paths to quickly check feasibility. We evaluated {CGSan} on Google V8 and Mozilla {SpiderMonkey}, and we found 13 unique use-after-cgc bugs with only 2 false-positives while two prior tools missed 10 bugs and had 34 false-positives in total.},
	pages = {17},
	journaltitle = {Proceeding of 30th {USENIX} Security Symposium},
	author = {Han, {HyungSeok} and Wesie, Andrew and Pak, Brian},
	date = {2021-08-11},
	langid = {english},
	file = {Han et al. - Precise and Scalable Detection of Use-after-Compac.pdf:/home/fordrl/Zotero/storage/QUJ44WV5/Han et al. - Precise and Scalable Detection of Use-after-Compac.pdf:application/pdf},
}

@article{disselkoen_finding_nodate,
	title = {Finding and Eliminating Timing Side-Channels in Crypto Code with Pitchfork},
	abstract = {We present Pitchfork, a symbolic analysis tool which veriﬁes that code is constant-time and does not leak secret values. Writing constant-time code is the de-facto defense against timing side-channel attacks, used today by many major cryptographic libraries. Unfortunately, writing constant-time code is notoriously difﬁcult. Even experts have repeatedly written buggy code and overlooked critical vulnerabilities in widely used cryptographic libraries. To address these issues, Pitchfork veriﬁes that code is constant-time. In particular, we used Pitchfork to verify that a large portion of Mozilla’s {NSS} cryptographic library is constant-time, while also ﬁnding several constant-time vulnerabilities, including a critical vulnerability which was assigned {CVE}-2019-11745.},
	pages = {8},
	author = {Disselkoen, Craig and Cauligi, Sunjay and Tullsen, Dean and Stefan, Deian},
	langid = {english},
	file = {Disselkoen et al. - Finding and Eliminating Timing Side-Channels in Cr.pdf:/home/fordrl/Zotero/storage/U56J8C65/Disselkoen et al. - Finding and Eliminating Timing Side-Channels in Cr.pdf:application/pdf},
}

@inproceedings{myreen_minimalistic_2021,
	location = {Virtual Denmark},
	title = {A minimalistic verified bootstrapped compiler (proof pearl)},
	isbn = {978-1-4503-8299-1},
	url = {https://dl.acm.org/doi/10.1145/3437992.3439915},
	doi = {10.1145/3437992.3439915},
	abstract = {This paper shows how a small verified bootstrapped compiler can be developed inside an interactive theorem prover ({ITP}). Throughout, emphasis is put on clarity and minimalism.},
	eventtitle = {{CPP} '21: 10th {ACM} {SIGPLAN} International Conference on Certified Programs and Proofs},
	pages = {32--45},
	booktitle = {Proceedings of the 10th {ACM} {SIGPLAN} International Conference on Certified Programs and Proofs},
	publisher = {{ACM}},
	author = {Myreen, Magnus O.},
	urldate = {2021-08-17},
	date = {2021-01-17},
	langid = {english},
	file = {Myreen - 2021 - A minimalistic verified bootstrapped compiler (pro.pdf:/home/fordrl/Zotero/storage/GYMMVP8C/Myreen - 2021 - A minimalistic verified bootstrapped compiler (pro.pdf:application/pdf},
}

@article{li_towards_2021,
	title = {Towards Making Deep Learning-based Vulnerability Detectors Robust},
	url = {http://arxiv.org/abs/2108.00669},
	abstract = {Automatically detecting software vulnerabilities in source code is an important problem that has attracted much attention. In particular, deep learning-based vulnerability detectors, or {DL}-based detectors, are attractive because they do not need human experts to define features or patterns of vulnerabilities. However, such detectors' robustness is unclear. In this paper, we initiate the study in this aspect by demonstrating that {DL}-based detectors are not robust against simple code transformations, dubbed attacks in this paper, as these transformations may be leveraged for malicious purposes. As a first step towards making {DL}-based detectors robust against such attacks, we propose an innovative framework, dubbed {ZigZag}, which is centered at (i) decoupling feature learning and classifier learning and (ii) using a {ZigZag}-style strategy to iteratively refine them until they converge to robust features and robust classifiers. Experimental results show that the {ZigZag} framework can substantially improve the robustness of {DL}-based detectors.},
	journaltitle = {{arXiv}:2108.00669 [cs]},
	author = {Li, Zhen and Tang, Jing and Zou, Deqing and Chen, Qian and Xu, Shouhuai and Zhang, Chao and Li, Yichen and Jin, Hai},
	urldate = {2021-08-09},
	date = {2021-08-04},
	eprinttype = {arxiv},
	eprint = {2108.00669},
	keywords = {Computer Science - Cryptography and Security, Computer Science - Machine Learning},
	file = {arXiv.org Snapshot:/home/fordrl/Zotero/storage/SLEHZS4G/2108.html:text/html;arXiv Fulltext PDF:/home/fordrl/Zotero/storage/LCYPG6DX/Li et al. - 2021 - Towards Making Deep Learning-based Vulnerability D.pdf:application/pdf},
}

@article{strydonck_proving_nodate,
	title = {Proving full-system security properties under multiple attacker models on capability machines},
	abstract = {Assembly-level protection mechanisms (virtual memory, trusted execution environments, virtualization) make it possible to guarantee security properties of a full system in the presence of arbitrary attacker provided code. However, they typically only support a single trust boundary: code is either trusted or untrusted, and protection cannot be nested. Capability machines provide protection mechanisms that are more ﬁnegrained and that do support arbitrary nesting of protection. We show in this paper how this enables the formal veriﬁcation of fullsystem security properties under multiple attacker models: different security objectives of the full system can be veriﬁed under a different choice of trust boundary (i.e. under a different attacker model). The veriﬁcation approach we propose is modular, and is robust: code outside the trust boundary for a given security objective can be arbitrary, unveriﬁed attacker-provided code. It is based on the use of universal contracts for untrusted adversarial code: sound, conservative contracts which can be combined with manual veriﬁcation of trusted components in a compositional program logic. Compositionality of the program logic also allows us to reuse common parts in the analyses for different attacker models. We instantiate the approach concretely by extending an existing capability machine model with support for memorymapped I/O and we obtain full system, machine-veriﬁed security properties about external effect traces while limiting the manual veriﬁcation effort to a small trusted computing base relevant for the speciﬁc property under study.},
	pages = {16},
	author = {Strydonck, Thomas Van and Leuven, {KU} and Georges, Aına Linn and Gueneau, Armael and Trieu, Alix},
	langid = {english},
	file = {Strydonck et al. - Proving full-system security properties under mult.pdf:/home/fordrl/Zotero/storage/8PUVKHAD/Strydonck et al. - Proving full-system security properties under mult.pdf:application/pdf},
}

@thesis{jourdan_verasco_2016,
	location = {Paris, France},
	title = {Verasco: a Formally Verified C Static Analyzer},
	url = {https://jhjourdan.mketjh.fr/thesis_jhjourdan.pdf},
	abstract = {In order to develop safer software for critical applications, some static analyzers aim at establishing, with mathematical certitude, the absence of some classes of bug in the input program. A possible limit to this approach is the possibility of a soundness bug in the static analyzer itself, which would nullify the guarantees it is supposed to deliver.},
	pagetotal = {240},
	institution = {L’université Paris Diderot (Paris 7) Sorbonne Paris Cité},
	type = {phdthesis},
	author = {Jourdan, Jacques-Henri},
	date = {2016-05-26},
	langid = {french},
	file = {Jourdan - Verasco a Formally Verified C Static Analyzer.pdf:/home/fordrl/Zotero/storage/BT8X3H4Q/Jourdan - Verasco a Formally Verified C Static Analyzer.pdf:application/pdf},
}

@article{marty_lio_2020,
	title = {{LIO}*: Low Level Information Flow Control in F*},
	url = {http://arxiv.org/abs/2004.12885},
	shorttitle = {{LIO}*},
	abstract = {We present Labeled Input Output in F* ({LIO}*), a verified framework that enforces information flow control ({IFC}) policies developed in F* and automatically extracted to C. Inspired by {LIO}, we encapsulated {IFC} policies into effects, but using F* we derived efficient, low level, and provably correct code. Concretely, runtime checks are lifted to static proof obligations, the developed code is automatically extracted to C and proved non-interferent using metaprogramming. We benchmarked our framework on three clients and observed up to 54\% speedup when {IFC} runtime checks are proved statically. Our framework is designed to aid development of embedded devices where both enforcement of security policies and low level efficient code is critical.},
	journaltitle = {{arXiv}:2004.12885 [cs]},
	author = {Marty, Jean-Joseph and Franceschino, Lucas and Talpin, Jean-Pierre and Vazou, Niki},
	urldate = {2021-07-29},
	date = {2020-04-27},
	eprinttype = {arxiv},
	eprint = {2004.12885},
	keywords = {Computer Science - Cryptography and Security, Computer Science - Programming Languages},
	file = {arXiv.org Snapshot:/home/fordrl/Zotero/storage/EC6GFGFA/2004.html:text/html;arXiv Fulltext PDF:/home/fordrl/Zotero/storage/PEVL5KFK/Marty et al. - 2020 - LIO Low Level Information Flow Control in F.pdf:application/pdf},
}

@article{lu_eagle_2021,
	title = {Eagle: {CFL}-Reachability-Based Precision-Preserving Acceleration of Object-Sensitive Pointer Analysis with Partial Context Sensitivity},
	volume = {30},
	issn = {1049-331X},
	url = {https://doi.org/10.1145/3450492},
	doi = {10.1145/3450492},
	shorttitle = {Eagle},
	abstract = {Object sensitivity is widely used as a context abstraction for computing the points-to information context-sensitively for object-oriented programming languages such as Java. Due to the combinatorial explosion of contexts in large object-oriented programs, k-object-sensitive pointer analysis (under k-limiting), denoted k-obj, is often inefficient even when it is scalable for small values of k, where k ⩽ 2 holds typically. A recent popular approach for accelerating k-obj trades precision for efficiency by instructing k-obj to analyze only some methods in a program context-sensitively, determined heuristically by a pre-analysis. In this article, we investigate how to develop a fundamentally different approach, Eagle, for designing a pre-analysis that can make k-obj run significantly faster while maintaining its precision. The novelty of Eagle is to enable k-obj to analyze a method with partial context sensitivity (i.e., context-sensitively for only some of its selected variables/allocation sites) by solving a context-free-language ({CFL}) reachability problem based on a new {CFL}-reachability formulation of k-obj. By regularizing one {CFL} for specifying field accesses and using another {CFL} for specifying method calls, we have formulated Eagle as a fully context-sensitive taint analysis (without k-limiting) that is both effective (by selecting the variables/allocation sites to be analyzed by k-obj context-insensitively so as to reduce the number of context-sensitive facts inferred by k-obj in the program) and efficient (by running linearly in terms of the number of pointer assignment edges in the program). As Eagle represents the first precision-preserving pre-analysis, our evaluation focuses on demonstrating its significant performance benefits in accelerating k-obj for a set of popular Java benchmarks and applications, with call graph construction, may-fail-casting, and polymorphic call detection as three important client analyses.},
	pages = {46:1--46:46},
	number = {4},
	journaltitle = {{ACM} Transactions on Software Engineering and Methodology},
	shortjournal = {{ACM} Trans. Softw. Eng. Methodol.},
	author = {Lu, Jingbo and He, Dongjie and Xue, Jingling},
	urldate = {2021-07-27},
	date = {2021-07-23},
	keywords = {{CFL}-reachability, object sensitivity, Pointer analysis},
	file = {Full Text PDF:/home/fordrl/Zotero/storage/8FFZP93L/Lu et al. - 2021 - Eagle CFL-Reachability-Based Precision-Preserving.pdf:application/pdf},
}

@article{murray_incremental_2021,
	title = {Incremental Vulnerability Detection via Back-Propagating Symbolic Execution of Insecurity Separation Logic},
	url = {http://arxiv.org/abs/2107.05225},
	abstract = {We present the first compositional, incremental static analysis for detecting memory-safety and information leakage vulnerabilities in C-like programs. To do so, we develop the first under-approximate relational program logics, including Insecurity Separation Logic ({InsecSL}). We show how {InsecSL} can be automated via back-propagating symbolic execution ({BPSE}) to build a bottom-up, inter-procedural and incremental analysis for detecting vulnerabilities. We prove our approach sound in Isabelle/{HOL} and implement it in a proof-of-concept tool, Underflow, for analysing C programs, which we apply to various case studies.},
	journaltitle = {{arXiv}:2107.05225 [cs]},
	author = {Murray, Toby and Yan, Pengbo and Ernst, Gidon},
	urldate = {2021-07-20},
	date = {2021-07-12},
	eprinttype = {arxiv},
	eprint = {2107.05225},
	keywords = {Computer Science - Cryptography and Security, Computer Science - Programming Languages, Computer Science - Logic in Computer Science},
	file = {arXiv.org Snapshot:/home/fordrl/Zotero/storage/PFQ3WLAP/2107.html:text/html;arXiv Fulltext PDF:/home/fordrl/Zotero/storage/CVLN4BMY/Murray et al. - 2021 - Incremental Vulnerability Detection via Back-Propa.pdf:application/pdf},
}

@article{fei_security_2021,
	title = {Security Vulnerabilities of {SGX} and Countermeasures: A Survey},
	volume = {54},
	issn = {0360-0300},
	url = {https://doi.org/10.1145/3456631},
	doi = {10.1145/3456631},
	shorttitle = {Security Vulnerabilities of {SGX} and Countermeasures},
	abstract = {Trusted Execution Environments ({TEEs}) have been widely used in many security-critical applications. The popularity of {TEEs} derives from its high security and trustworthiness supported by secure hardware. Intel Software Guard Extensions ({SGX}) is one of the most representative {TEEs} that creates an isolated environment on an untrusted operating system, thus providing run-time protection for the execution of security-critical code and data. However, Intel {SGX} is far from the acme of perfection. It has become a target of various attacks due to its security vulnerabilities. Researchers and practitioners have paid attention to the security vulnerabilities of {SGX} and investigated optimization solutions in real applications. Unfortunately, existing literature lacks a thorough review of security vulnerabilities of {SGX} and their countermeasures. In this article, we fill this gap. Specifically, we propose two sets of criteria for estimating security risks of existing attacks and evaluating defense effects brought by attack countermeasures. Furthermore, we propose a taxonomy of {SGX} security vulnerabilities and shed light on corresponding attack vectors. After that, we review published attacks and existing countermeasures, as well as evaluate them by employing our proposed criteria. At last, on the strength of our survey, we propose some open challenges and future directions in the research of {SGX} security.},
	pages = {126:1--126:36},
	number = {6},
	journaltitle = {{ACM} Computing Surveys},
	shortjournal = {{ACM} Comput. Surv.},
	author = {Fei, Shufan and Yan, Zheng and Ding, Wenxiu and Xie, Haomeng},
	urldate = {2021-07-20},
	date = {2021-07-13},
	keywords = {security, side-channel attacks, Trusted execution environment, trustworthiness},
	file = {Full Text PDF:/home/fordrl/Zotero/storage/QG3Z9V39/Fei et al. - 2021 - Security Vulnerabilities of SGX and Countermeasure.pdf:application/pdf},
}

@article{zhang_checking_2021,
	title = {Checking Conformance of Applications against {GUI} Policies},
	abstract = {A good graphical user interface ({GUI}) is crucial for an application’s usability, so vendors and regulatory agencies increasingly place restrictions on how {GUI} elements should appear to and interact with users. Motivated by this concern, this paper presents a new technique (based on static analysis) for checking conformance between (Android) applications and {GUI} g expressed in a formal specification language. In particular, this paper (1) describes a specification language for formalizing {GUI} policies, (2) proposes a new program abstraction called an event-driven layout forest, and (3) describes a static analysis for constructing this abstraction and checking it against a {GUI} policy. We have implemented the proposed approach in a tool called Venus, and we evaluate it on 2361 Android applications and 17 policies. Our evaluation shows that Venus can uncover malicious applications that perform ad fraud and identify violations of {GUI} design guidelines and {GDPR} laws.},
	pages = {12},
	author = {Zhang, Zhen and Feng, Yu and Ernst, Michael D and Porst, Sebastian and Dillig, Isil},
	date = {2021},
	langid = {english},
	file = {Zhang et al. - 2021 - Checking Conformance of Applications against GUI P.pdf:/home/fordrl/Zotero/storage/6CX88I44/Zhang et al. - 2021 - Checking Conformance of Applications against GUI P.pdf:application/pdf},
}

@inproceedings{straub_use_2020,
	title = {The Use of Runtime Verification for Identifying and Responding to Cybersecurity Threats Posed to State Actors During Cyberwarfare},
	doi = {10.1109/CSCI51800.2020.00021},
	abstract = {This paper considers the utility of the use of runtime verification techniques for detecting and responding to cybersecurity threats. To this end, it considers two questions: First, it evaluates the efficacy of runtime verification for identifying zero-day threats and threats that are not otherwise widely known based up system operations. Second, it considers the particular use of these techniques by state actors (i.e., nation states engaged in declared or undeclared cyberwarfare) who are likely to encounter a greater level of such vulnerability exploits than individuals or private businesses during the normal operations. Drawing on the analysis in the two foregoing areas, the paper concludes by identifying key areas of needed future work to support runtime verification's application in this area.},
	eventtitle = {2020 International Conference on Computational Science and Computational Intelligence ({CSCI})},
	pages = {83--87},
	booktitle = {2020 International Conference on Computational Science and Computational Intelligence ({CSCI})},
	author = {Straub, Jeremy},
	date = {2020-12},
	keywords = {Runtime, Business, Computational intelligence, Cyber warfare, cyberattacks, cybersecurity, cyberwarfare, runtime verification, Scientific computing, Systems operation, threats},
}

@article{hublet_databank_2021,
	title = {The Databank Model},
	rights = {http://rightsstatements.org/page/{InC}-{NC}/1.0/, info:eu-repo/semantics/{openAccess}},
	url = {http://hdl.handle.net/20.500.11850/477329},
	doi = {10.3929/ETHZ-B-000477329},
	pages = {212 p.},
	author = {Hublet, François},
	editora = {Basin, David and Krstić, Srđan},
	editoratype = {collaborator},
	urldate = {2021-04-20},
	date = {2021},
	langid = {english},
	note = {Artwork Size: 212 p.
Medium: application/pdf
Publisher: {ETH} Zurich},
	file = {Hublet - 2021 - The Databank Model.pdf:/home/fordrl/Zotero/storage/YYBDD75H/Hublet - 2021 - The Databank Model.pdf:application/pdf},
}

@article{cecchetti_compositional_nodate,
	title = {Compositional Security for Reentrant Applications (Technical Report)},
	abstract = {The disastrous vulnerabilities in smart contracts sharply remind us of our ignorance: we do not know how to write code that is secure in composition with malicious code. Information ﬂow control has long been proposed as a way to achieve compositional security, offering strong guarantees even when combining software from different trust domains. Unfortunately, this appealing story breaks down in the presence of reentrancy attacks. We formalize a general deﬁnition of reentrancy and introduce a security condition that allows software modules like smart contracts to protect their key invariants while retaining the expressive power of safe forms of reentrancy. We present a security type system that provably enforces secure information ﬂow; in conjunction with run-time mechanisms, it enforces secure reentrancy even in the presence of unknown code; and it helps locate and correct recent high-proﬁle vulnerabilities.},
	pages = {56},
	author = {Cecchetti, Ethan and Yao, Siqiu and Ni, Haobin and Myers, Andrew C},
	langid = {english},
	file = {Cecchetti et al. - Compositional Security for Reentrant Applications .pdf:/home/fordrl/Zotero/storage/8YSI956X/Cecchetti et al. - Compositional Security for Reentrant Applications .pdf:application/pdf},
}

@article{wang_bci-cfi_2021,
	title = {{BCI}-{CFI}: A Context-Sensitive Control-Flow Integrity Method Based on Branch Correlation Integrity},
	issn = {0950-5849},
	url = {https://www.sciencedirect.com/science/article/pii/S0950584921000550},
	doi = {10.1016/j.infsof.2021.106572},
	shorttitle = {{BCI}-{CFI}},
	abstract = {Context
: As part of the arms race, one emerging attack methodology has been control-hijacking attacks, e.g., return-oriented programming ({ROP}). Control-flow integrity ({CFI}) is a generic and effective defence against most control-hijacking attacks. However, existing {CFI} mechanisms have poor security as demonstrated by their equivalence class ({EC}) sizes, which are sets of targets that {CFI} policies cannot distinguish. Adversaries can choose an illegitimate control transfer within an {EC} that is included in the resulting {CFG} and incorrectly allowed by {CFI} protection policies.
Objective
: The paper introduces a context-sensitive control-flow integrity method, which aims to improve the security of {CFI} and prevent {ROP} attacks.
Method
: The paper presents {BCI}-{CFI}, a context-sensitive {CFI} technique based on branch correlation integrity ({BCI}), which can effectively break down {EC} sizes and improve the security of {CFI}. {BCI}-{CFI} takes the branch correlation relationship (i.e., a new type of context for {CFI}) as contextual information to refine the {CFI} policy and identify the {BCI} pairs in the target program via static analysis. Furthermore, the paper introduces a state machine {MCFI} for {BCI}-{CFI} to conduct target validation for the indirect control-flow transfer ({ICT}) instructions in the target program at runtime.
Results
: Our results show that, (i) {BCI}-{CFI} prevented adversaries from manipulating the control data and launching {ROP} attacks, (ii) protected both forward and backward {ICT} in the target program, and improved the security and effectiveness of {CFI}, and (iii) {BCI}-{CFI} introduced a 19.67\% runtime overhead on average and a maximum runtime overhead of 31.2\%
Conclusion
: {BCI}-{CFI} is a context-sensitive {CFI} technique aiming to prevent adversaries from manipulating the control data of the target program to launch {ROP} attacks. {BCI}-{CFI} can reduce {EC} sizes and improve the security of {CFI} while incurring a moderate runtime overhead on average.},
	pages = {106572},
	journaltitle = {Information and Software Technology},
	shortjournal = {Information and Software Technology},
	author = {Wang, Ye and Li, Qingbao and Chen, Zhifeng and Zhang, Ping and Zhang, Guimin and Shi, Zhihui},
	urldate = {2021-03-24},
	date = {2021-03-19},
	langid = {english},
	keywords = {{BCI}-{CFI}, Branch correlation integrity, Equivalence class, Indirect control-flow transfer, {ROP}},
	file = {ScienceDirect Snapshot:/home/fordrl/Zotero/storage/Y9PDLETM/S0950584921000550.html:text/html},
}

@inproceedings{wu_vulnerability_2021,
	title = {Vulnerability Detection in C/C++ Source Code With Graph Representation Learning},
	doi = {10.1109/CCWC51732.2021.9376145},
	abstract = {An open challenge in software vulnerability detection is how to identify potential vulnerabilities of source code at a fine-grained level automatically. This paper proposes an approach to automate vulnerability detection in source code at the software function level based on graph representation learning without the efforts of security experts. The proposed approach firstly represents software functions as Simplified Code Property Graphs ({SCPG}), which can conserve syntactic and semantic information of source code while keeping itself small enough for computing. It then utilizes graph neural network and multi layer perceptrons to learn graph representations and extract features automatically, saving efforts of feature engineering. The comparison experiments demonstrate the effectiveness of the proposed approach.},
	eventtitle = {2021 {IEEE} 11th Annual Computing and Communication Workshop and Conference ({CCWC})},
	pages = {1519--1524},
	booktitle = {2021 {IEEE} 11th Annual Computing and Communication Workshop and Conference ({CCWC})},
	author = {Wu, Y. and Lu, J. and Zhang, Y. and Jin, S.},
	date = {2021-01},
	keywords = {Security, Semantics, Syntactics, Software, Conferences, Feature extraction, Graph Neural Network, Graph neural networks, Source Code, Vulnerability Detection},
	file = {IEEE Xplore Abstract Record:/home/fordrl/Zotero/storage/J73NBJTG/9376145.html:text/html},
}

@inproceedings{busse_running_2020,
	location = {New York, {NY}, {USA}},
	title = {Running symbolic execution forever},
	isbn = {978-1-4503-8008-9},
	url = {https://doi.org/10.1145/3395363.3397360},
	doi = {10.1145/3395363.3397360},
	series = {{ISSTA} 2020},
	abstract = {When symbolic execution is used to analyse real-world applications, it often consumes all available memory in a relatively short amount of time, sometimes making it impossible to analyse an application for an extended period. In this paper, we present a technique that can record an ongoing symbolic execution analysis to disk and selectively restore paths of interest later, making it possible to run symbolic execution indefinitely. To be successful, our approach addresses several essential research challenges related to detecting divergences on re-execution, storing long-running executions efficiently, changing search heuristics during re-execution, and providing a global view of the stored execution. Our extensive evaluation of 93 Linux applications shows that our approach is practical, enabling these applications to run for days while continuing to explore new execution paths.},
	pages = {63--74},
	booktitle = {Proceedings of the 29th {ACM} {SIGSOFT} International Symposium on Software Testing and Analysis},
	publisher = {Association for Computing Machinery},
	author = {Busse, Frank and Nowack, Martin and Cadar, Cristian},
	urldate = {2021-03-09},
	date = {2020-07-18},
	keywords = {{KLEE}, memoization, symbolic execution},
}

@inproceedings{cadar_klee_2008,
	location = {{USA}},
	title = {{KLEE}: unassisted and automatic generation of high-coverage tests for complex systems programs},
	series = {{OSDI}'08},
	shorttitle = {{KLEE}},
	abstract = {We present a new symbolic execution tool, {KLEE}, capable of automatically generating tests that achieve high coverage on a diverse set of complex and environmentally-intensive programs. We used {KLEE} to thoroughly check all 89 stand-alone programs in the {GNU} {COREUTILS} utility suite, which form the core user-level environment installed on millions of Unix systems, and arguably are the single most heavily tested set of open-source programs in existence. {KLEE}-generated tests achieve high line coverage -- on average over 90\% per tool (median: over 94\%) -- and significantly beat the coverage of the developers' own hand-written test suite. When we did the same for 75 equivalent tools in the {BUSYBOX} embedded system suite, results were even better, including 100\% coverage on 31 of them. We also used {KLEE} as a bug finding tool, applying it to 452 applications (over 430K total lines of code), where it found 56 serious bugs, including three in {COREUTILS} that had been missed for over 15 years. Finally, we used {KLEE} to crosscheck purportedly identical {BUSYBOX} and {COREUTILS} utilities, finding functional correctness errors and a myriad of inconsistencies.},
	pages = {209--224},
	booktitle = {Proceedings of the 8th {USENIX} conference on Operating systems design and implementation},
	publisher = {{USENIX} Association},
	author = {Cadar, Cristian and Dunbar, Daniel and Engler, Dawson},
	urldate = {2021-03-08},
	date = {2008-12-08},
	file = {Cadar et al. - KLEE Unassisted and Automatic Generation of High-.pdf:/home/fordrl/Zotero/storage/SZFJPRBS/Cadar et al. - KLEE Unassisted and Automatic Generation of High-.pdf:application/pdf},
}

@inproceedings{islam_classification_2010,
	title = {Classification of Malware Based on String and Function Feature Selection},
	doi = {10.1109/CTC.2010.11},
	abstract = {Anti-malware software producers are continually challenged to identify and counter new malware as it is released into the wild. A dramatic increase in malware production in recent years has rendered the conventional method of manually determining a signature for each new malware sample untenable. This paper presents a scalable, automated approach for detecting and classifying malware by using pattern recognition algorithms and statistical methods at various stages of the malware analysis life cycle. Our framework combines the static features of function length and printable string information extracted from malware samples into a single test which gives classification results better than those achieved by using either feature individually. In our testing we input feature information from close to 1400 unpacked malware samples to a number of different classification algorithms. Using k-fold cross validation on the malware, which includes Trojans and viruses, along with 151 clean files, we achieve an overall classification accuracy of over 98\%.},
	eventtitle = {2010 Second Cybercrime and Trustworthy Computing Workshop},
	pages = {9--17},
	booktitle = {2010 Second Cybercrime and Trustworthy Computing Workshop},
	author = {Islam, R. and Tian, R. and Batten, L. and Versteeg, S.},
	date = {2010-07},
	keywords = {Software, Feature extraction, Accuracy, classification, Data mining, Databases, function feature selection, function length, invasive software, k-fold cross validation, Malware, malware analysis life cycle, malware classification, pattern recognition, pattern recognition algorithm, static feature, statistical analysis, statistical method, string, string feature selection, Support vector machine classification},
	file = {IEEE Xplore Abstract Record:/home/fordrl/Zotero/storage/82FIYDYX/5615149.html:text/html},
}

@online{witten_data_nodate,
	title = {Data Mining: Practical Machine Learning Tools and Techniques},
	url = {https://www.cs.waikato.ac.nz/ml/weka/book.html},
	author = {Witten, Ian and Frank, Eibe and Hall, Mark and Pal, Chris},
	urldate = {2021-03-05},
	file = {Data Mining\: Practical Machine Learning Tools and Techniques:/home/fordrl/Zotero/storage/VSRUSPA3/book.html:text/html},
}

@article{rumelhart_learning_1986,
	title = {Learning representations by back-propagating errors},
	volume = {323},
	rights = {1986 Nature Publishing Group},
	issn = {1476-4687},
	url = {https://www.nature.com/articles/323533a0},
	doi = {10.1038/323533a0},
	abstract = {We describe a new learning procedure, back-propagation, for networks of neurone-like units. The procedure repeatedly adjusts the weights of the connections in the network so as to minimize a measure of the difference between the actual output vector of the net and the desired output vector. As a result of the weight adjustments, internal ‘hidden’ units which are not part of the input or output come to represent important features of the task domain, and the regularities in the task are captured by the interactions of these units. The ability to create useful new features distinguishes back-propagation from earlier, simpler methods such as the perceptron-convergence procedure1.},
	pages = {533--536},
	number = {6088},
	journaltitle = {Nature},
	author = {Rumelhart, David E. and Hinton, Geoffrey E. and Williams, Ronald J.},
	urldate = {2021-03-05},
	date = {1986-10},
	langid = {english},
	note = {Number: 6088
Publisher: Nature Publishing Group},
	file = {Snapshot:/home/fordrl/Zotero/storage/FHH5NVQX/323533a0.html:text/html},
}

@inproceedings{jeong_razzer_2019,
	location = {San Francisco, {CA}, {USA}},
	title = {Razzer: Finding Kernel Race Bugs through Fuzzing},
	isbn = {978-1-5386-6660-9},
	url = {https://ieeexplore.ieee.org/document/8835326/},
	doi = {10.1109/SP.2019.00017},
	shorttitle = {Razzer},
	abstract = {A data race in a kernel is an important class of bugs, critically impacting the reliability and security of the associated system. As a result of a race, the kernel may become unresponsive. Even worse, an attacker may launch a privilege escalation attack to acquire root privileges. In this paper, we propose {RAZZER}, a tool to find race bugs in kernels. The core of {RAZZER} is in guiding fuzz testing towards potential data race spots in the kernel. {RAZZER} employs two techniques to find races efficiently: a static analysis and a deterministic thread interleaving technique. Using a static analysis, {RAZZER} identifies over-approximated potential data race spots, guiding the fuzzer to search for data races in the kernel more efficiently. Using the deterministic thread interleaving technique implemented at the hypervisor, {RAZZER} tames the non-deterministic behavior of the kernel such that it can deterministically trigger a race. We implemented a prototype of {RAZZER} and ran the latest Linux kernel (from v4.16-rc3 to v4.18rc3) using {RAZZER}. As a result, {RAZZER} discovered 30 new races in the kernel, with 16 subsequently confirmed and accordingly patched by kernel developers after they were reported.},
	eventtitle = {2019 {IEEE} Symposium on Security and Privacy ({SP})},
	pages = {754--768},
	booktitle = {2019 {IEEE} Symposium on Security and Privacy ({SP})},
	publisher = {{IEEE}},
	author = {Jeong, Dae R. and Kim, Kyungtae and Shivakumar, Basavesh and Lee, Byoungyoung and Shin, Insik},
	urldate = {2021-03-05},
	date = {2019-05},
	langid = {english},
	file = {Jeong et al. - 2019 - Razzer Finding Kernel Race Bugs through Fuzzing.pdf:/home/fordrl/Zotero/storage/GSZ7EG64/Jeong et al. - 2019 - Razzer Finding Kernel Race Bugs through Fuzzing.pdf:application/pdf},
}

@article{chen_savior_2019,
	title = {{SAVIOR}: Towards Bug-Driven Hybrid Testing},
	url = {http://arxiv.org/abs/1906.07327},
	shorttitle = {{SAVIOR}},
	abstract = {Hybrid testing combines fuzz testing and concolic execution. It leverages fuzz testing to test easy-to-reach code regions and uses concolic execution to explore code blocks guarded by complex branch conditions. However, its code coverage-centric design is inefficient in vulnerability detection. First, it blindly selects seeds for concolic execution and aims to explore new code continuously. However, as statistics show, a large portion of the explored code is often bug-free. Therefore, giving equal attention to every part of the code during hybrid testing is a non-optimal strategy. It slows down the detection of real vulnerabilities by over 43\%. Second, classic hybrid testing quickly moves on after reaching a chunk of code, rather than examining the hidden defects inside. It may frequently miss subtle vulnerabilities despite that it has already explored the vulnerable code paths. We propose {SAVIOR}, a new hybrid testing framework pioneering a bug-driven principle. Unlike the existing hybrid testing tools, {SAVIOR} prioritizes the concolic execution of the seeds that are likely to uncover more vulnerabilities. Moreover, {SAVIOR} verifies all vulnerable program locations along the executing program path. By modeling faulty situations using {SMT} constraints, {SAVIOR} reasons the feasibility of vulnerabilities and generates concrete test cases as proofs. Our evaluation shows that the bug-driven approach outperforms mainstream automated testing techniques, including state-of-the-art hybrid testing systems driven by code coverage. On average, {SAVIOR} detects vulnerabilities 43.4\% faster than {DRILLER} and 44.3\% faster than {QSYM}, leading to the discovery of 88 and 76 more uniquebugs,respectively.Accordingtotheevaluationon11 well fuzzed benchmark programs, within the first 24 hours, {SAVIOR} triggers 481 {UBSAN} violations, among which 243 are real bugs.},
	journaltitle = {{arXiv}:1906.07327 [cs]},
	author = {Chen, Yaohui and Li, Peng and Xu, Jun and Guo, Shengjian and Zhou, Rundong and Zhang, Yulong and Taowei and Lu, Long},
	urldate = {2021-03-05},
	date = {2019-06-17},
	eprinttype = {arxiv},
	eprint = {1906.07327},
	keywords = {Computer Science - Software Engineering},
	file = {arXiv.org Snapshot:/home/fordrl/Zotero/storage/9SDLXBK6/1906.html:text/html;arXiv Fulltext PDF:/home/fordrl/Zotero/storage/PFR2S2BP/Chen et al. - 2019 - SAVIOR Towards Bug-Driven Hybrid Testing.pdf:application/pdf},
}

@incollection{hinton_next_2020,
	location = {New York, {NY}, {USA}},
	title = {The Next Generation of Neural Networks},
	isbn = {978-1-4503-8016-4},
	url = {https://doi.org/10.1145/3397271.3402425},
	abstract = {The most important unsolved problem with artificial neural networks is how to do unsupervised learning as effectively as the brain. There are currently two main approaches to unsupervised learning. In the first approach, exemplified by {BERT} and Variational Autoencoders, a deep neural network is used to reconstruct its input. This is problematic for images because the deepest layers of the network need to encode the fine details of the image. An alternative approach, introduced by Becker and Hinton in 1992, is to train two copies of a deep neural network to produce output vectors that have high mutual information when given two different crops of the same image as their inputs. This approach was designed to allow the representations to be untethered from irrelevant details of the input. The method of optimizing mutual information used by Becker and Hinton was flawed (for a subtle reason that I will explain) so Pacannaro and Hinton (2001) replaced it by a discriminative objective in which one vector representation must select a corresponding vector representation from among many alternatives. With faster hardware, contrastive learning of representations has recently become very popular and is proving to be very effective, but it suffers from a major flaw: To learn pairs of representation vectors that have N bits of mutual information we need to contrast the correct corresponding vector with about 2N incorrect alternatives. I will describe a novel and effective way of dealing with this limitation. I will also show that this leads to a simple way of implementing perceptual learning in cortex.},
	pages = {1},
	booktitle = {Proceedings of the 43rd International {ACM} {SIGIR} Conference on Research and Development in Information Retrieval},
	publisher = {Association for Computing Machinery},
	author = {Hinton, Geoffrey},
	urldate = {2021-02-22},
	date = {2020-07-25},
	keywords = {deep learning, neural networks, unsupervised learning},
	file = {Full Text PDF:/home/fordrl/Zotero/storage/2XC3KVUD/Hinton - 2020 - The Next Generation of Neural Networks.pdf:application/pdf},
}

@article{wang_data-driven_2021,
	title = {Data-Driven Synthesis of Provably Sound Side Channel Analyses},
	url = {http://arxiv.org/abs/2102.06753},
	abstract = {We propose a data-driven method for synthesizing a static analyzer to detect side-channel information leaks in cryptographic software. Compared to the conventional way of manually crafting such a static analyzer, which can be labor intensive, error prone and suboptimal, our learning-based technique is not only automated but also provably sound. Our analyzer consists of a set of type-inference rules learned from the training data, i.e., example code snippets annotated with ground truth. Internally, we use syntax-guided synthesis ({SyGuS}) to generate new features and decision tree learning ({DTL}) to generate type-inference rules based on these features. We guarantee soundness by formally proving each learned rule via a technique called Datalog query containment checking. We have implemented our technique in the {LLVM} compiler and used it to detect power side channels in C programs. Our results show that, in addition to being automated and provably sound during synthesis, the learned analyzer also has the same empirical accuracy as two state-of-the-art, manually crafted analyzers while being 300X and 900X faster, respectively.},
	journaltitle = {{arXiv}:2102.06753 [cs]},
	author = {Wang, Jingbo and Sung, Chungha and Raghothaman, Mukund and Wang, Chao},
	urldate = {2021-02-22},
	date = {2021-02-12},
	eprinttype = {arxiv},
	eprint = {2102.06753},
	keywords = {Computer Science - Programming Languages, Computer Science - Software Engineering},
	file = {arXiv.org Snapshot:/home/fordrl/Zotero/storage/GA4RHPKY/2102.html:text/html;arXiv Fulltext PDF:/home/fordrl/Zotero/storage/IGIS6Y4V/Wang et al. - 2021 - Data-Driven Synthesis of Provably Sound Side Chann.pdf:application/pdf},
}

@report{morrisett_ipdl_2021,
	title = {{IPDL}: A Simple Framework for Formally Verifying Distributed Cryptographic Protocols},
	url = {http://eprint.iacr.org/2021/147},
	shorttitle = {{IPDL}},
	abstract = {Although there have been many successes in verifying proofs of non-interactive cryptographic primitives such as encryption and signatures, formal verification of interactive cryptographic protocols is still a nascent area. While in principle, it seems possible to extend general frameworks such as Easycrypt to encode proofs for more complex, interactive protocols, a big challenge is whether the human effort would be scalable enough for proof mechanization to eventually acquire mainstream usage among the cryptography community. We work towards closing this gap by introducing a simple framework, Interactive Probabilistic Dependency Logic ({IPDL}), for reasoning about a certain well-behaved subset of cryptographic protocols. A primary design goal of {IPDL} is for formal cryptographic proofs to resemble their on-paper counterparts. To this end, {IPDL} includes an equational logic to reason about approximate observational equivalence (i.e., computational indistinguishability) properties between protocols. {IPDL} adopts a channel-centric core logic, which decomposes the behavior of the protocol into the behaviors along each communication channel. {IPDL} supports straight-line programs with statically bounded loops. This design allows us to capture a broad class of protocols encountered in the cryptography literature, including multi-party, reactive, and/or inductively-defined protocols; meanwhile, the logic can track the runtime of the computational reduction in security proofs, thus ensuring computational soundness. We demonstrate the use of {IPDL} by a number of case studies, including a multi-use, secure message communication protocol, a multi-party coin toss with abort protocol, several oblivious transfer constructions, as well as the two-party {GMW} protocol for securely evaluating general circuits. We provide a mechanization of the {IPDL} proof system and our case studies in Coq, and our code is open sourced at https://github.com/ipdl/ipdl.},
	number = {147},
	author = {Morrisett, Greg and Shi, Elaine and Sojakova, Kristina and Fan, Xiong and Gancher, Joshua},
	urldate = {2021-02-22},
	date = {2021},
	file = {ePrint IACR Full Text PDF:/home/fordrl/Zotero/storage/BMMKZ8AM/Morrisett et al. - 2021 - IPDL A Simple Framework for Formally Verifying Di.pdf:application/pdf;ePrint IACR Snapshot:/home/fordrl/Zotero/storage/ZHKCV6YP/147.html:text/html},
}

@article{yadav_light-weighted_2020,
	title = {Light-Weighted {CNN} for Text Classification},
	url = {http://arxiv.org/abs/2004.07922},
	abstract = {For management, documents are categorized into a specific category, and to do these, most of the organizations use manual labor. In today's automation era, manual efforts on such a task are not justified, and to avoid this, we have so many software out there in the market. However, efficiency and minimal resource consumption is the focal point which is also creating a competition. The categorization of such documents into specified classes by machine provides excellent help. One of categorization technique is text classification using a Convolutional neural network({TextCNN}). {TextCNN} uses multiple sizes of filters, as in the case of the inception layer introduced in Googlenet. The network provides good accuracy but causes high memory consumption due to a large number of trainable parameters. As a solution to this problem, we introduced a whole new architecture based on separable convolution. The idea of separable convolution already exists in the field of image classification but not yet introduces to text classification tasks. With the help of this architecture, we can achieve a drastic reduction in trainable parameters.},
	journaltitle = {{arXiv}:2004.07922 [cs, stat]},
	author = {Yadav, Ritu},
	urldate = {2021-02-22},
	date = {2020-04-16},
	eprinttype = {arxiv},
	eprint = {2004.07922},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Computation and Language},
	file = {arXiv.org Snapshot:/home/fordrl/Zotero/storage/MNJZ8YBN/2004.html:text/html;arXiv Fulltext PDF:/home/fordrl/Zotero/storage/GY6544GG/Yadav - 2020 - Light-Weighted CNN for Text Classification.pdf:application/pdf},
}

@article{kim_convolutional_2014,
	title = {Convolutional Neural Networks for Sentence Classification},
	url = {http://arxiv.org/abs/1408.5882},
	abstract = {We report on a series of experiments with convolutional neural networks ({CNN}) trained on top of pre-trained word vectors for sentence-level classification tasks. We show that a simple {CNN} with little hyperparameter tuning and static vectors achieves excellent results on multiple benchmarks. Learning task-specific vectors through fine-tuning offers further gains in performance. We additionally propose a simple modification to the architecture to allow for the use of both task-specific and static vectors. The {CNN} models discussed herein improve upon the state of the art on 4 out of 7 tasks, which include sentiment analysis and question classification.},
	journaltitle = {{arXiv}:1408.5882 [cs]},
	author = {Kim, Yoon},
	urldate = {2021-02-19},
	date = {2014-09-02},
	eprinttype = {arxiv},
	eprint = {1408.5882},
	keywords = {Computer Science - Computation and Language, Computer Science - Neural and Evolutionary Computing},
	file = {arXiv.org Snapshot:/home/fordrl/Zotero/storage/XG3AA7E3/1408.html:text/html;arXiv Fulltext PDF:/home/fordrl/Zotero/storage/MUIWCB2P/Kim - 2014 - Convolutional Neural Networks for Sentence Classif.pdf:application/pdf},
}

@software{lee_instruction2vec_2021,
	title = {instruction2vec},
	rights = {{GPL}-2.0 License         ,                 {GPL}-2.0 License},
	url = {https://github.com/firmcode/instruction2vec},
	abstract = {Efficient Preprocessor of Assembly Code to Detect Software Weakness with {CNN}},
	author = {Lee, Yongjun},
	urldate = {2021-02-19},
	date = {2021-02-08},
	note = {original-date: 2019-09-17T16:14:33Z},
}

@article{lee_instruction2vec_2019,
	title = {Instruction2vec: Efficient Preprocessor of Assembly Code to Detect Software Weakness with {CNN}},
	volume = {9},
	rights = {http://creativecommons.org/licenses/by/3.0/},
	url = {https://www.mdpi.com/2076-3417/9/19/4086},
	doi = {10.3390/app9194086},
	shorttitle = {Instruction2vec},
	abstract = {Potential software weakness, which can lead to exploitable security vulnerabilities, continues to pose a risk to computer systems. According to Common Vulnerability and Exposures, 14,714 vulnerabilities were reported in 2017, more than twice the number reported in 2016. Automated vulnerability detection was recommended to efficiently detect vulnerabilities. Among detection techniques, static binary analysis detects software weakness based on existing patterns. In addition, it is based on existing patterns or rules, making it difficult to add and patch new rules whenever an unknown vulnerability is encountered. To overcome this limitation, we propose a new method\&mdash;Instruction2vec\&mdash;an improved static binary analysis technique using machine. Our framework consists of two steps: (1) it models assembly code efficiently using Instruction2vec, based on Word2vec; and (2) it learns the features of software weakness code using the feature extraction of Text-{CNN} without creating patterns or rules and detects new software weakness. We compared the preprocessing performance of three frameworks\&mdash;Instruction2vec, Word2vec, and Binary2img\&mdash;to assess the efficiency of Instruction2vec. We used the Juliet Test Suite, particularly the part related to Common Weakness Enumeration({CWE})-121, for training and Securely Taking On New Executable Software of Uncertain Provenance ({STONESOUP}) for testing. Experimental results show that the proposed scheme can detect software vulnerabilities with an accuracy of 91\% of the assembly code.},
	pages = {4086},
	number = {19},
	journaltitle = {Applied Sciences},
	author = {Lee, Yongjun and Kwon, Hyun and Choi, Sang-Hoon and Lim, Seung-Ho and Baek, Sung Hoon and Park, Ki-Woong},
	urldate = {2021-02-19},
	date = {2019-01},
	langid = {english},
	note = {Number: 19
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {\textit{Word2vec}, binary analysis, convolutional neural network, software weakness},
	file = {Snapshot:/home/fordrl/Zotero/storage/9LZAC25T/4086.html:text/html;Full Text PDF:/home/fordrl/Zotero/storage/ZNZ3Q2Y5/Lee et al. - 2019 - Instruction2vec Efficient Preprocessor of Assembl.pdf:application/pdf},
}

@misc{staats_scanner_2021,
	title = {Scanner Project V2},
	abstract = {Proposes an architecture for a scanner for vulnerabilites for programs in either source or binary format.},
	publisher = {Colsa},
	author = {Staats, Wayne},
	date = {2021},
}

@article{mikolov_distributed_2013,
	title = {Distributed Representations of Words and Phrases and their Compositionality},
	url = {http://arxiv.org/abs/1310.4546},
	abstract = {The recently introduced continuous Skip-gram model is an efficient method for learning high-quality distributed vector representations that capture a large number of precise syntactic and semantic word relationships. In this paper we present several extensions that improve both the quality of the vectors and the training speed. By subsampling of the frequent words we obtain significant speedup and also learn more regular word representations. We also describe a simple alternative to the hierarchical softmax called negative sampling. An inherent limitation of word representations is their indifference to word order and their inability to represent idiomatic phrases. For example, the meanings of "Canada" and "Air" cannot be easily combined to obtain "Air Canada". Motivated by this example, we present a simple method for finding phrases in text, and show that learning good vector representations for millions of phrases is possible.},
	journaltitle = {{arXiv}:1310.4546 [cs, stat]},
	author = {Mikolov, Tomas and Sutskever, Ilya and Chen, Kai and Corrado, Greg and Dean, Jeffrey},
	urldate = {2021-02-19},
	date = {2013-10-16},
	eprinttype = {arxiv},
	eprint = {1310.4546},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Computation and Language},
	file = {arXiv.org Snapshot:/home/fordrl/Zotero/storage/VAWMUEEN/1310.html:text/html;arXiv Fulltext PDF:/home/fordrl/Zotero/storage/MAPXX8CC/Mikolov et al. - 2013 - Distributed Representations of Words and Phrases a.pdf:application/pdf},
}

@article{mikolov_linguistic_2013,
	title = {Linguistic Regularities in Continuous Space Word Representations},
	url = {https://www.microsoft.com/en-us/research/publication/linguistic-regularities-in-continuous-space-word-representations/},
	abstract = {Continuous space language models have recently demonstrated outstanding results across a variety of tasks. In this paper, we examine the vector-space word representations that are implicitly learned by the input-layer weights. We find that these representations are surprisingly good at capturing syntactic and semantic regularities in language, and that each relationship is characterized by a […]},
	author = {Mikolov, Tomas and Yih, Scott Wen-tau and Zweig, Geoffrey},
	urldate = {2021-02-19},
	date = {2013-05-27},
	langid = {american},
	file = {Snapshot:/home/fordrl/Zotero/storage/AGLBGEDP/linguistic-regularities-in-continuous-space-word-representations.html:text/html;Full Text PDF:/home/fordrl/Zotero/storage/T8QW8TGC/Mikolov et al. - 2013 - Linguistic Regularities in Continuous Space Word R.pdf:application/pdf},
}

@article{mikolov_efficient_2013,
	title = {Efficient Estimation of Word Representations in Vector Space},
	url = {http://arxiv.org/abs/1301.3781},
	abstract = {We propose two novel model architectures for computing continuous vector representations of words from very large data sets. The quality of these representations is measured in a word similarity task, and the results are compared to the previously best performing techniques based on different types of neural networks. We observe large improvements in accuracy at much lower computational cost, i.e. it takes less than a day to learn high quality word vectors from a 1.6 billion words data set. Furthermore, we show that these vectors provide state-of-the-art performance on our test set for measuring syntactic and semantic word similarities.},
	journaltitle = {{arXiv}:1301.3781 [cs]},
	author = {Mikolov, Tomas and Chen, Kai and Corrado, Greg and Dean, Jeffrey},
	urldate = {2021-02-19},
	date = {2013-09-06},
	eprinttype = {arxiv},
	eprint = {1301.3781},
	keywords = {Computer Science - Computation and Language},
	file = {arXiv.org Snapshot:/home/fordrl/Zotero/storage/932GMRG3/1301.html:text/html;arXiv Fulltext PDF:/home/fordrl/Zotero/storage/F6R5WJ4Z/Mikolov et al. - 2013 - Efficient Estimation of Word Representations in Ve.pdf:application/pdf},
}

@online{korczynski_comparison_2019,
	title = {Comparison of the {LLVM} {IR} generated by three binary-to-llvm translators},
	url = {https://adalogics.com/blog/binary-to-llvm-comparison},
	author = {Korczynski, David},
	urldate = {2021-02-17},
	date = {2019-09-17},
	file = {Comparison of the LLVM IR generated by three binary-to-llvm translators:/home/fordrl/Zotero/storage/9I2YZN4T/binary-to-llvm-comparison.html:text/html},
}

@article{costanzo_end--end_2016,
	title = {End-to-end verification of information-flow security for C and assembly programs},
	volume = {51},
	issn = {0362-1340, 1558-1160},
	url = {https://dl.acm.org/doi/10.1145/2980983.2908100},
	doi = {10.1145/2980983.2908100},
	pages = {648--664},
	number = {6},
	journaltitle = {{ACM} {SIGPLAN} Notices},
	shortjournal = {{SIGPLAN} Not.},
	author = {Costanzo, David and Shao, Zhong and Gu, Ronghui},
	urldate = {2021-02-17},
	date = {2016-08},
	langid = {english},
	file = {Full Text:/home/fordrl/Zotero/storage/CS3VM3MK/Costanzo et al. - 2016 - End-to-end verification of information-flow securi.pdf:application/pdf},
}

@article{nguyen_regvd_2021,
	title = {{ReGVD}: Revisiting Graph Neural Networks for Vulnerability Detection},
	url = {http://arxiv.org/abs/2110.07317},
	shorttitle = {{ReGVD}},
	abstract = {Identifying vulnerabilities in the source code is essential to protect the software systems from cyber security attacks. It, however, is also a challenging step that requires specialized expertise in security and code representation. Inspired by the successful applications of pre-trained programming language ({PL}) models such as {CodeBERT} and graph neural networks ({GNNs}), we propose {ReGVD}, a general and novel graph neural network-based model for vulnerability detection. In particular, {ReGVD} views a given source code as a flat sequence of tokens and then examines two effective methods of utilizing unique tokens and indexes respectively to construct a single graph as an input, wherein node features are initialized only by the embedding layer of a pre-trained {PL} model. Next, {ReGVD} leverages a practical advantage of residual connection among {GNN} layers and explores a beneficial mixture of graph-level sum and max poolings to return a graph embedding for the given source code. Experimental results demonstrate that {ReGVD} outperforms the existing state-of-the-art models and obtain the highest accuracy on the real-world benchmark dataset from {CodeXGLUE} for vulnerability detection.},
	journaltitle = {{arXiv}:2110.07317 [cs]},
	author = {Nguyen, Van-Anh and Nguyen, Dai Quoc and Nguyen, Van and Le, Trung and Tran, Quan Hung and Phung, Dinh},
	urldate = {2021-10-26},
	date = {2021-10-14},
	eprinttype = {arxiv},
	eprint = {2110.07317},
	keywords = {Computer Science - Cryptography and Security, Computer Science - Machine Learning},
	file = {arXiv.org Snapshot:/home/fordrl/Zotero/storage/67PDHPWD/2110.html:text/html;arXiv Fulltext PDF:/home/fordrl/Zotero/storage/S96DK9Z6/Nguyen et al. - 2021 - ReGVD Revisiting Graph Neural Networks for Vulner.pdf:application/pdf},
}

@article{georges_cerise_nodate,
	title = {Cerise: Program Verification on a Capability Machine in the Presence of Untrusted Code},
	volume = {1},
	pages = {55},
	number = {1},
	author = {Georges, Aïna Linn and Guéneau, Armaël and Strydonck, Thomas Van and Timany, Amin and Trieu, Alix and Devriese, Dominique and Birkedal, Lars},
	langid = {english},
	file = {Georges et al. - Cerise Program Verification on a Capability Machi.pdf:/home/fordrl/Zotero/storage/2E7ZMBPG/Georges et al. - Cerise Program Verification on a Capability Machi.pdf:application/pdf},
}

@article{el-korashy_secureptrs_2021,
	title = {{SecurePtrs}: Proving Secure Compilation with Data-Flow Back-Translation and Turn-Taking Simulation},
	url = {http://arxiv.org/abs/2110.01439},
	shorttitle = {{SecurePtrs}},
	abstract = {Proving secure compilation of partial programs typically requires back-translating a target attack against the compiled program to an attack against the source program. To prove this back-translation step, one can syntactically translate the target attacker to a source one -- i.e., syntax-directed back-translation -- or show that the interaction traces of the target attacker can also be produced by source attackers -- i.e., trace-directed back-translation. Syntax-directed back-translation is not suitable when the target attacker uses unstructured control flow that the source language cannot directly represent. Trace-directed back-translation works with such syntactic dissimilarity because only the external interactions of the target attacker have to be mimicked in the source, not its internal control flow. Revealing only external interactions is, however, inconvenient when sharing memory via unforgeable pointers, since information about stashed pointers to shared memory gets lost. This made prior proofs complex, since the generated attacker had to stash all reachable pointers. In this work, we introduce more informative data-flow traces, which allow us to combine the best of syntax-directed and trace-directed back-translation. Our data-flow back-translation is simple, handles both syntactic dissimilarity and memory sharing well, and we have proved it correct in Coq. We, moreover, develop a novel turn-taking simulation relation and use it to prove a recomposition lemma, which is key to reusing compiler correctness in such secure compilation proofs. We are the first to mechanize such a recomposition lemma in a proof assistant in the presence of memory sharing. We put these two key innovations to use in a secure compilation proof for a code generation compiler pass between a safe source language with pointers and components, and a target language with unstructured control flow.},
	journaltitle = {{arXiv}:2110.01439 [cs]},
	author = {El-Korashy, Akram and Blanco, Roberto and Thibault, Jérémy and Durier, Adrien and Garg, Deepak and Hritcu, Catalin},
	urldate = {2021-10-12},
	date = {2021-10-04},
	eprinttype = {arxiv},
	eprint = {2110.01439},
	keywords = {Computer Science - Cryptography and Security, Computer Science - Programming Languages},
	file = {arXiv.org Snapshot:/home/fordrl/Zotero/storage/BEMUYISV/2110.html:text/html;arXiv Fulltext PDF:/home/fordrl/Zotero/storage/CGYCMSI4/El-Korashy et al. - 2021 - SecurePtrs Proving Secure Compilation with Data-F.pdf:application/pdf},
}

@inproceedings{messadi_precursor_2021,
	location = {New York, {NY}, {USA}},
	title = {Precursor: a fast, client-centric and trusted key-value store using {RDMA} and Intel {SGX}},
	isbn = {978-1-4503-8534-3},
	url = {https://doi.org/10.1145/3464298.3476129},
	doi = {10.1145/3464298.3476129},
	series = {Middleware '21},
	shorttitle = {Precursor},
	abstract = {As offered by the Intel Software Guard Extensions ({SGX}), trusted execution enables confidentiality and integrity for off-site deployed services. Thereby, securing key-value stores has received particular attention, as they are a building block for many complex applications to speed-up request processing. Initially, the developers' main design challenge has been to address the performance barriers of {SGX}. Besides, we identified the integration of a {SGX}-secured key-value store with recent network technologies, especially {RDMA}, as an essential emerging requirement. {RDMA} allows fast direct access to remote memory at high bandwidth. As {SGX}-protected memory cannot be directly accessed over the network, a fast exchange between the main and trusted memory must be enabled. More importantly, {SGX}-protected services can be expected to be {CPU}-bound as a result of the vast number of cryptographic operations required to transfer and store data securely. In this paper, we present Precursor, a new key-value store design that utilizes trusted execution to offer confidentiality and integrity while relying on {RDMA} for low latency and high bandwidth communication. Precursor offloads cryptographic operations to the client-side to prevent a server-side {CPU} bottleneck and reduces data movement in and out of the trusted execution environment. Our evaluation shows that Precursor achieves up to 6--8.5 times higher throughput when compared against similar {SGX}-secured key-value store approaches.},
	pages = {1--13},
	booktitle = {Proceedings of the 22nd International Middleware Conference},
	publisher = {Association for Computing Machinery},
	author = {Messadi, Ines and Neumann, Shivananda and Weichbrodt, Nico and Almstedt, Lennart and Mahhouk, Mohammad and Kapitza, Rüdiger},
	urldate = {2021-10-12},
	date = {2021-11-22},
	keywords = {Intel {SGX}, key-value stores, {RDMA}},
}

@article{recto_secure_nodate,
	title = {Secure Information Flow for Concurrent Programs with Expressive Synchronization},
	abstract = {Practical enforcement of secure information ﬂow in concurrent programs remains notoriously difﬁcult. An underexplored reason is that concurrent programs rely on a wide variety of synchronization primitives, which can leak information. However, the existing literature on security for concurrent programs has focused on a small set of such primitives.},
	pages = {28},
	author = {Recto, Rolph and Algehed, Maximilian and Myers, Andrew C},
	langid = {english},
	file = {Recto et al. - Secure Information Flow for Concurrent Programs wi.pdf:/home/fordrl/Zotero/storage/HPGLZWZY/Recto et al. - Secure Information Flow for Concurrent Programs wi.pdf:application/pdf},
}

@thesis{cauligi_foundations_nodate,
	title = {Foundations for Speculative Side Channels},
	url = {https://escholarship.org/uc/item/64n9f44x},
	pagetotal = {190},
	institution = {{UC} San Diego},
	type = {phdthesis},
	author = {Cauligi, Sunjay R},
	langid = {english},
	file = {Cauligi - Foundations for Speculative Side Channels.pdf:/home/fordrl/Zotero/storage/RABBVQJF/Cauligi - Foundations for Speculative Side Channels.pdf:application/pdf},
}

@article{zhang_statically_nodate,
	title = {Statically Discovering High-Order Taint Style Vulnerabilities in {OS} Kernels},
	abstract = {Static analysis is known to yield numerous false alarms when used in bug finding, especially for complex vulnerabilities in large code bases like the Linux kernel. One important class of such complex vulnerabilities is what we call “high-order taint style vulnerability”, where the taint flow from the user input to the vulnerable site crosses the boundary of a single entry function invocation (i.e., syscall). Due to the large scope and high precision requirement, few have attempted to solve the problem.},
	pages = {14},
	author = {Zhang, Hang and Chen, Weiteng and Hao, Yu and Li, Guoren and Zhai, Yizhuo and Zou, Xiaochen and Qian, Zhiyun},
	langid = {english},
	file = {Zhang et al. - Statically Discovering High-Order Taint Style Vuln.pdf:/home/fordrl/Zotero/storage/M8MA2Z5A/Zhang et al. - Statically Discovering High-Order Taint Style Vuln.pdf:application/pdf},
}

@article{li_towards_2021-1,
	title = {Towards a General-Purpose Dynamic Information Flow Policy},
	url = {http://arxiv.org/abs/2109.08096},
	abstract = {Noninterference offers a rigorous end-to-end guarantee for secure propagation of information. However, real-world systems almost always involve security requirements that change during program execution, making noninterference inapplicable. Prior works alleviate the limitation to some extent, but even for a veteran in information flow security, understanding the subtleties in the syntax and semantics of each policy is challenging, largely due to very different policy specification languages, and more fundamentally, semantic requirements of each policy. We take a top-down approach and present a novel information flow policy, called Dynamic Release, which allows information flow restrictions to downgrade and upgrade in arbitrary ways. Dynamic Release is formalized on a novel framework that, for the first time, allows us to compare and contrast various dynamic policies in the literature. We show that Dynamic Release generalizes declassification, erasure, delegation and revocation. Moreover, it is the only dynamic policy that is both applicable and correct on a benchmark of tests with dynamic policy.},
	journaltitle = {{arXiv}:2109.08096 [cs]},
	author = {Li, Peixuan and Zhang, Danfeng},
	urldate = {2021-09-24},
	date = {2021-09-16},
	eprinttype = {arxiv},
	eprint = {2109.08096},
	keywords = {Computer Science - Cryptography and Security},
	file = {arXiv.org Snapshot:/home/fordrl/Zotero/storage/FTJ4DPW3/2109.html:text/html;arXiv Fulltext PDF:/home/fordrl/Zotero/storage/S5MZD8YR/Li and Zhang - 2021 - Towards a General-Purpose Dynamic Information Flow.pdf:application/pdf},
}

@article{ishimwe_dynaplex_nodate,
	title = {Dynaplex: Analyzing Program Complexity using Dynamically Inferred Recurrence Relations},
	volume = {5},
	pages = {23},
	author = {Ishimwe, Didier and Nguyen, Kimhao and Nguyen, Thanhvu},
	langid = {english},
	file = {Ishimwe et al. - Dynaplex Analyzing Program Complexity using Dynam.pdf:/home/fordrl/Zotero/storage/9VYMC47D/Ishimwe et al. - Dynaplex Analyzing Program Complexity using Dynam.pdf:application/pdf},
}

@article{vu_reconciling_2021,
	title = {Reconciling Optimization with Secure Compilation},
	volume = {5},
	pages = {30},
	author = {Vu, Son Tuan and Cohen, Albert and Grandmaison, Arnaud De and Guillon, Christophe and Heydemann, Karine},
	date = {2021-10},
	langid = {english},
	file = {Vu et al. - Reconciling Optimization with Secure Compilation.pdf:/home/fordrl/Zotero/storage/7I88XGGQ/Vu et al. - Reconciling Optimization with Secure Compilation.pdf:application/pdf},
}

@article{neumann_risks_nodate,
	title = {The {RISKS} Digest},
	url = {http://catless.ncl.ac.uk/risks/},
	abstract = {The web page of the {RISKS} digest moderated by Peter G. Neumman of {SRI}},
	journaltitle = {The {RISKS} Digest},
	author = {Neumann, Peter G.},
	urldate = {2021-09-24},
	langid = {english},
	file = {Snapshot:/home/fordrl/Zotero/storage/KXDPH7YL/risks.html:text/html},
}

@inproceedings{li_potential_2015,
	location = {Vancouver, {BC}, Canada},
	title = {Potential Component Leaks in Android Apps: An Investigation into a New Feature Set for Malware Detection},
	isbn = {978-1-4673-7989-2},
	url = {http://ieeexplore.ieee.org/document/7272932/},
	doi = {10.1109/QRS.2015.36},
	shorttitle = {Potential Component Leaks in Android Apps},
	abstract = {We discuss the capability of a new feature set for malware detection based on potential component leaks ({PCLs}). {PCLs} are deﬁned as sensitive data-ﬂows that involve Android inter-component communications. We show that {PCLs} are common in Android apps and that malicious applications indeed manipulate signiﬁcantly more {PCLs} than benign apps. Then, we evaluate a machine learning-based approach relying on {PCLs}. Experimental validations show high performance for identifying malware, demonstrating that {PCLs} can be used for discriminating malicious apps from benign apps.},
	eventtitle = {2015 {IEEE} International Conference on Software Quality, Reliability and Security ({QRS})},
	pages = {195--200},
	booktitle = {2015 {IEEE} International Conference on Software Quality, Reliability and Security},
	publisher = {{IEEE}},
	author = {Li, Li and Allix, Kevin and Li, Daoyuan and Bartel, Alexandre and Bissyande, Tegawende F. and Klein, Jacques},
	urldate = {2021-09-20},
	date = {2015-08},
	langid = {english},
	file = {Li et al. - 2015 - Potential Component Leaks in Android Apps An Inve.pdf:/home/fordrl/Zotero/storage/LB8FZT63/Li et al. - 2015 - Potential Component Leaks in Android Apps An Inve.pdf:application/pdf},
}

@inproceedings{van_schaik_cacheout_2021,
	location = {San Francisco, {CA}, {USA}},
	title = {{CacheOut}: Leaking Data on Intel {CPUs} via Cache Evictions},
	isbn = {978-1-72818-934-5},
	url = {https://ieeexplore.ieee.org/document/9519461/},
	doi = {10.1109/SP40001.2021.00064},
	shorttitle = {{CacheOut}},
	abstract = {Recent transient-execution attacks, such as {RIDL}, Fallout, and {ZombieLoad}, demonstrated that attackers can leak information while it transits through microarchitectural buffers. Named Microarchitectural Data Sampling ({MDS}) by Intel, these attacks are likened to “drinking from the ﬁrehose”, as the attacker has little control over what data is observed and from what origin. Unable to prevent the buffers from leaking, Intel issued countermeasures via microcode updates that overwrite the buffers when the {CPU} changes security domains.},
	eventtitle = {2021 {IEEE} Symposium on Security and Privacy ({SP})},
	pages = {339--354},
	booktitle = {2021 {IEEE} Symposium on Security and Privacy ({SP})},
	publisher = {{IEEE}},
	author = {van Schaik, Stephan and Minkin, Marina and Kwong, Andrew and Genkin, Daniel and Yarom, Yuval},
	urldate = {2021-09-20},
	date = {2021-05},
	langid = {english},
	file = {van Schaik et al. - 2021 - CacheOut Leaking Data on Intel CPUs via Cache Evi.pdf:/home/fordrl/Zotero/storage/QBNEJCBZ/van Schaik et al. - 2021 - CacheOut Leaking Data on Intel CPUs via Cache Evi.pdf:application/pdf},
}

@online{alam_tailoring_nodate,
	title = {Tailoring Taint Analysis for Database Applications in the K Framework},
	url = {https://www.scitepress.org/Papers/2021/106186/106186.pdf},
	author = {Alam, Imran},
	urldate = {2021-12-07},
	file = {106186.pdf:/home/fordrl/Zotero/storage/4AVHSV9Z/106186.pdf:application/pdf},
}

@online{brown_semi-automatic_nodate,
	title = {Semi-Automatic Ladderisation: Improving Code Security through Rewriting and Dependent Types},
	url = {https://research-repository.st-andrews.ac.uk/bitstream/handle/10023/24384/Brown_2021_Semi_automatic_ladderisation_PEPM2022_AAM.pdf?sequence=1&isAllowed=y},
	author = {Brown, Christopher},
	urldate = {2021-12-07},
	file = {Brown_2021_Semi_automatic_ladderisation_PEPM2022_AAM.pdf:/home/fordrl/Zotero/storage/AYXBKYXT/Brown_2021_Semi_automatic_ladderisation_PEPM2022_AAM.pdf:application/pdf},
}

@article{genkin_lend_nodate,
	title = {Lend Me Your Ear: Passive Remote Physical Side Channels on {PCs}},
	abstract = {We show that built-in sensors in commodity {PCs}, such as microphones, inadvertently capture electromagnetic sidechannel leakage from ongoing computation. Moreover, this information is often conveyed by supposedly-benign channels such as audio recordings and common Voice-over-{IP} applications, even after lossy compression. Thus, we show, it is possible to conduct physical sidechannel attacks on computation by remote and purely passive analysis of commonly-shared channels. These attacks require neither physical proximity (which could be mitigated by distance and shielding), nor the ability to run code on the target or conﬁgure its hardware. Consequently, we argue, physical side channels on {PCs} can no longer be excluded from remoteattack threat models. We analyze the computation-dependent leakage captured by internal microphones, and empirically demonstrate its efﬁcacy for attacks. In one scenario, an attacker steals the secret {ECDSA} signing keys of the counterparty in a voice call. In another, the attacker detects what web page their counterparty is loading. In the third scenario, a player in the Counter-Strike online multiplayer game can detect a hidden opponent waiting in ambush, by analyzing how the 3D rendering done by the opponent’s computer induces faint but detectable signals into the opponent’s audio feed.},
	pages = {18},
	author = {Genkin, Daniel and Nissan, Noam and Schuster, Roei and Tromer, Eran},
	langid = {english},
	file = {Genkin et al. - Lend Me Your Ear Passive Remote Physical Side Cha.pdf:/home/fordrl/Zotero/storage/BTV9ZB6E/Genkin et al. - Lend Me Your Ear Passive Remote Physical Side Cha.pdf:application/pdf},
}

@article{li_towards_nodate,
	title = {{TOWARDS} {PRACTICAL} {INFORMATION} {FLOW} {ANALYSIS}},
	pages = {226},
	author = {Li, Peixuan},
	langid = {english},
	file = {Li - TOWARDS PRACTICAL INFORMATION FLOW ANALYSIS.pdf:/home/fordrl/Zotero/storage/5I3D2KL6/Li - TOWARDS PRACTICAL INFORMATION FLOW ANALYSIS.pdf:application/pdf},
}

@article{bacelar_almeida_formal_2021,
	title = {A Formal Treatment of the Role of Verified Compilers in Secure Computation},
	issn = {2352-2208},
	url = {https://www.sciencedirect.com/science/article/pii/S2352220821000997},
	doi = {10.1016/j.jlamp.2021.100736},
	abstract = {Secure multiparty computation ({SMC}) allows for complex computations over encrypted data. Privacy concerns for cloud applications makes this a highly desired technology and recent performance improvements show that it is practical. To make {SMC} accessible to non-experts and empower its use in varied applications, many domain-specific compilers are being proposed. We review the role of these compilers and provide a formal treatment of the core steps that they perform to bridge the abstraction gap between high-level ideal specifications and efficient {SMC} protocols. Our abstract framework bridges this secure compilation problem across two dimensions: 1) language-based source- to target-level semantic and efficiency gaps, and 2) cryptographic ideal- to real-world security gaps. We link the former to the setting of certified compilation, paving the way to leverage long-run efforts such as {CompCert} in future {SMC} compilers. Security is framed in the standard cryptographic sense. Our results are supported by a machine-checked formalisation carried out in {EasyCrypt}.},
	pages = {100736},
	journaltitle = {Journal of Logical and Algebraic Methods in Programming},
	shortjournal = {Journal of Logical and Algebraic Methods in Programming},
	author = {Bacelar Almeida, José Carlos and Barbosa, Manuel and Barthe, Gilles and Pacheco, Hugo and Pereira, Vitor and Portela, Bernardo},
	urldate = {2021-11-26},
	date = {2021-11-19},
	langid = {english},
	keywords = {formal verification, certified compilation, computer-aided cryptography, {EasyCrypt}, secure compilation, Secure multiparty computation},
	file = {ScienceDirect Snapshot:/home/fordrl/Zotero/storage/5GWF7VFU/S2352220821000997.html:text/html},
}

@inproceedings{debnath_re-engineering_2021,
	location = {New York, {NY}, {USA}},
	title = {On Re-engineering the X.509 {PKI} with Executable Specification for Better Implementation Guarantees},
	isbn = {978-1-4503-8454-4},
	url = {https://doi.org/10.1145/3460120.3484793},
	doi = {10.1145/3460120.3484793},
	series = {{CCS} '21},
	abstract = {The X.509 Public-Key Infrastructure ({PKI}) standard is widely used as a scalable and flexible authentication mechanism. Flaws in X.509 implementations can make relying applications susceptible to impersonation attacks or interoperability issues. In practice, many libraries implementing X.509 have been shown to suffer from flaws that are due to noncompliance with the standard. Developing a compliant implementation is especially hindered by the design complexity, ambiguities, or under-specifications in the standard written in natural languages. In this paper, we set out to alleviate this unsatisfactory state of affairs by re-engineering and formalizing a widely used fragment of the X.509 standard specification, and then using it to develop a high-assurance implementation. Our X.509 specification re-engineering effort is guided by the principle of decoupling the syntactic requirements from the semantic requirements. For formalizing the syntactic requirements of X.509 standard, we observe that a restricted fragment of attribute grammar is sufficient. In contrast, for precisely capturing the semantic requirements imposed on the most-widely used X.509 features, we use quantifier-free first-order logic ({QFFOL}). Interestingly, using {QFFOL} results in an executable specification that can be efficiently enforced by an {SMT} solver. We use these and other insights to develop a high-assurance X.509 implementation named {CERES}. A comparison of {CERES} with 3 mainstream libraries (i.e., {mbedTLS}, {OpenSSL}, and {GnuTLS}) based on 2 million real certificate chains and 2 million synthetic certificate chains shows that {CERES} rightfully rejects malformed and invalid certificates.},
	pages = {1388--1404},
	booktitle = {Proceedings of the 2021 {ACM} {SIGSAC} Conference on Computer and Communications Security},
	publisher = {Association for Computing Machinery},
	author = {Debnath, Joyanta and Chau, Sze Yiu and Chowdhury, Omar},
	urldate = {2021-11-26},
	date = {2021-11-12},
	keywords = {authentication, differential testing, network security, {PKI}, {SMT} solver, {SSL}/{TLS} protocol, X.509 certificate},
	file = {Full Text PDF:/home/fordrl/Zotero/storage/J9AFT3FA/Debnath et al. - 2021 - On Re-engineering the X.509 PKI with Executable Sp.pdf:application/pdf},
}

@online{noauthor_convergence_nodate,
	title = {The convergence of source code and binary vulnerability discovery - A case study {\textbar} {EURECOM}},
	url = {https://www.eurecom.fr/publication/6732},
	urldate = {2021-11-26},
	file = {The convergence of source code and binary vulnerab.pdf:/home/fordrl/Zotero/storage/4XB5EF8H/The convergence of source code and binary vulnerab.pdf:application/pdf;The convergence of source code and binary vulnerability discovery - A case study | EURECOM:/home/fordrl/Zotero/storage/Z869B4BV/6732.html:text/html},
}

@article{ding_velvet_2021,
	title = {{VELVET}: a {noVel} Ensemble Learning approach to automatically locate {VulnErable} {sTatements}},
	url = {http://arxiv.org/abs/2112.10893},
	shorttitle = {{VELVET}},
	abstract = {Automatically locating vulnerable statements in source code is crucial to assure software security and alleviate developers' debugging efforts. This becomes even more important in today's software ecosystem, where vulnerable code can flow easily and unwittingly within and across software repositories like {GitHub}. Across such millions of lines of code, traditional static and dynamic approaches struggle to scale. Although existing machine-learning-based approaches look promising in such a setting, most work detects vulnerable code at a higher granularity -- at the method or file level. Thus, developers still need to inspect a significant amount of code to locate the vulnerable statement(s) that need to be fixed. This paper presents {VELVET}, a novel ensemble learning approach to locate vulnerable statements. Our model combines graph-based and sequence-based neural networks to successfully capture the local and global context of a program graph and effectively understand code semantics and vulnerable patterns. To study {VELVET}'s effectiveness, we use an off-the-shelf synthetic dataset and a recently published real-world dataset. In the static analysis setting, where vulnerable functions are not detected in advance, {VELVET} achieves 4.5x better performance than the baseline static analyzers on the real-world data. For the isolated vulnerability localization task, where we assume the vulnerability of a function is known while the specific vulnerable statement is unknown, we compare {VELVET} with several neural networks that also attend to local and global context of code. {VELVET} achieves 99.6\% and 43.6\% top-1 accuracy over synthetic data and real-world data, respectively, outperforming the baseline deep-learning models by 5.3-29.0\%.},
	journaltitle = {{arXiv}:2112.10893 [cs]},
	author = {Ding, Yangruibo and Suneja, Sahil and Zheng, Yunhui and Laredo, Jim and Morari, Alessandro and Kaiser, Gail and Ray, Baishakhi},
	urldate = {2021-12-27},
	date = {2021-12-20},
	eprinttype = {arxiv},
	eprint = {2112.10893},
	keywords = {Computer Science - Machine Learning, Computer Science - Software Engineering},
	file = {arXiv Fulltext PDF:/home/fordrl/Zotero/storage/8FMZF52V/Ding et al. - 2021 - VELVET a noVel Ensemble Learning approach to auto.pdf:application/pdf;arXiv.org Snapshot:/home/fordrl/Zotero/storage/89D5QDKF/2112.html:text/html},
}

@thesis{hiet_security_2021,
	title = {Security at the Hardware/Software Interface},
	url = {https://hal.archives-ouvertes.fr/tel-03511334},
	institution = {Université de Rennes 1},
	type = {Habilitation à diriger des recherches},
	author = {Hiet, Guillaume},
	urldate = {2022-01-14},
	date = {2021-12},
	keywords = {formal methods, computer security, détection d'intrusion, intrusion detection, intrusion response, méthodes formelles, réponse aux intrusions, sécurité informatique},
	file = {HAL PDF Full Text:/home/fordrl/Zotero/storage/UXR5GSSU/Hiet - 2021 - Security at the HardwareSoftware Interface.pdf:application/pdf},
}

@article{huang_taming_nodate,
	title = {The Taming of the Stack: Isolating Stack Data from Memory Errors},
	abstract = {Despite vast research on defenses to protect stack objects from the exploitation of memory errors, much stack data remains at risk. Historically, stack defenses focus on the protection of code pointers, such as return addresses, but emerging techniques to exploit memory errors motivate the need for practical solutions to protect stack data objects as well. However, recent approaches provide an incomplete view of security by not accounting for memory errors comprehensively and by limiting the set of objects that can be protected unnecessarily. In this paper, we present the {DATAGUARD} system that identiﬁes which stack objects are safe statically from spatial, type, and temporal memory errors to protect those objects efﬁciently. {DATAGUARD} improves security through a more comprehensive and accurate safety analysis that proves a larger number of stack objects are safe from memory errors, while ensuring that no unsafe stack objects are mistakenly classiﬁed as safe. {DATAGUARD}’s analysis of server programs and the {SPEC} {CPU}2006 benchmark suite shows that {DATAGUARD} improves security by: (1) ensuring that no memory safety violations are possible for any stack objects classiﬁed as safe, removing 6.3\% of the stack objects previously classiﬁed safe by the Safe Stack method, and (2) blocking exploit of all 118 stack vulnerabilities in the {CGC} Binaries. {DATAGUARD} extends the scope of stack protection by validating as safe over 70\% of the stack objects classiﬁed as unsafe by the Safe Stack method, leading to an average of 91.45\% of all stack objects that can only be referenced safely. By identifying more functions with only safe stack objects, {DATAGUARD} reduces the overhead of using Clang’s Safe Stack defense for protection of the {SPEC} {CPU}2006 benchmarks from 11.3\% to 4.3\%. Thus, {DATAGUARD} shows that a comprehensive and accurate analysis can both increase the scope of stack data protection and reduce overheads.},
	pages = {17},
	journaltitle = {Network and Distributed Systems Security ({NDSS}) Symposium 2022},
	author = {Huang, Kaiming and Huang, Yongzhe and Payer, Mathias and Qian, Zhiyun and Sampson, Jack and Tan, Gang and Jaeger, Trent},
	langid = {english},
	file = {Huang et al. - The Taming of the Stack Isolating Stack Data from.pdf:/home/fordrl/Zotero/storage/GL2CWI24/Huang et al. - The Taming of the Stack Isolating Stack Data from.pdf:application/pdf},
}

@report{leger_exploring_2021,
	title = {Exploring Explicit Uncertainty for Binary Analysis ({EUBA}).},
	url = {https://www.osti.gov/servlets/purl/1832314/},
	pages = {SAND2021--14600, 1832314, 701941},
	number = {{SAND}2021-14600, 1832314, 701941},
	author = {Leger, Michelle and Darling, Michael and Jones, Stephen and Matzen, Laura and Stracuzzi, David and Wilson, Andrew and Bueno, Denis and Christentsen, Matthew and Ginaldi, Melissa and Hannasch, David and Heidbrink, Scott and Howell, Breannan and Leger, Chris and Reedy, Geoffrey and Rogers, Alisa and Williams, Jack},
	urldate = {2022-01-27},
	date = {2021-11-01},
	langid = {english},
	doi = {10.2172/1832314},
	file = {Exporing Explicit Uncertainty for Binary Analysis (EUBA):/home/fordrl/Zotero/storage/WZX9S6ZL/Leger et al. - 2021 - Exploring Explicit Uncertainty for Binary Analysis.pdf:application/pdf},
}

@article{cowley_job_2014,
	title = {Job Analysis Results for Malicious-Code Reverse Engineers: A Case Study},
	pages = {114},
	author = {Cowley, Jennifer},
	date = {2014-05},
	langid = {english},
	file = {Cowley - Job Analysis Results for Malicious-Code Reverse En.pdf:/home/fordrl/Zotero/storage/3CUF7526/Cowley - Job Analysis Results for Malicious-Code Reverse En.pdf:application/pdf},
}

@article{mazuera-rozo_taxonomy_2022,
	title = {Taxonomy of security weaknesses in Java and Kotlin Android apps},
	issn = {0164-1212},
	url = {https://www.sciencedirect.com/science/article/pii/S0164121222000103},
	doi = {10.1016/j.jss.2022.111233},
	abstract = {Android is nowadays the most popular operating system in the world, not only in the realm of mobile devices, but also when considering desktop and laptop computers. Such a popularity makes it an attractive target for security attacks, also due to the sensitive information often manipulated by mobile apps. The latter are going through a transition in which the Android ecosystem is moving from the usage of Java as the official language for developing apps, to the adoption of Kotlin as the first choice supported by Google. While previous studies have partially studied security weaknesses affecting Java Android apps, there is no comprehensive empirical investigation studying software security weaknesses affecting Android apps considering (and comparing) the two main languages used for their development, namely Java and Kotlin. We present an empirical study in which we: (i) manually analyze 681 commits including security weaknesses fixed by developers in Java and Kotlin apps, with the goal of defining a taxonomy highlighting the types of software security weaknesses affecting Java and Kotlin Android apps; (ii) survey 43 Android developers to validate and complement our taxonomy. Based on our findings, we propose a list of future actions that could be performed by researchers and practitioners to improve the security of Android apps.},
	pages = {111233},
	journaltitle = {Journal of Systems and Software},
	shortjournal = {Journal of Systems and Software},
	author = {Mazuera-Rozo, Alejandro and Escobar-Velásquez, Camilo and Espitia-Acero, Juan and Vega-Guzmán, David and Trubiani, Catia and Linares-Vásquez, Mario and Bavota, Gabriele},
	urldate = {2022-02-08},
	date = {2022-01-31},
	langid = {english},
	keywords = {Security, Android},
	file = {Submitted Version:/home/fordrl/Zotero/storage/R6JB4STH/Mazuera-Rozo et al. - 2022 - Taxonomy of security weaknesses in Java and Kotlin.pdf:application/pdf;ScienceDirect Snapshot:/home/fordrl/Zotero/storage/NSB6YB9A/S0164121222000103.html:text/html},
}

@thesis{garcia_side-channel_nodate,
	title = {Side-Channel Analysis and Cryptography Engineering - Getting {OpenSSL} Closer to Constant-Time},
	url = {https://trepo.tuni.fi/bitstream/handle/10024/137100/978-952-03-2289-2.pdf?sequence=2},
	type = {phdthesis},
	author = {{GARCÍA}, {CESAR} {PEREIDA}},
	urldate = {2022-02-08},
	file = {978-952-03-2289-2.pdf:/home/fordrl/Zotero/storage/YNWJLTIV/978-952-03-2289-2.pdf:application/pdf},
}

@article{potteiger_moving_2022,
	title = {Moving target defense for the security and resilience of mixed time and event triggered cyber-physical systems},
	issn = {1383-7621},
	url = {https://www.sciencedirect.com/science/article/pii/S1383762122000212},
	doi = {10.1016/j.sysarc.2022.102420},
	abstract = {Memory corruption attacks such as code injection, code reuse, and non-control data attacks have become widely popular for compromising safety-critical Cyber-Physical Systems ({CPS}). Moving target defense ({MTD}) techniques such as instruction set randomization ({ISR}), address space randomization ({ASR}), and data space randomization ({DSR}) can be used to protect systems against such attacks. {CPS} often use time-triggered architectures to guarantee predictable and reliable operation. {MTD} techniques can cause time delays with unpredictable behavior. To protect {CPS} against memory corruption attacks, {MTD} techniques can be implemented in a mixed time and event-triggered architecture that provides capabilities for maintaining safety and availability during an attack. This paper presents a mixed time and event-triggered {MTD} security approach based on the {ARINC} 653 architecture that provides predictable and reliable operation during normal operation and rapid detection and reconfiguration upon detection of attacks. We leverage a hardware-in-the-loop testbed and an advanced emergency braking system ({AEBS}) case study to show the effectiveness of our approach.},
	pages = {102420},
	journaltitle = {Journal of Systems Architecture},
	shortjournal = {Journal of Systems Architecture},
	author = {Potteiger, Bradley and Dubey, Abhishek and Cai, Feiyang and Koutsoukos, Xenofon and Zhang, Zhenkai},
	urldate = {2022-02-11},
	date = {2022-02-05},
	langid = {english},
	keywords = {Cyber-physical systems, Event triggered, Moving target defense, Time triggered},
	file = {ScienceDirect Snapshot:/home/fordrl/Zotero/storage/YK2NYAF8/S1383762122000212.html:text/html},
}

@report{janson_sponge-based_2022,
	title = {Sponge-based Authenticated Encryption: Security against Quantum Attackers},
	url = {http://eprint.iacr.org/2022/139},
	shorttitle = {Sponge-based Authenticated Encryption},
	abstract = {In this work, we study the security of sponge-based authenticated encryption schemes against quantum attackers. In particular, we analyse the sponge-based authenticated encryption scheme {SLAE} as put forward by Degabriele et al. ({ASIACRYPT}'19). We show that the scheme achieves security in the post-quantum ({QS}1) setting in the quantum random oracle model by using the one-way to hiding lemma. Furthermore, we analyse the scheme in a fully-quantum ({QS}2) setting. There we provide a set of attacks showing that {SLAE} does not achieve ciphertext indistinguishability and hence overall does not provide the desired level of security.},
	number = {139},
	author = {Janson, Christian and Struck, Patrick},
	urldate = {2022-02-13},
	date = {2022},
	keywords = {secret-key cryptography},
	file = {ePrint IACR Snapshot:/home/fordrl/Zotero/storage/9QGXI5S4/139.html:text/html;ePrint IACR Full Text PDF:/home/fordrl/Zotero/storage/64TBCH2U/Janson and Struck - 2022 - Sponge-based Authenticated Encryption Security ag.pdf:application/pdf},
}

@report{bertoni_sponge_nodate,
	title = {Sponge Functions},
	url = {https://keccak.team/files/SpongeFunctions.pdf},
	abstract = {A good cryptographic hash function should behave like a random oracle: it should
not have weaknesses that a random oracle does not have. Due to the existence of inner collisions,
iterated hash functions can never satisfy this ideal. We propose a construction with a finite
state called a sponge and show that a random sponge can only be distinguished from a random
oracle due to inner collisions. We evaluate the strength of random sponges by computing the
probability of success for a number of attacks as a function of their workload and show that
these results shed a new light on the classical Merkle-Damg˚ard construction. We propose to
use random sponges of given parameters as a reference for specifying security claims for hash
functions, but also {MAC} functions and some types of stream ciphers. The main goal of sponge
functions is for designers to be able to formulate a compact security claim.},
	institution = {{STMicroelectronics}, Radbound University},
	author = {Bertoni, Guido and Daemen, Joan and Peeters, Micha¨el},
	urldate = {2022-02-13},
	file = {SpongeFunctions.pdf:/home/fordrl/Zotero/storage/KTLKPXTS/SpongeFunctions.pdf:application/pdf},
}

@article{zou_buddy_2022,
	title = {Buddy Stacks: Protecting Return Addresses with Efficient Thread-Local Storage and Runtime Re-Randomization},
	volume = {31},
	issn = {1049-331X},
	url = {https://doi.org/10.1145/3494516},
	doi = {10.1145/3494516},
	shorttitle = {Buddy Stacks},
	abstract = {Shadow stacks play an important role in protecting return addresses to mitigate {ROP} attacks. Parallel shadow stacks, which shadow the call stack of each thread at the same constant offset for all threads, are known not to support multi-threading well. On the other hand, compact shadow stacks must maintain a separate shadow stack pointer in thread-local storage ({TLS}), which can be implemented in terms of a register or the per-thread Thread-Control-Block ({TCB}), suffering from poor compatibility in the former or high performance overhead in the latter. In addition, shadow stacks are vulnerable to information disclosure attacks. In this paper, we propose to mitigate {ROP} attacks for single- and multi-threaded server programs running on general-purpose computing systems by using a novel stack layout, called a buddy stack (referred to as Bustk), that is highly performant, compatible with existing code, and provides meaningful security. These goals are met due to three novel design aspects in Bustk. First, Bustk places a parallel shadow stack just below a thread’s call stack (as each other’s buddies allocated together), avoiding the need to maintain a separate shadow stack pointer and making it now well-suited for multi-threading. Second, Bustk uses an efficient stack-based thread-local storage mechanism, denoted {STK}-{TLS}, to store thread-specific metadata in two {TLS} sections just below the shadow stack in dual redundancy (as each other’s buddies), so that both can be accessed and updated in a lightweight manner from the call stack pointer rsp alone. Finally, Bustk re-randomizes continuously (on the order of milliseconds) the return addresses on the shadow stack by using a new microsecond-level runtime re-randomization technique, denoted {STK}-{MSR}. This mechanism aims to obsolete leaked information, making it extremely unlikely for the attacker to hijack return addresses, particularly against a server program that sits often tens of milliseconds away from the attacker. Our evaluation using web servers, Nginx and Apache Httpd, shows that Bustk works well in terms of performance, compatibility, and security provided, with its parallel shadow stacks incurring acceptable memory overhead for real-world applications and its {STK}-{TLS} mechanism costing only two pages per thread. In particular, Bustk can protect the Nginx and Apache servers with an adaptive 1-ms re-randomization policy (without observable overheads when {IO} is intensive, with about 17,000 requests per second). In addition, we have also evaluated Bustk using other non-server applications, Firefox, Python, {LLVM}, {JDK} and {SPEC} {CPU}2006, to demonstrate further the same degree of performance and compatibility provided, but the protection provided for, say, browsers, is weaker (since network-access delays can no longer be assumed).},
	pages = {35e:1--35e:37},
	number = {2},
	journaltitle = {{ACM} Transactions on Software Engineering and Methodology},
	shortjournal = {{ACM} Trans. Softw. Eng. Methodol.},
	author = {Zou, Changwei and Wang, Xudong and Gao, Yaoqing and Xue, Jingling},
	urldate = {2022-03-08},
	date = {2022-03-04},
	keywords = {buddy stack, {CFI}, {ROP}, runtime re-randomization, Shadow stack},
	file = {Full Text PDF:/home/fordrl/Zotero/storage/8ES933EK/Zou et al. - 2022 - Buddy Stacks Protecting Return Addresses with Eff.pdf:application/pdf},
}

@article{bernhard_xtag_2022,
	title = {{xTag}: Mitigating Use-After-Free Vulnerabilities via Software-Based Pointer Tagging on Intel x86-64},
	url = {http://arxiv.org/abs/2203.04117},
	shorttitle = {{xTag}},
	abstract = {Memory safety in complex applications implemented in unsafe programming languages such as C/C++ is still an unresolved problem in practice. Many different types of defenses have been proposed in the past to mitigate this problem. The most promising next step is a tighter integration of the hardware and software level: modern mitigation techniques are either accelerated using hardware extensions or implemented in the hardware by extensions of the {ISA}. In particular, memory tagging, as proposed by {ARM} or {SPARC}, promises to solve many issues for practical memory safety. Unfortunately, Intel x86-64, which represents the most important {ISA} for both the desktop and server domain, lacks support for hardware-accelerated memory tagging, so memory tagging is not considered practical for this platform. In this paper, we present the design and implementation of an efficient, software-only pointer tagging scheme for Intel x86-64 based on a novel metadata embedding scheme. The basic idea is to alias multiple virtual pages to one physical page so that we can efficiently embed tag bits into a pointer. Furthermore, we introduce several optimizations that significantly reduce the performance impact of this approach to memory tagging. Based on this scheme, we propose a novel use-after-free mitigation scheme, called {xTag}, that offers better performance and strong security properties compared to state-of-the-art methods. We also show how double-free vulnerabilities can be mitigated. Our approach is highly compatible, allowing pointers to be passed back and forth between instrumented and non-instrumented code without losing metadata, and it is even compatible with inline assembly. We conclude that building exploit mitigation mechanisms on top of our memory tagging scheme is feasible on Intel x86-64, as demonstrated by the effective prevention of use-after-free bugs in the Firefox web browser.},
	journaltitle = {{arXiv}:2203.04117 [cs]},
	author = {Bernhard, Lukas and Rodler, Michael and Holz, Thorsten and Davi, Lucas},
	urldate = {2022-03-14},
	date = {2022-03-08},
	eprinttype = {arxiv},
	eprint = {2203.04117},
	keywords = {Computer Science - Cryptography and Security},
	file = {arXiv Fulltext PDF:/home/fordrl/Zotero/storage/7B2QN7KE/Bernhard et al. - 2022 - xTag Mitigating Use-After-Free Vulnerabilities vi.pdf:application/pdf;arXiv.org Snapshot:/home/fordrl/Zotero/storage/4VQS33WD/2203.html:text/html},
}