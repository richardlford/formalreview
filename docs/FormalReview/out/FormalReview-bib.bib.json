{
  "_preamble": "",
  "_comments": "",
  "calcagno_compositional_2011": {
    "id": "calcagno_compositional_2011",
    "type": "article-journal",
    "author": [
      {
        "family": "Calcagno",
        "given": "Cristiano"
      },
      {
        "family": "Distefano",
        "given": "Dino"
      },
      {
        "family": "O’Hearn",
        "given": "Peter W."
      },
      {
        "family": "Yang",
        "given": "Hongseok"
      }
    ],
    "title": "Compositional Shape Analysis by Means of Bi-Abduction",
    "container-title": "Journal of the ACM",
    "issued": {
      "date-parts": [
        [
          "2011",
          "12",
          "1"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "1",
          "30"
        ]
      ]
    },
    "issn": "00045411",
    "URL": "http://dl.acm.org/citation.cfm?doid=2049697.2049700",
    "DOI": "10.1145/2049697.2049700",
    "page": "1-66",
    "page-first": "1",
    "volume": "58",
    "issue": "6",
    "language": "en-US",
    "_line": "FormalReview.bib:2"
  },
  "krishnan_modelling_2018": {
    "id": "krishnan_modelling_2018",
    "type": "paper-conference",
    "author": [
      {
        "family": "Krishnan",
        "given": "Ranjani"
      },
      {
        "family": "Lalithambika",
        "given": "V R"
      }
    ],
    "title": "Modelling and validating 1553B protocol using the SPIN model checker",
    "container-title": "2018 10th International Conference on Communication Systems &amp; Networks (COMSNETS)",
    "event-title": "2018 10th International Conference on Communication Systems &amp; Networks (COMSNETS)",
    "issued": {
      "date-parts": [
        [
          "2018",
          "1"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "1",
          "31"
        ]
      ]
    },
    "publisher": "IEEE",
    "isbn": "978-1-5386-1182-1",
    "URL": "http://ieeexplore.ieee.org/document/8328247/",
    "DOI": "10.1109/COMSNETS.2018.8328247",
    "publisher-place": "Bengaluru",
    "page": "472-475",
    "page-first": "472",
    "note": "1553B/08328247.pdf",
    "_line": "FormalReview.bib:18"
  },
  "jung_rustbelt:_2017": {
    "id": "jung_rustbelt:_2017",
    "type": "article-journal",
    "author": [
      {
        "family": "Jung",
        "given": "Ralf"
      },
      {
        "family": "Jourdan",
        "given": "Jacques-Henri"
      },
      {
        "family": "Krebbers",
        "given": "Robbert"
      },
      {
        "family": "Dreyer",
        "given": "Derek"
      }
    ],
    "title": "RustBelt: securing the foundations of the rust programming language",
    "container-title": "Proceedings of the ACM on Programming Languages",
    "container-title-short": "RustBelt",
    "title-short": "RustBelt",
    "issued": {
      "date-parts": [
        [
          "2017",
          "12",
          "27"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "1",
          "31"
        ]
      ]
    },
    "issn": "24751421",
    "URL": "http://dl.acm.org/citation.cfm?doid=3177123.3158154",
    "DOI": "10.1145/3158154",
    "page": "1-34",
    "page-first": "1",
    "volume": "2",
    "language": "en-US",
    "_line": "FormalReview.bib:34"
  },
  "ohearn_separation_2019": {
    "id": "ohearn_separation_2019",
    "type": "article-journal",
    "author": [
      {
        "family": "O'Hearn",
        "given": "Peter"
      }
    ],
    "title": "Separation logic",
    "container-title": "Communications of the ACM",
    "issued": {
      "date-parts": [
        [
          "2019",
          "1",
          "28"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "1",
          "31"
        ]
      ]
    },
    "issn": "00010782",
    "URL": "http://dl.acm.org/citation.cfm?doid=3310134.3211968",
    "DOI": "10.1145/3211968",
    "page": "86-95",
    "page-first": "86",
    "volume": "62",
    "issue": "2",
    "language": "en-US",
    "_line": "FormalReview.bib:51"
  },
  "ohearn_peter_nodate": {
    "id": "ohearn_peter_nodate",
    "type": "no-type",
    "author": [
      {
        "family": "O'Hearn",
        "given": "Peter W."
      }
    ],
    "title": "Peter W O'hearn - acm profile",
    "URL": "https://dl.acm.org/author_page.cfm?id=81332519314&coll=DL&dl=ACM&trk=0",
    "_line": "FormalReview.bib:66"
  },
  "gorogiannis_true_2019": {
    "id": "gorogiannis_true_2019",
    "type": "article-journal",
    "author": [
      {
        "family": "Gorogiannis",
        "given": "Nikos"
      },
      {
        "family": "O'Hearn",
        "given": "Peter W."
      },
      {
        "family": "Sergey",
        "given": "Ilya"
      }
    ],
    "title": "A true positives theorem for a static race detector",
    "container-title": "Proceedings of the ACM on Programming Languages",
    "issued": {
      "date-parts": [
        [
          "2019",
          "1",
          "2"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "1",
          "31"
        ]
      ]
    },
    "issn": "24751421",
    "URL": "http://dl.acm.org/citation.cfm?doid=3302515.3290370",
    "DOI": "10.1145/3290370",
    "page": "1-29",
    "page-first": "1",
    "volume": "3",
    "language": "en-US",
    "_line": "FormalReview.bib:72"
  },
  "ohearn_continuous_2018": {
    "id": "ohearn_continuous_2018",
    "type": "paper-conference",
    "author": [
      {
        "family": "O'Hearn",
        "given": "Peter W."
      }
    ],
    "title": "Continuous Reasoning: Scaling the impact of formal methods",
    "container-title": "Proceedings of the 33rd Annual ACM/IEEE Symposium on Logic in Computer Science  - LICS '18",
    "container-title-short": "Continuous Reasoning",
    "title-short": "Continuous Reasoning",
    "event-title": "the 33rd Annual ACM/IEEE Symposium",
    "issued": {
      "date-parts": [
        [
          "2018"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "1",
          "31"
        ]
      ]
    },
    "publisher": "ACM Press",
    "isbn": "978-1-4503-5583-4",
    "URL": "http://dl.acm.org/citation.cfm?doid=3209108.3209109",
    "DOI": "10.1145/3209108.3209109",
    "publisher-place": "Oxford, United Kingdom",
    "page": "13-25",
    "page-first": "13",
    "language": "en-US",
    "_line": "FormalReview.bib:88"
  },
  "brookes_concurrent_2016": {
    "id": "brookes_concurrent_2016",
    "type": "article-journal",
    "author": [
      {
        "family": "Brookes",
        "given": "Stephen"
      },
      {
        "family": "O'Hearn",
        "given": "Peter W."
      }
    ],
    "title": "Concurrent Separation Logic",
    "container-title": "ACM SIGLOG News",
    "issued": {
      "date-parts": [
        [
          "2016",
          "8"
        ]
      ]
    },
    "issn": "2372-3491",
    "URL": "http://doi.acm.org/10.1145/2984450.2984457",
    "DOI": "10.1145/2984450.2984457",
    "page": "47-65",
    "page-first": "47",
    "volume": "3",
    "issue": "3",
    "_line": "FormalReview.bib:106"
  },
  "brookes_semantics_2007": {
    "id": "brookes_semantics_2007",
    "type": "article-journal",
    "author": [
      {
        "family": "Brookes",
        "given": "Stephen"
      }
    ],
    "title": "A semantics for concurrent separation logic",
    "container-title": "Theoretical Computer Science",
    "issued": {
      "date-parts": [
        [
          "2007",
          "5"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "1",
          "31"
        ]
      ]
    },
    "issn": "03043975",
    "URL": "https://linkinghub.elsevier.com/retrieve/pii/S0304397506009248",
    "DOI": "10.1016/j.tcs.2006.12.034",
    "page": "227-270",
    "page-first": "227",
    "volume": "375",
    "issue": "1",
    "language": "en-US",
    "_line": "FormalReview.bib:119"
  },
  "ohearn_categorical_2015": {
    "id": "ohearn_categorical_2015",
    "type": "paper-conference",
    "author": [
      {
        "family": "O'Hearn",
        "given": "Peter"
      }
    ],
    "title": "From Categorical Logic to Facebook Engineering",
    "container-title": "Proceedings of the 2015 30th Annual ACM/IEEE Symposium on Logic in Computer Science (LICS)",
    "collection-title": "LICS '15",
    "issued": {
      "date-parts": [
        [
          "2015"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "1",
          "31"
        ]
      ]
    },
    "publisher": "IEEE Computer Society",
    "isbn": "978-1-4799-8875-4",
    "URL": "https://doi.org/10.1109/LICS.2015.11",
    "DOI": "10.1109/LICS.2015.11",
    "publisher-place": "Washington, DC, USA",
    "page": "17-20",
    "page-first": "17",
    "_line": "FormalReview.bib:135"
  },
  "wikipedia_category:formal_2017": {
    "id": "wikipedia_category:formal_2017",
    "type": "entry-encyclopedia",
    "author": [
      {
        "family": "Wikipedia"
      }
    ],
    "title": "Category:Formal methods people",
    "container-title": "Wikipedia",
    "container-title-short": "Category",
    "title-short": "Category",
    "issued": {
      "date-parts": [
        [
          "2017",
          "11",
          "29"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "1",
          "31"
        ]
      ]
    },
    "abstract": "People involved with formal methods.",
    "URL": "https://en.wikipedia.org/w/index.php?title=Category:Formal_methods_people&oldid=812800009",
    "note": "Page Version ID: 812800009",
    "language": "en-US",
    "_line": "FormalReview.bib:151"
  },
  "qureshi_formal_nodate": {
    "id": "qureshi_formal_nodate",
    "type": "article-journal",
    "author": [
      {
        "family": "Qureshi",
        "given": "Zahid H"
      }
    ],
    "title": "Formal Modelling and Analysis of Mission-Critical Software in Military Avionics Systems",
    "container-title": "11th Australian Workshop on Safety Related Programmable Systems (SCS’06)",
    "abstract": "A typical avionics mission system of a military aircraft is a complex real-time system consisting of a mission control computer, different kinds of sensors, navigation and communication subsystems, and various displays and stores; all interconnected by a number of serial data buses. The mission capability is increasingly implemented in the mission-critical software and the robustness of this software is vital for mission success. The complexity and real-time requirements of mission systems represent major challenges to the Australian Defence Force during new acquisitions, upgrades and maintenance. This paper describes the experiences on a joint research project between the University of South Australia and Australia’s Defence Science and Technology Organisation into the modelling and analysis of avionics mission systems. The paper provides a summary of the key aspects of our previous research work on the modelling of a generic mission system using Coloured Petri Nets and the analysis of task scheduling on the mission computer. Finally, the paper briefly discusses the extension of the generic model to obtain a formal model of the mission system of the AP3C Orion maritime surveillance aircraft..",
    "URL": "http://crpit.com/confpapers/CRPITV69Qureshi.pdf",
    "page": "11",
    "page-first": "11",
    "language": "en-US",
    "_line": "FormalReview.bib:166"
  },
  "conchon_alt-ergo_2018": {
    "id": "conchon_alt-ergo_2018",
    "type": "paper-conference",
    "author": [
      {
        "family": "Conchon",
        "given": "Sylvain"
      },
      {
        "family": "Coquereau",
        "given": "Albin"
      },
      {
        "family": "Iguernlala",
        "given": "Mohamed"
      },
      {
        "family": "Mebsout",
        "given": "Alain"
      }
    ],
    "title": "Alt-Ergo 2.2",
    "container-title": "SMT Workshop: International Workshop on Satisfiability Modulo Theories",
    "issued": {
      "date-parts": [
        [
          "2018",
          "7"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "1",
          "31"
        ]
      ]
    },
    "abstract": "Alt-Ergo is an SMT solver jointly developed by Université Paris-Sud and the OCamlPro company. The first version was released in 2006. Since then, its architecture has been continuously adapted for proving formulas generated by software development frameworks. As type systems with polymorphism arise naturally is such platforms, the design of Alt-Ergo has been guided (and constrained) by a native-and non SMT-LIB compliant-input language for a polymorphic first-order logic. In this paper, we present the last version of Alt-Ergo, its architecture and main features. The main recent work is a support for a conservative polymorphic extension of the SMT-LIB 2 standard. We measure Alt-Ergo's performances with this new frontend on a set of benchmarks coming from the deductive program verification systems Frama-C, SPARK 2014, Why3 and Atelier-B, as well as from the SMT-LIB benchmarks library.",
    "URL": "https://hal.inria.fr/hal-01960203",
    "publisher-place": "Oxford, United Kingdom",
    "note": "alt-ergo/Alt-Ergo-2.2&ndash;SMT-Workshop-2018.pdf",
    "_line": "FormalReview.bib:177"
  },
  "conchon_increasing_2016": {
    "id": "conchon_increasing_2016",
    "type": "paper-conference",
    "author": [
      {
        "family": "Conchon",
        "given": "Sylvain"
      },
      {
        "family": "Iguernlala",
        "given": "Mohamed"
      }
    ],
    "editor": [
      {
        "family": "Lecomte",
        "given": "Thierry"
      },
      {
        "family": "Pinger",
        "given": "Ralf"
      },
      {
        "family": "Romanovsky",
        "given": "Alexander"
      }
    ],
    "title": "Increasing Proofs Automation Rate of Atelier-B Thanks to Alt-Ergo",
    "container-title": "Reliability, Safety, and Security of Railway Systems. Modelling, Analysis, Verification, and Certification",
    "collection-title": "Lecture Notes in Computer Science",
    "issued": {
      "date-parts": [
        [
          "2016"
        ]
      ]
    },
    "publisher": "Springer International Publishing",
    "isbn": "978-3-319-33951-1",
    "abstract": "In this paper, we report on our recent improvements in the Alt-Ergo SMT solver to make it effective in discharging proof obligations (POs) translated from the Atelier-B framework. In particular, we made important modifications in its internal data structures to boost performances of its core decision procedures, we improved quantifiers instantiation heuristics, and enhanced the interaction between the SAT solver and the decision procedures. We also introduced a new plugin architecture to facilitate experiments with different SAT engines, and implemented a profiling plugin to track and identify “bottlenecks” when a formula requires a long time to be discharged, or makes the solver timeout. Experiments made with more than 10,000 POs generated from real industrial B projects show significant improvements compared to both previous versions of Alt-Ergo and Atelier-B’s automatic main prover.",
    "keywords": "B method, B proof obligations, SMT solvers",
    "page": "243-253",
    "page-first": "243",
    "note": "alt-ergo/Alt-Ergo&ndash;Atelier-B&ndash;RSSR-2016.pdf",
    "language": "en-US",
    "_line": "FormalReview.bib:190"
  },
  "altenkirch_quotient_2018": {
    "id": "altenkirch_quotient_2018",
    "type": "article-journal",
    "author": [
      {
        "family": "Altenkirch",
        "given": "Thorsten"
      },
      {
        "family": "Capriotti",
        "given": "Paolo"
      },
      {
        "family": "Dijkstra",
        "given": "Gabe"
      },
      {
        "family": "Kraus",
        "given": "Nicolai"
      },
      {
        "family": "Forsberg",
        "given": "Fredrik Nordvall"
      }
    ],
    "title": "Quotient inductive-inductive types",
    "container-title": "arXiv:1612.02346 \\[cs\\]",
    "issued": {
      "date-parts": [
        [
          "2018"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "1",
          "31"
        ]
      ]
    },
    "abstract": "Higher inductive types (HITs) in Homotopy Type Theory (HoTT) allow the definition of datatypes which have constructors for equalities over the defined type. HITs generalise quotient types and allow to define types which are not sets in the sense of HoTT (i.e. do not satisfy uniqueness of equality proofs) such as spheres, suspensions and the torus. However, there are also interesting uses of HITs to define sets, such as the Cauchy reals, the partiality monad, and the internal, total syntax of type theory. In each of these examples we define several types that depend on each other mutually, i.e. they are inductive-inductive definitions. We call those HITs quotient inductive-inductive types (QIITs). Although there has been recent progress on the general theory of HITs, there isn't yet a theoretical foundation of the combination of equality constructors and induction-induction, despite having many interesting applications. In the present paper we present a first step towards a semantic definition of QIITs. In particular, we give an initial-algebra semantics and show that this is equivalent to the section induction principle, which justifies the intuitively expected elimination rules.",
    "keywords": "03B15 (Primary) 18C10 (Secondary), Computer Science - Logic in Computer Science",
    "URLtext": "1612.02346,",
    "URLpretext": "[arXiv:]{.etype}",
    "eprint-type": "arxiv",
    "eprint": "1612.02346,",
    "URL": "http://arxiv.org/abs/1612.02346",
    "DOI": "10.1007/978-3-319-89366-2_16",
    "page": "293-310",
    "page-first": "293",
    "volume": "10803",
    "note": "altenkirch/Quotient&underscore;inductive-inductive&underscore;types.pdf",
    "_line": "FormalReview.bib:207"
  },
  "hritcu_micro-policies:_2015": {
    "id": "hritcu_micro-policies:_2015",
    "type": "paper-conference",
    "author": [
      {
        "family": "Hriţcu",
        "given": "Cǎtǎlin"
      }
    ],
    "title": "Micro-Policies: Formally Verified, Tag-Based Security Monitors",
    "container-title": "Proceedings of the 10th ACM Workshop on Programming Languages and Analysis for Security - PLAS'15",
    "container-title-short": "Micro-Policies",
    "title-short": "Micro-Policies",
    "event-title": "the 10th ACM Workshop",
    "issued": {
      "date-parts": [
        [
          "2015"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "1",
          "31"
        ]
      ]
    },
    "publisher": "ACM Press",
    "isbn": "978-1-4503-3661-1",
    "URL": "http://dl.acm.org/citation.cfm?doid=2786558.2786560",
    "DOI": "10.1145/2786558.2786560",
    "publisher-place": "Prague, Czech Republic",
    "page": "1-1",
    "page-first": "1",
    "note": "amorim/nicro-policies.pdf",
    "language": "en-US",
    "_line": "FormalReview.bib:225"
  },
  "hobor_theory_2010": {
    "id": "hobor_theory_2010",
    "type": "paper-conference",
    "author": [
      {
        "family": "Hobor",
        "given": "Aquinas"
      },
      {
        "family": "Dockins",
        "given": "Robert"
      },
      {
        "family": "Appel",
        "given": "Andrew W."
      }
    ],
    "title": "A Theory of Indirection via Approximation",
    "container-title": "Proceedings of the 37th Annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages",
    "collection-title": "POPL '10",
    "issued": {
      "date-parts": [
        [
          "2010"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "1",
          "31"
        ]
      ]
    },
    "publisher": "ACM",
    "isbn": "978-1-60558-479-9",
    "abstract": "Building semantic models that account for various kinds of indirect reference has traditionally been a difficult problem. Indirect reference can appear in many guises, such as heap pointers, higher-order functions, object references, and shared-memory mutexes. We give a general method to construct models containing indirect reference by presenting a \"theory of indirection\". Our method can be applied in a wide variety of settings and uses only simple, elementary mathematics. In addition to various forms of indirect reference, the resulting models support powerful features such as impredicative quantification and equirecursion; moreover they are compatible with the kind of powerful substructural accounting required to model (higher-order) separation logic. In contrast to previous work, our model is easy to apply to new settings and has a simple axiomatization, which is complete in the sense that all models of it are isomorphic. Our proofs are machine-checked in Coq.",
    "keywords": "indirection theory, step-indexed models",
    "URL": "http://doi.acm.org/10.1145/1706299.1706322",
    "DOI": "10.1145/1706299.1706322",
    "publisher-place": "New York, NY, USA",
    "page": "171-184",
    "page-first": "171",
    "_line": "FormalReview.bib:243"
  },
  "cao_vst-floyd:_2018": {
    "id": "cao_vst-floyd:_2018",
    "type": "article-journal",
    "author": [
      {
        "family": "Cao",
        "given": "Qinxiang"
      },
      {
        "family": "Beringer",
        "given": "Lennart"
      },
      {
        "family": "Gruetter",
        "given": "Samuel"
      },
      {
        "family": "Dodds",
        "given": "Josiah"
      },
      {
        "family": "Appel",
        "given": "Andrew W."
      }
    ],
    "title": "VST-Floyd: A Separation Logic Tool to Verify Correctness of C Programs",
    "container-title": "J. Autom. Reason.",
    "container-title-short": "VST-Floyd",
    "title-short": "VST-Floyd",
    "issued": {
      "date-parts": [
        [
          "2018",
          "6"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "1",
          "31"
        ]
      ]
    },
    "issn": "0168-7433",
    "abstract": "The Verified Software Toolchain builds foundational machine-checked proofs of the functional correctness of C programs. Its program logic, Verifiable C, is a shallowly embedded higher-order separation Hoare logic which is proved sound in Coq with respect to the operational semantics of CompCert Clight. This paper introduces VST-Floyd, a verification assistant which offers a set of semiautomatic tactics helping users build functional correctness proofs for C programs using Verifiable C.",
    "keywords": "Program verification, Proof automation, Separation logic, Symbolic execution",
    "URL": "https://doi.org/10.1007/s10817-018-9457-5",
    "DOI": "10.1007/s10817-018-9457-5",
    "page": "367-422",
    "page-first": "367",
    "volume": "61",
    "issue": "1",
    "_line": "FormalReview.bib:261"
  },
  "hutchison_verified_2014": {
    "id": "hutchison_verified_2014",
    "type": "chapter",
    "author": [
      {
        "family": "Beringer",
        "given": "Lennart"
      },
      {
        "family": "Stewart",
        "given": "Gordon"
      },
      {
        "family": "Dockins",
        "given": "Robert"
      },
      {
        "family": "Appel",
        "given": "Andrew W."
      }
    ],
    "editor": [
      {
        "family": "Shao",
        "given": "Zhong"
      }
    ],
    "title": "Verified Compilation for Shared-Memory C",
    "container-title": "Programming Languages and Systems",
    "issued": {
      "date-parts": [
        [
          "2014"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "1",
          "31"
        ]
      ]
    },
    "publisher": "Springer Berlin Heidelberg",
    "isbn": "978-3-642-54832-1 978-3-642-54833-8",
    "URL": "http://link.springer.com/10.1007/978-3-642-54833-8_7",
    "DOI": "10.1007/978-3-642-54833-8_7,",
    "publisher-place": "Berlin, Heidelberg",
    "page": "107-127",
    "page-first": "107",
    "volume": "8410",
    "note": "appel/shmemc.pdf is a preview",
    "_line": "FormalReview.bib:279"
  },
  "appel_verifiabble_2014": {
    "id": "appel_verifiabble_2014",
    "type": "book",
    "author": [
      {
        "family": "Appel",
        "given": "Andrew W."
      },
      {
        "family": "Dockins",
        "given": "Robert"
      },
      {
        "family": "Hobor",
        "given": "Aquinas"
      },
      {
        "family": "Beringer",
        "given": "Lennart"
      },
      {
        "family": "Dodds",
        "given": "Josiah"
      },
      {
        "family": "Stewart",
        "given": "Gordon"
      },
      {
        "family": "Blazy",
        "given": "Sandrine"
      },
      {
        "family": "Leroy",
        "given": "Xavier"
      }
    ],
    "title": "Verifiabble C, Version 2.2",
    "issued": {
      "date-parts": [
        [
          "2014"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "1",
          "31"
        ]
      ]
    },
    "publisher": "Cambridge University Press",
    "isbn": "978-1-107-25655-2",
    "URL": "http://ebooks.cambridge.org/ref/id/CBO9781107256552",
    "DOI": "10.1017/CBO9781107256552",
    "publisher-place": "Cambridge",
    "language": "en-US",
    "_line": "FormalReview.bib:299"
  },
  "appel_verification_2015": {
    "id": "appel_verification_2015",
    "type": "article-journal",
    "author": [
      {
        "family": "Appel",
        "given": "Andrew W."
      }
    ],
    "title": "Verification of a Cryptographic Primitive: SHA-256",
    "container-title": "ACM Trans. Program. Lang. Syst.",
    "container-title-short": "Verification of a Cryptographic Primitive",
    "title-short": "Verification of a Cryptographic Primitive",
    "issued": {
      "date-parts": [
        [
          "2015",
          "4"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "1",
          "31"
        ]
      ]
    },
    "issn": "0164-0925",
    "abstract": "This article presents a full formal machine-checked verification of a C program: the OpenSSL implementation of SHA-256. This is an interactive proof of functional correctness in the Coq proof assistant, using the Verifiable C program logic. Verifiable C is a separation logic for the C language, proved sound with respect to the operational semantics for C, connected to the CompCert verified optimizing C compiler.",
    "keywords": "Cryptography",
    "URL": "http://doi.acm.org/10.1145/2701415",
    "DOI": "10.1145/2701415",
    "page": "7:1-7:31",
    "page-first": "7",
    "volume": "37",
    "issue": "2",
    "_line": "FormalReview.bib:313"
  },
  "jouannaud_verismall:_2011": {
    "id": "jouannaud_verismall:_2011",
    "type": "chapter",
    "author": [
      {
        "family": "Appel",
        "given": "Andrew W."
      }
    ],
    "editor": [
      {
        "family": "Jouannaud",
        "given": "Jean-Pierre"
      },
      {
        "family": "Shao",
        "given": "Zhong"
      }
    ],
    "title": "VeriSmall: Verified Smallfoot Shape Analysis",
    "container-title": "Certified Programs and Proofs",
    "container-title-short": "VeriSmall",
    "title-short": "VeriSmall",
    "issued": {
      "date-parts": [
        [
          "2011"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "1",
          "31"
        ]
      ]
    },
    "publisher": "Springer Berlin Heidelberg",
    "isbn": "978-3-642-25378-2 978-3-642-25379-9",
    "URL": "http://link.springer.com/10.1007/978-3-642-25379-9_18",
    "DOI": "10.1007/978-3-642-25379-9_18",
    "publisher-place": "Berlin, Heidelberg",
    "page": "231-246",
    "page-first": "231",
    "volume": "7086",
    "_line": "FormalReview.bib:331"
  },
  "stewart_verified_2012": {
    "id": "stewart_verified_2012",
    "type": "paper-conference",
    "author": [
      {
        "family": "Stewart",
        "given": "Gordon"
      },
      {
        "family": "Beringer",
        "given": "Lennart"
      },
      {
        "family": "Appel",
        "given": "Andrew W."
      }
    ],
    "title": "Verified Heap Theorem Prover by Paramodulation",
    "container-title": "Proceedings of the 17th ACM SIGPLAN International Conference on Functional Programming",
    "collection-title": "ICFP '12",
    "issued": {
      "date-parts": [
        [
          "2012"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "1",
          "31"
        ]
      ]
    },
    "publisher": "ACM",
    "isbn": "978-1-4503-1054-3",
    "abstract": "We present VeriStar, a verified theorem prover for a decidable subset of separation logic. Together with VeriSmall \\[3\\], a proved-sound Smallfoot-style program analysis for C minor, VeriStar demonstrates that fully machine-checked static analyses equipped with efficient theorem provers are now within the reach of formal methods. As a pair, VeriStar and VeriSmall represent the first application of the Verified Software Toolchain \\[4\\], a tightly integrated collection of machine-verified program logics and compilers giving foundational correctness guarantees. VeriStar is (1) purely functional, (2) machine-checked, (3) end-to-end, (4) efficient and (5) modular. By purely functional, we mean it is implemented in Gallina, the pure functional programming language embedded in the Coq theorem prover. By machine-checked, we mean it has a proof in Coq that when the prover says \"valid\", the checked entailment holds in a proved-sound separation logic for C minor. By end-to-end, we mean that when the static analysis+theorem prover says a C minor program is safe, the program will be compiled to a semantically equivalent assembly program that runs on real hardware. By efficient, we mean that the prover implements a state-of-the-art algorithm for deciding heap entailments and uses highly tuned verified functional data structures. By modular, we mean that VeriStar can be retrofitted to other static analyses as a plug-compatible entailment checker and its soundness proof can easily be ported to other separation logics.",
    "keywords": "paramodulation, separation logic, theorem proving",
    "URL": "http://doi.acm.org/10.1145/2364527.2364531",
    "DOI": "10.1145/2364527.2364531",
    "publisher-place": "New York, NY, USA",
    "page": "3-14",
    "page-first": "3",
    "_line": "FormalReview.bib:349"
  },
  "appel_verified_2012": {
    "id": "appel_verified_2012",
    "type": "paper-conference",
    "author": [
      {
        "family": "Appel",
        "given": "Andrew W."
      }
    ],
    "title": "Verified Software Toolchain",
    "container-title": "Proceedings of the 4th International Conference on NASA Formal Methods",
    "collection-title": "NFM'12",
    "issued": {
      "date-parts": [
        [
          "2012"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "1",
          "31"
        ]
      ]
    },
    "publisher": "Springer-Verlag",
    "isbn": "978-3-642-28890-6",
    "abstract": "The software toolchain includes static analyzers to check assertions about programs; optimizing compilers to translate programs to machine language; operating systems and libraries to supply context for programs. Our Verified Software Toolchain verifies with machine-checked proofs that the assertions claimed at the top of the toolchain really hold in the machine-language program, running in the operating-system context, on a weakly-consistent-shared-memory machine. Our verification approach is modular, in that proofs about operating systems or concurrency libraries are oblivious of the programming language or machine language, proofs about compilers are oblivious of the program logic used to verify static analyzers, and so on. The approach is scalable, in that each component is verified in the semantic idiom most natural for that component. Finally, the verification is foundational: the trusted base for proofs of observable properties of the machine-language program includes only the operational semantics of the machine language, not the source language, the compiler, the program logic, or any other part of the toolchain&ndash;even when these proofs are carried out by source-level static analyzers. In this paper I explain the construction of a a verified toolchain, using the Coq proof assistant. I will illustrate with shape analysis for C programs based on separation logic.",
    "URL": "http://dx.doi.org/10.1007/978-3-642-28891-3_2",
    "DOI": "10.1007/978-3-642-28891-3_2",
    "publisher-place": "Berlin, Heidelberg",
    "page": "2-2",
    "page-first": "2",
    "_line": "FormalReview.bib:367"
  },
  "kastner_program_2015": {
    "id": "kastner_program_2015",
    "type": "paper-conference",
    "author": [
      {
        "family": "Kästner",
        "given": "Daniel"
      },
      {
        "family": "Pohland",
        "given": "Jan"
      }
    ],
    "editor": [
      {
        "family": "Roy",
        "given": "Matthieu"
      }
    ],
    "title": "Program Analysis on Evolving Software",
    "container-title": "CARS 2015 - Critical Automotive applications: Robustness &amp; Safety",
    "issued": {
      "date-parts": [
        [
          "2015",
          "9"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "1",
          "31"
        ]
      ]
    },
    "abstract": "Static analysis is well-suited for continuous verification during the software development stage since it only works on the source code and does not require a running system for testing. However, applying the program analysis during software development means that the analysis has to cope with evolving software and evolving analyzer configurations, especially in a model-based development process. In this article we present a unique history-aware concept for program analysis that has been developed for the static analyzer Astrée. It not only provides the ability to backtrack and access previous versions of the analysis configuration, it can also automatically determine the differences between two analysis configurations and relate them to the correct source code versions. Users can explicitly create a revision, i.e. a snapshot of the analysis project; changes of the source code, analysis options, analysis directives and results in different revisions are automatically detected and highlighted. The analyzer provides automatic correctness checks for all specified analysis directives, e.g., to tune the precision of the analyzer or provide information about the environment. This makes software verification applicable during the implementation stage, significantly reduces the effort to adapt the analyzer configuration to new source code versions, and makes analysis results on previous software versions easily reproducible.",
    "URL": "https://hal.archives-ouvertes.fr/hal-01192985",
    "publisher-place": "Paris, France",
    "_line": "FormalReview.bib:384"
  },
  "monniaux_parallel_2005": {
    "id": "monniaux_parallel_2005",
    "type": "article-journal",
    "author": [
      {
        "family": "Monniaux",
        "given": "David"
      }
    ],
    "title": "The parallel implementation of the Astr&bslash;'&lcurly;e&rcurly;e static analyzer",
    "container-title": "arXiv:cs/0701191",
    "issued": {
      "date-parts": [
        [
          "2005"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "1",
          "31"
        ]
      ]
    },
    "abstract": "The Astr&bslash;'&lcurly;e&rcurly;e static analyzer is a specialized tool that can prove the absence of runtime errors, including arithmetic overflows, in large critical programs. Keeping analysis times reasonable for industrial use is one of the design objectives. In this paper, we discuss the parallel implementation of the analysis.",
    "keywords": "Computer Science - Performance, Computer Science - Programming Languages, D.2.4",
    "URLtext": "cs/0701191",
    "URLpretext": "[arXiv:]{.etype}",
    "eprint-type": "arxiv",
    "eprint": "cs/0701191",
    "URL": "http://arxiv.org/abs/cs/0701191",
    "DOI": "10.1007/11575467_7",
    "page": "86-96",
    "page-first": "86",
    "volume": "3780",
    "_line": "FormalReview.bib:397"
  },
  "kastner_astree:_nodate": {
    "id": "kastner_astree:_nodate",
    "type": "article-journal",
    "author": [
      {
        "family": "Kästner",
        "given": "D"
      },
      {
        "family": "Wilhelm",
        "given": "S"
      },
      {
        "family": "Nenova",
        "given": "S"
      },
      {
        "family": "Miné",
        "given": "A"
      },
      {
        "family": "Rival",
        "given": "X"
      },
      {
        "family": "Mauborgne",
        "given": "L"
      },
      {
        "family": "Feret",
        "given": "J"
      },
      {
        "family": "Cousot",
        "given": "P"
      },
      {
        "family": "Cousot",
        "given": "R"
      }
    ],
    "title": "Astree: Proving the Absence of Runtime Errors",
    "abstract": "Safety-critical embedded software has to satisfy stringent quality requirements. Testing and validation consumes a large – and growing – fraction of development cost. The last years have seen the emergence of semantics-based static analysis tools in various application areas, from runtime error analysis to worst-case execution time prediction. Their appeal is that they have the potential to reduce testing eﬀort while providing 100&perc; coverage, thus enhancing safety. Static runtime error analysis is applicable to large industryscale projects and produces a list of deﬁnite runtime errors and of potential runtime errors which might be true errors or false alarms. In the past, often only the deﬁnite errors were ﬁxed because manually inspecting each alarm was too time-consuming due to a large number of false alarms. Therefore no proof of the absence of runtime errors could be given. In this article the parameterizable static analyzer Astr´ee is presented. By specialization and parameterization Astr´ee can be adapted to the software under analysis. This enables Astr´ee to eﬃciently compute precise results. Astr´ee has successfully been used to analyze large-scale safety-critical avionics software with zero false alarms.",
    "URL": "https://www.di.ens.fr/~rival/papers/erts10.pdf",
    "page": "9",
    "page-first": "9",
    "note": "astree/astee-proving-absence-rte.pdf",
    "language": "en-US",
    "_line": "FormalReview.bib:414"
  },
  "mine_taking_2016": {
    "id": "mine_taking_2016",
    "type": "paper-conference",
    "author": [
      {
        "family": "Miné",
        "given": "Antoine"
      },
      {
        "family": "Mauborgne",
        "given": "Laurent"
      },
      {
        "family": "Rival",
        "given": "Xavier"
      },
      {
        "family": "Feret",
        "given": "Jerome"
      },
      {
        "family": "Cousot",
        "given": "Patrick"
      },
      {
        "family": "Kästner",
        "given": "Daniel"
      },
      {
        "family": "Wilhelm",
        "given": "Stephan"
      },
      {
        "family": "Ferdinand",
        "given": "Christian"
      }
    ],
    "title": "Taking Static Analysis to the Next Level: Proving the Absence of Run-Time Errors and Data Races with Astrée",
    "container-title": "8th European Congress on Embedded Real Time Software and Systems (ERTS 2016)",
    "container-title-short": "Taking Static Analysis to the Next Level",
    "title-short": "Taking Static Analysis to the Next Level",
    "issued": {
      "date-parts": [
        [
          "2016",
          "1"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "1",
          "31"
        ]
      ]
    },
    "abstract": "We present an extension of Astrée to concurrent C software. Astrée is a sound static analyzer for run-time errors previously limited to sequential C software. Our extension employs a scalable abstraction which covers all possible thread interleavings, and soundly reports all run-time errors and data races: when the analyzer does not report any alarm, the program is proven free from those classes of errors. We show how this extension is able to support a variety of operating systems (such as POSIX threads, ARINC 653, OSEK/AUTOSAR) and report on experimental results obtained on concurrent software from different domains, including large industrial software.",
    "URL": "https://hal.archives-ouvertes.fr/hal-01271552",
    "publisher-place": "Toulouse, France",
    "_line": "FormalReview.bib:425"
  },
  "bedford_coqatoo:_nodate": {
    "id": "bedford_coqatoo:_nodate",
    "type": "article-journal",
    "author": [
      {
        "family": "Bedford",
        "given": "Andrew"
      }
    ],
    "title": "Coqatoo: Generating Natural Language Versions of Coq Proofs - Slides",
    "page": "16",
    "page-first": "16",
    "language": "en-US",
    "_line": "FormalReview.bib:438"
  },
  "bedford_coqatoo:_2017": {
    "id": "bedford_coqatoo:_2017",
    "type": "article-journal",
    "author": [
      {
        "family": "Bedford",
        "given": "Andrew"
      }
    ],
    "title": "Coqatoo: Generating Natural Language Versions of Coq Proofs",
    "container-title": "arXiv:1712.03894 \\[cs\\]",
    "container-title-short": "Coqatoo",
    "title-short": "Coqatoo",
    "issued": {
      "date-parts": [
        [
          "2017",
          "12",
          "11"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "1",
          "31"
        ]
      ]
    },
    "abstract": "Due to their numerous advantages, formal proofs and proof assistants, such as Coq, are becoming increasingly popular. However, one disadvantage of using proof assistants is that the resulting proofs can sometimes be hard to read and understand, particularly for less-experienced users. To address this issue, we have implemented a tool capable of generating natural language versions of Coq proofs called Coqatoo, which we present in this paper.",
    "keywords": "Computer Science - Programming Languages",
    "URLtext": "1712.03894",
    "URLpretext": "[arXiv:]{.etype}",
    "eprint-type": "arxiv",
    "eprint": "1712.03894",
    "URL": "http://arxiv.org/abs/1712.03894",
    "_line": "FormalReview.bib:446"
  },
  "sherman_making_2017": {
    "id": "sherman_making_2017",
    "type": "thesis",
    "genre": "Master of Science",
    "author": [
      {
        "family": "Sherman",
        "given": "Benjamin"
      }
    ],
    "title": "Making Discrete Decisions Based on Continuous Values",
    "issued": {
      "date-parts": [
        [
          "2017",
          "6"
        ]
      ]
    },
    "publisher": "MIT",
    "number-of-pages": "105",
    "abstract": "Many safety-critical software systems are cyber-physical systems that compute with continuous values; confirming their safety requires guaranteeing the accuracy of their computations. It is impossible for these systems to compute (total and deterministic) discrete computations (e.g., decisions) based on connected input spaces such as R. We propose a programming language based on constructive topology, whose types are spaces and programs are executable continuous maps, that facilitates making formal guarantees of accuracy of computed results. We demonstrate that discrete decisions can be made based on continuous values by permitting nondeterminism. This thesis describes variants of the programming language allowing nondeterminism and/or partiality, and introduces two tools for creating nondeterministic programs on spaces. Overlapping pattern matching is a generalization of pattern matching in functional programming, where patterns need not represent decidable predicates and also may overlap, allowing potentially nondeterministic behavior in overlapping regions. Binary covers, which are pairs of predicates such that at least one of them holds, yield a formal logic for constructing approximate decision procedures.",
    "URL": "http://adam.chlipala.net/theses/sherman_sm.pdf",
    "publisher-place": "Cambridge, MA",
    "note": "ben-sherman/sm-thesis.pdf",
    "language": "en-US",
    "_line": "FormalReview.bib:461"
  },
  "boulier_next_2017": {
    "id": "boulier_next_2017",
    "type": "paper-conference",
    "author": [
      {
        "family": "Boulier",
        "given": "Simon"
      },
      {
        "family": "Pédrot",
        "given": "Pierre-Marie"
      },
      {
        "family": "Tabareau",
        "given": "Nicolas"
      }
    ],
    "title": "The next 700 syntactical models of type theory",
    "event-title": "Certified Programs and Proofs (CPP 2017)",
    "issued": {
      "date-parts": [
        [
          "2017",
          "1",
          "16"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "1",
          "31"
        ]
      ]
    },
    "abstract": "A family of syntactic models for the calculus of construction with universes (CC ω) is described, all of them preserving conversion of the calculus definitionally, and thus giving rise directly to a program transformation of CC ω into itself. Those models are based on the remark that negative type constructors (e.g., dependent product, coinductive types or universes) are underspecified in type theory—which leaves some freedom on extra intensional specifications. The model construction can be seen as a compilation phase from a complex type theory into a simpler type theory. Such models can be used to derive (the negative part of) independence results with respect to CC ω , such as functional extensional-ity, propositional extensionality, univalence or the fact that bisimulation on a coinductive type may not coincide with equality. They can also be used to add new principles to the theory, which we illustrate by defining a version of CC ω with ad-hoc polymorphism that shows in particular that para-metricity is not an implicit requirement of type theory. The correctness of some of the models/program transformations have been checked in the COQ proof assistant and have been instrumented as a COQ plugin.",
    "URL": "https://hal.inria.fr/hal-01445835/document",
    "DOI": "10.1145/3018610.3018620",
    "page": "182 - 194",
    "page-first": "182",
    "language": "en-US",
    "_line": "FormalReview.bib:476"
  },
  "bowman_j1:_nodate": {
    "id": "bowman_j1:_nodate",
    "type": "book",
    "author": [
      {
        "family": "Bowman",
        "given": "James"
      }
    ],
    "title": "J1: a small Forth CPU Core for FPGAs",
    "container-title-short": "J1",
    "title-short": "J1",
    "abstract": "Abstract—This paper describes a 16-bit Forth CPU core, intended for FPGAs. The instruction set closely matches the Forth programming language, simplifying cross-compilation. Because it has higher throughput than comparable CPU cores, it can stream uncompressed video over Ethernet using a simple software loop.The entire system (source Verilog,cross compiler, and TCP/IP networking code) is published under the BSD license. The core is less than 200 lines of Verilog, and operates reliably at 80 MHz in a Xilinx Spartan R○-3E FPGA, delivering approximately 100 ANS Forth MIPS. I.",
    "_line": "FormalReview.bib:490"
  },
  "gu_deep_2015": {
    "id": "gu_deep_2015",
    "type": "paper-conference",
    "author": [
      {
        "family": "Gu",
        "given": "Ronghui"
      },
      {
        "family": "Koenig",
        "given": "Jérémie"
      },
      {
        "family": "Ramananandro",
        "given": "Tahina"
      },
      {
        "family": "Shao",
        "given": "Zhong"
      },
      {
        "family": "Wu",
        "given": "Xiongnan (Newman)"
      },
      {
        "family": "Weng",
        "given": "Shu-Chun"
      },
      {
        "family": "Zhang",
        "given": "Haozhong"
      },
      {
        "family": "Guo",
        "given": "Yu"
      }
    ],
    "title": "Deep Specifications and Certified Abstraction Layers",
    "container-title": "Proceedings of the 42Nd Annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages",
    "collection-title": "POPL '15",
    "issued": {
      "date-parts": [
        [
          "2015"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "1",
          "31"
        ]
      ]
    },
    "publisher": "ACM",
    "isbn": "978-1-4503-3300-9",
    "abstract": "Modern computer systems consist of a multitude of abstraction layers (e.g., OS kernels, hypervisors, device drivers, network protocols), each of which defines an interface that hides the implementation details of a particular set of functionality. Client programs built on top of each layer can be understood solely based on the interface, independent of the layer implementation. Despite their obvious importance, abstraction layers have mostly been treated as a system concept; they have almost never been formally specified or verified. This makes it difficult to establish strong correctness properties, and to scale program verification across multiple layers. In this paper, we present a novel language-based account of abstraction layers and show that they correspond to a strong form of abstraction over a particularly rich class of specifications which we call deep specifications. Just as data abstraction in typed functional languages leads to the important representation independence property, abstraction over deep specification is characterized by an important implementation independence property: any two implementations of the same deep specification must have contextually equivalent behaviors. We present a new layer calculus showing how to formally specify, program, verify, and compose abstraction layers. We show how to instantiate the layer calculus in realistic programming languages such as C and assembly, and how to adapt the CompCert verified compiler to compile certified C layers such that they can be linked with assembly layers. Using these new languages and tools, we have successfully developed multiple certified OS kernels in the Coq proof assistant, the most realistic of which consists of 37 abstraction layers, took less than one person year to develop, and can boot a version of Linux as a guest.",
    "keywords": "abstraction layer, certified compilers, certified os kernels, deep specification, modularity, program verification",
    "URL": "http://doi.acm.org/10.1145/2676726.2676975",
    "DOI": "10.1145/2676726.2676975",
    "publisher-place": "New York, NY, USA",
    "page": "595-608",
    "page-first": "595",
    "_line": "FormalReview.bib:498"
  },
  "murawski_invitation_2016": {
    "id": "murawski_invitation_2016",
    "type": "article-journal",
    "author": [
      {
        "family": "Murawski",
        "given": "Andrzej S."
      },
      {
        "family": "Tzevelekos",
        "given": "Nikos"
      }
    ],
    "title": "An Invitation to Game Semantics",
    "container-title": "ACM SIGLOG News",
    "issued": {
      "date-parts": [
        [
          "2016",
          "5"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "1",
          "31"
        ]
      ]
    },
    "issn": "2372-3491",
    "abstract": "Game semantics is a flexible semantic theory that has led in recent years to an unprecedented number of full abstraction results for various programming paradigms. We present a gentle introduction to the subject, focussing on high-level ideas and examples with a view to providing a bridge to more technical literature.",
    "URL": "http://doi.acm.org/10.1145/2948896.2948902",
    "DOI": "10.1145/2948896.2948902",
    "page": "56-67",
    "page-first": "56",
    "volume": "3",
    "issue": "2",
    "_line": "FormalReview.bib:516"
  },
  "herlihy_linearizability:_1990": {
    "id": "herlihy_linearizability:_1990",
    "type": "article-journal",
    "author": [
      {
        "family": "Herlihy",
        "given": "Maurice P."
      },
      {
        "family": "Wing",
        "given": "Jeannette M."
      }
    ],
    "title": "Linearizability: A Correctness Condition for Concurrent Objects",
    "container-title": "ACM Trans. Program. Lang. Syst.",
    "container-title-short": "Linearizability",
    "title-short": "Linearizability",
    "issued": {
      "date-parts": [
        [
          "1990",
          "7"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "1",
          "31"
        ]
      ]
    },
    "issn": "0164-0925",
    "abstract": "A concurrent object is a data object shared by concurrent processes. Linearizability is a correctness condition for concurrent objects that exploits the semantics of abstract data types. It permits a high degree of concurrency, yet it permits programmers to specify and reason about concurrent objects using known techniques from the sequential domain. Linearizability provides the illusion that each operation applied by concurrent processes takes effect instantaneously at some point between its invocation and its response, implying that the meaning of a concurrent object's operations can be given by pre- and post-conditions. This paper defines linearizability, compares it to other correctness conditions, presents and demonstrates a method for proving the correctness of implementations, and shows how to reason about concurrent objects, given they are linearizable.",
    "URL": "http://doi.acm.org/10.1145/78969.78972",
    "DOI": "10.1145/78969.78972",
    "page": "463-492",
    "page-first": "463",
    "volume": "12",
    "issue": "3",
    "_line": "FormalReview.bib:532"
  },
  "gu_certikos:_2016": {
    "id": "gu_certikos:_2016",
    "type": "paper-conference",
    "author": [
      {
        "family": "Gu",
        "given": "Ronghui"
      },
      {
        "family": "Shao",
        "given": "Zhong"
      },
      {
        "family": "Chen",
        "given": "Hao"
      },
      {
        "family": "Wu",
        "given": "Xiongnan"
      },
      {
        "family": "Kim",
        "given": "Jieung"
      },
      {
        "family": "Sjöberg",
        "given": "Vilhelm"
      },
      {
        "family": "Costanzo",
        "given": "David"
      }
    ],
    "title": "CertiKOS: An Extensible Architecture for Building Certified Concurrent OS Kernels",
    "container-title": "Proceedings of the 12th USENIX Conference on Operating Systems Design and Implementation",
    "container-title-short": "CertiKOS",
    "collection-title": "OSDI'16",
    "title-short": "CertiKOS",
    "issued": {
      "date-parts": [
        [
          "2016"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "1",
          "31"
        ]
      ]
    },
    "publisher": "USENIX Association",
    "isbn": "978-1-931971-33-1",
    "abstract": "Complete formal verification of a non-trivial concurrent OS kernel is widely considered a grand challenge. We present a novel compositional approach for building certified concurrent OS kernels. Concurrency allows interleaved execution of kernel/user modules across different layers of abstraction. Each such layer can have a different set of observable events. We insist on formally specifying these layers and their observable events, and then verifying each kernel module at its proper abstraction level. To support certified linking with other CPUs or threads, we prove a strong contextual refinement property for every kernel function, which states that the implementation of each such function will behave like its specification under any kernel/user context with any valid interleaving. We have successfully developed a practical concurrent OS kernel and verified its (contextual) functional correctness in Coq. Our certified kernel is written in 6500 lines of C and x86 assembly and runs on stock x86 multicore machines. To our knowledge, this is the first proof of functional correctness of a complete, general-purpose concurrent OS kernel with fine-grained locking.",
    "URL": "http://dl.acm.org/citation.cfm?id=3026877.3026928",
    "publisher-place": "Berkeley, CA, USA",
    "page": "653-669",
    "page-first": "653",
    "_line": "FormalReview.bib:549"
  },
  "costanzo_end--end_nodate": {
    "id": "costanzo_end--end_nodate",
    "type": "article-journal",
    "author": [
      {
        "family": "Costanzo",
        "given": "David"
      },
      {
        "family": "Shao",
        "given": "Zhong"
      },
      {
        "family": "Gu",
        "given": "Ronghui"
      }
    ],
    "title": "End-to-End Veriﬁcation of Information-Flow Security for C and Assembly Programs - Tech Report",
    "abstract": "Protecting the conﬁdentiality of information manipulated by a computing system is one of the most important challenges facing today’s cybersecurity community. A promising step toward conquering this challenge is to formally verify that the end-to-end behavior of the computing system really satisﬁes various information-ﬂow policies. Unfortunately, because today’s system software still consists of both C and assembly programs, the end-to-end veriﬁcation necessarily requires that we not only prove the security properties of individual components, but also carefully preserve these properties through compilation and cross-language linking.",
    "URL": "http://flint.cs.yale.edu/certikos/publications/security-tr.pdf",
    "page": "21",
    "page-first": "21",
    "note": "certikos/pldi16-certikos-security-tr.pdf",
    "language": "en-US",
    "_line": "FormalReview.bib:566"
  },
  "costanzo_end--end_2016": {
    "id": "costanzo_end--end_2016",
    "type": "paper-conference",
    "author": [
      {
        "family": "Costanzo",
        "given": "David"
      },
      {
        "family": "Shao",
        "given": "Zhong"
      },
      {
        "family": "Gu",
        "given": "Ronghui"
      }
    ],
    "title": "End-to-end Verification of Information-flow Security for C and Assembly Programs",
    "container-title": "Proceedings of the 37th ACM SIGPLAN Conference on Programming Language Design and Implementation",
    "collection-title": "PLDI '16",
    "issued": {
      "date-parts": [
        [
          "2016"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "1",
          "31"
        ]
      ]
    },
    "publisher": "ACM",
    "isbn": "978-1-4503-4261-2",
    "abstract": "Protecting the confidentiality of information manipulated by a computing system is one of the most important challenges facing today's cybersecurity community. A promising step toward conquering this challenge is to formally verify that the end-to-end behavior of the computing system really satisfies various information-flow policies. Unfortunately, because today's system software still consists of both C and assembly programs, the end-to-end verification necessarily requires that we not only prove the security properties of individual components, but also carefully preserve these properties through compilation and cross-language linking. In this paper, we present a novel methodology for formally verifying end-to-end security of a software system that consists of both C and assembly programs. We introduce a general definition of observation function that unifies the concepts of policy specification, state indistinguishability, and whole-execution behaviors. We show how to use different observation functions for different levels of abstraction, and how to link different security proofs across abstraction levels using a special kind of simulation that is guaranteed to preserve state indistinguishability. To demonstrate the effectiveness of our new methodology, we have successfully constructed an end-to-end security proof, fully formalized in the Coq proof assistant, of a nontrivial operating system kernel (running on an extended CompCert x86 assembly machine model). Some parts of the kernel are written in C and some are written in assembly; we verify all of the code, regardless of language.",
    "keywords": "Certified OS Kernels, Information Flow Control, Program Verification, Security Policy Specification, Security-Preserving Simulation",
    "URL": "http://doi.acm.org/10.1145/2908080.2908100",
    "DOI": "10.1145/2908080.2908100",
    "publisher-place": "New York, NY, USA",
    "page": "648-664",
    "page-first": "648",
    "_line": "FormalReview.bib:577"
  },
  "gu_certified_2018": {
    "id": "gu_certified_2018",
    "type": "paper-conference",
    "author": [
      {
        "family": "Gu",
        "given": "Ronghui"
      },
      {
        "family": "Shao",
        "given": "Zhong"
      },
      {
        "family": "Kim",
        "given": "Jieung"
      },
      {
        "family": "Wu",
        "given": "Xiongnan (Newman)"
      },
      {
        "family": "Koenig",
        "given": "Jérémie"
      },
      {
        "family": "Sjöberg",
        "given": "Vilhelm"
      },
      {
        "family": "Chen",
        "given": "Hao"
      },
      {
        "family": "Costanzo",
        "given": "David"
      },
      {
        "family": "Ramananandro",
        "given": "Tahina"
      }
    ],
    "title": "Certified Concurrent Abstraction Layers",
    "container-title": "Proceedings of the 39th ACM SIGPLAN Conference on Programming Language Design and Implementation",
    "collection-title": "PLDI 2018",
    "issued": {
      "date-parts": [
        [
          "2018"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "1",
          "31"
        ]
      ]
    },
    "publisher": "ACM",
    "isbn": "978-1-4503-5698-5",
    "abstract": "Concurrent abstraction layers are ubiquitous in modern computer systems because of the pervasiveness of multithreaded programming and multicore hardware. Abstraction layers are used to hide the implementation details (e.g., fine-grained synchronization) and reduce the complex dependencies among components at different levels of abstraction. Despite their obvious importance, concurrent abstraction layers have not been treated formally. This severely limits the applicability of layer-based techniques and makes it difficult to scale verification across multiple concurrent layers.   In this paper, we present CCAL&mdash;a fully mechanized programming toolkit developed under the CertiKOS project&mdash;for specifying, composing, compiling, and linking certified concurrent abstraction layers. CCAL consists of three technical novelties: a new game-theoretical, strategy-based compositional semantic model for concurrency (and its associated program verifiers), a set of formal linking theorems for composing multithreaded and multicore concurrent layers, and a new CompCertX compiler that supports certified thread-safe compilation and linking. The CCAL toolkit is implemented in Coq and supports layered concurrent programming in both C and assembly. It has been successfully applied to build a fully certified concurrent OS kernel with fine-grained locking.",
    "keywords": "abstraction layer, certified compilers, certified OS kernels, concurrency, modularity, Verification",
    "URL": "http://doi.acm.org/10.1145/3192366.3192381",
    "DOI": "10.1145/3192366.3192381",
    "publisher-place": "New York, NY, USA",
    "page": "646-661",
    "page-first": "646",
    "_line": "FormalReview.bib:595"
  },
  "chargueraud_program_2010": {
    "id": "chargueraud_program_2010",
    "type": "paper-conference",
    "author": [
      {
        "family": "Charguéraud",
        "given": "Arthur"
      }
    ],
    "title": "Program Verification Through Characteristic Formulae",
    "container-title": "Proceedings of the 15th ACM SIGPLAN International Conference on Functional Programming",
    "collection-title": "ICFP '10",
    "issued": {
      "date-parts": [
        [
          "2010"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "1",
          "31"
        ]
      ]
    },
    "publisher": "ACM",
    "isbn": "978-1-60558-794-3",
    "abstract": "This paper describes CFML, the first program verification tool based on characteristic formulae. Given the source code of a pure Caml program, this tool generates a logical formula that implies any valid post-condition for that program. One can then prove that the program satisfies a given specification by reasoning interactively about the characteristic formula using a proof assistant such as Coq. Our characteristic formulae improve over Honda et al's total characteristic assertion pairs in that they are expressible in standard higher-order logic, allowing to exploit them in practice to verify programs using existing proof assistants. Our technique has been applied to formally verify more than half of the content of Okasaki's Purely Functional Data Structures reference book",
    "keywords": "characteristic formula, functional program, total correctness",
    "URL": "http://doi.acm.org/10.1145/1863543.1863590",
    "DOI": "10.1145/1863543.1863590",
    "publisher-place": "New York, NY, USA",
    "page": "321-332",
    "page-first": "321",
    "_line": "FormalReview.bib:613"
  },
  "chargueraud_characteristic_2011": {
    "id": "chargueraud_characteristic_2011",
    "type": "paper-conference",
    "author": [
      {
        "family": "Charguéraud",
        "given": "Arthur"
      }
    ],
    "title": "Characteristic Formulae for the Verification of Imperative Programs",
    "container-title": "Proceedings of the 16th ACM SIGPLAN International Conference on Functional Programming",
    "collection-title": "ICFP '11",
    "issued": {
      "date-parts": [
        [
          "2011"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "1",
          "31"
        ]
      ]
    },
    "publisher": "ACM",
    "isbn": "978-1-4503-0865-6",
    "abstract": "In previous work, we introduced an approach to program verification based on characteristic formulae. The approach consists of generating a higher-order logic formula from the source code of a program. This characteristic formula is constructed in such a way that it gives a sound and complete description of the semantics of that program. The formula can thus be exploited in an interactive proof assistant to formally verify that the program satisfies a particular specification. This previous work was, however, only concerned with purely-functional programs. In the present paper, we describe the generalization of characteristic formulae to an imperative programming language. In this setting, characteristic formulae involve specifications expressed in the style of Separation Logic. They also integrate the frame rule, which enables local reasoning. We have implemented a tool based on characteristic formulae. This tool, called CFML, supports the verification of imperative Caml programs using the Coq proof assistant. Using CFML, we have formally verified nontrivial imperative algorithms, as well as CPS functions, higher-order iterators, and programs involving higher-order stores.",
    "keywords": "characteristic formula, interactive verification, total correctness",
    "URL": "http://doi.acm.org/10.1145/2034773.2034828",
    "DOI": "10.1145/2034773.2034828",
    "publisher-place": "New York, NY, USA",
    "page": "418-430",
    "page-first": "418",
    "_line": "FormalReview.bib:631"
  },
  "chargueraud_characteristic_2010": {
    "id": "chargueraud_characteristic_2010",
    "type": "thesis",
    "genre": "phdthesis",
    "author": [
      {
        "family": "Charguéraud",
        "given": "Arthur"
      }
    ],
    "title": "Characteristic Formulae for Mechanized Program Verification",
    "issued": {
      "date-parts": [
        [
          "2010",
          "12",
          "16"
        ]
      ]
    },
    "publisher": "UNIVERSITÉ PARIS.DIDEROT",
    "number-of-pages": "185",
    "abstract": "This dissertation describes a new approach to program veri cation,\nbased on characteristic formulae. The characteristic formula of a program\nis a higher-order logic formula that describes the behavior of that\nprogram, in the sense that it is sound and complete with respect to\nthe semantics. This formula can be exploited in an interactive theorem\nprover to establish that the program satis es a speci cation expressed\nin the style of Separation Logic, with respect to total correctness.\nThe characteristic formula of a program is automatically generated\nfrom its source code alone. In particular, there is no need to annotate the\nsource code with speci cations or loop invariants, as such information\ncan be given in interactive proof scripts. One key feature of characteristic\nformulae is that they are of linear size and that they can be prettyprinted\nin a way that closely resemble the source code they describe, even\nthough they do not refer to the syntax of the programming language.\nCharacteristic formulae serve as a basis for a tool, called CFML, that\nsupports the veri cation of Caml programs using the Coq proof assistant.\nCFML has been employed to verify about half of the content of\nOkasaki's book on purely functional data structures, and to verify several\nimperative data structures such as mutable lists, sparse arrays and\nunion- nd. CFML also supports reasoning on higher-order imperative\nfunctions, such as functions in CPS form and higher-order iterators",
    "publisher-place": "Paris, France",
    "note": "chargueraud/chargueraud&underscore;thesis&underscore;final.pdf",
    "language": "en-US",
    "_line": "FormalReview.bib:649"
  },
  "chlipala_introduction_nodate": {
    "id": "chlipala_introduction_nodate",
    "type": "article-journal",
    "author": [
      {
        "family": "Chlipala",
        "given": "Adam"
      }
    ],
    "title": "An Introduction to Programming and Proving with Dependent Types in Coq",
    "container-title": "Journal of Formalized Reasoning",
    "abstract": "Computer proof assistants vary along many dimensions. Among the mature implementations, the Coq system is distinguished by two key features. First, we have support for programming with\ndependent types in the tradition of type theory, based on dependent function types and inductive type families. Second, we have a domain-specific language for coding correct-by-construction proof automation. Though the Coq user community has grown quite large, neither of the aspects\nI highlight is widely used. In this tutorial, I aim to provide a pragmatic introduction to both, showing how they can bring significant improvements in productivity.",
    "page": "93",
    "page-first": "93",
    "volume": "3",
    "note": "chlipala/1978-4445-1-PB.pdf",
    "issue": "2",
    "language": "en-US",
    "_line": "FormalReview.bib:683"
  },
  "chlipala_certified_2013": {
    "id": "chlipala_certified_2013",
    "type": "book",
    "author": [
      {
        "family": "Chlipala",
        "given": "Adam"
      }
    ],
    "title": "Certified programming with dependent types: a pragmatic introduction to the Coq proof assistant",
    "container-title-short": "Certified programming with dependent types",
    "title-short": "Certified programming with dependent types",
    "issued": {
      "date-parts": [
        [
          "2013"
        ]
      ]
    },
    "publisher": "The MIT Press",
    "number-of-pages": "424",
    "isbn": "978-0-262-02665-9",
    "keywords": "Automatic theorem proving, Computer programming, Computer programs, Coq (Electronic resource)",
    "URL": "http://adam.chlipala.net/cpdt/",
    "publisher-place": "Cambridge, MA",
    "_line": "FormalReview.bib:698"
  },
  "chlipala_certied_nodate": {
    "id": "chlipala_certied_nodate",
    "type": "article-journal",
    "author": [
      {
        "family": "Chlipala",
        "given": "Adam"
      }
    ],
    "title": "Certiﬁed Programming with Dependent Types",
    "page": "369",
    "page-first": "369",
    "language": "en-US",
    "_line": "FormalReview.bib:711"
  },
  "chlipala_formal_2019": {
    "id": "chlipala_formal_2019",
    "type": "book",
    "author": [
      {
        "family": "Chlipala",
        "given": "Adam"
      }
    ],
    "title": "Formal Reasoning About Programs - Github",
    "issued": {
      "date-parts": [
        [
          "2019",
          "1",
          "31"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "1",
          "31"
        ]
      ]
    },
    "URL": "https://github.com/achlipala/frap",
    "note": "original-date: 2016-02-02T18:43:56Z",
    "_line": "FormalReview.bib:719"
  },
  "pit-claudel_extensible_nodate": {
    "id": "pit-claudel_extensible_nodate",
    "type": "article-journal",
    "author": [
      {
        "family": "Pit-Claudel",
        "given": "Clément"
      },
      {
        "family": "Wang",
        "given": "Peng"
      },
      {
        "family": "Delaware",
        "given": "Benjamin"
      },
      {
        "family": "Gross",
        "given": "Jason"
      },
      {
        "family": "Chlipala",
        "given": "Adam"
      }
    ],
    "title": "Extensible Extraction of Efﬁcient Imperative Programs with Foreign Functions, Manually Managed Memory, and Proofs",
    "abstract": "We present an original approach to sound program extraction in a proof assistant, using syntax-driven automation to derive correct-by-construction imperative programs from nondeterministic functional source code. Our approach does not require committing to a single inﬂexible compilation strategy and instead makes it straightforward to create domainspeciﬁc code translators. In addition to a small set of core definitions, our framework is a large, user-extensible collection of compilation rules each phrased to handle speciﬁc language constructs, code patterns, or data manipulations. By mixing and matching these pieces of logic, users can easily tailor extraction to their own domains and programs, getting maximum performance and ensuring correctness of the resulting assembly code. Using this approach, we complete the ﬁrst proof-generating pipeline that goes automatically from high-level speciﬁcations to assembly code. In our main case study, the original speciﬁcations are phrased to resemble SQL-style queries, while the ﬁnal assembly code does manual memory management, calls out to foreign data structures and functions, and is suitable to deploy on resource-constrained platforms. The pipeline runs entirely within the Coq proof assistant, leading to ﬁnal, linked assembly code inside Coq with overall full-functional-correctness proofs in separation logic.",
    "URL": "http://pit-claudel.fr/clement/papers/fiat-to-facade.pdf",
    "page": "14",
    "page-first": "14",
    "note": "clement/fiat-to-facade.pdg",
    "language": "en-US",
    "_line": "FormalReview.bib:729"
  },
  "feng_correct-by-construction_2018": {
    "id": "feng_correct-by-construction_2018",
    "type": "chapter",
    "author": [
      {
        "family": "Zhang",
        "given": "Teng"
      },
      {
        "family": "Wiegley",
        "given": "John"
      },
      {
        "family": "Giannakopoulos",
        "given": "Theophilos"
      },
      {
        "family": "Eakman",
        "given": "Gregory"
      },
      {
        "family": "Pit-Claudel",
        "given": "Clément"
      },
      {
        "family": "Lee",
        "given": "Insup"
      },
      {
        "family": "Sokolsky",
        "given": "Oleg"
      }
    ],
    "editor": [
      {
        "family": "Feng",
        "given": "Xinyu"
      },
      {
        "family": "Müller-Olm",
        "given": "Markus"
      },
      {
        "family": "Yang",
        "given": "Zijiang"
      }
    ],
    "title": "Correct-by-Construction Implementation of Runtime Monitors Using Stepwise Refinement",
    "container-title": "Dependable Software Engineering. Theories, Tools, and Applications",
    "issued": {
      "date-parts": [
        [
          "2018"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "1",
          "31"
        ]
      ]
    },
    "publisher": "Springer International Publishing",
    "isbn": "978-3-319-99932-6 978-3-319-99933-3",
    "URL": "http://link.springer.com/10.1007/978-3-319-99933-3_3",
    "DOI": "10.1007/978-3-319-99933-3_3",
    "publisher-place": "Cham",
    "page": "31-49",
    "page-first": "31",
    "volume": "10998",
    "_line": "FormalReview.bib:740"
  },
  "martin_mastering_2013": {
    "id": "martin_mastering_2013",
    "type": "book",
    "author": [
      {
        "family": "Martin",
        "given": "Ken"
      },
      {
        "family": "Hoffman",
        "given": "Bill"
      },
      {
        "family": "Cedilnik",
        "given": "Andy"
      }
    ],
    "title": "Mastering CMake: a cross-platform build system ; covers installing and running CMake ; details converting existing build processes to CMake ; create powerful cross-platform build scripts",
    "container-title-short": "Mastering CMake",
    "title-short": "Mastering CMake",
    "issued": {
      "date-parts": [
        [
          "2013"
        ]
      ]
    },
    "publisher": "Kitware",
    "number-of-pages": "640",
    "edition": "6. ed",
    "isbn": "978-1-930934-26-9",
    "publisher-place": "Clifton Park, NY",
    "note": "OCLC: 869872480",
    "_line": "FormalReview.bib:757"
  },
  "absint_compcert_nodate": {
    "id": "absint_compcert_nodate",
    "type": "webpage",
    "author": [
      {
        "family": "Absint"
      }
    ],
    "title": "CompCert - Publications",
    "accessed": {
      "date-parts": [
        [
          "2019",
          "1",
          "31"
        ]
      ]
    },
    "URL": "http://compcert.inria.fr/publi.html",
    "_line": "FormalReview.bib:771"
  },
  "chaudhuri_trigger_2016": {
    "id": "chaudhuri_trigger_2016",
    "type": "chapter",
    "author": [
      {
        "family": "Leino",
        "given": "K. R. M."
      },
      {
        "family": "Pit-Claudel",
        "given": "Clément"
      }
    ],
    "editor": [
      {
        "family": "Chaudhuri",
        "given": "Swarat"
      },
      {
        "family": "Farzan",
        "given": "Azadeh"
      }
    ],
    "title": "Trigger Selection Strategies to Stabilize Program Verifiers",
    "container-title": "Computer Aided Verification",
    "issued": {
      "date-parts": [
        [
          "2016"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "1",
          "31"
        ]
      ]
    },
    "publisher": "Springer International Publishing",
    "isbn": "978-3-319-41527-7 978-3-319-41528-4",
    "URL": "http://link.springer.com/10.1007/978-3-319-41528-4_20",
    "DOI": "10.1007/978-3-319-41528-4_20",
    "publisher-place": "Cham",
    "page": "361-381",
    "page-first": "361",
    "volume": "9779",
    "_line": "FormalReview.bib:779"
  },
  "pit-claudel_clement_nodate": {
    "id": "pit-claudel_clement_nodate",
    "type": "webpage",
    "author": [
      {
        "family": "Pit-Claudel",
        "given": "Clément"
      }
    ],
    "title": "Clément Pit-Claudel",
    "accessed": {
      "date-parts": [
        [
          "2019",
          "1",
          "31"
        ]
      ]
    },
    "URL": "http://pit-claudel.fr/clement/",
    "_line": "FormalReview.bib:796"
  },
  "bertot_interactive_2004": {
    "id": "bertot_interactive_2004",
    "type": "book",
    "author": [
      {
        "family": "Bertot",
        "given": "Yves"
      },
      {
        "family": "Castéran",
        "given": "P."
      }
    ],
    "title": "Interactive theorem proving and program development: Coq'Art: the calculus of inductive constructions",
    "container-title-short": "Interactive theorem proving and program development",
    "collection-title": "Texts in theoretical computer science",
    "title-short": "Interactive theorem proving and program development",
    "issued": {
      "date-parts": [
        [
          "2004"
        ]
      ]
    },
    "publisher": "Springer",
    "number-of-pages": "469",
    "isbn": "978-3-540-20854-9",
    "keywords": "Automatic theorem proving, Computer programming",
    "URL": "http://www.labri.fr/perso/casteran/CoqArt/index.html",
    "publisher-place": "Berlin ; New York",
    "note": "OCLC: ocm55514299",
    "_line": "FormalReview.bib:804"
  },
  "casteran_pierre_nodate": {
    "id": "casteran_pierre_nodate",
    "type": "webpage",
    "author": [
      {
        "family": "Castéran",
        "given": "Pierre"
      }
    ],
    "title": "Pierre Castéran's Home page",
    "accessed": {
      "date-parts": [
        [
          "2019",
          "1",
          "31"
        ]
      ]
    },
    "URL": "http://www.labri.fr/perso/casteran/index.html",
    "_line": "FormalReview.bib:819"
  },
  "bertot_yves_nodate": {
    "id": "bertot_yves_nodate",
    "type": "webpage",
    "author": [
      {
        "family": "Bertot",
        "given": "Yves"
      }
    ],
    "title": "Yves Bertot",
    "accessed": {
      "date-parts": [
        [
          "2019",
          "1",
          "31"
        ]
      ]
    },
    "URL": "http://www-sop.inria.fr/members/Yves.Bertot/index.html",
    "_line": "FormalReview.bib:827"
  },
  "inria_inria_nodate": {
    "id": "inria_inria_nodate",
    "type": "webpage",
    "author": [
      {
        "family": "Inria"
      }
    ],
    "title": "Inria - Inventors for the digital world.Inria",
    "accessed": {
      "date-parts": [
        [
          "2019",
          "1",
          "31"
        ]
      ]
    },
    "abstract": "Inria is a public research body dedicated to digital science and technology.",
    "URL": "https://www.inria.fr/en",
    "language": "en-US",
    "_line": "FormalReview.bib:835"
  },
  "crary_modules_2017": {
    "id": "crary_modules_2017",
    "type": "paper-conference",
    "author": [
      {
        "family": "Crary",
        "given": "Karl"
      }
    ],
    "title": "Modules, Abstraction, and Parametric Polymorphism",
    "container-title": "Proceedings of the 44th ACM SIGPLAN Symposium on Principles of Programming Languages",
    "collection-title": "POPL 2017",
    "issued": {
      "date-parts": [
        [
          "2017"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "1",
          "31"
        ]
      ]
    },
    "publisher": "ACM",
    "isbn": "978-1-4503-4660-3",
    "abstract": "Reynolds's Abstraction theorem forms the mathematical foundation for data abstraction. His setting was the polymorphic lambda calculus. Today, many modern languages, such as the ML family, employ rich module systems designed to give more expressive support for data abstraction than the polymorphic lambda calculus, but analogues of the Abstraction theorem for such module systems have lagged far behind.   We give an account of the Abstraction theorem for a modern module calculus supporting generative and applicative functors, higher-order functors, sealing, and translucent signatures. The main issues to be overcome are: (1) the fact that modules combine both types and terms, so they must be treated as both simultaneously, (2) the effect discipline that models the distinction between transparent and opaque modules, and (3) a very rich language of type constructors supporting singleton kinds. We define logical equivalence for modules and show that it coincides with contextual equivalence. This substantiates the folk theorem that modules are good for data abstraction. All our proofs are formalized in Coq.",
    "keywords": "Abstraction, logical relations, modules, parametricity",
    "URL": "http://doi.acm.org/10.1145/3009837.3009892",
    "DOI": "10.1145/3009837.3009892",
    "publisher-place": "New York, NY, USA",
    "page": "100-113",
    "page-first": "100",
    "note": "crary/crary-mapp.pdf",
    "_line": "FormalReview.bib:846"
  },
  "platzer_differential_2018": {
    "id": "platzer_differential_2018",
    "type": "chapter",
    "author": [
      {
        "family": "Platzer",
        "given": "André"
      }
    ],
    "container-author": [
      {
        "family": "Platzer",
        "given": "André"
      }
    ],
    "title": "Differential Equations &amp; Differential Invariants",
    "container-title": "Logical Foundations of Cyber-Physical Systems",
    "issued": {
      "date-parts": [
        [
          "2018"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "1",
          "31"
        ]
      ]
    },
    "publisher": "Springer International Publishing",
    "isbn": "978-3-319-63587-3 978-3-319-63588-0",
    "URL": "http://link.springer.com/10.1007/978-3-319-63588-0_10",
    "DOI": "10.1007/978-3-319-63588-0_10",
    "publisher-place": "Cham",
    "page": "287-322",
    "page-first": "287",
    "language": "en-US",
    "_line": "FormalReview.bib:865"
  },
  "platzer_differential_2015": {
    "id": "platzer_differential_2015",
    "type": "article-journal",
    "author": [
      {
        "family": "Platzer",
        "given": "André"
      }
    ],
    "title": "Differential Game Logic",
    "container-title": "ACM Trans. Comput. Logic",
    "issued": {
      "date-parts": [
        [
          "2015",
          "11"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "1",
          "31"
        ]
      ]
    },
    "issn": "1529-3785",
    "abstract": "Differential game logic (dGL) is a logic for specifying and verifying properties of hybrid games, i.e., games that combine discrete, continuous, and adversarial dynamics. Unlike hybrid systems, hybrid games allow choices in the system dynamics to be resolved adversarially by different players with different objectives. The logic dGL can be used to study the existence of winning strategies for such hybrid games, i.e., ways of resolving the player’s choices in some way so that he wins by achieving his objective for all choices of the opponent. Hybrid games are determined, i.e., from each state, one player has a winning strategy, yet computing their winning regions may take transfinitely many steps. The logic dGL, nevertheless, has a sound and complete axiomatization relative to any expressive logic. Separating axioms are identified that distinguish hybrid games from hybrid systems. Finally, dGL is proved to be strictly more expressive than the corresponding logic of hybrid systems by characterizing the expressiveness of both.",
    "keywords": "axiomatization, expressiveness, Game logic, hybrid games",
    "URL": "http://doi.acm.org/10.1145/2817824",
    "DOI": "10.1145/2817824",
    "page": "1:1-1:51",
    "page-first": "1",
    "volume": "17",
    "issue": "1",
    "_line": "FormalReview.bib:882"
  },
  "platzer_differential_2008": {
    "id": "platzer_differential_2008",
    "type": "article-journal",
    "author": [
      {
        "family": "Platzer",
        "given": "André"
      }
    ],
    "title": "Differential Dynamic Logic for Hybrid Systems",
    "container-title": "Journal of Automated Reasoning",
    "issued": {
      "date-parts": [
        [
          "2008",
          "8"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "1",
          "31"
        ]
      ]
    },
    "issn": "0168-7433, 1573-0670",
    "URL": "http://link.springer.com/10.1007/s10817-008-9103-8",
    "DOI": "10.1007/s10817-008-9103-8",
    "page": "143-189",
    "page-first": "143",
    "volume": "41",
    "issue": "2",
    "language": "en-US",
    "_line": "FormalReview.bib:899"
  },
  "hutchison_verifying_2007": {
    "id": "hutchison_verifying_2007",
    "type": "chapter",
    "author": [
      {
        "family": "Ahrendt",
        "given": "Wolfgang"
      },
      {
        "family": "Beckert",
        "given": "Bernhard"
      },
      {
        "family": "Hähnle",
        "given": "Reiner"
      },
      {
        "family": "Rümmer",
        "given": "Philipp"
      },
      {
        "family": "Schmitt",
        "given": "Peter H."
      }
    ],
    "editor": [
      {
        "family": "Boer",
        "given": "Frank S.",
        "dropping-particle": "de"
      },
      {
        "family": "Bonsangue",
        "given": "Marcello M."
      },
      {
        "family": "Graf",
        "given": "Susanne"
      },
      {
        "family": "Roever",
        "given": "Willem-Paul",
        "dropping-particle": "de"
      }
    ],
    "title": "Verifying Object-Oriented Programs with KeY: A Tutorial",
    "container-title": "Formal Methods for Components and Objects",
    "container-title-short": "Verifying Object-Oriented Programs with KeY",
    "title-short": "Verifying Object-Oriented Programs with KeY",
    "issued": {
      "date-parts": [
        [
          "2007"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "1",
          "31"
        ]
      ]
    },
    "publisher": "Springer Berlin Heidelberg",
    "isbn": "978-3-540-74791-8 978-3-540-74792-5",
    "abstract": "This paper is a tutorial on performing formal speciﬁcation and semi-automatic veriﬁcation of Java programs with the formal software development tool KeY. This tutorial aims to ﬁll the gap between elementary introductions using toy examples and state-of-art case studies by going through a self-contained, yet non-trivial, example. It is hoped that this contributes to explain the problems encountered in veriﬁcation of imperative, object-oriented programs to a readership outside the limited community of active researchers.",
    "URL": "http://link.springer.com/10.1007/978-3-540-74792-5_4",
    "DOI": "10.1007/978-3-540-74792-5_4",
    "publisher-place": "Berlin, Heidelberg",
    "page": "70-101",
    "page-first": "70",
    "volume": "4709",
    "language": "en-US",
    "_line": "FormalReview.bib:915"
  },
  "platzer_logical_2018": {
    "id": "platzer_logical_2018",
    "type": "book",
    "author": [
      {
        "family": "Platzer",
        "given": "Andre"
      }
    ],
    "title": "Logical Foundations of Cyber-Physical Systems",
    "issued": {
      "date-parts": [
        [
          "2018"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "1",
          "31"
        ]
      ]
    },
    "publisher": "Springer International Publishing",
    "isbn": "978-3-319-63587-3",
    "abstract": "Cyber-physical systems (CPSs) combine cyber capabilities, such as computation or communication, with physical capabilities, such as motion or other physical processes. Cars, aircraft, and robots are prime examples, because they move physically in space in a way that is determined by discrete computerized control algorithms. Designing these algorithms is challenging due to their tight coupling with physical behavior, while it is vital that these algorithms be correct because we rely on them for safety-critical tasks. This textbook teaches undergraduate students the core principles behind CPSs. It shows them how to develop models and controls; identify safety specifications and critical properties; reason rigorously about CPS models; leverage multi-dynamical systems compositionality to tame CPS complexity; identify required control constraints; verify CPS models of appropriate scale in logic; and develop an intuition for operational effects. The book is supported with homework exercises, lecture videos, and slides.",
    "URL": "https://www.springer.com/gp/book/9783319635873",
    "language": "en-US",
    "_line": "FormalReview.bib:937"
  },
  "platzer_keymaera_nodate": {
    "id": "platzer_keymaera_nodate",
    "type": "webpage",
    "author": [
      {
        "family": "Platzer",
        "given": "André"
      }
    ],
    "title": "KeYmaera X: Documentation",
    "accessed": {
      "date-parts": [
        [
          "2019",
          "1",
          "31"
        ]
      ]
    },
    "URL": "http://www.ls.cs.cmu.edu/KeYmaeraX/documentation.html",
    "_line": "FormalReview.bib:950"
  },
  "felty_keymaera_2015": {
    "id": "felty_keymaera_2015",
    "type": "chapter",
    "author": [
      {
        "family": "Fulton",
        "given": "Nathan"
      },
      {
        "family": "Mitsch",
        "given": "Stefan"
      },
      {
        "family": "Quesel",
        "given": "Jan-David"
      },
      {
        "family": "Völp",
        "given": "Marcus"
      },
      {
        "family": "Platzer",
        "given": "André"
      }
    ],
    "editor": [
      {
        "family": "Felty",
        "given": "Amy P."
      },
      {
        "family": "Middeldorp",
        "given": "Aart"
      }
    ],
    "title": "KeYmaera X: An Axiomatic Tactical Theorem Prover for Hybrid Systems",
    "container-title": "Automated Deduction - CADE-25",
    "container-title-short": "KeYmaera X",
    "title-short": "KeYmaera X",
    "issued": {
      "date-parts": [
        [
          "2015"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "1",
          "31"
        ]
      ]
    },
    "publisher": "Springer International Publishing",
    "isbn": "978-3-319-21400-9 978-3-319-21401-6",
    "abstract": "KeYmaera X is a theorem prover for differential dynamic logic (dL), a logic for specifying and verifying properties of hybrid systems. Reasoning about complicated hybrid systems models requires support for sophisticated proof techniques, efﬁcient computation, and a user interface that crystallizes salient properties of the system. KeYmaera X allows users to specify custom proof search techniques as tactics, execute these tactics in parallel, and interface with partial proofs via an extensible user interface.",
    "URL": "http://link.springer.com/10.1007/978-3-319-21401-6_36",
    "DOI": "10.1007/978-3-319-21401-6_36",
    "publisher-place": "Cham",
    "page": "527-538",
    "page-first": "527",
    "volume": "9195",
    "language": "en-US",
    "_line": "FormalReview.bib:958"
  },
  "platzer_logical_2018-1": {
    "id": "platzer_logical_2018-1",
    "type": "book",
    "author": [
      {
        "family": "Platzer",
        "given": "André"
      }
    ],
    "title": "Logical Foundations of Cyber-Physical Systems - Slides",
    "issued": {
      "date-parts": [
        [
          "2018"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "1",
          "31"
        ]
      ]
    },
    "publisher": "Springer International Publishing",
    "isbn": "978-3-319-63587-3 978-3-319-63588-0",
    "URL": "http://link.springer.com/10.1007/978-3-319-63588-0",
    "DOI": "10.1007/978-3-319-63588-0",
    "publisher-place": "Cham",
    "language": "en-US",
    "_line": "FormalReview.bib:978"
  },
  "platzer_complete_2017": {
    "id": "platzer_complete_2017",
    "type": "article-journal",
    "author": [
      {
        "family": "Platzer",
        "given": "André"
      }
    ],
    "title": "A Complete Uniform Substitution Calculus for Differential Dynamic Logic",
    "container-title": "Journal of Automated Reasoning",
    "issued": {
      "date-parts": [
        [
          "2017",
          "8"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "1",
          "31"
        ]
      ]
    },
    "issn": "0168-7433, 1573-0670",
    "abstract": "This article introduces a relatively complete proof calculus for differential dynamic logic (dL) that is entirely based on uniform substitution, a proof rule that substitutes a formula for a predicate symbol everywhere. Uniform substitutions make it possible to use axioms instead of axiom schemata, thereby substantially simplifying implementations. Instead of subtle schema variables and soundness-critical side conditions on the occurrence patterns of logical variables to restrict infinitely many axiom schema instances to sound ones, the resulting calculus adopts only a finite number of ordinary dL formulas as axioms, which uniform substitutions instantiate soundly. The static semantics of differential dynamic logic and the soundness-critical restrictions it imposes on proof steps is captured exclusively in uniform substitutions and variable renamings as opposed to being spread in delicate ways across the prover implementation. In addition to sound uniform substitutions, this article introduces differential forms for differential dynamic logic that make it possible to internalize differential invariants, differential substitutions, and derivatives as first-class axioms to reason about differential equations axiomatically. The resulting axiomatization of differential dynamic logic is proved to be sound and relatively complete.",
    "keywords": "03F03, 03B70, 34A38, Computer Science - Logic in Computer Science, Computer Science - Programming Languages, F.3.1, F.3.2, F.4.1, I.2.3, Mathematics - Logic",
    "URLtext": "1601.06183",
    "URLpretext": "[arXiv:]{.etype}",
    "eprint-type": "arxiv",
    "eprint": "1601.06183",
    "URL": "http://arxiv.org/abs/1601.06183",
    "DOI": "10.1007/s10817-016-9385-1",
    "page": "219-265",
    "page-first": "219",
    "volume": "59",
    "issue": "2",
    "_line": "FormalReview.bib:992"
  },
  "beckert_verification_2006": {
    "id": "beckert_verification_2006",
    "type": "book",
    "editor": [
      {
        "family": "Beckert",
        "given": "Bernhard"
      },
      {
        "family": "Hähnle",
        "given": "Reiner"
      },
      {
        "family": "Schmitt",
        "given": "Peter H."
      }
    ],
    "title": "Verification of Object-Oriented Software. The KeY Approach",
    "collection-title": "Lecture Notes in Computer Science",
    "issued": {
      "date-parts": [
        [
          "2006"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "1",
          "31"
        ]
      ]
    },
    "publisher": "Springer Berlin Heidelberg",
    "isbn": "978-3-540-68977-5",
    "URL": "http://link.springer.com/10.1007/978-3-540-69061-0",
    "DOI": "10.1007/978-3-540-69061-0",
    "publisher-place": "Berlin, Heidelberg",
    "volume": "4334",
    "language": "en-US",
    "_line": "FormalReview.bib:1011"
  },
  "bohrer_veriphy:_2018": {
    "id": "bohrer_veriphy:_2018",
    "type": "paper-conference",
    "author": [
      {
        "family": "Bohrer",
        "given": "Brandon"
      },
      {
        "family": "Tan",
        "given": "Yong Kiam"
      },
      {
        "family": "Mitsch",
        "given": "Stefan"
      },
      {
        "family": "Myreen",
        "given": "Magnus O."
      },
      {
        "family": "Platzer",
        "given": "André"
      }
    ],
    "title": "VeriPhy: verified controller executables from verified cyber-physical system models",
    "container-title": "Proceedings of the 39th ACM SIGPLAN Conference on Programming Language Design and Implementation  - PLDI 2018",
    "container-title-short": "VeriPhy",
    "title-short": "VeriPhy",
    "event-title": "the 39th ACM SIGPLAN Conference",
    "issued": {
      "date-parts": [
        [
          "2018"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "1",
          "31"
        ]
      ]
    },
    "publisher": "ACM Press",
    "isbn": "978-1-4503-5698-5",
    "URL": "http://dl.acm.org/citation.cfm?doid=3192366.3192406",
    "DOI": "10.1145/3192366.3192406",
    "publisher-place": "Philadelphia, PA, USA",
    "page": "617-630",
    "page-first": "617",
    "language": "en-US",
    "_line": "FormalReview.bib:1027"
  },
  "ahrendt_deductive_nodate": {
    "id": "ahrendt_deductive_nodate",
    "type": "webpage",
    "author": [
      {
        "family": "Ahrendt",
        "given": "Wolfgang"
      }
    ],
    "title": "Deductive Software Verification – The KeY BookFrom Theory to Practice – The KeY Project",
    "accessed": {
      "date-parts": [
        [
          "2019",
          "1",
          "31"
        ]
      ]
    },
    "URL": "https://www.key-project.org/thebook2/",
    "note": "cyber-physical/KeY directory has pdfs for the chapters.",
    "language": "en-US",
    "_line": "FormalReview.bib:1044"
  },
  "czajka_coqhammer:_nodate": {
    "id": "czajka_coqhammer:_nodate",
    "type": "webpage",
    "author": [
      {
        "family": "Czajka",
        "given": "Lukasz"
      },
      {
        "family": "Kaliszyk",
        "given": "Cezary"
      }
    ],
    "title": "CoqHammer: Strong Automation for Program Verification - CoqPL 2018",
    "accessed": {
      "date-parts": [
        [
          "2019",
          "1",
          "31"
        ]
      ]
    },
    "abstract": "We present CoqHammer: the first full hammer system for\nthe Coq proof assistant. The system translates Coq logic\nto untyped first-order logic and uses external automated\ntheorem provers (ATPs) to prove the translations of user\ngiven conjectures. Based on the output of the ATPs, the\nconjecture is then re-proved in the logic of Coq using an\neauto-type proof search algorithm. Together with machinelearning\nbased selection of relevant premises this constitutes\na full hammer system.\nThe performance of the overall procedure has been evaluated\nin a bootstrapping scenario emulating the development\nof the Coq standard library. Over 40&perc; of the theorems in\nthe Coq standard library can be proved in a push-button\nmode in about 40 seconds of real time on a 8-CPU system.\nThis offers a huge saving of human work in programming\nlanguage formalizations.",
    "URL": "https://popl18.sigplan.org/event/coqpl-2018-coqhammer-strong-automation-for-program-verification",
    "_line": "FormalReview.bib:1054"
  },
  "acm_coqpl_nodate": {
    "id": "acm_coqpl_nodate",
    "type": "webpage",
    "author": [
      {
        "family": "",
        "dropping-particle": "acm"
      }
    ],
    "title": "CoqPL 2019 The Fifth International Workshop on Coq for Programming Languages - POPL 2019",
    "accessed": {
      "date-parts": [
        [
          "2019",
          "1",
          "31"
        ]
      ]
    },
    "URL": "https://popl19.sigplan.org/track/CoqPL-2019#program",
    "_line": "FormalReview.bib:1078"
  },
  "acm_coqpl_nodate-1": {
    "id": "acm_coqpl_nodate-1",
    "type": "webpage",
    "author": [
      {
        "family": "",
        "dropping-particle": "acm"
      }
    ],
    "title": "CoqPL 2018 The Fourth International Workshop on Coq for Programming Languages - POPL 2018",
    "accessed": {
      "date-parts": [
        [
          "2019",
          "1",
          "31"
        ]
      ]
    },
    "URL": "https://popl18.sigplan.org/track/CoqPL-2018",
    "_line": "FormalReview.bib:1086"
  },
  "acm_coq_nodate": {
    "id": "acm_coq_nodate",
    "type": "webpage",
    "author": [
      {
        "family": "",
        "dropping-particle": "acm"
      }
    ],
    "title": "Coq for PL conference series - CoqPL 2019",
    "accessed": {
      "date-parts": [
        [
          "2019",
          "1",
          "31"
        ]
      ]
    },
    "URL": "https://popl18.sigplan.org/series/CoqPL",
    "_line": "FormalReview.bib:1094"
  },
  "acm_popl_nodate": {
    "id": "acm_popl_nodate",
    "type": "webpage",
    "author": [
      {
        "family": "",
        "dropping-particle": "acm"
      }
    ],
    "title": "POPL conference series - POPL 2020",
    "accessed": {
      "date-parts": [
        [
          "2019",
          "1",
          "31"
        ]
      ]
    },
    "URL": "https://popl18.sigplan.org/series/POPL",
    "_line": "FormalReview.bib:1102"
  },
  "polikarpova_structuring_2019": {
    "id": "polikarpova_structuring_2019",
    "type": "article-journal",
    "author": [
      {
        "family": "Polikarpova",
        "given": "Nadia"
      },
      {
        "family": "Sergey",
        "given": "Ilya"
      }
    ],
    "title": "Structuring the Synthesis of Heap-manipulating Programs",
    "container-title": "Proc. ACM Program. Lang.",
    "issued": {
      "date-parts": [
        [
          "2019",
          "1"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "1",
          "31"
        ]
      ]
    },
    "issn": "2475-1421",
    "abstract": "This paper describes a deductive approach to synthesizing imperative programs with pointers from declarative specifications expressed in Separation Logic. Our synthesis algorithm takes as input a pair of assertions—a pre- and a postcondition—which describe two states of the symbolic heap, and derives a program that transforms one state into the other, guided by the shape of the heap. Our approach to program synthesis is grounded in proof theory: we introduce the novel framework of Synthetic Separation Logic (SSL), which generalises the classical notion of heap entailment P ⊢ Q to incorporate a possibility of transforming a heap satisfying an assertion P into a heap satisfying an assertion Q. A synthesized program represents a proof term for a transforming entailment statement P ↝ Q, and the synthesis procedure corresponds to a proof search. The derived programs are, thus, correct by construction, in the sense that they satisfy the ascribed pre/postconditions, and are accompanied by complete proof derivations, which can be checked independently.  We have implemented a proof search engine for SSL in a form of the program synthesizer called SuSLik. For efficiency, the engine exploits properties of SSL rules, such as invertibility and commutativity of rule applications on separate heaps, to prune the space of derivations it has to consider. We explain and showcase the use of SSL on characteristic examples, describe the design of SuSLik, and report on our experience of using it to synthesize a series of benchmark programs manipulating heap-based linked data structures.",
    "keywords": "Program Synthesis, Proof Systems, Separation Logic, Type Theory",
    "URL": "http://doi.acm.org/10.1145/3290385",
    "DOI": "10.1145/3290385",
    "page": "72:1-72:30",
    "page-first": "72",
    "volume": "3",
    "_line": "FormalReview.bib:1128"
  },
  "leino_assertional_2015": {
    "id": "leino_assertional_2015",
    "type": "article-journal",
    "author": [
      {
        "family": "Leino",
        "given": "K. Rustan M."
      },
      {
        "family": "Lucio",
        "given": "Paqui"
      }
    ],
    "title": "An Assertional Proof of the Stability and Correctness of Natural Mergesort",
    "container-title": "ACM Trans. Comput. Logic",
    "issued": {
      "date-parts": [
        [
          "2015",
          "11"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "1",
          "31"
        ]
      ]
    },
    "issn": "1529-3785",
    "abstract": "We present a mechanically verified implementation of the sorting algorithm Natural Mergesort that consists of a few methods specified by their contracts of pre/post conditions. Methods are annotated with assertions that allow the automatic verification of the contract satisfaction. This program-proof is made using the state-of-the-art verifier Dafny. We verify not only the standard sortedness property, but also that the algorithm performs a stable sort. Throughout the article, we provide and explain the complete text of the program-proof.",
    "keywords": "dafny, formal methods, natural mergesort, software engineering, sorting, stability, theorem proving, Verification",
    "URL": "http://doi.acm.org/10.1145/2814571",
    "DOI": "10.1145/2814571",
    "page": "6:1-6:22",
    "page-first": "6",
    "volume": "17",
    "issue": "1",
    "_line": "FormalReview.bib:1145"
  },
  "christakis_collaborative_2012": {
    "id": "christakis_collaborative_2012",
    "type": "paper-conference",
    "author": [
      {
        "family": "Christakis",
        "given": "Maria"
      },
      {
        "family": "Müller",
        "given": "Peter"
      },
      {
        "family": "Wüstholz",
        "given": "Valentin"
      }
    ],
    "editor": [
      {
        "family": "Giannakopoulou",
        "given": "Dimitra"
      },
      {
        "family": "Méry",
        "given": "Dominique"
      }
    ],
    "title": "Collaborative Verification and Testing with Explicit Assumptions",
    "container-title": "FM 2012: Formal Methods",
    "collection-title": "Lecture Notes in Computer Science",
    "issued": {
      "date-parts": [
        [
          "2012"
        ]
      ]
    },
    "publisher": "Springer Berlin Heidelberg",
    "isbn": "978-3-642-32759-9",
    "abstract": "Many mainstream static code checkers make a number of compromises to improve automation, performance, and accuracy. These compromises include not checking certain program properties as well as making implicit, unsound assumptions. Consequently, the results of such static checkers do not provide definite guarantees about program correctness, which makes it unclear which properties remain to be tested. We propose a technique for collaborative verification and testing that makes compromises of static checkers explicit such that they can be compensated for by complementary checkers or testing. Our experiments suggest that our technique finds more errors and proves more properties than static checking alone, testing alone, and combinations that do not explicitly document the compromises made by static checkers. Our technique is also useful to obtain small test suites for partially-verified programs.",
    "keywords": "Static Checker, Symbolic Execution, Test Case Generation, Testing Tool, Tool Chain",
    "page": "132-146",
    "page-first": "132",
    "language": "en-US",
    "_line": "FormalReview.bib:1162"
  },
  "leino_co-induction_2013": {
    "id": "leino_co-induction_2013",
    "type": "article-journal",
    "author": [
      {
        "family": "Leino",
        "given": "Rustan"
      },
      {
        "family": "Moskal",
        "given": "Michal"
      }
    ],
    "title": "Co-Induction Simply: Automatic Co-Inductive Proofs in a Program Verifier",
    "container-title-short": "Co-Induction Simply",
    "title-short": "Co-Induction Simply",
    "issued": {
      "date-parts": [
        [
          "2013",
          "7",
          "12"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "1",
          "31"
        ]
      ]
    },
    "abstract": "Program verification relies heavily on induction, which has received decades of attention in mechanical verification tools. When program correctness is best described by infinite structures, program verification is usefully aided also by co-induction, which has not benefited from the same degree of tool support. Co-induction is complicated to work with in interactive proof assistants and …",
    "URL": "https://www.microsoft.com/en-us/research/publication/co-induction-simply-automatic-co-inductive-proofs-in-a-program-verifier/",
    "language": "en-US",
    "_line": "FormalReview.bib:1178"
  },
  "amin_computing_2016": {
    "id": "amin_computing_2016",
    "type": "article-journal",
    "author": [
      {
        "family": "Amin",
        "given": "Nada"
      },
      {
        "family": "Leino",
        "given": "Rustan"
      },
      {
        "family": "Rompf",
        "given": "Tiark"
      }
    ],
    "title": "Computing with an SMT Solver",
    "issued": {
      "date-parts": [
        [
          "2016",
          "12",
          "28"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "1",
          "31"
        ]
      ]
    },
    "abstract": "Satisfiability modulo theories (SMT) solvers that support quantifier instantiations via matching triggers can be programmed to give practical support for user-defined theories. Care must be taken to avoid so-called matching loops, which may prevent termination of the solver. By design, such avoidance limits the extent to which the SMT solver is able to apply the …",
    "URL": "https://www.microsoft.com/en-us/research/publication/computing-smt-solver/",
    "volume": "8570",
    "language": "en-US",
    "_line": "FormalReview.bib:1190"
  },
  "hatcliff_behavioral_2012": {
    "id": "hatcliff_behavioral_2012",
    "type": "article-journal",
    "author": [
      {
        "family": "Hatcliff",
        "given": "John"
      },
      {
        "family": "Leavens",
        "given": "Gary T."
      },
      {
        "family": "Leino",
        "given": "K. Rustan M."
      },
      {
        "family": "Müller",
        "given": "Peter"
      },
      {
        "family": "Parkinson",
        "given": "Matthew"
      }
    ],
    "title": "Behavioral Interface Specification Languages",
    "container-title": "ACM Comput. Surv.",
    "issued": {
      "date-parts": [
        [
          "2012",
          "6"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "1",
          "31"
        ]
      ]
    },
    "issn": "0360-0300",
    "abstract": "Behavioral interface specification languages provide formal code-level annotations, such as preconditions, postconditions, invariants, and assertions that allow programmers to express the intended behavior of program modules. Such specifications are useful for precisely documenting program behavior, for guiding implementation, and for facilitating agreement between teams of programmers in modular development of software. When used in conjunction with automated analysis and program verification tools, such specifications can support detection of common code vulnerabilities, capture of light-weight application-specific semantic properties, generation of test cases and test oracles, and full formal program verification. This article surveys behavioral interface specification languages with a focus toward automatic program verification and with a view towards aiding the Verified Software Initiative—a fifteen-year, cooperative, international project directed at the scientific challenges of large-scale software verification.",
    "keywords": "Abstraction, assertion, behavioral subtyping, frame conditions, interface specification language, invariant, JML, postcondition, precondition, separation logic, SPARK, Spec&hash;",
    "URL": "http://doi.acm.org/10.1145/2187671.2187678",
    "DOI": "10.1145/2187671.2187678",
    "page": "16:1-16:58",
    "page-first": "16",
    "volume": "44",
    "issue": "3",
    "_line": "FormalReview.bib:1202"
  },
  "leino_verification_2016": {
    "id": "leino_verification_2016",
    "type": "article-journal",
    "author": [
      {
        "family": "Leino",
        "given": "Rustan"
      },
      {
        "family": "Müller",
        "given": "Peter"
      },
      {
        "family": "Smans",
        "given": "Jan"
      }
    ],
    "title": "Verification of Concurrent Programs with Chalice",
    "issued": {
      "date-parts": [
        [
          "2016",
          "12",
          "29"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "1",
          "31"
        ]
      ]
    },
    "abstract": "A program verifier is a tool that allows developers to prove that their code satisfies its specification for every possible input and every thread schedule. These lecture notes describe a verifier for concurrent programs called Chalice. Chalice’s verification methodology centers around permissions and permission transfer. In particular, a memory location may be accessed by a …",
    "URL": "https://www.microsoft.com/en-us/research/publication/verification-concurrent-programs-chalice/",
    "language": "en-US",
    "_line": "FormalReview.bib:1219"
  },
  "leino_stepwise_2016": {
    "id": "leino_stepwise_2016",
    "type": "article-journal",
    "author": [
      {
        "family": "Leino",
        "given": "Rustan"
      },
      {
        "family": "Yessenov",
        "given": "Kuat"
      }
    ],
    "title": "Stepwise Refinement of Heap-Manipulating Code in Chalice",
    "issued": {
      "date-parts": [
        [
          "2016",
          "12",
          "29"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "1",
          "31"
        ]
      ]
    },
    "abstract": "Stepwise refinement is a well-studied technique for developing a program from an abstract description to a concrete implementation. This paper describes a system with automated tool support for refinement, powered by a stateof-the-art verification engine that uses an SMT solver. Unlike previous refinement systems, users of the presented system interact only via declarations in the …",
    "URL": "https://www.microsoft.com/en-us/research/publication/stepwise-refinement-heap-manipulating-code-chalice/",
    "language": "en-US",
    "_line": "FormalReview.bib:1230"
  },
  "leino_fine-grained_2016": {
    "id": "leino_fine-grained_2016",
    "type": "article-journal",
    "author": [
      {
        "family": "Leino",
        "given": "Rustan"
      },
      {
        "family": "Wüstholz",
        "given": "Valentin"
      }
    ],
    "title": "Fine-grained Caching of Verification Results",
    "issued": {
      "date-parts": [
        [
          "2016",
          "12",
          "28"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "1",
          "31"
        ]
      ]
    },
    "abstract": "Developing provably correct programs is an incremental process that often involves a series of interactions with a program verifier. To increase the responsiveness of the program verifier during such interactions, we designed a system for fine-grained caching of verification results. The caching system uses the program’s call graph and control-flow graph to focus the verification …",
    "URL": "https://www.microsoft.com/en-us/research/publication/fine-grained-caching-verification-results/",
    "volume": "9206",
    "language": "en-US",
    "_line": "FormalReview.bib:1241"
  },
  "koenig_programming_2016": {
    "id": "koenig_programming_2016",
    "type": "article-journal",
    "author": [
      {
        "family": "Koenig",
        "given": "Jason"
      },
      {
        "family": "Leino",
        "given": "Rustan"
      }
    ],
    "title": "Programming Language Features for Refinement",
    "issued": {
      "date-parts": [
        [
          "2016",
          "12",
          "28"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "1",
          "31"
        ]
      ]
    },
    "abstract": "Algorithmic and data refinement are well studied topics that provide a mathematically rigorous approach to gradually introducing details in the implementation of software. Program refinements are performed in the context of some programming language, but mainstream languages lack features for recording the sequence of refinement steps in the program text. To experiment with the combination …",
    "URL": "https://www.microsoft.com/en-us/research/publication/programming-language-features-refinement/",
    "language": "en-US",
    "_line": "FormalReview.bib:1253"
  },
  "leino_compiling_2016": {
    "id": "leino_compiling_2016",
    "type": "article-journal",
    "author": [
      {
        "family": "Leino",
        "given": "Rustan"
      }
    ],
    "title": "Compiling Hilbert's epsilon Operator",
    "container-title": "LPAR-20. 20th International Conferences on Logic for Programming, Artificial Intelligence and Reasoning",
    "issued": {
      "date-parts": [
        [
          "2016",
          "12",
          "28"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "1",
          "31"
        ]
      ]
    },
    "abstract": "Hilbert’s epsilon (ϵ) operator is a binder that picks an arbitrary element from a nonempty set. The operator is typically used in logics and proof engines. This paper contributes a discussion of considerations in supporting this operator in a programming language. More specifically, the paper presents the design choices made around supporting this operator in …",
    "URL": "https://www.microsoft.com/en-us/research/publication/compiling-hilberts-%cf%b5-operator/",
    "volume": "35",
    "language": "en-US",
    "_line": "FormalReview.bib:1264"
  },
  "parkinson_relationship_nodate": {
    "id": "parkinson_relationship_nodate",
    "type": "article-journal",
    "author": [
      {
        "family": "Parkinson",
        "given": "Matthew J"
      },
      {
        "family": "Summers",
        "given": "Alexander J"
      }
    ],
    "title": "The Relationship between Separation Logic and Implicit Dynamic Frames",
    "container-title": "LNCS",
    "abstract": "Separation logic is a concise method for specifying programs that manipulate dynamically allocated storage. Partially inspired by separation logic, Implicit Dynamic Frames has recently been proposed, aiming at ﬁrst-order tool support. In this paper, we provide a total heap semantics for a standard separation logic, and prove it equivalent to the standard model. With small adaptations, we then show how to give a direct semantics to implicit dynamic frames and show this semantics correctly captures the existing deﬁnitions. This precisely connects the two logics. As a consequence of this connection, we show that a fragment of separation logic can be faithfully encoded in a ﬁrst-order automatic veriﬁcation tool (Chalice).",
    "page": "439-458",
    "page-first": "439",
    "volume": "6602",
    "note": "ESOP 2011",
    "language": "en-US",
    "_line": "FormalReview.bib:1277"
  },
  "leino_verified_2016": {
    "id": "leino_verified_2016",
    "type": "article-journal",
    "author": [
      {
        "family": "Leino",
        "given": "Rustan"
      },
      {
        "family": "Polikarpova",
        "given": "Nadia"
      }
    ],
    "title": "Verified Calculations",
    "issued": {
      "date-parts": [
        [
          "2016",
          "12",
          "28"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "1",
          "31"
        ]
      ]
    },
    "abstract": "Calculational proofs—proofs by stepwise formula manipulation—are praised for their rigor, readability, and elegance. It seems desirable to reuse this style, often employed on paper, in the context of mechanized reasoning, and in particular, program verification. This work leverages the power of SMT solvers to machine-check calculational proofs at the level of detail they are usually …",
    "URL": "https://www.microsoft.com/en-us/research/publication/verified-calculations/",
    "language": "en-US",
    "_line": "FormalReview.bib:1289"
  },
  "leino_well-founded_2016": {
    "id": "leino_well-founded_2016",
    "type": "article-journal",
    "author": [
      {
        "family": "Leino",
        "given": "Rustan"
      }
    ],
    "title": "Well-Founded Functions and Extreme Predicates in Dafny: A Tutorial",
    "container-title-short": "Well-Founded Functions and Extreme Predicates in Dafny",
    "title-short": "Well-Founded Functions and Extreme Predicates in Dafny",
    "issued": {
      "date-parts": [
        [
          "2016",
          "12",
          "28"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "1",
          "31"
        ]
      ]
    },
    "abstract": "A recursive function is well defined if its every recursive call corresponds a decrease in some well-founded order. Such well-founded functions are useful for example in computer programs when computing a value from some input. A boolean function can also be defined as an extreme solution to a recurrence relation, that is, as a least …",
    "URL": "https://www.microsoft.com/en-us/research/publication/well-founded-functions-extreme-predicates-dafny-tutorial/",
    "volume": "40",
    "language": "en-US",
    "_line": "FormalReview.bib:1300"
  },
  "acm_acm_nodate": {
    "id": "acm_acm_nodate",
    "type": "webpage",
    "author": [
      {
        "family": "",
        "dropping-particle": "acm"
      }
    ],
    "title": "ACM Classification Codes",
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "URL": "https://cran.r-project.org/web/classifications/ACM.html",
    "_line": "FormalReview.bib:1313"
  },
  "acm_msc2010_nodate": {
    "id": "acm_msc2010_nodate",
    "type": "webpage",
    "author": [
      {
        "family": "",
        "dropping-particle": "acm"
      }
    ],
    "title": "MSC2010 database",
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "URL": "https://mathscinet.ams.org/msc/msc2010.html",
    "_line": "FormalReview.bib:1321"
  },
  "sozeau_typed_nodate": {
    "id": "sozeau_typed_nodate",
    "type": "webpage",
    "author": [
      {
        "family": "Sozeau",
        "given": "Matthieu"
      }
    ],
    "title": "Typed Template Coq - POPL 2018",
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "URL": "https://popl18.sigplan.org/event/coqpl-2018-typed-template-coq",
    "_line": "FormalReview.bib:1329"
  },
  "anand_typed_nodate": {
    "id": "anand_typed_nodate",
    "type": "article-journal",
    "author": [
      {
        "family": "Anand",
        "given": "Abhishek"
      },
      {
        "family": "Tabareau",
        "given": "Simon Boulier Nicolas"
      },
      {
        "family": "Sozeau",
        "given": "Matthieu"
      }
    ],
    "title": "Typed Template Coq",
    "abstract": "Template-Coq1 is a plugin for Coq, originally implemented by Malecha \\[7\\], which provides a reifier for Coq terms and global declarations, as represented in the Coq kernel, as well as a denotation command. Initially, it was developed for the purpose of writing functions on Coq’s AST in Gallina. Recently, its use was extended for the needs of the CertiCoq certified compiler project \\[2\\], which uses it as its front-end language and to derive parametricity properties \\[1\\], and the work of \\[5\\] on extracting Coq terms to a CBV λ-calculus. However, the syntax currently lacks semantics, be it typing semantics or operational semantics, which should reflect, as formal specifications in Coq, the semantics of Coq itself. This is an issue for CertiCoq where both a non-deterministic small step semantics and a deterministic call-by-value big step semantics had to be defined and preserved, without an “official” reference specification to refer to. Our hope with this work is to remedy this situation and provide a formal semantics of Coq’s implemented type theory, that can independently be refined and studied. By implementing a (partial) independent checker in Coq, we can also help formalize certified translations from Coq to Coq (Section 3).",
    "page": "2",
    "page-first": "2",
    "language": "en-US",
    "_line": "FormalReview.bib:1337"
  },
  "sozeau_typed_nodate-1": {
    "id": "sozeau_typed_nodate-1",
    "type": "article-journal",
    "author": [
      {
        "family": "Sozeau",
        "given": "Matthieu"
      }
    ],
    "title": "Typed Template Coq - Slides",
    "page": "11",
    "page-first": "11",
    "language": "en-US",
    "_line": "FormalReview.bib:1346"
  },
  "appel_certicoq:_nodate": {
    "id": "appel_certicoq:_nodate",
    "type": "webpage",
    "author": [
      {
        "family": "Appel",
        "given": "Andrew W."
      }
    ],
    "title": "CertiCoq: A verified compiler for Coq - POPL 2017",
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "URL": "https://popl17.sigplan.org/event/main-certicoq-a-verified-compiler-for-coq",
    "_line": "FormalReview.bib:1354"
  },
  "adewale_implementing_nodate": {
    "id": "adewale_implementing_nodate",
    "type": "webpage",
    "author": [
      {
        "family": "Adewale",
        "given": "Oluwatosin"
      }
    ],
    "title": "Implementing a high-performance key-value store using a trie of B+-Trees with cursors &bar; Computer Science Department at Princeton University",
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "abstract": "Abstract\nIn this paper, we discuss the implementation of a serial main-memory key-value store based on Masstree\\[6\\]. Similar to Masstree, the key-value store is implemented as a trie-like tree of B+-Trees, where each B+-Tree is responsible for a xed-length slice of a variable-length key. However, one of the major dierences between our key-value store and Masstree is that our B+-tree implementation (a component of the key-value store) takes linear time to insert a set of sorted records. This is compared to a traditional B+-tree implementation that would take linearithmic time. Moreover, partially sorting a sequence of operation leads to substantial performance gains. This is made possible using a data structure for navigating B+-trees called a B+-tree cursor. As our next operation is amortized constant time, our B+-tree does not need to maintain cross links between leaf nodes. We also briefy show that this same data structure can be extended to the trie of B+-Trees to ensure amortized linear time for bulk insertion of key-value pairs in the key-value store. We were inspired with this idea of B+-Tree cursors from the SQLite \\[5\\] B-tree source code.",
    "URL": "https://www.cs.princeton.edu/research/techreps/TR-004-18",
    "_line": "FormalReview.bib:1362"
  },
  "barriere_vst_nodate": {
    "id": "barriere_vst_nodate",
    "type": "article-journal",
    "author": [
      {
        "family": "Barriere",
        "given": "Aurele"
      },
      {
        "family": "Appel",
        "given": "Andrew"
      }
    ],
    "title": "VST Veriﬁcation of B+Trees with Cursors",
    "abstract": "The DeepSpecDB project aims to deﬁne, specify and verify a high-performance concurrent in-memory database system. Based on MassTree, it uses B+Trees, a well-studied key-value data structure. Our sequential B+Trees library uses cursors, introduced in the database engine SQLite. Such cursors reduce the complexity of operations when dealing with partially sorted data. We deﬁne a Coq formal model for such trees, then use it to specify and prove the correctness of the C implementation using the Veriﬁed Software Toolchain.",
    "page": "19",
    "page-first": "19",
    "language": "en-US",
    "_line": "FormalReview.bib:1372"
  },
  "appel_deepspecdb_2019": {
    "id": "appel_deepspecdb_2019",
    "type": "book",
    "author": [
      {
        "family": "Appel",
        "given": "Andrew W."
      }
    ],
    "title": "DeepSpecDB - github",
    "issued": {
      "date-parts": [
        [
          "2019",
          "1",
          "31"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "publisher": "PrincetonUniversity",
    "URL": "https://github.com/PrincetonUniversity/DeepSpecDB",
    "note": "original-date: 2017-11-30T14:24:30Z",
    "_line": "FormalReview.bib:1381"
  },
  "chen_project_nodate": {
    "id": "chen_project_nodate",
    "type": "article-journal",
    "author": [
      {
        "family": "Chen",
        "given": "Yixuan"
      }
    ],
    "title": "Project Report on DeepSpecDB",
    "abstract": "Recent years have witnessed a rapid development of mainmemory database systems thanks to the growingly aﬀordable memory. DeepSpecDB is another main-memory database management system implemented in C with deep speciﬁcation and end-to-end veriﬁcation guaranteeing the correctness of the system.",
    "page": "35",
    "page-first": "35",
    "language": "en-US",
    "_line": "FormalReview.bib:1392"
  },
  "sozeau_equations:_2010": {
    "id": "sozeau_equations:_2010",
    "type": "paper-conference",
    "author": [
      {
        "family": "Sozeau",
        "given": "Matthieu"
      }
    ],
    "editor": [
      {
        "family": "Kaufmann",
        "given": "Matt"
      },
      {
        "family": "Paulson",
        "given": "Lawrence C."
      }
    ],
    "title": "Equations: A Dependent Pattern-Matching Compiler",
    "container-title": "Interactive Theorem Proving",
    "container-title-short": "Equations",
    "collection-title": "Lecture Notes in Computer Science",
    "title-short": "Equations",
    "issued": {
      "date-parts": [
        [
          "2010"
        ]
      ]
    },
    "publisher": "Springer Berlin Heidelberg",
    "isbn": "978-3-642-14052-5",
    "abstract": "We present a compiler for definitions made by pattern matching on inductive families in the Coq system. It allows to write structured, recursive dependently-typed functions as a set of equations, automatically find their realization in the core type theory and generate proofs to ease reasoning on them. It provides a complete package to define and reason on functions in the proof assistant, substantially reducing the boilerplate code and proofs one usually has to write, also hiding the intricacies related to the use of dependent types and complex recursion schemes.",
    "keywords": "Proof Assistant, Recursive Call, Split Node, Type Theory, User Node",
    "page": "419-434",
    "page-first": "419",
    "language": "en-US",
    "_line": "FormalReview.bib:1401"
  },
  "delaware_fiat:_2015": {
    "id": "delaware_fiat:_2015",
    "type": "paper-conference",
    "author": [
      {
        "family": "Delaware",
        "given": "Benjamin"
      },
      {
        "family": "Pit-Claudel",
        "given": "Clément"
      },
      {
        "family": "Gross",
        "given": "Jason"
      },
      {
        "family": "Chlipala",
        "given": "Adam"
      }
    ],
    "title": "Fiat: Deductive Synthesis of Abstract Data Types in a Proof Assistant",
    "container-title": "Proceedings of the 42Nd Annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages",
    "container-title-short": "Fiat",
    "collection-title": "POPL '15",
    "title-short": "Fiat",
    "issued": {
      "date-parts": [
        [
          "2015"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "publisher": "ACM",
    "isbn": "978-1-4503-3300-9",
    "abstract": "We present Fiat, a library for the Coq proof assistant supporting refinement of declarative specifications into efficient functional programs with a high degree of automation. Each refinement process leaves a proof trail, checkable by the normal Coq kernel, justifying its soundness. We focus on the synthesis of abstract data types that package methods with private data. We demonstrate the utility of our framework by applying it to the synthesis of query structures &ndash; abstract data types with SQL-like query and insert operations. Fiat includes a library for writing specifications of query structures in SQL-inspired notation, expressing operations over relations (tables) in terms of mathematical sets. This library includes a suite of tactics for automating the refinement of specifications into efficient, correct-by-construction OCaml code. Using these tactics, a programmer can generate such an implementation completely automatically by only specifying the equivalent of SQL indexes, data structures capturing useful views of the abstract data. Throughout we speculate on the new programming modularity possibilities enabled by an automated refinement system with proved-correct rules.",
    "keywords": "deductive synthesis, mechanized derivation of abstract data types",
    "URL": "http://doi.acm.org/10.1145/2676726.2677006",
    "DOI": "10.1145/2676726.2677006",
    "publisher-place": "New York, NY, USA",
    "page": "689-700",
    "page-first": "689",
    "_line": "FormalReview.bib:1418"
  },
  "chlipala_end_nodate": {
    "id": "chlipala_end_nodate",
    "type": "webpage",
    "author": [
      {
        "family": "Chlipala",
        "given": "Adam"
      },
      {
        "family": "Delaware",
        "given": "Benjamin"
      },
      {
        "family": "Duchovni",
        "given": "Samuel"
      },
      {
        "family": "Gross",
        "given": "Jason"
      },
      {
        "family": "Pit-Claudel",
        "given": "Clément"
      },
      {
        "family": "Suriyakarn",
        "given": "Sorawit"
      },
      {
        "family": "Wang",
        "given": "Peng"
      },
      {
        "family": "ye",
        "given": "Katherine"
      }
    ],
    "title": "THE END OF HISTORY? USING A PROOF ASSISTANT TO REPLACE LANGUAGE DESIGN WITH LIBRARY DESIGN",
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "abstract": "Functionality of software systems has exploded in part because of advances in programming-language support for packaging reusable functionality as libraries. Developers benefit from the uniformity that comes of exposing many interfaces in the same language, as opposed to stringing together hodgepodges of command-line tools. Domain-specific languages may be viewed as an evolution of the power of reusable interfaces, when those interfaces become so flexible as to deserve to be called programming languages. However, common approaches to domain-specific languages give up many of the hard-won advantages of library-building in a rich common language, and even the traditional approach poses significant challenges in learning new APIs. We suggest that instead of continuing to develop new domain-specific languages, our community should embrace library-based ecosystems within very expressive languages that mix programming and theorem proving. Our prototype framework Fiat, a library for the Coq proof assistant, turns languages into easily comprehensible libraries via the key idea of modularizing functionality and performance away from each other, the former via macros that desugar into higher-order logic and the latter via optimization scripts that derive efficient code from logical programs.",
    "URL": "https://snapl.org/2017/abstracts/Chlipala.html",
    "_line": "FormalReview.bib:1437"
  },
  "gonthier_formal_2008": {
    "id": "gonthier_formal_2008",
    "type": "article-journal",
    "author": [
      {
        "family": "Gonthier",
        "given": "Georges"
      }
    ],
    "title": "Formal Proof—The Four- Color Theorem",
    "issued": {
      "date-parts": [
        [
          "2008"
        ]
      ]
    },
    "page": "12",
    "page-first": "12",
    "volume": "55",
    "issue": "11",
    "language": "en-US",
    "_line": "FormalReview.bib:1446"
  },
  "wiedijk_formal_2008": {
    "id": "wiedijk_formal_2008",
    "type": "article-journal",
    "author": [
      {
        "family": "Wiedijk",
        "given": "Freek"
      }
    ],
    "title": "Formal Proof—Getting Started",
    "issued": {
      "date-parts": [
        [
          "2008"
        ]
      ]
    },
    "page": "7",
    "page-first": "7",
    "volume": "55",
    "issue": "11",
    "language": "en-US",
    "_line": "FormalReview.bib:1457"
  },
  "harrison_formal_2008": {
    "id": "harrison_formal_2008",
    "type": "article-journal",
    "author": [
      {
        "family": "Harrison",
        "given": "John"
      }
    ],
    "title": "Formal Proof—Theory and Practice",
    "issued": {
      "date-parts": [
        [
          "2008"
        ]
      ]
    },
    "page": "12",
    "page-first": "12",
    "volume": "55",
    "issue": "11",
    "language": "en-US",
    "_line": "FormalReview.bib:1468"
  },
  "petcher_foundational_2015": {
    "id": "petcher_foundational_2015",
    "type": "paper-conference",
    "author": [
      {
        "family": "Petcher",
        "given": "Adam"
      },
      {
        "family": "Morrisett",
        "given": "Greg"
      }
    ],
    "editor": [
      {
        "family": "Focardi",
        "given": "Riccardo"
      },
      {
        "family": "Myers",
        "given": "Andrew"
      }
    ],
    "title": "The Foundational Cryptography Framework",
    "container-title": "Principles of Security and Trust",
    "collection-title": "Lecture Notes in Computer Science",
    "issued": {
      "date-parts": [
        [
          "2015"
        ]
      ]
    },
    "publisher": "Springer Berlin Heidelberg",
    "isbn": "978-3-662-46666-7",
    "abstract": "We present the Foundational Cryptography Framework (FCF) for developing and checking complete proofs of security for cryptographic schemes within a proof assistant. This is a general-purpose framework that is capable of modeling and reasoning about a wide range of cryptographic schemes, security definitions, and assumptions. Security is proven in the computational model, and the proof provides concrete bounds as well as asymptotic conclusions. FCF provides a language for probabilistic programs, a theory that is used to reason about programs, and a library of tactics and definitions that are useful in proofs about cryptography. The framework is designed to leverage fully the existing theory and capabilities of the Coq proof assistant in order to reduce the effort required to develop proofs.",
    "keywords": "Coq, Cryptography, Proof Assistant, Protocol Verification",
    "URL": "http://www.cs.cornell.edu/~jgm/papers/FCF.pdf",
    "page": "53-72",
    "page-first": "53",
    "language": "en-US",
    "_line": "FormalReview.bib:1479"
  },
  "fisher_kathleen_hacms_2017": {
    "id": "fisher_kathleen_hacms_2017",
    "type": "article-journal",
    "author": [
      {
        "family": "Fisher Kathleen"
      },
      {
        "family": "Launchbury John"
      },
      {
        "family": "Richards Raymond"
      }
    ],
    "title": "The HACMS program: using formal methods to eliminate exploitable bugs",
    "container-title": "Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences",
    "container-title-short": "The HACMS program",
    "title-short": "The HACMS program",
    "issued": {
      "date-parts": [
        [
          "2017",
          "10",
          "13"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "abstract": "For decades, formal methods have offered the promise of verified software that does not have exploitable bugs. Until recently, however, it has not been possible to verify software of sufficient complexity to be useful. Recently, that situation has changed. SeL4 is an open-source operating system microkernel efficient enough to be used in a wide range of practical applications. Its designers proved it to be fully functionally correct, ensuring the absence of buffer overflows, null pointer exceptions, use-after-free errors, etc., and guaranteeing integrity and confidentiality. The CompCert Verifying C Compiler maps source C programs to provably equivalent assembly language, ensuring the absence of exploitable bugs in the compiler. A number of factors have enabled this revolution, including faster processors, increased automation, more extensive infrastructure, specialized logics and the decision to co-develop code and correctness proofs rather than verify existing artefacts. In this paper, we explore the promise and limitations of current formal-methods techniques. We discuss these issues in the context of DARPA’s HACMS program, which had as its goal the creation of high-assurance software for vehicles, including quadcopters, helicopters and automobiles.This article is part of the themed issue ‘Verified trustworthy software systems’.",
    "URL": "https://royalsocietypublishing.org/doi/10.1098/rsta.2015.0401",
    "DOI": "10.1098/rsta.2015.0401",
    "page": "20150401",
    "page-first": "20150401",
    "volume": "375",
    "issue": "2104",
    "_line": "FormalReview.bib:1496"
  },
  "royalsociety_philosophical_nodate": {
    "id": "royalsociety_philosophical_nodate",
    "type": "webpage",
    "author": [
      {
        "family": "",
        "dropping-particle": "royalsociety"
      }
    ],
    "title": "Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences",
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "URL": "https://royalsocietypublishing.org/journal/rsta",
    "_line": "FormalReview.bib:1512"
  },
  "royalsociety_proceedings_nodate": {
    "id": "royalsociety_proceedings_nodate",
    "type": "webpage",
    "author": [
      {
        "family": "",
        "dropping-particle": "royalsociety"
      }
    ],
    "title": "Proceedings of the Royal Society A: Mathematical, Physical and Engineering Sciences",
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "URL": "https://royalsocietypublishing.org/journal/rspa",
    "_line": "FormalReview.bib:1520"
  },
  "choi_kami:_2017": {
    "id": "choi_kami:_2017",
    "type": "article-journal",
    "author": [
      {
        "family": "Choi",
        "given": "Joonwon"
      },
      {
        "family": "Vijayaraghavan",
        "given": "Muralidaran"
      },
      {
        "family": "Sherman",
        "given": "Benjamin"
      },
      {
        "family": "Chlipala",
        "given": "Adam"
      },
      {
        "family": "Arvind"
      }
    ],
    "title": "Kami: A Platform for High-level Parametric Hardware Specification and Its Modular Verification",
    "container-title": "Proc. ACM Program. Lang.",
    "container-title-short": "Kami",
    "title-short": "Kami",
    "issued": {
      "date-parts": [
        [
          "2017",
          "8"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "issn": "2475-1421",
    "abstract": "It has become fairly standard in the programming-languages research world to verify functional programs in proof assistants using induction, algebraic simplification, and rewriting. In this paper, we introduce Kami, a Coq library that enables similar expressive and modular reasoning for hardware designs expressed in the style of the Bluespec language. We can specify, implement, and verify realistic designs entirely within Coq, ending with automatic extraction into a pipeline that bottoms out in FPGAs. Our methodology, using labeled transition systems, has been evaluated in a case study verifying an infinite family of multicore systems, with cache-coherent shared memory and pipelined cores implementing (the base integer subset of) the RISC-V instruction set.",
    "keywords": "formal verification, hardware, proof assistants",
    "URL": "http://doi.acm.org/10.1145/3110268",
    "DOI": "10.1145/3110268",
    "page": "24:1-24:30",
    "page-first": "24",
    "volume": "1",
    "_line": "FormalReview.bib:1528"
  },
  "delaware_narcissus:_nodate": {
    "id": "delaware_narcissus:_nodate",
    "type": "article-journal",
    "author": [
      {
        "family": "Delaware",
        "given": "Benjamin"
      },
      {
        "family": "Suriyakarn",
        "given": "Sorawit"
      },
      {
        "family": "Pit-Claudel",
        "given": "Clément"
      },
      {
        "family": "Ye",
        "given": "Qianchuan"
      },
      {
        "family": "Chlipala",
        "given": "Adam"
      }
    ],
    "title": "Narcissus: Correct-By-Construction Derivation of Decoders and Encoders from Binary Formats",
    "abstract": "It is a neat result from functional programming that libraries of parser combinators can support rapid construction of decoders for quite a range of formats. With a little more work, the same combinator program can denote both a decoder and an encoder. Unfortunately, the real world is full of gnarly formats, as with the packet formats that make up the standard Internet protocol stack. Most past parser-combinator approaches cannot handle these formats, and the few exceptions require redundancy – one part of the natural grammar needs to be hand-translated into hints in multiple parts of a parser program. We show how to recover very natural and nonredundant format specifications, covering all popular network packet formats and generating both decoders and encoders automatically. The catch is that we use the Coq proof assistant to derive both kinds of artifacts using tactics, automatically, in a way that guarantees that they form inverses of each other. We used our approach to reimplement packet processing for a full Internet protocol stack, inserting our replacement into the OCaml-based MirageOS unikernel, resulting in minimal performance degradation.",
    "page": "14",
    "page-first": "14",
    "language": "en-US",
    "_line": "FormalReview.bib:1546"
  },
  "delaware_narcissus:_2018": {
    "id": "delaware_narcissus:_2018",
    "type": "article-journal",
    "author": [
      {
        "family": "Delaware",
        "given": "Benjamin"
      },
      {
        "family": "Suriyakarn",
        "given": "Sorawit"
      },
      {
        "family": "Pit&ndash;Claudel",
        "given": "Clément"
      },
      {
        "family": "Ye",
        "given": "Qianchuan"
      },
      {
        "family": "Chlipala",
        "given": "Adam"
      }
    ],
    "title": "Narcissus: Deriving Correct-By-Construction Decoders and Encoders from Binary Formats",
    "container-title-short": "Narcissus",
    "title-short": "Narcissus",
    "issued": {
      "date-parts": [
        [
          "2018",
          "3",
          "13"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "abstract": "It is a neat result from functional programming that libraries of parser\ncombinators can support rapid construction of decoders for quite a range of\nformats. With a little more work, the same combinator program can denote both a\ndecoder and an encoder. Unfortunately, the real world is full of gnarly\nformats, as with the packet formats that make up the standard Internet protocol\nstack. Most past parser-combinator approaches cannot handle these formats, and\nthe few exceptions require redundancy &ndash; one part of the natural grammar needs\nto be hand-translated into hints in multiple parts of a parser program. We show\nhow to recover very natural and nonredundant format specifications, covering\nall popular network packet formats and generating both decoders and encoders\nautomatically. The catch is that we use the Coq proof assistant to derive both\nkinds of artifacts using tactics, automatically, in a way that guarantees that\nthey form inverses of each other. We used our approach to reimplement packet\nprocessing for a full Internet protocol stack, inserting our replacement into\nthe OCaml-based MirageOS unikernel, resulting in minimal performance\ndegradation.",
    "URL": "https://arxiv.org/abs/1803.04870v2",
    "language": "en-US",
    "_line": "FormalReview.bib:1555"
  },
  "klein_gerwin_provably_2017": {
    "id": "klein_gerwin_provably_2017",
    "type": "article-journal",
    "author": [
      {
        "family": "Klein Gerwin"
      },
      {
        "family": "Andronick June"
      },
      {
        "family": "Keller Gabriele"
      },
      {
        "family": "Matichuk Daniel"
      },
      {
        "family": "Murray Toby"
      },
      {
        "family": "O'Connor Liam"
      }
    ],
    "title": "Provably trustworthy systems",
    "container-title": "Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences",
    "issued": {
      "date-parts": [
        [
          "2017",
          "10",
          "13"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "abstract": "We present recent work on building and scaling trustworthy systems with formal, machine-checkable proof from the ground up, including the operating system kernel, at the level of binary machine code. We first give a brief overview of the seL4 microkernel verification and how it can be used to build verified systems. We then show two complementary techniques for scaling these methods to larger systems: proof engineering, to estimate verification effort; and code/proof co-generation, for scalable development of provably trustworthy applications.This article is part of the themed issue ‘Verified trustworthy software systems’.",
    "URL": "https://royalsocietypublishing.org/doi/10.1098/rsta.2015.0404",
    "DOI": "10.1098/rsta.2015.0404",
    "page": "20150404",
    "page-first": "20150404",
    "volume": "375",
    "issue": "2104",
    "_line": "FormalReview.bib:1582"
  },
  "batty_mark_compositional_2017": {
    "id": "batty_mark_compositional_2017",
    "type": "article-journal",
    "author": [
      {
        "family": "Batty Mark"
      }
    ],
    "title": "Compositional relaxed concurrency",
    "container-title": "Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences",
    "issued": {
      "date-parts": [
        [
          "2017",
          "10",
          "13"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "abstract": "There is a broad design space for concurrent computer processors: they can be optimized for low power, low latency or high throughput. This freedom to tune each processor design to its niche has led to an increasing diversity of machines, from powerful pocketable devices to those responsible for complex and critical tasks, such as car guidance systems. Given this context, academic concurrency research sounds notes of both caution and optimism. Caution because recent work has uncovered flaws in the way we explain the subtle memory behaviour of concurrent systems: specifications have been shown to be incorrect, leading to bugs throughout the many layers of the system. And optimism because our tools and methods for verifying the correctness of concurrent code—although built above an idealized model of concurrency—are becoming more mature. This paper looks at the way we specify the memory behaviour of concurrent systems and suggests a new direction. Currently, there is a siloed approach, with each processor and programming language specified separately in an incomparable way. But this does not match the structure of our programs, which may use multiple processors and languages together. Instead we propose a compositional approach, where program components carry with them a description of the sort of concurrency they rely on, and there is a mechanism for composing these. This will support not only components written for the multiple varied processors found in a modern system but also those that use idealized models of concurrency, providing a sound footing for mature verification techniques.This article is part of the themed issue ‘Verified trustworthy software systems’.",
    "URL": "https://royalsocietypublishing.org/doi/10.1098/rsta.2015.0406",
    "DOI": "10.1098/rsta.2015.0406",
    "page": "20150406",
    "page-first": "20150406",
    "volume": "375",
    "issue": "2104",
    "_line": "FormalReview.bib:1597"
  },
  "appel_andrew_w._position_2017": {
    "id": "appel_andrew_w._position_2017",
    "type": "article-journal",
    "author": [
      {
        "family": "Appel Andrew W."
      },
      {
        "family": "Beringer Lennart"
      },
      {
        "family": "Chlipala Adam"
      },
      {
        "family": "Pierce Benjamin C."
      },
      {
        "family": "Shao Zhong"
      },
      {
        "family": "Weirich Stephanie"
      },
      {
        "family": "Zdancewic Steve"
      }
    ],
    "title": "Position paper: the science of deep specification",
    "container-title": "Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences",
    "container-title-short": "Position paper",
    "title-short": "Position paper",
    "issued": {
      "date-parts": [
        [
          "2017",
          "10",
          "13"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "abstract": "We introduce our efforts within the project ‘The science of deep specification’ to work out the key formal underpinnings of industrial-scale formal specifications of software and hardware components, anticipating a world where large verified systems are routinely built out of smaller verified components that are also used by many other projects. We identify an important class of specification that has already been used in a few experiments that connect strong component-correctness theorems across the work of different teams. To help popularize the unique advantages of that style, we dub it deep specification, and we say that it encompasses specifications that are rich, two-sided, formal and live (terms that we define in the article). Our core team is developing a proof-of-concept system (based on the Coq proof assistant) whose specification and verification work is divided across largely decoupled subteams at our four institutions, encompassing hardware microarchitecture, compilers, operating systems and applications, along with cross-cutting principles and tools for effective specification. We also aim to catalyse interest in the approach, not just by basic researchers but also by users in industry.This article is part of the themed issue ‘Verified trustworthy software systems’.",
    "URL": "https://royalsocietypublishing.org/doi/10.1098/rsta.2016.0331",
    "DOI": "10.1098/rsta.2016.0331",
    "page": "20160331",
    "page-first": "20160331",
    "volume": "375",
    "issue": "2104",
    "_line": "FormalReview.bib:1612"
  },
  "david_cristina_program_2017": {
    "id": "david_cristina_program_2017",
    "type": "article-journal",
    "author": [
      {
        "family": "David Cristina"
      },
      {
        "family": "Kroening Daniel"
      }
    ],
    "title": "Program synthesis: challenges and opportunities",
    "container-title": "Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences",
    "container-title-short": "Program synthesis",
    "title-short": "Program synthesis",
    "issued": {
      "date-parts": [
        [
          "2017",
          "10",
          "13"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "abstract": "Program synthesis is the mechanized construction of software, dubbed ‘self-writing code’. Synthesis tools relieve the programmer from thinking about how the problem is to be solved; instead, the programmer only provides a description of what is to be achieved. Given a specification of what the program should do, the synthesizer generates an implementation that provably satisfies this specification. From a logical point of view, a program synthesizer is a solver for second-order existential logic. Owing to the expressiveness of second-order logic, program synthesis has an extremely broad range of applications. We survey some of these applications as well as recent trends in the algorithms that solve the program synthesis problem. In particular, we focus on an approach that has raised the profile of program synthesis and ushered in a generation of new synthesis tools, namely counter-example-guided inductive synthesis (CEGIS). We provide a description of the CEGIS architecture, followed by recent algorithmic improvements. We conjecture that the capacity of program synthesis engines will see further step change, in a manner that is transparent to the applications, which will open up an even broader range of use-cases.This article is part of the themed issue ‘Verified trustworthy software systems’.",
    "URL": "https://royalsocietypublishing.org/doi/10.1098/rsta.2015.0403",
    "DOI": "10.1098/rsta.2015.0403",
    "page": "20150403",
    "page-first": "20150403",
    "volume": "375",
    "issue": "2104",
    "_line": "FormalReview.bib:1628"
  },
  "white_neil_formal_2017": {
    "id": "white_neil_formal_2017",
    "type": "article-journal",
    "author": [
      {
        "family": "White Neil"
      },
      {
        "family": "Matthews Stuart"
      },
      {
        "family": "Chapman Roderick"
      }
    ],
    "title": "Formal verification: will the seedling ever flower?",
    "container-title": "Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences",
    "container-title-short": "Formal verification",
    "title-short": "Formal verification",
    "issued": {
      "date-parts": [
        [
          "2017",
          "10",
          "13"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "abstract": "In one sense, formal specification and verification have been highly successful: techniques have been developed in pioneering academic research, transferred to software companies through training and partnerships, and successfully deployed in systems with national significance. Altran UK has been in the vanguard of this movement. This paper summarizes some of our key deployments of formal techniques over the past 20 years, including both security- and safety-critical systems. The impact of formal techniques, however, remains within an industrial niche, and while government and suppliers across industry search for solutions to the problems of poor-quality software, the wider software industry remains resistant to adoption of this proven solution. We conclude by reflecting on some of the challenges we face as a community in ensuring that formal techniques achieve their true potential impact on society.This article is part of the themed issue ‘Verified trustworthy software systems’.",
    "URL": "https://royalsocietypublishing.org/doi/10.1098/rsta.2015.0402",
    "DOI": "10.1098/rsta.2015.0402",
    "page": "20150402",
    "page-first": "20150402",
    "volume": "375",
    "issue": "2104",
    "_line": "FormalReview.bib:1644"
  },
  "hunt_warren_a._industrial_2017": {
    "id": "hunt_warren_a._industrial_2017",
    "type": "article-journal",
    "author": [
      {
        "family": "Hunt Warren A."
      },
      {
        "family": "Kaufmann Matt"
      },
      {
        "family": "Moore J Strother"
      },
      {
        "family": "Slobodova Anna"
      }
    ],
    "title": "Industrial hardware and software verification with ACL2",
    "container-title": "Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences",
    "issued": {
      "date-parts": [
        [
          "2017",
          "10",
          "13"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "abstract": "The ACL2 theorem prover has seen sustained industrial use since the mid-1990s. Companies that have used ACL2 regularly include AMD, Centaur Technology, IBM, Intel, Kestrel Institute, Motorola/Freescale, Oracle and Rockwell Collins. This paper introduces ACL2 and focuses on how and why ACL2 is used in industry. ACL2 is well-suited to its industrial application to numerous software and hardware systems, because it is an integrated programming/proof environment supporting a subset of the ANSI standard Common Lisp programming language. As a programming language ACL2 permits the coding of efficient and robust programs; as a prover ACL2 can be fully automatic but provides many features permitting domain-specific human-supplied guidance at various levels of abstraction. ACL2 specifications and models often serve as efficient execution engines for the modelled artefacts while permitting formal analysis and proof of properties. Crucially, ACL2 also provides support for the development and verification of other formal analysis tools. However, ACL2 did not find its way into industrial use merely because of its technical features. The core ACL2 user/development community has a shared vision of making mechanized verification routine when appropriate and has been committed to this vision for the quarter century since the Computational Logic, Inc., Verified Stack. The community has focused on demonstrating the viability of the tool by taking on industrial projects (often at the expense of not being able to publish much).This article is part of the themed issue ‘Verified trustworthy software systems’.",
    "URL": "https://royalsocietypublishing.org/doi/10.1098/rsta.2015.0399",
    "DOI": "10.1098/rsta.2015.0399",
    "page": "20150399",
    "page-first": "20150399",
    "volume": "375",
    "issue": "2104",
    "_line": "FormalReview.bib:1660"
  },
  "ekici_smtcoq:_2017": {
    "id": "ekici_smtcoq:_2017",
    "type": "paper-conference",
    "author": [
      {
        "family": "Ekici",
        "given": "Burak"
      },
      {
        "family": "Mebsout",
        "given": "Alain"
      },
      {
        "family": "Tinelli",
        "given": "Cesare"
      },
      {
        "family": "Keller",
        "given": "Chantal"
      },
      {
        "family": "Katz",
        "given": "Guy"
      },
      {
        "family": "Reynolds",
        "given": "Andrew"
      },
      {
        "family": "Barrett",
        "given": "Clark"
      }
    ],
    "editor": [
      {
        "family": "Majumdar",
        "given": "Rupak"
      },
      {
        "family": "Kunčak",
        "given": "Viktor"
      }
    ],
    "title": "SMTCoq: A Plug-In for Integrating SMT Solvers into Coq",
    "container-title": "Computer Aided Verification",
    "container-title-short": "SMTCoq",
    "collection-title": "Lecture Notes in Computer Science",
    "title-short": "SMTCoq",
    "issued": {
      "date-parts": [
        [
          "2017"
        ]
      ]
    },
    "publisher": "Springer International Publishing",
    "isbn": "978-3-319-63390-9",
    "abstract": "This paper describes SMTCoq, a plug-in for the integration of external solvers into the Coq proof assistant. Based on a checker for generic first-order proof certificates fully implemented and proved correct in Coq, SMTCoq offers facilities to check answers from external SAT and SMT solvers and to increase Coq’s automation using such solvers, all in a safe way. The current version supports proof certificates produced by the SAT solver ZChaff, for propositional logic, and the SMT solvers veriT and CVC4, for the quantifier-free fragment of the combined theory of fixed-size bit vectors, functional arrays with extensionality, linear integer arithmetic, and uninterpreted function symbols.",
    "page": "126-133",
    "page-first": "126",
    "language": "en-US",
    "_line": "FormalReview.bib:1675"
  },
  "anand_towards_nodate": {
    "id": "anand_towards_nodate",
    "type": "webpage",
    "author": [
      {
        "family": "Anand",
        "given": "Abhishek"
      },
      {
        "family": "Boulier",
        "given": "Simon"
      },
      {
        "family": "Cohen",
        "given": "Cyril"
      },
      {
        "family": "Sozeau",
        "given": "Matthieu"
      },
      {
        "family": "Tabareau",
        "given": "Nicolas"
      }
    ],
    "title": "Towards Certified Meta-Programming with Typed Template-Coq &bar; SpringerLink",
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "abstract": "Template-Coq (https://template-coq.github.io/template-coq) is a plugin for Coq, originally implemented by Malecha \\[18\\], which provides a reifier for Coq terms and global declarations, as represented in the Coq kernel, as well as a denotation command. Initially, it was developed for the purpose of writing functions on Coq’s AST in Gallina. Recently, it was used in the CertiCoq certified compiler project \\[4\\], as its front-end language, to derive parametricity properties \\[3\\], and to extract Coq terms to a CBV   𝜆 -calculus \\[13\\]. However, the syntax lacked semantics, be it typing semantics or operational semantics, which should reflect, as formal specifications in Coq, the semantics of Coq’s type theory itself. The tool was also rather bare bones, providing only rudimentary quoting and unquoting commands. We generalize it to handle the entire Calculus of Inductive Constructions (CIC), as implemented by Coq, including the kernel’s declaration structures for definitions and inductives, and implement a monad for general manipulation of Coq’s logical environment. We demonstrate how this setup allows Coq users to define many kinds of general purpose plugins, whose correctness can be readily proved in the system itself, and that can be run efficiently after extraction. We give a few examples of implemented plugins, including a parametricity translation. We also advocate the use of Template-Coq as a foundation for higher-level tools.",
    "URL": "https://link.springer.com/chapter/10.1007%2F978-3-319-94821-8_2",
    "_line": "FormalReview.bib:1691"
  },
  "malecha_reflection_2018": {
    "id": "malecha_reflection_2018",
    "type": "book",
    "author": [
      {
        "family": "Malecha",
        "given": "Gregory"
      }
    ],
    "title": "Reflection library for Coq. Contribute to gmalecha/template-coq development by creating an account on GitHub",
    "issued": {
      "date-parts": [
        [
          "2018",
          "3",
          "2"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "URL": "https://github.com/gmalecha/template-coq",
    "note": "original-date: 2014-07-09T20:13:52Z",
    "_line": "FormalReview.bib:1700"
  },
  "sozeau_metacoq_2019": {
    "id": "sozeau_metacoq_2019",
    "type": "book",
    "author": [
      {
        "family": "Sozeau",
        "given": "Matthieu"
      }
    ],
    "title": "MetaCoq - Metaprogramming in Coq (Was template-coq)",
    "issued": {
      "date-parts": [
        [
          "2019",
          "1",
          "22"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "publisher": "MetaCoq",
    "URL": "https://github.com/MetaCoq/metacoq",
    "note": "original-date: 2017-10-19T11:10:54Z",
    "_line": "FormalReview.bib:1710"
  },
  "parigot_logic_2000": {
    "id": "parigot_logic_2000",
    "type": "book",
    "author": [
      {
        "family": "Parigot",
        "given": "Michel"
      },
      {
        "family": "Voronkov",
        "given": "Andrei"
      }
    ],
    "title": "Logic for Programming and Automated Reasoning: 7th International Conference, LPAR 2000 Reunion Island, France, November 6-10, 2000 Proceedings",
    "container-title-short": "Logic for Programming and Automated Reasoning",
    "title-short": "Logic for Programming and Automated Reasoning",
    "issued": {
      "date-parts": [
        [
          "2000"
        ]
      ]
    },
    "publisher": "Springer Berlin Heidelberg",
    "isbn": "978-3-540-41285-4 978-3-540-44404-6",
    "abstract": "This book constitutes the refereed proceedings of the 7th International Conference on Logic for Programming and Automated Reasoning, LPAR 2000, held in Reunion Island, France in November 2000. The 26 revised full papers presented together with four invited contributions were carefully reviewed and selected from 65 submissions. The papers are organized in topical sections on nonmonotonic reasoning, descriptive complexity, specification and automatic proof-assistants, theorem proving, verification, logic programming and constraint logic programming, nonclassical logics and the lambda calculus, logic and databases, program analysis, mu-calculus, planning and reasoning about actions.",
    "publisher-place": "Berlin, Heidelberg",
    "note": "OCLC: 851805469",
    "_line": "FormalReview.bib:1721"
  },
  "parigot_tactic_2000": {
    "id": "parigot_tactic_2000",
    "type": "chapter",
    "author": [
      {
        "family": "Delahaye",
        "given": "David"
      }
    ],
    "editor": [
      {
        "family": "Parigot",
        "given": "Michel"
      },
      {
        "family": "Voronkov",
        "given": "Andrei"
      }
    ],
    "title": "A Tactic Language for the System Coq",
    "container-title": "Logic for Programming and Automated Reasoning",
    "issued": {
      "date-parts": [
        [
          "2000"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "publisher": "Springer Berlin Heidelberg",
    "isbn": "978-3-540-41285-4",
    "URL": "http://link.springer.com/10.1007/3-540-44404-1_7",
    "DOI": "10.1007/3-540-44404-1_7",
    "publisher-place": "Berlin, Heidelberg",
    "page": "85-95",
    "page-first": "85",
    "volume": "1955",
    "language": "en-US",
    "_line": "FormalReview.bib:1733"
  },
  "bate_fundamentals_1971": {
    "id": "bate_fundamentals_1971",
    "type": "book",
    "author": [
      {
        "family": "Bate",
        "given": "Roger R."
      },
      {
        "family": "Mueller",
        "given": "Donald D."
      },
      {
        "family": "White",
        "given": "Jerry E."
      }
    ],
    "title": "Fundamentals of astrodynamics",
    "issued": {
      "date-parts": [
        [
          "1971"
        ]
      ]
    },
    "publisher": "Dover Publications",
    "number-of-pages": "455",
    "isbn": "978-0-486-60061-1",
    "keywords": "Astrodynamics",
    "publisher-place": "New York",
    "_line": "FormalReview.bib:1751"
  },
  "fowler_deriving_nodate": {
    "id": "fowler_deriving_nodate",
    "type": "webpage",
    "author": [
      {
        "family": "Fowler",
        "given": "Michael"
      }
    ],
    "title": "Deriving Kepler’s Laws from the Inverse-Square Law",
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "URL": "http://galileo.phys.virginia.edu/classes/152.mf1i.spring02/KeplersLaws.htm",
    "_line": "FormalReview.bib:1763"
  },
  "lancaster_unified_1969": {
    "id": "lancaster_unified_1969",
    "type": "article-journal",
    "author": [
      {
        "family": "Lancaster",
        "given": "E R"
      },
      {
        "family": "Blanchard",
        "given": "R C"
      }
    ],
    "title": "A unified form of lambert's theorem",
    "container-title": "NASA Technical Note",
    "issued": {
      "date-parts": [
        [
          "1969",
          "9"
        ]
      ]
    },
    "page": "18",
    "page-first": "18",
    "volume": "{TN} D-5368",
    "language": "en-US",
    "_line": "FormalReview.bib:1771"
  },
  "protzenko_verified_2017": {
    "id": "protzenko_verified_2017",
    "type": "article-journal",
    "author": [
      {
        "family": "Protzenko",
        "given": "Jonathan"
      },
      {
        "family": "Zinzindohoué",
        "given": "Jean-Karim"
      },
      {
        "family": "Rastogi",
        "given": "Aseem"
      },
      {
        "family": "Ramananandro",
        "given": "Tahina"
      },
      {
        "family": "Wang",
        "given": "Peng"
      },
      {
        "family": "Zanella-Béguelin",
        "given": "Santiago"
      },
      {
        "family": "Delignat-Lavaud",
        "given": "Antoine"
      },
      {
        "family": "Hriţcu",
        "given": "Cătălin"
      },
      {
        "family": "Bhargavan",
        "given": "Karthikeyan"
      },
      {
        "family": "Fournet",
        "given": "Cédric"
      },
      {
        "family": "Swamy",
        "given": "Nikhil"
      }
    ],
    "title": "Verified Low-level Programming Embedded in F\\*",
    "container-title": "Proc. ACM Program. Lang.",
    "issued": {
      "date-parts": [
        [
          "2017",
          "8"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "issn": "2475-1421",
    "abstract": "We present Low\\*, a language for low-level programming and verification, and its application to high-assurance optimized cryptographic libraries. Low\\* is a shallow embedding of a small, sequential, well-behaved subset of C in F\\*, a dependently- typed variant of ML aimed at program verification. Departing from ML, Low\\* does not involve any garbage collection or implicit heap allocation; instead, it has a structured memory model à la CompCert, and it provides the control required for writing efficient low-level security-critical code.   By virtue of typing, any Low\\* program is memory safe. In addition, the programmer can make full use of the verification power of F\\* to write high-level specifications and verify the functional correctness of Low\\* code using a combination of SMT automation and sophisticated manual proofs. At extraction time, specifications and proofs are erased, and the remaining code enjoys a predictable translation to C. We prove that this translation preserves semantics and side-channel resistance.   We provide a new compiler back-end from Low\\* to C and, to evaluate our approach, we implement and verify various cryptographic algorithms, constructions, and tools for a total of about 28,000 lines of code. We show that our Low\\* code delivers performance competitive with existing (unverified) C cryptographic libraries, suggesting our approach may be applicable to larger-scale low-level software.",
    "keywords": "Compilers, Functional languages, Semantics, Software verifcation, Source code generation, Type theory, źSoftware and its engineering ź Correctness, źTheory of computation ź Hoare logic",
    "URL": "http://doi.acm.org/10.1145/3110261",
    "DOI": "10.1145/3110261",
    "page": "17:1-17:29",
    "page-first": "17",
    "volume": "1",
    "_line": "FormalReview.bib:1782"
  },
  "delignat-lavaud_implementing_2017": {
    "id": "delignat-lavaud_implementing_2017",
    "type": "article-journal",
    "author": [
      {
        "family": "Delignat-Lavaud",
        "given": "Antoine"
      },
      {
        "family": "Fournet",
        "given": "Cédric"
      },
      {
        "family": "Kohlweiss",
        "given": "Markulf"
      },
      {
        "family": "Protzenko",
        "given": "Jonathan"
      },
      {
        "family": "Rastogi",
        "given": "Aseem"
      },
      {
        "family": "Swamy",
        "given": "Nikhil"
      },
      {
        "family": "Zanella-Beguelin",
        "given": "Santiago"
      },
      {
        "family": "Bhargavan",
        "given": "Karthikeyan"
      },
      {
        "family": "Pan",
        "given": "Jianyang"
      },
      {
        "family": "Zinzindohoue",
        "given": "Jean Karim"
      }
    ],
    "title": "Implementing and Proving the TLS 1.3 Record Layer",
    "issued": {
      "date-parts": [
        [
          "2017",
          "8",
          "17"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "abstract": "The record layer is the main bridge between TLS applications and internal sub-protocols. Its core functionality is an elaborate form of authenticated encryption: streams of messages for each sub-protocol (handshake, alert, and application data) are fragmented, multiplexed, and encrypted with optional padding to hide their lengths. Conversely, the sub-protocols may provide fresh keys or signal …",
    "URL": "https://www.microsoft.com/en-us/research/publication/implementing-proving-tls-1-3-record-layer/",
    "language": "en-US",
    "_line": "FormalReview.bib:1799"
  },
  "cea_frama-c_nodate": {
    "id": "cea_frama-c_nodate",
    "type": "webpage",
    "author": [
      {
        "family": "",
        "dropping-particle": "cea"
      }
    ],
    "title": "Frama-C",
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "URL": "https://frama-c.com/",
    "_line": "FormalReview.bib:1810"
  },
  "brahmi_formalise_2018": {
    "id": "brahmi_formalise_2018",
    "type": "paper-conference",
    "author": [
      {
        "family": "Brahmi",
        "given": "Abderrahmane"
      },
      {
        "family": "Delmas",
        "given": "David"
      },
      {
        "family": "Essoussi",
        "given": "Mohamed Habib"
      },
      {
        "family": "Randimbivololona",
        "given": "Famantanantsoa"
      },
      {
        "family": "Atki",
        "given": "Abdellatif"
      },
      {
        "family": "Marie",
        "given": "Thomas"
      }
    ],
    "title": "Formalise to automate: deployment of a safe and cost-efficient process for avionics software",
    "container-title": "9th European Congress on Embedded Real Time Software and Systems (ERTS 2018)",
    "container-title-short": "Formalise to automate",
    "title-short": "Formalise to automate",
    "issued": {
      "date-parts": [
        [
          "2018",
          "1"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "abstract": "For over a decade, Airbus have been introducing formal techniques into the verification processes of some of their avionics software products, to cope with the steady increase of the size and complexity of related avionics systems. These techniques have come of age for large-scale industrial deployment. All design and verification processes are currently being revised to take maximum advantage from them, i.e. improve industrial efficiency while maintaining the safety and reliability of avionics systems. To achieve this goal, all human-engineered design artefacts are being formalised using languages with well-defined syntaxes and semantics, in order to allow for the automatic generation of all subsequent, computable design or verification artefacts, and the preparation of the input data for non computable activities. To this aim, several domain-specific languages and related compilers have been developed internally, which cover all design activities, and bridge the gaps to integrate external tools into the overall development processes, e.g. sound, semantics-based, static analysis tools. For instance, the formalisation of detailed designs in the form of function contracts expressed in a first-order logic-based language allows for a hybrid approach to unit verification. Designs may be compiled down to ACSL \\[5\\] contracts, allowing for program proof with Frama-C \\[22\\], or they may be compiled down to test contracts, allowing for semi-automatic unit tests.",
    "keywords": "avionics software, compilation, design, development process, DO-178C, domain-specific languages, formal methods, formalisation, industrial application, static analysis",
    "URL": "https://hal.archives-ouvertes.fr/hal-01708332",
    "publisher-place": "Toulouse, France",
    "_line": "FormalReview.bib:1818"
  },
  "brahmi_formalise_nodate": {
    "id": "brahmi_formalise_nodate",
    "type": "article-journal",
    "author": [
      {
        "family": "Brahmi",
        "given": "Abderrahmane"
      },
      {
        "family": "Delmas",
        "given": "David"
      },
      {
        "family": "Essoussi",
        "given": "Mohamed Habib"
      },
      {
        "family": "Randimbivololona",
        "given": "Famantanantsoa"
      },
      {
        "family": "Informatics",
        "given": "CEPRESY"
      },
      {
        "family": "Nauzere",
        "given": "La"
      },
      {
        "family": "Atki",
        "given": "Abdellatif"
      },
      {
        "family": "Marie",
        "given": "Thomas"
      }
    ],
    "title": "Formalise to automate: deployment of a safe and cost-efﬁcient process for avionics software -Extended",
    "abstract": "For over a decade, Airbus have been introducing formal techniques into the veriﬁcation processes of some of their avionics software products, to cope with the steady increase of the size and complexity of related avionics systems. These techniques have come of age for large-scale industrial deployment. All design and veriﬁcation processes are currently being revised to take maximum advantage from them, i.e. improve industrial efﬁciency while maintaining the safety and reliability of avionics systems.",
    "page": "17",
    "page-first": "17",
    "language": "en-US",
    "_line": "FormalReview.bib:1832"
  },
  "jeannet_apron_nodate": {
    "id": "jeannet_apron_nodate",
    "type": "webpage",
    "author": [
      {
        "family": "Jeannet",
        "given": "Bertrand"
      },
      {
        "family": "Miné",
        "given": "Antoine"
      }
    ],
    "title": "APRON numerical abstract domain library",
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "URL": "http://apron.cri.ensmp.fr/library/",
    "_line": "FormalReview.bib:1841"
  },
  "blanchard_concurrent_2017": {
    "id": "blanchard_concurrent_2017",
    "type": "article-journal",
    "author": [
      {
        "family": "Blanchard",
        "given": "Allan"
      },
      {
        "family": "Loulergue",
        "given": "Frédéric"
      },
      {
        "family": "Kosmatov",
        "given": "Nikolai"
      }
    ],
    "title": "From Concurrent Programs to Simulating Sequential Programs: Correctness of a Transformation",
    "container-title": "Electronic Proceedings in Theoretical Computer Science",
    "container-title-short": "From Concurrent Programs to Simulating Sequential Programs",
    "title-short": "From Concurrent Programs to Simulating Sequential Programs",
    "issued": {
      "date-parts": [
        [
          "2017",
          "8",
          "23"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "issn": "2075-2180",
    "abstract": "Frama-C is a software analysis framework that provides a common infrastructure and a common behavioral specification language to plugins that implement various static and dynamic analyses of C programs. Most plugins do not support concurrency. We have proposed Conc2Seq, a Frama-C plugin based on program transformation, capable to leverage the existing huge code base of plugins and to handle concurrent C programs. In this paper we formalize and sketch the proof of correctness of the program transformation principle behind Conc2Seq, and present an effort towards the full mechanization of both the formalization and proofs with the proof assistant Coq.",
    "keywords": "Computer Science - Programming Languages",
    "URLtext": "1708.07226",
    "URLpretext": "[arXiv:]{.etype}",
    "eprint-type": "arxiv",
    "eprint": "1708.07226",
    "URL": "http://arxiv.org/abs/1708.07226",
    "DOI": "10.4204/EPTCS.253.9",
    "page": "109-123",
    "page-first": "109",
    "volume": "253",
    "_line": "FormalReview.bib:1849"
  },
  "petiot_how_2018": {
    "id": "petiot_how_2018",
    "type": "article-journal",
    "author": [
      {
        "family": "Petiot",
        "given": "Guillaume"
      },
      {
        "family": "Kosmatov",
        "given": "Nikolai"
      },
      {
        "family": "Botella",
        "given": "Bernard"
      },
      {
        "family": "Giorgetti",
        "given": "Alain"
      },
      {
        "family": "Julliand",
        "given": "Jacques"
      }
    ],
    "title": "How testing helps to diagnose proof failures",
    "container-title": "Form Asp Comp",
    "issued": {
      "date-parts": [
        [
          "2018",
          "11",
          "1"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "issn": "1433-299X",
    "abstract": "Applying deductive verification to formally prove that a program respects its formal specification is a very complex and time-consuming task due in particular to the lack of feedback in case of proof failures. Along with a non-compliance between the code and its specification (due to an error in at least one of them), possible reasons of a proof failure include a missing or too weak specification for a called function or a loop, and lack of time or simply incapacity of the prover to finish a particular proof. This work proposes a methodology where test generation helps to identify the reason of a proof failure and to exhibit a counterexample clearly illustrating the issue. We define the categories of proof failures, introduce two subcategories of contract weaknesses (single and global ones), and examine their properties. We describe how to transform a C program formally specified in an executable specification language into C code suitable for testing, and illustrate the benefits of the method on comprehensive examples. The method has been implemented in StaDy, a plugin of the software analysis platform Frama-C. Initial experiments show that detecting non-compliances and contract weaknesses allows to precisely diagnose most proof failures.",
    "keywords": "Deductive verification, Frama-C, Proof debugging, Specification, Test generation",
    "URL": "https://doi.org/10.1007/s00165-018-0456-4",
    "DOI": "10.1007/s00165-018-0456-4",
    "page": "629-657",
    "page-first": "629",
    "volume": "30",
    "issue": "6",
    "language": "en-US",
    "_line": "FormalReview.bib:1868"
  },
  "petiot_your_2015": {
    "id": "petiot_your_2015",
    "type": "article-journal",
    "author": [
      {
        "family": "Petiot",
        "given": "Guillaume"
      },
      {
        "family": "Kosmatov",
        "given": "Nikolai"
      },
      {
        "family": "Botella",
        "given": "Bernard"
      },
      {
        "family": "Giorgetti",
        "given": "Alain"
      },
      {
        "family": "Julliand",
        "given": "Jacques"
      }
    ],
    "title": "Your Proof Fails? Testing Helps to Find the Reason",
    "container-title": "arXiv:1508.01691 \\[cs\\]",
    "container-title-short": "Your Proof Fails?",
    "title-short": "Your Proof Fails?",
    "issued": {
      "date-parts": [
        [
          "2015",
          "8",
          "7"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "abstract": "Applying deductive verification to formally prove that a program respects its formal specification is a very complex and time-consuming task due in particular to the lack of feedback in case of proof failures. Along with a non-compliance between the code and its specification (due to an error in at least one of them), possible reasons of a proof failure include a missing or too weak specification for a called function or a loop, and lack of time or simply incapacity of the prover to finish a particular proof. This work proposes a new methodology where test generation helps to identify the reason of a proof failure and to exhibit a counter-example clearly illustrating the issue. We describe how to transform an annotated C program into C code suitable for testing and illustrate the benefits of the method on comprehensive examples. The method has been implemented in STADY, a plugin of the software analysis platform FRAMA-C. Initial experiments show that detecting non-compliances and contract weaknesses allows to precisely diagnose most proof failures.",
    "keywords": "Computer Science - Software Engineering, D.2.4, D.2.5",
    "URLtext": "1508.01691",
    "URLpretext": "[arXiv:]{.etype}",
    "eprint-type": "arxiv",
    "eprint": "1508.01691",
    "URL": "http://arxiv.org/abs/1508.01691",
    "_line": "FormalReview.bib:1886"
  },
  "blatter_static_2018": {
    "id": "blatter_static_2018",
    "type": "paper-conference",
    "author": [
      {
        "family": "Blatter",
        "given": "Lionel"
      },
      {
        "family": "Kosmatov",
        "given": "Nikolai"
      },
      {
        "family": "Le Gall",
        "given": "Pascale"
      },
      {
        "family": "Prevosto",
        "given": "Virgile"
      },
      {
        "family": "Petiot",
        "given": "Guillaume"
      }
    ],
    "editor": [
      {
        "family": "Dubois",
        "given": "Catherine"
      },
      {
        "family": "Wolff",
        "given": "Burkhart"
      }
    ],
    "title": "Static and Dynamic Verification of Relational Properties on Self-composed C Code",
    "container-title": "Tests and Proofs",
    "collection-title": "Lecture Notes in Computer Science",
    "issued": {
      "date-parts": [
        [
          "2018"
        ]
      ]
    },
    "publisher": "Springer International Publishing",
    "isbn": "978-3-319-92994-1",
    "abstract": "Function contracts are a well-established way of formally specifying the intended behavior of a function. However, they usually only describe what should happen during a single call. Relational properties, on the other hand, link several function calls. They include such properties as non-interference, continuity and monotonicity. Other examples relate sequences of function calls, for instance, to show that decrypting an encrypted message with the appropriate key gives back the original message. Such properties cannot be expressed directly in the traditional setting of modular deductive verification, but are amenable to verification through self-composition. This paper presents a verification technique dedicated to relational properties in C programs and its implementation in the form of a Frama-C plugin called RPP and based on self-composition. It supports functions with side effects and recursive functions. The proposed approach makes it possible to prove a relational property, to check it at runtime, to generate a counterexample using testing and to use it as a hypothesis in the subsequent verification. Our initial experiments on existing benchmarks confirm that the proposed technique is helpful for static and dynamic analysis of relational properties.",
    "keywords": "Deductive verification, Dynamic verification, Frama-C, Relational properties, Self-composition, Specification",
    "page": "44-62",
    "page-first": "44",
    "language": "en-US",
    "_line": "FormalReview.bib:1901"
  },
  "melquiond_why3_nodate": {
    "id": "melquiond_why3_nodate",
    "type": "webpage",
    "author": [
      {
        "family": "Melquiond",
        "given": "Guillaume"
      }
    ],
    "title": "Why3",
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "URL": "http://why3.lri.fr/",
    "_line": "FormalReview.bib:1917"
  },
  "dijkstra_guarded_1975": {
    "id": "dijkstra_guarded_1975",
    "type": "article-journal",
    "author": [
      {
        "family": "Dijkstra",
        "given": "Edsger W."
      }
    ],
    "title": "Guarded Commands, Nondeterminacy and Formal Derivation of Programs",
    "container-title": "Commun. ACM",
    "issued": {
      "date-parts": [
        [
          "1975",
          "8"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "issn": "0001-0782",
    "abstract": "So-called “guarded commands” are introduced as a building block for alternative and repetitive constructs that allow nondeterministic program components for which at least the activity evoked, but possibly even the final state, is not necessarily uniquely determined by the initial state. For the formal derivation of programs expressed in terms of these constructs, a calculus will be be shown.",
    "keywords": "case-construction, correctness proof, derivation of programs, nondeterminancy, program semantics, programming language semantics, programming languages, programming methodology, repetition, sequencing primitives, termination",
    "URL": "http://doi.acm.org/10.1145/360933.360975",
    "DOI": "10.1145/360933.360975",
    "page": "453-457",
    "page-first": "453",
    "volume": "18",
    "issue": "8",
    "_line": "FormalReview.bib:1925"
  },
  "swamy_verifying_2013": {
    "id": "swamy_verifying_2013",
    "type": "article-journal",
    "author": [
      {
        "family": "Swamy",
        "given": "Nikhil"
      },
      {
        "family": "Chen",
        "given": "Juan"
      },
      {
        "family": "Livshits",
        "given": "Ben"
      }
    ],
    "title": "Verifying Higher-order Programs with the Dijkstra Monad",
    "issued": {
      "date-parts": [
        [
          "2013",
          "6",
          "1"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "abstract": "Modern programming languages, ranging from Haskell and ML, to JavaScript, C&hash; and Java, all make extensive use of higher-order state. This paper advocates a new verification methodology for higher-order stateful programs, based on a new monad of predicate transformers called the Dijkstra monad. Using the Dijkstra monad has a number of benefits. First, the monad …",
    "URL": "https://www.microsoft.com/en-us/research/publication/verifying-higher-order-programs-with-the-dijkstra-monad/",
    "language": "en-US",
    "_line": "FormalReview.bib:1942"
  },
  "swamy_dependent_2016": {
    "id": "swamy_dependent_2016",
    "type": "paper-conference",
    "author": [
      {
        "family": "Swamy",
        "given": "Nikhil"
      },
      {
        "family": "Hriţcu",
        "given": "Cătălin"
      },
      {
        "family": "Keller",
        "given": "Chantal"
      },
      {
        "family": "Rastogi",
        "given": "Aseem"
      },
      {
        "family": "Delignat-Lavaud",
        "given": "Antoine"
      },
      {
        "family": "Forest",
        "given": "Simon"
      },
      {
        "family": "Bhargavan",
        "given": "Karthikeyan"
      },
      {
        "family": "Fournet",
        "given": "Cédric"
      },
      {
        "family": "Strub",
        "given": "Pierre-Yves"
      },
      {
        "family": "Kohlweiss",
        "given": "Markulf"
      },
      {
        "family": "Zinzindohoue",
        "given": "Jean-Karim"
      },
      {
        "family": "Zanella-Béguelin",
        "given": "Santiago"
      }
    ],
    "title": "Dependent Types and Multi-monadic Effects in F\\*",
    "container-title": "Proceedings of the 43rd Annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages",
    "collection-title": "POPL '16",
    "issued": {
      "date-parts": [
        [
          "2016"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "publisher": "ACM",
    "isbn": "978-1-4503-3549-2",
    "abstract": "We present a new, completely redesigned, version of F\\*, a language that works both as a proof assistant as well as a general-purpose, verification-oriented, effectful programming language. In support of these complementary roles, F\\* is a dependently typed, higher-order, call-by-value language with &underscore;primitive&underscore; effects including state, exceptions, divergence and IO. Although primitive, programmers choose the granularity at which to specify effects by equipping each effect with a monadic, predicate transformer semantics. F\\* uses this to efficiently compute weakest preconditions and discharges the resulting proof obligations using a combination of SMT solving and manual proofs. Isolated from the effects, the core of F\\* is a language of pure functions used to write specifications and proof terms&mdash;its consistency is maintained by a semantic termination check based on a well-founded order. We evaluate our design on more than 55,000 lines of F\\* we have authored in the last year, focusing on three main case studies. Showcasing its use as a general-purpose programming language, F\\* is programmed (but not verified) in F\\*, and bootstraps in both OCaml and F&hash;. Our experience confirms F\\*'s pay-as-you-go cost model: writing idiomatic ML-like code with no finer specifications imposes no user burden. As a verification-oriented language, our most significant evaluation of F\\* is in verifying several key modules in an implementation of the TLS-1.2 protocol standard. For the modules we considered, we are able to prove more properties, with fewer annotations using F\\* than in a prior verified implementation of TLS-1.2. Finally, as a proof assistant, we discuss our use of F\\* in mechanizing the metatheory of a range of lambda calculi, starting from the simply typed lambda calculus to System F-omega and even micro-F\\*, a sizeable fragment of F\\* itself&mdash;these proofs make essential use of F\\*'s flexible combination of SMT automation and constructive proofs, enabling a tactic-free style of programming and proving at a relatively large scale.",
    "keywords": "effectful programming, proof assistants, verification",
    "URL": "http://doi.acm.org/10.1145/2837614.2837655",
    "DOI": "10.1145/2837614.2837655",
    "publisher-place": "New York, NY, USA",
    "page": "256-270",
    "page-first": "256",
    "_line": "FormalReview.bib:1953"
  },
  "ahman_dijkstra_2017": {
    "id": "ahman_dijkstra_2017",
    "type": "paper-conference",
    "author": [
      {
        "family": "Ahman",
        "given": "Danel"
      },
      {
        "family": "Hriţcu",
        "given": "Cătălin"
      },
      {
        "family": "Maillard",
        "given": "Kenji"
      },
      {
        "family": "Martínez",
        "given": "Guido"
      },
      {
        "family": "Plotkin",
        "given": "Gordon"
      },
      {
        "family": "Protzenko",
        "given": "Jonathan"
      },
      {
        "family": "Rastogi",
        "given": "Aseem"
      },
      {
        "family": "Swamy",
        "given": "Nikhil"
      }
    ],
    "title": "Dijkstra Monads for Free",
    "container-title": "Proceedings of the 44th ACM SIGPLAN Symposium on Principles of Programming Languages",
    "collection-title": "POPL 2017",
    "issued": {
      "date-parts": [
        [
          "2017"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "publisher": "ACM",
    "isbn": "978-1-4503-4660-3",
    "abstract": "Dijkstra monads enable a dependent type theory to be enhanced with support for specifying and verifying effectful code via weakest preconditions. Together with their closely related counterparts, Hoare monads, they provide the basis on which verification tools like F\\*, Hoare Type Theory (HTT), and Ynot are built. We show that Dijkstra monads can be derived \"for free\" by applying a continuation-passing style (CPS) translation to the standard monadic definitions of the underlying computational effects. Automatically deriving Dijkstra monads in this way provides a correct-by-construction and efficient way of reasoning about user-defined effects in dependent type theories. We demonstrate these ideas in EMF\\*, a new dependently typed calculus, validating it via both formal proof and a prototype implementation within F\\*. Besides equipping F\\* with a more uniform and extensible effect system, EMF\\* enables a novel mixture of intrinsic and extrinsic proofs within F\\*.",
    "keywords": "dependent types, effectful programming, proof assistants, verification",
    "URL": "http://doi.acm.org/10.1145/3009837.3009878",
    "DOI": "10.1145/3009837.3009878",
    "publisher-place": "New York, NY, USA",
    "page": "515-529",
    "page-first": "515",
    "_line": "FormalReview.bib:1971"
  },
  "hritcu_quest_nodate": {
    "id": "hritcu_quest_nodate",
    "type": "article-journal",
    "author": [
      {
        "family": "Hriţcu",
        "given": "Cătălin"
      }
    ],
    "title": "The Quest for Formally Secure Compartmentalizing Compilation",
    "abstract": "Severe low-level vulnerabilities abound in today’s computer systems, allowing cyber-attackers to remotely gain full control. This happens in big part because our programming languages, compilation chains, and architectures too often trade o security for e ciency. The semantics of mainstream low-level languages like C is inherently insecure, and even for safer languages, all guarantees are lost when interacting with low-level code, for instance when using low-level libraries. This habilitation presents my ongoing quest to build formally secure compartmentalizing compilation chains that defend against such attacks. In particular, we propose several formal de nitions that characterize what it means for a compartmentalizing compilation chain to be secure, both in the case of safe and of unsafe source languages.",
    "page": "96",
    "page-first": "96",
    "language": "en-US",
    "_line": "FormalReview.bib:1989"
  },
  "ahman_recalling_2017": {
    "id": "ahman_recalling_2017",
    "type": "article-journal",
    "author": [
      {
        "family": "Ahman",
        "given": "Danel"
      },
      {
        "family": "Fournet",
        "given": "Cédric"
      },
      {
        "family": "Hriţcu",
        "given": "Cătălin"
      },
      {
        "family": "Maillard",
        "given": "Kenji"
      },
      {
        "family": "Rastogi",
        "given": "Aseem"
      },
      {
        "family": "Swamy",
        "given": "Nikhil"
      }
    ],
    "title": "Recalling a Witness: Foundations and Applications of Monotonic State",
    "container-title": "Proc. ACM Program. Lang.",
    "container-title-short": "Recalling a Witness",
    "title-short": "Recalling a Witness",
    "issued": {
      "date-parts": [
        [
          "2017",
          "12"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "issn": "2475-1421",
    "abstract": "We provide a way to ease the verification of programs whose state evolves monotonically. The main idea is that a property witnessed in a prior state can be soundly recalled in the current state, provided (1) state evolves according to a given preorder, and (2) the property is preserved by this preorder. In many scenarios, such monotonic reasoning yields concise modular proofs, saving the need for explicit program invariants. We distill our approach into the monotonic-state monad, a general yet compact interface for Hoare-style reasoning about monotonic state in a dependently typed language. We prove the soundness of the monotonic-state monad and use it as a unified foundation for reasoning about monotonic state in the F⋆ verification system. Based on this foundation, we build libraries for various mutable data structures like monotonic references and apply these libraries at scale to the verification of several distributed applications.",
    "keywords": "Formal Foundations, Hoare Logic, Modular Reasoning, Monotonic References, Monotonic-State Monad, Program Verification, Secure File Transfer, State Continuity",
    "URL": "http://doi.acm.org/10.1145/3158153",
    "DOI": "10.1145/3158153",
    "page": "65:1-65:30",
    "page-first": "65",
    "volume": "2",
    "_line": "FormalReview.bib:1998"
  },
  "syme_fsharp_2019": {
    "id": "syme_fsharp_2019",
    "type": "book",
    "author": [
      {
        "family": "Syme",
        "given": "Don"
      }
    ],
    "title": "Fsharp design: RFCs and docs related to the F&hash; language design process,",
    "container-title-short": "RFCs and docs related to the F&hash; language design process, see https",
    "title-short": "RFCs and docs related to the F&hash; language design process, see https",
    "issued": {
      "date-parts": [
        [
          "2019",
          "1",
          "29"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "publisher": "F&hash; Software Foundation Repositories",
    "URL": "https://github.com/fsharp/fslang-design",
    "note": "original-date: 2014-06-25T13:07:35Z",
    "_line": "FormalReview.bib:2016"
  },
  "syme_fsharp_2019-1": {
    "id": "syme_fsharp_2019-1",
    "type": "book",
    "author": [
      {
        "family": "Syme",
        "given": "Don"
      }
    ],
    "title": "The Fsharp Compiler, Core Library &amp; Tools (F&hash; Software Foundation Repository): fsharp/fsharp",
    "container-title-short": "The F&hash; Compiler, Core Library &amp; Tools (F&hash; Software Foundation Repository)",
    "title-short": "The F&hash; Compiler, Core Library &amp; Tools (F&hash; Software Foundation Repository)",
    "issued": {
      "date-parts": [
        [
          "2019",
          "1",
          "30"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "publisher": "F&hash; Software Foundation Repositories",
    "URL": "https://github.com/fsharp/fsharp",
    "note": "original-date: 2010-12-13T00:19:52Z",
    "_line": "FormalReview.bib:2027"
  },
  "filinski_representing_1994": {
    "id": "filinski_representing_1994",
    "type": "paper-conference",
    "author": [
      {
        "family": "Filinski",
        "given": "Andrzej"
      }
    ],
    "title": "Representing Monads",
    "container-title": "Proceedings of the 21st ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages",
    "collection-title": "POPL '94",
    "issued": {
      "date-parts": [
        [
          "1994"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "publisher": "ACM",
    "isbn": "978-0-89791-636-3",
    "abstract": "We show that any monad whose unit and extension operations are expressible as purely functional terms can be embedded in a call-by-value language with “composable continuations”. As part of the development, we extend Meyer and Wand's characterization of the relationship between continuation-passing and direct style to one for continuation-passing vs. general “monadic” style. We further show that the composable-continuations construct can itself be represented using ordinary, non-composable first-class continuations and a single piece of state. Thus, in the presence of two specific computational effects - storage and escapes - any expressible monadic structure (e.g., nondeterminism as represented by the list monad) can be added as a purely definitional extension, without requiring a reinterpretation of the whole language. The paper includes an implementation of the construction (in Standard ML with some New Jersey extensions) and several examples.",
    "URL": "http://doi.acm.org/10.1145/174675.178047",
    "DOI": "10.1145/174675.178047",
    "publisher-place": "New York, NY, USA",
    "page": "446-457",
    "page-first": "446",
    "_line": "FormalReview.bib:2054"
  },
  "filinski_representing_1999": {
    "id": "filinski_representing_1999",
    "type": "paper-conference",
    "author": [
      {
        "family": "Filinski",
        "given": "Andrzej"
      }
    ],
    "title": "Representing Layered Monads",
    "container-title": "Proceedings of the 26th ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages",
    "collection-title": "POPL '99",
    "issued": {
      "date-parts": [
        [
          "1999"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "publisher": "ACM",
    "isbn": "978-1-58113-095-9",
    "abstract": "There has already been considerable research on constructing modular, monad-based specifications of computational effects (state, exceptions, nondeterminism, etc.) in programming languages. We present a simple framework in this tradition, based on a Church-style effect-typing system for an ML-like language. The semantics of this language is formally defined by a series of monadic translations, each one expanding away a layer of effects. Such a layered specification is easy to reason about, but its direct implementation (whether by parameterized interpretation or by actual translation) is often prohibitively inefficient.By exploiting deeper semantic properties of monads, however, it is also possible to derive a vastly more efficient implementation: we show that each layer of effects can be uniformly simulated by continuation-passing, and further that multiple such layers can themselves be simulated by a standard semantics for call/cc and mutable state. Thus, even multi-effect programs can be executed in Scheme or SML/NJ at full native speed, generalizing an earlier single-effect result. As an example, we show how a simple resumption-based semantics of concurrency allows us to directly simulate a shared-state program across all possible dynamic interleavings of execution threads.",
    "URL": "http://doi.acm.org/10.1145/292540.292557",
    "DOI": "10.1145/292540.292557",
    "publisher-place": "New York, NY, USA",
    "page": "175-188",
    "page-first": "175",
    "_line": "FormalReview.bib:2071"
  },
  "gonthier_introduction_2010": {
    "id": "gonthier_introduction_2010",
    "type": "article-journal",
    "author": [
      {
        "family": "Gonthier",
        "given": "Georges"
      },
      {
        "family": "Mahboubi",
        "given": "Assia"
      }
    ],
    "title": "An introduction to small scale reflection in Coq",
    "container-title": "Journal of Formalized Reasoning",
    "issued": {
      "date-parts": [
        [
          "2010"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "issn": "1972-5787",
    "abstract": "This tutorial presents the SSReflect extension to the Coq system. This extension consists of an extension to the Coq language of script, and of a set of libraries, originating from the formal proof of the Four Color theorem. This tutorial proposes a guided tour in some of the basic libraries distributed in the SSReflect package. It focuses on the application of the small scale reflection methodology to the formalization of finite objects in intuitionistic type theory.",
    "URL": "https://jfr.unibo.it/article/view/1979",
    "DOI": "10.6092/issn.1972-5787/1979",
    "page": "95-152",
    "page-first": "95",
    "volume": "3",
    "issue": "2",
    "language": "en-US",
    "_line": "FormalReview.bib:2088"
  },
  "gonthier_how_2011": {
    "id": "gonthier_how_2011",
    "type": "paper-conference",
    "author": [
      {
        "family": "Gonthier",
        "given": "Georges"
      },
      {
        "family": "Ziliani",
        "given": "Beta"
      },
      {
        "family": "Nanevski",
        "given": "Aleksandar"
      },
      {
        "family": "Dreyer",
        "given": "Derek"
      }
    ],
    "title": "How to Make Ad Hoc Proof Automation Less Ad Hoc",
    "container-title": "Proceedings of the 16th ACM SIGPLAN International Conference on Functional Programming",
    "collection-title": "ICFP '11",
    "issued": {
      "date-parts": [
        [
          "2011"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "publisher": "ACM",
    "isbn": "978-1-4503-0865-6",
    "abstract": "Most interactive theorem provers provide support for some form of user-customizable proof automation. In a number of popular systems, such as Coq and Isabelle, this automation is achieved primarily through tactics, which are programmed in a separate language from that of the prover's base logic. While tactics are clearly useful in practice, they can be difficult to maintain and compose because, unlike lemmas, their behavior cannot be specified within the expressive type system of the prover itself. We propose a novel approach to proof automation in Coq that allows the user to specify the behavior of custom automated routines in terms of Coq's own type system. Our approach involves a sophisticated application of Coq's canonical structures, which generalize Haskell type classes and facilitate a flexible style of dependently-typed logic programming. Specifically, just as Haskell type classes are used to infer the canonical implementation of an overloaded term at a given type, canonical structures can be used to infer the canonical proof of an overloaded lemma for a given instantiation of its parameters. We present a series of design patterns for canonical structure programming that enable one to carefully and predictably coax Coq's type inference engine into triggering the execution of user-supplied algorithms during unification, and we illustrate these patterns through several realistic examples drawn from Hoare Type Theory. We assume no prior knowledge of Coq and describe the relevant aspects of Coq type inference from first principles.",
    "keywords": "canonical structures, coq, custom proof automation, hoare type theory, interactive theorem proving, tactics, type classes",
    "URL": "http://doi.acm.org/10.1145/2034773.2034798",
    "DOI": "10.1145/2034773.2034798",
    "publisher-place": "New York, NY, USA",
    "page": "163-175",
    "page-first": "163",
    "_line": "FormalReview.bib:2106"
  },
  "mokhov_algebraic_2017": {
    "id": "mokhov_algebraic_2017",
    "type": "paper-conference",
    "author": [
      {
        "family": "Mokhov",
        "given": "Andrey"
      }
    ],
    "title": "Algebraic Graphs with Class (Functional Pearl)",
    "container-title": "Proceedings of the 10th ACM SIGPLAN International Symposium on Haskell",
    "collection-title": "Haskell 2017",
    "issued": {
      "date-parts": [
        [
          "2017"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "publisher": "ACM",
    "isbn": "978-1-4503-5182-9",
    "abstract": "The paper presents a minimalistic and elegant approach to working with graphs in Haskell. It is built on a rigorous mathematical foundation &mdash; an algebra of graphs &mdash; that allows us to apply equational reasoning for proving the correctness of graph transformation algorithms. Algebraic graphs let us avoid partial functions typically caused by 'malformed graphs' that contain an edge referring to a non-existent vertex. This helps to liberate APIs of existing graph libraries from partial functions.   The algebra of graphs can represent directed, undirected, reflexive and transitive graphs, as well as hypergraphs, by appropriately choosing the set of underlying axioms. The flexibility of the approach is demonstrated by developing a library for constructing and transforming polymorphic graphs.",
    "keywords": "algebra, graph theory, Haskell",
    "URL": "http://doi.acm.org/10.1145/3122955.3122956",
    "DOI": "10.1145/3122955.3122956",
    "publisher-place": "New York, NY, USA",
    "page": "2-13",
    "page-first": "2",
    "_line": "FormalReview.bib:2124"
  },
  "ramsey_applicative_2006": {
    "id": "ramsey_applicative_2006",
    "type": "article-journal",
    "author": [
      {
        "family": "Ramsey",
        "given": "Norman"
      },
      {
        "family": "Dias",
        "given": "João"
      }
    ],
    "title": "An Applicative Control-Flow Graph Based on Huet's Zipper",
    "container-title": "Electronic Notes in Theoretical Computer Science",
    "collection-title": "Proceedings of the ACM-SIGPLAN Workshop on ML (ML 2005)",
    "issued": {
      "date-parts": [
        [
          "2006",
          "3",
          "24"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "issn": "1571-0661",
    "abstract": "We are using ML to build a compiler that does low-level optimization. To support optimizations in classic imperative style, we built a control-flow graph using mutable pointers and other mutable state in the nodes. This decision proved unfortunate: the mutable flow graph was big and complex, and it led to many bugs. We have replaced it by a smaller, simpler, applicative flow graph based on Huet's \\[Huet, Gérard, 1997. The Zipper. Journal of Functional Programming, 7(5):549–554. Functional Pearl\\] zipper. The new flow graph is a success; this paper presents its design and shows how it leads to a gratifyingly simple implementation of the dataflow framework developed by \\[Lerner, Sorin, David Grove, and Craig Chambers. 2002. Composing dataflow analyses and transformations. Conference Record of the 29th Annual ACM Symposium on Principles of Programming Languages, in SIGPLAN Notices, 31(1):270–282\\].",
    "keywords": "applicative data structures, compilers, control-flow graphs, dataflow analysis, optimization",
    "URL": "http://www.sciencedirect.com/science/article/pii/S1571066106001289",
    "DOI": "10.1016/j.entcs.2005.11.042",
    "page": "105-126",
    "page-first": "105",
    "volume": "148",
    "issue": "2",
    "_line": "FormalReview.bib:2142"
  },
  "harper_framework_1993": {
    "id": "harper_framework_1993",
    "type": "article-journal",
    "author": [
      {
        "family": "Harper",
        "given": "Robert"
      },
      {
        "family": "Honsell",
        "given": "Furio"
      },
      {
        "family": "Plotkin",
        "given": "Gordon"
      }
    ],
    "title": "A Framework for Defining Logics",
    "container-title": "J. ACM",
    "issued": {
      "date-parts": [
        [
          "1993",
          "1"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "issn": "0004-5411",
    "abstract": "The Edinburgh Logical Framework (LF) provides a means to define (or present) logics. It is based on a general treatment of syntax, rules, and proofs by means of a typed &amp;lgr;-calculus with dependent types. Syntax is treated in a style similar to, but more general than, Martin-Lo¨f's system of arities. The treatment of rules and proofs focuses on his notion of a judgment. Logics are represented in LF via a new principle, the judgments as types principle, whereby each judgment is identified with the type of its proofs. This allows for a smooth treatment of discharge and variable occurence conditions and leads to a uniform treatment of rules and proofs whereby rules are viewed as proofs of higher-order judgments and proof checking is reduced to type checking. The practical benefit of our treatment of formal systems is that logic-independent tools, such as proof editors and proof checkers, can be constructed.",
    "keywords": "formal systems, interactive theorem proving, proof checking, typed lambda calculus",
    "URL": "http://doi.acm.org/10.1145/138027.138060",
    "DOI": "10.1145/138027.138060",
    "page": "143-184",
    "page-first": "143",
    "volume": "40",
    "issue": "1",
    "_line": "FormalReview.bib:2160"
  },
  "harrison_hol_2013": {
    "id": "harrison_hol_2013",
    "type": "article-journal",
    "author": [
      {
        "family": "Harrison",
        "given": "John"
      }
    ],
    "title": "The HOL Light Theory of Euclidean Space",
    "container-title": "Journal of Automated Reasoning",
    "issued": {
      "date-parts": [
        [
          "2013",
          "2"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "issn": "0168-7433, 1573-0670",
    "URL": "http://link.springer.com/10.1007/s10817-012-9250-9",
    "DOI": "10.1007/s10817-012-9250-9",
    "page": "173-190",
    "page-first": "173",
    "volume": "50",
    "issue": "2",
    "language": "en-US",
    "_line": "FormalReview.bib:2177"
  },
  "spector-zabusky_total_2018": {
    "id": "spector-zabusky_total_2018",
    "type": "paper-conference",
    "author": [
      {
        "family": "Spector-Zabusky",
        "given": "Antal"
      },
      {
        "family": "Breitner",
        "given": "Joachim"
      },
      {
        "family": "Rizkallah",
        "given": "Christine"
      },
      {
        "family": "Weirich",
        "given": "Stephanie"
      }
    ],
    "title": "Total Haskell is Reasonable Coq",
    "container-title": "Proceedings of the 7th ACM SIGPLAN International Conference on Certified Programs and Proofs",
    "collection-title": "CPP 2018",
    "issued": {
      "date-parts": [
        [
          "2018"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "publisher": "ACM",
    "isbn": "978-1-4503-5586-5",
    "abstract": "We would like to use the Coq proof assistant to mechanically verify properties of Haskell programs. To that end, we present a tool, named &lt;tt&gt;hs-to-coq&lt;/tt&gt;, that translates total Haskell programs into Coq programs via a shallow embedding. We apply our tool in three case studies – a lawful &lt;tt&gt;Monad&lt;/tt&gt; instance, “Hutton’s razor”, and an existing data structure library – and prove their correctness. These examples show that this approach is viable: both that &lt;tt&gt;hs-to-coq&lt;/tt&gt; applies to existing Haskell code, and that the output it produces is amenable to verification.",
    "keywords": "Coq, Haskell, verification",
    "URL": "http://doi.acm.org/10.1145/3167092",
    "DOI": "10.1145/3167092",
    "publisher-place": "New York, NY, USA",
    "page": "14-27",
    "page-first": "14",
    "_line": "FormalReview.bib:2193"
  },
  "hutchison_fresh_2009": {
    "id": "hutchison_fresh_2009",
    "type": "chapter",
    "author": [
      {
        "family": "Dockins",
        "given": "Robert"
      },
      {
        "family": "Hobor",
        "given": "Aquinas"
      },
      {
        "family": "Appel",
        "given": "Andrew W."
      }
    ],
    "editor": [
      {
        "family": "Hu",
        "given": "Zhenjiang"
      }
    ],
    "title": "A Fresh Look at Separation Algebras and Share Accounting",
    "container-title": "Programming Languages and Systems",
    "issued": {
      "date-parts": [
        [
          "2009"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "publisher": "Springer Berlin Heidelberg",
    "isbn": "978-3-642-10671-2 978-3-642-10672-9",
    "abstract": "Separation Algebras serve as models of Separation Logics; Share Accounting allows reasoning about concurrent-read/exclusive-write resources in Separation Logic. In designing a Concurrent Separation Logic and in mechanizing proofs of its soundness, we found previous axiomatizations of separation algebras and previous systems of share accounting to be useful but ﬂawed. We adjust the axioms of separation algebras; we demonstrate an operator calculus for constructing new separation algebras; we present a more powerful system of share accounting with a new, simple model; and we provide a reusable Coq development.",
    "URL": "http://link.springer.com/10.1007/978-3-642-10672-9_13",
    "DOI": "10.1007/978-3-642-10672-9_13",
    "publisher-place": "Berlin, Heidelberg",
    "page": "161-177",
    "page-first": "161",
    "volume": "5904",
    "language": "en-US",
    "_line": "FormalReview.bib:2211"
  },
  "swamy_project_nodate": {
    "id": "swamy_project_nodate",
    "type": "webpage",
    "author": [
      {
        "family": "Swamy",
        "given": "Nikhil"
      }
    ],
    "title": "Project Everest - Verified Secure Implementations of the HTTPS Ecosystem.Microsoft Research",
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "abstract": "This project proposes to deﬁnitively solve the problem of a brittle HTTPS ecosystem by constructing a more secure, high performance, standards-compliant, veriﬁed implementation of the full HTTPS ecosystem. Unlike other veriﬁed software projects, our expedition aims to deploy Everest within existing software as a drop-in replacement in mainstream web browsers, servers, and other popular tools.",
    "URL": "https://www.microsoft.com/en-us/research/project/project-everest-verified-secure-implementations-https-ecosystem/",
    "language": "en-US",
    "_line": "FormalReview.bib:2232"
  },
  "fournet_deploying_nodate": {
    "id": "fournet_deploying_nodate",
    "type": "article-journal",
    "author": [
      {
        "family": "Fournet",
        "given": "Cedric"
      },
      {
        "family": "Hawblitzel",
        "given": "Chris"
      },
      {
        "family": "Parno",
        "given": "Bryan"
      },
      {
        "family": "Swamy",
        "given": "Nikhil"
      }
    ],
    "title": "Deploying a Veriﬁed Secure Implementation of the HTTPS Ecosystem",
    "page": "10",
    "page-first": "10",
    "language": "en-US",
    "_line": "FormalReview.bib:2243"
  },
  "hawblitzel_ironclad_nodate": {
    "id": "hawblitzel_ironclad_nodate",
    "type": "article-journal",
    "author": [
      {
        "family": "Hawblitzel",
        "given": "Chris"
      },
      {
        "family": "Howell",
        "given": "Jon"
      },
      {
        "family": "Lorch",
        "given": "Jacob R"
      },
      {
        "family": "Narayan",
        "given": "Arjun"
      },
      {
        "family": "Parno",
        "given": "Bryan"
      },
      {
        "family": "Zhang",
        "given": "Danfeng"
      },
      {
        "family": "Zill",
        "given": "Brian"
      }
    ],
    "title": "Ironclad Apps: End-to-End Security via Automated Full-System Veriﬁcation",
    "abstract": "An Ironclad App lets a user securely transmit her data to a remote machine with the guarantee that every instruction executed on that machine adheres to a formal abstract speciﬁcation of the app’s behavior. This does more than eliminate implementation vulnerabilities such as buffer overﬂows, parsing errors, or data leaks; it tells the user exactly how the app will behave at all times. We provide these guarantees via complete, low-level software veriﬁcation. We then use cryptography and secure hardware to enable secure channels from the veriﬁed software to remote users. To achieve such complete veriﬁcation, we developed a set of new and modiﬁed tools, a collection of techniques and engineering disciplines, and a methodology focused on rapid development of veriﬁed systems software. We describe our methodology, formal results, and lessons we learned from building a full stack of veriﬁed software. That software includes a veriﬁed kernel; veriﬁed drivers; veriﬁed system and crypto libraries including SHA, HMAC, and RSA; and four Ironclad Apps.",
    "page": "18",
    "page-first": "18",
    "language": "en-US",
    "_line": "FormalReview.bib:2251"
  },
  "hawblitzel_ironfleet:_2015": {
    "id": "hawblitzel_ironfleet:_2015",
    "type": "paper-conference",
    "author": [
      {
        "family": "Hawblitzel",
        "given": "Chris"
      },
      {
        "family": "Howell",
        "given": "Jon"
      },
      {
        "family": "Kapritsos",
        "given": "Manos"
      },
      {
        "family": "Lorch",
        "given": "Jacob R."
      },
      {
        "family": "Parno",
        "given": "Bryan"
      },
      {
        "family": "Roberts",
        "given": "Michael L."
      },
      {
        "family": "Setty",
        "given": "Srinath"
      },
      {
        "family": "Zill",
        "given": "Brian"
      }
    ],
    "title": "IronFleet: Proving Practical Distributed Systems Correct",
    "container-title": "Proceedings of the 25th Symposium on Operating Systems Principles",
    "container-title-short": "IronFleet",
    "collection-title": "SOSP '15",
    "title-short": "IronFleet",
    "issued": {
      "date-parts": [
        [
          "2015"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "publisher": "ACM",
    "isbn": "978-1-4503-3834-9",
    "abstract": "Distributed systems are notorious for harboring subtle bugs. Verification can, in principle, eliminate these bugs a priori, but verification has historically been difficult to apply at full-program scale, much less distributed-system scale. We describe a methodology for building practical and provably correct distributed systems based on a unique blend of TLA-style state-machine refinement and Hoare-logic verification. We demonstrate the methodology on a complex implementation of a Paxos-based replicated state machine library and a lease-based sharded key-value store. We prove that each obeys a concise safety specification, as well as desirable liveness requirements. Each implementation achieves performance competitive with a reference system. With our methodology and lessons learned, we aim to raise the standard for distributed systems from \"tested\" to \"correct.\"",
    "URL": "http://doi.acm.org/10.1145/2815400.2815428",
    "DOI": "10.1145/2815400.2815428",
    "publisher-place": "New York, NY, USA",
    "page": "1-17",
    "page-first": "1",
    "_line": "FormalReview.bib:2260"
  },
  "hawblitzel_automated_2015": {
    "id": "hawblitzel_automated_2015",
    "type": "paper-conference",
    "author": [
      {
        "family": "Hawblitzel",
        "given": "Chris"
      },
      {
        "family": "Petrank",
        "given": "Erez"
      },
      {
        "family": "Qadeer",
        "given": "Shaz"
      },
      {
        "family": "Tasiran",
        "given": "Serdar"
      }
    ],
    "title": "Automated and Modular Refinement Reasoning for Concurrent Programs",
    "container-title": "Computer Aided Verification",
    "event-title": "International Conference on Computer Aided Verification",
    "issued": {
      "date-parts": [
        [
          "2015",
          "7",
          "18"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "publisher": "Springer, Cham",
    "abstract": "We present civl, a language and verifier for concurrent programs based on automated and modular refinement reasoning. civlsupports reasoning about a concurrent program at many levels of abstraction....",
    "URL": "https://link.springer.com/chapter/10.1007/978-3-319-21668-3_26",
    "DOI": "10.1007/978-3-319-21668-3_26",
    "page": "449-465",
    "page-first": "449",
    "language": "en-US",
    "_line": "FormalReview.bib:2278"
  },
  "lahiri_automatic_2015": {
    "id": "lahiri_automatic_2015",
    "type": "paper-conference",
    "author": [
      {
        "family": "Lahiri",
        "given": "Shuvendu K."
      },
      {
        "family": "Sinha",
        "given": "Rohit"
      },
      {
        "family": "Hawblitzel",
        "given": "Chris"
      }
    ],
    "editor": [
      {
        "family": "Kroening",
        "given": "Daniel"
      },
      {
        "family": "Păsăreanu",
        "given": "Corina S."
      }
    ],
    "title": "Automatic Rootcausing for Program Equivalence Failures in Binaries",
    "container-title": "Computer Aided Verification",
    "collection-title": "Lecture Notes in Computer Science",
    "issued": {
      "date-parts": [
        [
          "2015"
        ]
      ]
    },
    "publisher": "Springer International Publishing",
    "isbn": "978-3-319-21690-4",
    "abstract": "Equivalence checking of imperative programs has several applications including compiler validation and cross-version verification. Debugging equivalence failures can be tedious for large examples, especially for low-level binary programs. In this paper, we formalize a simple yet precise notion of verifiable rootcause for equivalence failures that leverages semantic similarity between two programs. Unlike existing works on program repair, our definition of rootcause avoids the need for a template of fixes or the need for a complete repair to ensure equivalence. We show progressively weaker checks for detecting rootcauses that can be applicable even when multiple fixes are required to make the two programs equivalent. We provide optimizations based on Maximum Satisfiability (MAXSAT) and binary search to prune the search space of such rootcauses. We have implemented the techniques in SymDiff and provide an evaluation on a set of real-world compiler validation binary benchmarks.",
    "page": "362-379",
    "page-first": "362",
    "language": "en-US",
    "_line": "FormalReview.bib:2294"
  },
  "yang_safe_2011": {
    "id": "yang_safe_2011",
    "type": "article-journal",
    "author": [
      {
        "family": "Yang",
        "given": "Jean"
      },
      {
        "family": "Hawblitzel",
        "given": "Chris"
      }
    ],
    "title": "Safe to the last instruction: automated verification of a type-safe operating system",
    "container-title": "Communications of the ACM",
    "container-title-short": "Safe to the last instruction",
    "title-short": "Safe to the last instruction",
    "issued": {
      "date-parts": [
        [
          "2011",
          "12",
          "1"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "issn": "00010782",
    "URL": "http://dl.acm.org/citation.cfm?doid=2043174.2043197",
    "DOI": "10.1145/2043174.2043197",
    "page": "123",
    "page-first": "123",
    "volume": "54",
    "issue": "12",
    "language": "en-US",
    "_line": "FormalReview.bib:2309"
  },
  "lahiri_symdiff:_2012": {
    "id": "lahiri_symdiff:_2012",
    "type": "paper-conference",
    "author": [
      {
        "family": "Lahiri",
        "given": "Shuvendu K."
      },
      {
        "family": "Hawblitzel",
        "given": "Chris"
      },
      {
        "family": "Kawaguchi",
        "given": "Ming"
      },
      {
        "family": "Rebêlo",
        "given": "Henrique"
      }
    ],
    "editor": [
      {
        "family": "Madhusudan",
        "given": "P."
      },
      {
        "family": "Seshia",
        "given": "Sanjit A."
      }
    ],
    "title": "SYMDIFF: A Language-Agnostic Semantic Diff Tool for Imperative Programs",
    "container-title": "Computer Aided Verification",
    "container-title-short": "SYMDIFF",
    "collection-title": "Lecture Notes in Computer Science",
    "title-short": "SYMDIFF",
    "issued": {
      "date-parts": [
        [
          "2012"
        ]
      ]
    },
    "publisher": "Springer Berlin Heidelberg",
    "isbn": "978-3-642-31424-7",
    "abstract": "In this paper, we describe SymDiff, a language-agnostic tool for equivalence checking and displaying semantic (behavioral) differences over imperative programs. The tool operates on an intermediate verification language Boogie, for which translations exist from various source languages such as C, C&hash; and x86. We discuss the tool and the front-end interface to target various source languages. Finally, we provide a brief description of the front-end for C programs.",
    "keywords": "Equivalence Check, Imperative Language, Imperative Program, Source Language, Symbolic Execution",
    "page": "712-717",
    "page-first": "712",
    "language": "en-US",
    "_line": "FormalReview.bib:2326"
  },
  "adams_common_2015": {
    "id": "adams_common_2015",
    "type": "article-journal",
    "author": [
      {
        "family": "Adams",
        "given": "Mark"
      }
    ],
    "title": "The Common HOL Platform",
    "container-title": "Electronic Proceedings in Theoretical Computer Science",
    "issued": {
      "date-parts": [
        [
          "2015",
          "7",
          "30"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "issn": "2075-2180",
    "abstract": "The Common HOL project aims to facilitate porting source code and proofs between members of the HOL family of theorem provers. At the heart of the project is the Common HOL Platform, which defines a standard HOL theory and API that aims to be compatible with all HOL systems. So far, HOL Light and hol90 have been adapted for conformance, and HOL Zero was originally developed to conform. In this paper we provide motivation for a platform, give an overview of the Common HOL Platform's theory and API components, and show how to adapt legacy systems. We also report on the platform's successful application in the hand-translation of a few thousand lines of source code from HOL Light to HOL Zero.",
    "keywords": "Computer Science - Digital Libraries, Computer Science - Logic in Computer Science",
    "URLtext": "1507.08718",
    "URLpretext": "[arXiv:]{.etype}",
    "eprint-type": "arxiv",
    "eprint": "1507.08718",
    "URL": "http://arxiv.org/abs/1507.08718",
    "DOI": "10.4204/EPTCS.186.6",
    "page": "42-56",
    "page-first": "42",
    "volume": "186",
    "_line": "FormalReview.bib:2343"
  },
  "shulman_hott_2013": {
    "id": "shulman_hott_2013",
    "type": "webpage",
    "author": [
      {
        "family": "Shulman",
        "given": "Mike"
      }
    ],
    "title": "The HoTT Book.Homotopy Type Theory",
    "issued": {
      "date-parts": [
        [
          "2013",
          "3",
          "12"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "abstract": "Homotopy Type Theory: Univalent Foundations of Mathematics The Univalent Foundations Program Institute for Advanced Study Buy a hardcover copy for &dollar;22.05. \\[620 pages, 6″ × 9″ size, hard…",
    "URL": "https://homotopytypetheory.org/book/",
    "language": "en-US",
    "_line": "FormalReview.bib:2361"
  },
  "voevodsky_homotopy_nodate": {
    "id": "voevodsky_homotopy_nodate",
    "type": "article-journal",
    "author": [
      {
        "family": "Voevodsky",
        "given": "Vladimir"
      }
    ],
    "title": "Homotopy Type Theory: Univalent Foundations of Mathematics",
    "page": "490",
    "page-first": "490",
    "language": "en-US",
    "_line": "FormalReview.bib:2373"
  },
  "nelson_hyperkernel:_2017": {
    "id": "nelson_hyperkernel:_2017",
    "type": "paper-conference",
    "author": [
      {
        "family": "Nelson",
        "given": "Luke"
      },
      {
        "family": "Sigurbjarnarson",
        "given": "Helgi"
      },
      {
        "family": "Zhang",
        "given": "Kaiyuan"
      },
      {
        "family": "Johnson",
        "given": "Dylan"
      },
      {
        "family": "Bornholt",
        "given": "James"
      },
      {
        "family": "Torlak",
        "given": "Emina"
      },
      {
        "family": "Wang",
        "given": "Xi"
      }
    ],
    "title": "Hyperkernel: Push-Button Verification of an OS Kernel",
    "container-title": "Proceedings of the 26th Symposium on Operating Systems Principles",
    "container-title-short": "Hyperkernel",
    "collection-title": "SOSP '17",
    "title-short": "Hyperkernel",
    "issued": {
      "date-parts": [
        [
          "2017"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "publisher": "ACM",
    "isbn": "978-1-4503-5085-3",
    "abstract": "This paper describes an approach to designing, implementing, and formally verifying the functional correctness of an OS kernel, named Hyperkernel, with a high degree of proof automation and low proof burden. We base the design of Hyperkernel's interface on xv6, a Unix-like teaching operating system. Hyperkernel introduces three key ideas to achieve proof automation: it finitizes the kernel interface to avoid unbounded loops or recursion; it separates kernel and user address spaces to simplify reasoning about virtual memory; and it performs verification at the LLVM intermediate representation level to avoid modeling complicated C semantics. We have verified the implementation of Hyperkernel with the Z3 SMT solver, checking a total of 50 system calls and other trap handlers. Experience shows that Hyperkernel can avoid bugs similar to those found in xv6, and that the verification of Hyperkernel can be achieved with a low proof burden.",
    "URL": "http://doi.acm.org/10.1145/3132747.3132748",
    "DOI": "10.1145/3132747.3132748",
    "publisher-place": "New York, NY, USA",
    "page": "252-269",
    "page-first": "252",
    "_line": "FormalReview.bib:2381"
  },
  "nelson_hyperkernel:_2017-1": {
    "id": "nelson_hyperkernel:_2017-1",
    "type": "paper-conference",
    "author": [
      {
        "family": "Nelson",
        "given": "Luke"
      },
      {
        "family": "Sigurbjarnarson",
        "given": "Helgi"
      },
      {
        "family": "Zhang",
        "given": "Kaiyuan"
      },
      {
        "family": "Johnson",
        "given": "Dylan"
      },
      {
        "family": "Bornholt",
        "given": "James"
      },
      {
        "family": "Torlak",
        "given": "Emina"
      },
      {
        "family": "Wang",
        "given": "Xi"
      }
    ],
    "title": "Hyperkernel: Push-Button Verification of an OS Kernel - Slides",
    "container-title": "Proceedings of the 26th Symposium on Operating Systems Principles  - SOSP '17",
    "container-title-short": "Hyperkernel",
    "title-short": "Hyperkernel",
    "event-title": "the 26th Symposium",
    "issued": {
      "date-parts": [
        [
          "2017"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "publisher": "ACM Press",
    "isbn": "978-1-4503-5085-3",
    "URL": "http://dl.acm.org/citation.cfm?doid=3132747.3132748",
    "DOI": "10.1145/3132747.3132748",
    "publisher-place": "Shanghai, China",
    "page": "252-269",
    "page-first": "252",
    "language": "en-US",
    "_line": "FormalReview.bib:2399"
  },
  "jung_iris_nodate": {
    "id": "jung_iris_nodate",
    "type": "webpage",
    "author": [
      {
        "family": "Jung",
        "given": "Ralf"
      }
    ],
    "title": "Iris Project",
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "URL": "https://iris-project.org/",
    "_line": "FormalReview.bib:2417"
  },
  "birkedal_iris_nodate": {
    "id": "birkedal_iris_nodate",
    "type": "webpage",
    "author": [
      {
        "family": "Birkedal",
        "given": "Lars"
      },
      {
        "family": "Bizjak",
        "given": "Aleš"
      }
    ],
    "title": "Iris Tutorial",
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "URL": "https://iris-project.org/tutorial-material.html",
    "_line": "FormalReview.bib:2425"
  },
  "jung_iris_2018": {
    "id": "jung_iris_2018",
    "type": "article-journal",
    "author": [
      {
        "family": "Jung",
        "given": "Ralf"
      },
      {
        "family": "Krebbers",
        "given": "Robbert"
      },
      {
        "family": "Jourdan",
        "given": "Jacques-Henri"
      },
      {
        "family": "Bizjak",
        "given": "Aleš"
      },
      {
        "family": "Birkedal",
        "given": "Lars"
      },
      {
        "family": "Dreyer",
        "given": "Derek"
      }
    ],
    "title": "Iris from the ground up: A modular foundation for higher-order concurrent separation logic",
    "container-title": "Journal of Functional Programming",
    "container-title-short": "Iris from the ground up",
    "title-short": "Iris from the ground up",
    "issued": {
      "date-parts": [
        [
          "2018"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "issn": "0956-7968, 1469-7653",
    "abstract": "Iris is a framework for higher-order concurrent separation logic, which has been implemented in the Coq proof assistant and deployed very effectively in a wide variety of verification projects. Iris was designed with the express goal of simplifying and consolidating the foundations of modern separation logics, but it has evolved over time, and the design and semantic foundations of Iris itself have yet to be fully written down and explained together properly in one place. Here, we attempt to fill this gap, presenting a reasonably complete picture of the latest version of Iris (version 3.1), from first principles and in one coherent narrative.",
    "URL": "https://www.cambridge.org/core/journals/journal-of-functional-programming/article/iris-from-the-ground-up-a-modular-foundation-for-higherorder-concurrent-separation-logic/26301B518CE2C52796BFA12B8BAB5B5F",
    "DOI": "10.1017/S0956796818000151",
    "volume": "28",
    "language": "en-US",
    "_line": "FormalReview.bib:2433"
  },
  "paulson_foundation_2000": {
    "id": "paulson_foundation_2000",
    "type": "article-journal",
    "author": [
      {
        "family": "Paulson",
        "given": "Lawrence C."
      }
    ],
    "title": "The Foundation of a Generic Theorem Prover",
    "container-title": "arXiv:cs/9301105",
    "issued": {
      "date-parts": [
        [
          "2000",
          "10",
          "30"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "abstract": "Isabelle is an interactive theorem prover that supports a variety of logics. It represents rules as propositions (not as functions) and builds proofs by combining rules. These operations constitute a meta-logic (or 'logical framework') in which the object-logics are formalized. Isabelle is now based on higher-order logic &ndash; a precise and well-understood foundation. Examples illustrate use of this meta-logic to formalize logics and proofs. Axioms for first-order logic are shown sound and complete. Backwards proof is formalized by meta-reasoning about object-level entailment. Higher-order logic has several practical advantages over other meta-logics. Many proof techniques are known, such as Huet's higher-order unification procedure.",
    "keywords": "Computer Science - Logic in Computer Science, F.3.1, F.4.1",
    "URLtext": "cs/9301105",
    "URLpretext": "[arXiv:]{.etype}",
    "eprint-type": "arxiv",
    "eprint": "cs/9301105",
    "URL": "http://arxiv.org/abs/cs/9301105",
    "_line": "FormalReview.bib:2449"
  },
  "wenzel_isabelle/isar_2018": {
    "id": "wenzel_isabelle/isar_2018",
    "type": "article-journal",
    "author": [
      {
        "family": "Wenzel",
        "given": "Markus"
      }
    ],
    "title": "The Isabelle/Isar Reference Manual",
    "issued": {
      "date-parts": [
        [
          "2018"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "abstract": "Intelligible semi-automated reasoning (Isar) is a generic approach to readable formal proof documents. It sets out to bridge the semantic gap between any internal notions of proof based on primitive inferences and tactics, and an appropriate level of abstraction for user-level work. The Isar formal proof language has been designed to satisfy quite contradictory requirements, being both &amp;quot;declarative&amp;quot; and immediately &amp;quot;executable&amp;quot;, by virtue of the Isar/VM  interpreter. The Isabelle/Isar system provides an interpreter for the Isar formal proof language. The input may consist either of proper document constructors, or improper auxiliary commands (for diagnostics, exploration etc.). Proof texts consisting of proper elements only admit a purely static reading, thus being intelligible later without requiring dynamic replay that is so typical for traditional proof scripts. Any of the Isabelle/Isar commands may be executed in single-steps, so basically the interpreter has a proof text debugger ..",
    "URL": "https://core.ac.uk/display/22830292",
    "language": "en-US",
    "_line": "FormalReview.bib:2463"
  },
  "ishtiaq_bi_2011": {
    "id": "ishtiaq_bi_2011",
    "type": "article-journal",
    "author": [
      {
        "family": "Ishtiaq",
        "given": "Samin"
      },
      {
        "family": "O'Hearn",
        "given": "Peter W."
      }
    ],
    "title": "BI As an Assertion Language for Mutable Data Structures",
    "container-title": "SIGPLAN Not.",
    "issued": {
      "date-parts": [
        [
          "2011",
          "5"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "issn": "0362-1340",
    "abstract": "Reynolds has developed a logic for reasoning about mutable data structures in which the pre- and postconditions are written in an intuitionistic logic enriched with a spatial form of conjunction. We investigate the approach from the point of view of the logic BI of bunched implications of O'Hearn and Pym. We begin by giving a model in which the law of the excluded middle holds, thus showing that the approach is compatible with classical logic. The relationship between the intuitionistic and classical versions of the system is established by a translation, analogous to a translation from intuitionistic logic into the modal logic S4. We also consider the question of completeness of the axioms. BI's spatial implication is used to express weakest preconditions for object-component assignments, and an axiom for allocating a cons cell is shown to be complete under an interpretation of triples that allows a command to be applied to states with dangling pointers. We make this latter a feature, by incorporating an operation, and axiom, for disposing of memory. Finally, we describe a local character enjoyed by specifications in the logic, and show how this enables a class of frame axioms, which say what parts of the heap don't change, to be inferred automatically.",
    "URL": "http://doi.acm.org/10.1145/1988042.1988050",
    "DOI": "10.1145/1988042.1988050",
    "page": "84-96",
    "page-first": "84",
    "volume": "46",
    "issue": "4",
    "_line": "FormalReview.bib:2474"
  },
  "hutchison_seloger:_2013": {
    "id": "hutchison_seloger:_2013",
    "type": "chapter",
    "author": [
      {
        "family": "Haase",
        "given": "Christoph"
      },
      {
        "family": "Ishtiaq",
        "given": "Samin"
      },
      {
        "family": "Ouaknine",
        "given": "Joël"
      },
      {
        "family": "Parkinson",
        "given": "Matthew J."
      }
    ],
    "editor": [
      {
        "family": "Sharygina",
        "given": "Natasha"
      },
      {
        "family": "Veith",
        "given": "Helmut"
      }
    ],
    "title": "SeLoger: A Tool for Graph-Based Reasoning in Separation Logic",
    "container-title": "Computer Aided Verification",
    "container-title-short": "SeLoger",
    "title-short": "SeLoger",
    "issued": {
      "date-parts": [
        [
          "2013"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "publisher": "Springer Berlin Heidelberg",
    "isbn": "978-3-642-39798-1 978-3-642-39799-8",
    "abstract": "This paper introduces the tool SeLoger, which is a reasoner for satisﬁability and entailment in a fragment of separation logic with pointers and linked lists. SeLoger builds upon and extends graphbased algorithms that have recently been introduced in order to settle both decision problems in polynomial time. Running SeLoger on standard benchmarks shows that the tool outperforms current state-of-theart tools by orders of magnitude.",
    "URL": "http://link.springer.com/10.1007/978-3-642-39799-8_55",
    "DOI": "10.1007/978-3-642-39799-8_55",
    "publisher-place": "Berlin, Heidelberg",
    "page": "790-795",
    "page-first": "790",
    "volume": "8044",
    "language": "en-US",
    "_line": "FormalReview.bib:2490"
  },
  "crick_share_2014": {
    "id": "crick_share_2014",
    "type": "article-journal",
    "author": [
      {
        "family": "Crick",
        "given": "Tom"
      },
      {
        "family": "Hall",
        "given": "Benjamin A."
      },
      {
        "family": "Ishtiaq",
        "given": "Samin"
      },
      {
        "family": "Takeda",
        "given": "Kenji"
      }
    ],
    "title": "\"Share and Enjoy\": Publishing Useful and Usable Scientific Models",
    "container-title": "arXiv:1409.0367 \\[cs\\]",
    "container-title-short": "\"Share and Enjoy\"",
    "title-short": "\"Share and Enjoy\"",
    "issued": {
      "date-parts": [
        [
          "2014",
          "9",
          "1"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "abstract": "The reproduction and replication of reported scientific results is a hot topic within the academic community. The retraction of numerous studies from a wide range of disciplines, from climate science to bioscience, has drawn the focus of many commentators, but there exists a wider socio-cultural problem that pervades the scientific community. Sharing code, data and models often requires extra effort; this is currently seen as a significant overhead that may not be worth the time investment. Automated systems, which allow easy reproduction of results, offer the potential to incentivise a culture change and drive the adoption of new techniques to improve the efficiency of scientific exploration. In this paper, we discuss the value of improved access and sharing of the two key types of results arising from work done in the computational sciences: models and algorithms. We propose the development of an integrated cloud-based system underpinning computational science, linking together software and data repositories, toolchains, workflows and outputs, providing a seamless automated infrastructure for the verification and validation of scientific models and in particular, performance benchmarks.",
    "keywords": "Computer Science - Computational Engineering, Finance, and Science",
    "URLtext": "1409.0367",
    "URLpretext": "[arXiv:]{.etype}",
    "eprint-type": "arxiv",
    "eprint": "1409.0367",
    "URL": "http://arxiv.org/abs/1409.0367",
    "_line": "FormalReview.bib:2512"
  },
  "brockschmidt_t2:_2016": {
    "id": "brockschmidt_t2:_2016",
    "type": "paper-conference",
    "author": [
      {
        "family": "Brockschmidt",
        "given": "Marc"
      },
      {
        "family": "Cook",
        "given": "Byron"
      },
      {
        "family": "Ishtiaq",
        "given": "Samin"
      },
      {
        "family": "Khlaaf",
        "given": "Heidy"
      },
      {
        "family": "Piterman",
        "given": "Nir"
      }
    ],
    "editor": [
      {
        "family": "Chechik",
        "given": "Marsha"
      },
      {
        "family": "Raskin",
        "given": "Jean-François"
      }
    ],
    "title": "T2: Temporal Property Verification",
    "container-title": "Tools and Algorithms for the Construction and Analysis of Systems",
    "container-title-short": "T2",
    "collection-title": "Lecture Notes in Computer Science",
    "title-short": "T2",
    "issued": {
      "date-parts": [
        [
          "2016"
        ]
      ]
    },
    "publisher": "Springer Berlin Heidelberg",
    "isbn": "978-3-662-49674-9",
    "abstract": "We present the open-source tool T2, the first public release from the TERMINATOR project \\[9\\]. T2 has been extended over the past decade to support automatic temporal-logic proving techniques and to handle a general class of user-provided liveness and safety properties. Input can be provided in a native format and in C, via the support of the LLVM compiler framework. We briefly discuss T2’s architecture, its underlying techniques, and conclude with an experimental illustration of its competitiveness and directions for future extensions.",
    "page": "387-393",
    "page-first": "387",
    "language": "en-US",
    "_line": "FormalReview.bib:2527"
  },
  "arias_jscoq:_2017": {
    "id": "arias_jscoq:_2017",
    "type": "article-journal",
    "author": [
      {
        "family": "Arias",
        "given": "Emilio Jesús Gallego"
      },
      {
        "family": "Pin",
        "given": "Benoît"
      },
      {
        "family": "Jouvelot",
        "given": "Pierre"
      }
    ],
    "title": "jsCoq: Towards Hybrid Theorem Proving Interfaces",
    "container-title": "Electronic Proceedings in Theoretical Computer Science",
    "container-title-short": "jsCoq",
    "title-short": "jsCoq",
    "issued": {
      "date-parts": [
        [
          "2017",
          "1",
          "24"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "issn": "2075-2180",
    "abstract": "We describe jsCcoq, a new platform and user environment for the Coq interactive proof assistant. The jsCoq system targets the HTML5-ECMAScript 2015 specification, and it is typically run inside a standards-compliant browser, without the need of external servers or services. Targeting educational use, jsCoq allows the user to start interaction with proof scripts right away, thanks to its self-contained nature. Indeed, a full Coq environment is packed along the proof scripts, easing distribution and installation. Starting to use jsCoq is as easy as clicking on a link. The current release ships more than 10 popular Coq libraries, and supports popular books such as Software Foundations or Certified Programming with Dependent Types. The new target platform has opened up new interaction and display possibilities. It has also fostered the development of some new Coq-related technology. In particular, we have implemented a new serialization-based protocol for interaction with the proof assistant, as well as a new package format for library distribution.",
    "keywords": "Computer Science - Human-Computer Interaction, Computer Science - Logic in Computer Science, Computer Science - Machine Learning, Computer Science - Programming Languages",
    "URLtext": "1701.07125",
    "URLpretext": "[arXiv:]{.etype}",
    "eprint-type": "arxiv",
    "eprint": "1701.07125",
    "URL": "http://arxiv.org/abs/1701.07125",
    "DOI": "10.4204/EPTCS.239.2",
    "page": "15-27",
    "page-first": "15",
    "volume": "239",
    "_line": "FormalReview.bib:2543"
  },
  "kaiser_destruct_nodate": {
    "id": "kaiser_destruct_nodate",
    "type": "webpage",
    "author": [
      {
        "family": "Kaiser",
        "given": "Jan-Oliver"
      },
      {
        "family": "Ziliani",
        "given": "Beta"
      }
    ],
    "title": "A “destruct” Tactic for Mtac2 - POPL 2018",
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "URL": "https://popl18.sigplan.org/event/coqpl-2018-a-destruct-tactic-for-mtac2",
    "_line": "FormalReview.bib:2562"
  },
  "hathhorn_defining_2015": {
    "id": "hathhorn_defining_2015",
    "type": "paper-conference",
    "author": [
      {
        "family": "Hathhorn",
        "given": "Chris"
      },
      {
        "family": "Ellison",
        "given": "Chucky"
      },
      {
        "family": "Roşu",
        "given": "Grigore"
      }
    ],
    "title": "Defining the Undefinedness of C",
    "container-title": "Proceedings of the 36th ACM SIGPLAN Conference on Programming Language Design and Implementation",
    "collection-title": "PLDI '15",
    "issued": {
      "date-parts": [
        [
          "2015"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "publisher": "ACM",
    "isbn": "978-1-4503-3468-6",
    "abstract": "We present a \"negative\" semantics of the C11 language&mdash;a semantics that does not just give meaning to correct programs, but also rejects undefined programs. We investigate undefined behavior in C and discuss the techniques and special considerations needed for formally specifying it. We have used these techniques to modify and extend a semantics of C into one that captures undefined behavior. The amount of semantic infrastructure and effort required to achieve this was unexpectedly high, in the end nearly doubling the size of the original semantics. From our semantics, we have automatically extracted an undefinedness checker, which we evaluate against other popular analysis tools, using our own test suite in addition to a third-party test suite. Our checker is capable of detecting examples of all 77 categories of core language undefinedness appearing in the C11 standard, more than any other tool we considered. Based on this evaluation, we argue that our work is the most comprehensive and complete semantic treatment of undefined behavior in C, and thus of the C language itself.",
    "keywords": "C11, K Framework, Programming language semantics, Undefined behavior",
    "URL": "http://doi.acm.org/10.1145/2737924.2737979",
    "DOI": "10.1145/2737924.2737979",
    "publisher-place": "New York, NY, USA",
    "page": "336-345",
    "page-first": "336",
    "_line": "FormalReview.bib:2570"
  },
  "kubota_foundations_nodate": {
    "id": "kubota_foundations_nodate",
    "type": "webpage",
    "author": [
      {
        "family": "Kubota",
        "given": "Ken"
      }
    ],
    "title": "Foundations of Mathematics – Owl of Minerva Press",
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "URL": "http://owlofminerva.net/foundations-of-mathematics/",
    "language": "en-US",
    "_line": "FormalReview.bib:2588"
  },
  "kubota_foundations_2016": {
    "id": "kubota_foundations_2016",
    "type": "article-journal",
    "author": [
      {
        "family": "Kubota",
        "given": "Ken"
      }
    ],
    "title": "Foundations of Mathematics",
    "issued": {
      "date-parts": [
        [
          "2016"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "URL": "http://www.owlofminerva.net/doi/10.4444/100/111/",
    "DOI": "10.4444/100.111",
    "language": "en-US",
    "_line": "FormalReview.bib:2597"
  },
  "lamport_specifying_nodate": {
    "id": "lamport_specifying_nodate",
    "type": "webpage",
    "author": [
      {
        "family": "Lamport",
        "given": "Leslie"
      }
    ],
    "title": "Specifying Systems",
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "URL": "https://lamport.azurewebsites.net/tla/book.html",
    "_line": "FormalReview.bib:2608"
  },
  "wikibook_latex_nodate": {
    "id": "wikibook_latex_nodate",
    "type": "webpage",
    "author": [
      {
        "family": "",
        "dropping-particle": "wikibook"
      }
    ],
    "title": "LaTeX - Wikibooks, open books for an open world",
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "URL": "https://en.wikibooks.org/wiki/LaTeX",
    "_line": "FormalReview.bib:2616"
  },
  "pakin_comprehensive_nodate": {
    "id": "pakin_comprehensive_nodate",
    "type": "article-journal",
    "author": [
      {
        "family": "Pakin",
        "given": "Scott"
      }
    ],
    "title": "The Comprehensive LaTeX Symbol List",
    "abstract": "This document lists 14283 symbols and the corresponding LATEX commands that produce them. Some of these symbols are guaranteed to be available in every LATEX 2������ system; others require fonts and packages that may not accompany a given distribution and that therefore need to be installed. All of the fonts and packages used to prepare this document—as well as this document itself—are freely available from the Comprehensive TEX Archive Network (http://www.ctan.org/).",
    "page": "358",
    "page-first": "358",
    "language": "en-US",
    "_line": "FormalReview.bib:2624"
  },
  "ebner_metaprogramming_2017": {
    "id": "ebner_metaprogramming_2017",
    "type": "article-journal",
    "author": [
      {
        "family": "Ebner",
        "given": "Gabriel"
      },
      {
        "family": "Ullrich",
        "given": "Sebastian"
      },
      {
        "family": "Roesch",
        "given": "Jared"
      },
      {
        "family": "Avigad",
        "given": "Jeremy"
      },
      {
        "family": "Moura",
        "given": "Leonardo",
        "dropping-particle": "de"
      }
    ],
    "title": "A Metaprogramming Framework for Formal Verification",
    "container-title": "Proc. ACM Program. Lang.",
    "issued": {
      "date-parts": [
        [
          "2017",
          "8"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "issn": "2475-1421",
    "abstract": "We describe the metaprogramming framework currently used in Lean, an interactive theorem prover based on dependent type theory. This framework extends Lean's object language with an API to some of Lean's internal structures and procedures, and provides ways of reflecting object-level expressions into the metalanguage. We provide evidence to show that our implementation is performant, and that it provides a convenient and flexible way of writing not only small-scale interactive tactics, but also more substantial kinds of automation.",
    "keywords": "dependent type theory, metaprogramming, tactic language, theorem proving",
    "URL": "http://doi.acm.org/10.1145/3110278",
    "DOI": "10.1145/3110278",
    "page": "34:1-34:29",
    "page-first": "34",
    "volume": "1",
    "_line": "FormalReview.bib:2633"
  },
  "letouzey_certified_nodate": {
    "id": "letouzey_certified_nodate",
    "type": "webpage",
    "author": [
      {
        "family": "Letouzey",
        "given": "Pierre"
      }
    ],
    "title": "Certified functional programming : Program extraction within Coq proof assistant.ResearchGate",
    "container-title-short": "(8) (PDF) Certified functional programming",
    "title-short": "(8) (PDF) Certified functional programming",
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "abstract": "NOTA: THIS IS THE ENGLISH TRANSLATION OF MY FRENCH PHD MANUSCRIPT. This work concerns the generation of programs which are certified to be correct by construction. These programs are obtained by extracting relevant information from constructive proofs made with the Coq proof assistant. Such a translation, named \"extraction\", of constructive proofs into functional programs is not new, and corresponds to an isomorphism known as Curry-Howard's. An extraction tool has been part of Coq assistant for a long time. But this old extraction tool suffered from several limitations: in particular, some Coq proofs were refused by it, whereas some others led to incorrect programs. In order to overcome these limitations, we built a completely new extraction tool for Coq, including both a new theory and a new implementation. Concerning theory, we developed new correctness proofs for this extraction mechanism. These new proofs are both complex and original. Concerning implementation, we focused on the generation of efficient and realistic code, which can be integrated in large-scale software developments, using modules and interfaces. Finally, we also present several case studies illustrating the capabilities of our new extraction. For example, we describe the certification of a modular library of finite set structures, and the production of programs about real exact arithmetic, starting from a formalization of constructive real analysis. These examples show the progress already achieved, even if the situation is not perfect yet, in particular in the last study.",
    "URL": "https://www.researchgate.net/publication/280790704_Certified_functional_programming_Program_extraction_within_Coq_proof_assistant",
    "language": "en-US",
    "_line": "FormalReview.bib:2650"
  },
  "kang_crellvm:_2018": {
    "id": "kang_crellvm:_2018",
    "type": "paper-conference",
    "author": [
      {
        "family": "Kang",
        "given": "Jeehoon"
      },
      {
        "family": "Kim",
        "given": "Yoonseung"
      },
      {
        "family": "Song",
        "given": "Youngju"
      },
      {
        "family": "Lee",
        "given": "Juneyoung"
      },
      {
        "family": "Park",
        "given": "Sanghoon"
      },
      {
        "family": "Shin",
        "given": "Mark Dongyeon"
      },
      {
        "family": "Kim",
        "given": "Yonghyun"
      },
      {
        "family": "Cho",
        "given": "Sungkeun"
      },
      {
        "family": "Choi",
        "given": "Joonwon"
      },
      {
        "family": "Hur",
        "given": "Chung-Kil"
      },
      {
        "family": "Yi",
        "given": "Kwangkeun"
      }
    ],
    "title": "Crellvm: Verified Credible Compilation for LLVM",
    "container-title": "Proceedings of the 39th ACM SIGPLAN Conference on Programming Language Design and Implementation",
    "container-title-short": "Crellvm",
    "collection-title": "PLDI 2018",
    "title-short": "Crellvm",
    "issued": {
      "date-parts": [
        [
          "2018"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "publisher": "ACM",
    "isbn": "978-1-4503-5698-5",
    "abstract": "Production compilers such as GCC and LLVM are large complex software systems, for which achieving a high level of reliability is hard. Although testing is an effective method for finding bugs, it alone cannot guarantee a high level of reliability. To provide a higher level of reliability, many approaches that examine compilers' internal logics have been proposed. However, none of them have been successfully applied to major optimizations of production compilers. This paper presents Crellvm: a verified credible compilation framework for LLVM, which can be used as a systematic way of providing a high level of reliability for major optimizations in LLVM. Specifically, we augment an LLVM optimizer to generate translation results together with their correctness proofs, which can then be checked by a proof checker formally verified in Coq. As case studies, we applied our approach to two major optimizations of LLVM: register promotion mem2reg and global value numbering gvn, having found four new miscompilation bugs (two in each).",
    "keywords": "compiler verification, Coq, credible compilation, LLVM, relational Hoare logic, translation validation",
    "URL": "http://doi.acm.org/10.1145/3192366.3192377",
    "DOI": "10.1145/3192366.3192377",
    "publisher-place": "New York, NY, USA",
    "page": "631-645",
    "page-first": "631",
    "_line": "FormalReview.bib:2662"
  },
  "luo_extended_nodate": {
    "id": "luo_extended_nodate",
    "type": "webpage",
    "author": [
      {
        "family": "Luo",
        "given": "Zhaohui"
      }
    ],
    "title": "An Extended Calculus of Constructions",
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "URL": "http://www.lfcs.inf.ed.ac.uk/reports/90/ECS-LFCS-90-118/",
    "_line": "FormalReview.bib:2681"
  },
  "patterson_compositional_nodate": {
    "id": "patterson_compositional_nodate",
    "type": "webpage",
    "author": [
      {
        "family": "Patterson",
        "given": "Daniel"
      },
      {
        "family": "Ahmed",
        "given": "Amal"
      }
    ],
    "title": "On Compositional Compiler Correctness and Fully Abstract Compilation - POPL 2018",
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "URL": "https://popl18.sigplan.org/event/prisc-2018-on-compositional-compiler-correctness-and-fully-abstract-compilation",
    "_line": "FormalReview.bib:2689"
  },
  "patterson_compositional_nodate-1": {
    "id": "patterson_compositional_nodate-1",
    "type": "article-journal",
    "author": [
      {
        "family": "Patterson",
        "given": "Daniel"
      },
      {
        "family": "Ahmed",
        "given": "Amal"
      }
    ],
    "title": "On Compositional Compiler Correctness and Fully Abstract Compilation",
    "URL": "https://popl18.sigplan.org/event/prisc-2018-on-compositional-compiler-correctness-and-fully-abstract-compilation",
    "page": "3",
    "page-first": "3",
    "language": "en-US",
    "_line": "FormalReview.bib:2697"
  },
  "gasser_building_1988": {
    "id": "gasser_building_1988",
    "type": "book",
    "author": [
      {
        "family": "Gasser",
        "given": "Morrie"
      }
    ],
    "title": "Building a secure computer system",
    "issued": {
      "date-parts": [
        [
          "1988"
        ]
      ]
    },
    "publisher": "Van Nostrand Reinhold Co",
    "number-of-pages": "288",
    "isbn": "978-0-442-23022-7",
    "keywords": "Computer security, System design",
    "publisher-place": "New York",
    "_line": "FormalReview.bib:2706"
  },
  "costan_sanctum:_2016": {
    "id": "costan_sanctum:_2016",
    "type": "paper-conference",
    "author": [
      {
        "family": "Costan",
        "given": "Victor"
      },
      {
        "family": "Lebedev",
        "given": "Ilia"
      },
      {
        "family": "Devadas",
        "given": "Srinivas"
      }
    ],
    "title": "Sanctum: Minimal Hardware Extensions for Strong Software Isolation",
    "container-title-short": "Sanctum",
    "title-short": "Sanctum",
    "event-title": "25th &lcurly;USENIX&rcurly; Security Symposium (&lcurly;USENIX&rcurly; Security 16)",
    "issued": {
      "date-parts": [
        [
          "2016"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "URL": "https://www.usenix.org/conference/usenixsecurity16/technical-sessions/presentation/costan",
    "page": "857-874",
    "page-first": "857",
    "language": "en-US",
    "_line": "FormalReview.bib:2718"
  },
  "costan_secure_2017": {
    "id": "costan_secure_2017",
    "type": "article-journal",
    "author": [
      {
        "family": "Costan",
        "given": "Victor"
      },
      {
        "family": "Lebedev",
        "given": "Ilia"
      },
      {
        "family": "Devadas",
        "given": "Srinivas"
      }
    ],
    "title": "Secure Processors Part I: Background, Taxonomy for Secure Enclaves and Intel SGX Architecture",
    "container-title": "Foundations and Trends® in Electronic Design Automation",
    "container-title-short": "Secure Processors Part I",
    "title-short": "Secure Processors Part I",
    "issued": {
      "date-parts": [
        [
          "2017"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "issn": "1551-3939, 1551-3947",
    "URL": "http://www.nowpublishers.com/article/Details/EDA-051",
    "DOI": "10.1561/1000000051",
    "page": "1-248",
    "page-first": "1",
    "volume": "11",
    "issue": "1",
    "language": "en-US",
    "_line": "FormalReview.bib:2731"
  },
  "costan_secure_2017-1": {
    "id": "costan_secure_2017-1",
    "type": "article-journal",
    "author": [
      {
        "family": "Costan",
        "given": "Victor"
      },
      {
        "family": "Lebedev",
        "given": "Ilia"
      },
      {
        "family": "Devadas",
        "given": "Srinivas"
      }
    ],
    "title": "Secure Processors Part II: Intel SGX Security Analysis and MIT Sanctum Architecture",
    "container-title": "Foundations and Trends® in Electronic Design Automation",
    "container-title-short": "Secure Processors Part II",
    "title-short": "Secure Processors Part II",
    "issued": {
      "date-parts": [
        [
          "2017"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "issn": "1551-3939, 1551-3947",
    "URL": "http://www.nowpublishers.com/article/Details/EDA-052",
    "DOI": "10.1561/1000000052",
    "page": "249-361",
    "page-first": "249",
    "volume": "11",
    "issue": "3",
    "language": "en-US",
    "_line": "FormalReview.bib:2748"
  },
  "pottier_menhir_nodate": {
    "id": "pottier_menhir_nodate",
    "type": "webpage",
    "author": [
      {
        "family": "Pottier",
        "given": "Francois"
      },
      {
        "family": "REgis-Gianas",
        "given": "Yan"
      }
    ],
    "title": "Menhir Reference Manual (version 20181113)",
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "URL": "http://gallium.inria.fr/~fpottier/menhir/manual.html",
    "_line": "FormalReview.bib:2765"
  },
  "jacobs_verifast/verifast:_2019": {
    "id": "jacobs_verifast/verifast:_2019",
    "type": "book",
    "author": [
      {
        "family": "Jacobs",
        "given": "Bart"
      }
    ],
    "title": "verifast/verifast: Research prototype tool for modular formal verification of C and Java programs",
    "container-title-short": "Research prototype tool for modular formal verification of C and Java programs",
    "title-short": "Research prototype tool for modular formal verification of C and Java programs",
    "issued": {
      "date-parts": [
        [
          "2019",
          "1",
          "25"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "publisher": "verifast",
    "URL": "https://github.com/verifast/verifast",
    "note": "original-date: 2013-11-19T08:57:02Z",
    "_line": "FormalReview.bib:2773"
  },
  "jacobs_featherweight_2015": {
    "id": "jacobs_featherweight_2015",
    "type": "article-journal",
    "author": [
      {
        "family": "Jacobs",
        "given": "Bart"
      },
      {
        "family": "Vogels",
        "given": "Frédéric"
      },
      {
        "family": "Piessens",
        "given": "Frank"
      }
    ],
    "title": "Featherweight VeriFast",
    "container-title": "Logical Methods in Computer Science",
    "issued": {
      "date-parts": [
        [
          "2015",
          "9",
          "22"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "issn": "18605974",
    "abstract": "VeriFast is a leading research prototype tool for the sound modular verification of safety and correctness properties of single-threaded and multithreaded C and Java programs. It has been used as a vehicle for exploration and validation of novel program verification techniques and for industrial case studies; it has served well at a number of program verification competitions; and it has been used for teaching by multiple teachers independent of the authors. However, until now, while VeriFast's operation has been described informally in a number of publications, and specific verification techniques have been formalized, a clear and precise exposition of how VeriFast works has not yet appeared. In this article we present for the first time a formal definition and soundness proof of a core subset of the VeriFast program verification approach. The exposition aims to be both accessible and rigorous: the text is based on lecture notes for a graduate course on program verification, and it is backed by an executable machine-readable definition and machine-checked soundness proof in Coq.",
    "keywords": "Computer Science - Logic in Computer Science",
    "URLtext": "1507.07697",
    "URLpretext": "[arXiv:]{.etype}",
    "eprint-type": "arxiv",
    "eprint": "1507.07697",
    "URL": "http://arxiv.org/abs/1507.07697",
    "DOI": "10.2168/LMCS-11(3:19)2015",
    "volume": "11",
    "issue": "3",
    "_line": "FormalReview.bib:2785"
  },
  "jacobs_verifast_2008": {
    "id": "jacobs_verifast_2008",
    "type": "report",
    "author": [
      {
        "family": "Jacobs",
        "given": "Bart"
      },
      {
        "family": "Piessens",
        "given": "Frank"
      }
    ],
    "title": "The VeriFast program verifier",
    "issued": {
      "date-parts": [
        [
          "2008"
        ]
      ]
    },
    "abstract": "This note describes a separation-logic-based approach for the spec-ification and verification of safety properties of pointer-manipulating imperative programs. We describe the approach for the C language. The safety properties to be verified are specified as annotations in the source code, in the form of function preconditions and post-conditions expressed as separation logic assertions. To enable rich specifications, the user may include additional annotations that de-fine inductive datatypes, primitive recursive pure functions over these datatypes, and abstract predicates (i.e. named, parameterized assertions). A restricted form of existential quantification is sup-ported in assertions in the form of pattern matching. Verification is based on forward symbolic execution, where memory is represented as a separate conjunction of points-to as-sertions and abstract predicate assertions, and data values are rep-",
    "_line": "FormalReview.bib:2803"
  },
  "jacobs_verifast_2017": {
    "id": "jacobs_verifast_2017",
    "type": "article-journal",
    "author": [
      {
        "family": "Jacobs",
        "given": "Bart"
      },
      {
        "family": "Smans",
        "given": "Jan"
      },
      {
        "family": "Piessens",
        "given": "Frank"
      }
    ],
    "title": "The VeriFast Program Veriﬁer: A Tutorial",
    "issued": {
      "date-parts": [
        [
          "2017",
          "11",
          "28"
        ]
      ]
    },
    "page": "102",
    "page-first": "102",
    "language": "en-US",
    "_line": "FormalReview.bib:2811"
  },
  "leroy_ocaml_nodate": {
    "id": "leroy_ocaml_nodate",
    "type": "webpage",
    "author": [
      {
        "family": "Leroy",
        "given": "Xavier"
      }
    ],
    "title": "OCaml Home Page",
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "URL": "https://ocaml.org/",
    "_line": "FormalReview.bib:2820"
  },
  "minsky_real_nodate": {
    "id": "minsky_real_nodate",
    "type": "webpage",
    "author": [
      {
        "family": "Minsky",
        "given": "Yaron"
      },
      {
        "family": "Madhavapeddy",
        "given": "Anil"
      },
      {
        "family": "Hickey",
        "given": "Jason"
      }
    ],
    "title": "Real World OCaml",
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "URL": "http://dev.realworldocaml.org/",
    "_line": "FormalReview.bib:2828"
  },
  "lampson_abcds_2001": {
    "id": "lampson_abcds_2001",
    "type": "paper-conference",
    "author": [
      {
        "family": "Lampson",
        "given": "Butler"
      }
    ],
    "title": "The ABCD's of Paxos",
    "container-title": "Proceedings of the Twentieth Annual ACM Symposium on Principles of Distributed Computing",
    "collection-title": "PODC '01",
    "issued": {
      "date-parts": [
        [
          "2001"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "publisher": "ACM",
    "isbn": "978-1-58113-383-7",
    "abstract": "We explain how consensus is used to implement replicated state machines, the general mechanism for fault-tolerance. We describe an abstract version of Lamport's Paxos algorithm for asynchronous consensus. Then we derive the Byzantine, classic, and disk versions of Paxos from the abstract one, show how they are related to each other, and discuss the safety, liveness, and performance of each one.",
    "URL": "http://doi.acm.org/10.1145/383962.383969",
    "DOI": "10.1145/383962.383969",
    "publisher-place": "New York, NY, USA",
    "page": "13-",
    "page-first": "13",
    "_line": "FormalReview.bib:2836"
  },
  "van_renesse_paxos_2015": {
    "id": "van_renesse_paxos_2015",
    "type": "article-journal",
    "author": [
      {
        "family": "Van Renesse",
        "given": "Robbert"
      },
      {
        "family": "Altinbuken",
        "given": "Deniz"
      }
    ],
    "title": "Paxos Made Moderately Complex",
    "container-title": "ACM Comput. Surv.",
    "issued": {
      "date-parts": [
        [
          "2015",
          "2"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "issn": "0360-0300",
    "abstract": "This article explains the full reconfigurable multidecree Paxos (or multi-Paxos) protocol. Paxos is by no means a simple protocol, even though it is based on relatively simple invariants. We provide pseudocode and explain it guided by invariants. We initially avoid optimizations that complicate comprehension. Next we discuss liveness, list various optimizations that make the protocol practical, and present variants of the protocol.",
    "keywords": "consensus, Replicated state machines, voting",
    "URL": "http://doi.acm.org/10.1145/2673577",
    "DOI": "10.1145/2673577",
    "page": "42:1-42:36",
    "page-first": "42",
    "volume": "47",
    "issue": "3",
    "_line": "FormalReview.bib:2853"
  },
  "hutchison_improving_2012": {
    "id": "hutchison_improving_2012",
    "type": "chapter",
    "author": [
      {
        "family": "Boldo",
        "given": "Sylvie"
      },
      {
        "family": "Lelay",
        "given": "Catherine"
      },
      {
        "family": "Melquiond",
        "given": "Guillaume"
      }
    ],
    "editor": [
      {
        "family": "Hawblitzel",
        "given": "Chris"
      },
      {
        "family": "Miller",
        "given": "Dale"
      }
    ],
    "title": "Improving Real Analysis in Coq: A User-Friendly Approach to Integrals and Derivatives",
    "container-title": "Certified Programs and Proofs",
    "container-title-short": "Improving Real Analysis in Coq",
    "title-short": "Improving Real Analysis in Coq",
    "issued": {
      "date-parts": [
        [
          "2012"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "publisher": "Springer Berlin Heidelberg",
    "isbn": "978-3-642-35307-9 978-3-642-35308-6",
    "abstract": "Veriﬁcation of numerical analysis programs requires dealing with derivatives and integrals. High conﬁdence in this process can be achieved using a formal proof checker, such as Coq. Its standard library provides an axiomatization of real numbers and various lemmas about real analysis, which may be used for this purpose. Unfortunately, its deﬁnitions of derivative and integral are unpractical as they are partial functions that demand a proof term. This proof term makes the handling of mathematical formulas cumbersome and does not conform to traditional analysis. Other proof assistants usually do not suﬀer from this issue; for instance, they may rely on Hilbert’s epsilon to get total operators. In this paper, we propose a way to deﬁne total operators for derivative and integral without having to extend Coq’s standard axiomatization of real numbers. We proved the compatibility of our deﬁnitions with the standard library’s in order to leverage existing results. We also greatly improved automation for real analysis proofs that use Coq standard deﬁnitions. We exercised our approach on lemmas involving iterated partial derivatives and diﬀerentiation under the integral sign, that were missing from the formal proof of a numerical program solving the wave equation.",
    "URL": "http://link.springer.com/10.1007/978-3-642-35308-6_22",
    "DOI": "10.1007/978-3-642-35308-6_22",
    "publisher-place": "Berlin, Heidelberg",
    "page": "289-304",
    "page-first": "289",
    "volume": "7679",
    "language": "en-US",
    "_line": "FormalReview.bib:2870"
  },
  "martin-dorel_proving_2016": {
    "id": "martin-dorel_proving_2016",
    "type": "article-journal",
    "author": [
      {
        "family": "Martin-Dorel",
        "given": "Érik"
      },
      {
        "family": "Melquiond",
        "given": "Guillaume"
      }
    ],
    "title": "Proving Tight Bounds on Univariate Expressions with Elementary Functions in Coq",
    "container-title": "J Autom Reasoning",
    "issued": {
      "date-parts": [
        [
          "2016",
          "10",
          "1"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "issn": "1573-0670",
    "abstract": "The verification of floating-point mathematical libraries requires computing numerical bounds on approximation errors. Due to the tightness of these bounds and the peculiar structure of approximation errors, such a verification is out of the reach of generic tools such as computer algebra systems. In fact, the inherent difficulty of computing such bounds often mandates a formal proof of them. In this paper, we present a tactic for the Coq proof assistant that is designed to automatically and formally prove bounds on univariate expressions. It is based on a formalization of floating-point and interval arithmetic, associated with an on-the-fly computation of Taylor expansions. All the computations are performed inside Coq’s logic, in a reflexive setting. This paper also compares our tactic with various existing tools on a large set of examples.",
    "keywords": "Coq proof assistant, Decision procedure, Floating-point arithmetic, Formal proof, Interval arithmetic, Nonlinear arithmetic",
    "URL": "https://doi.org/10.1007/s10817-015-9350-4",
    "DOI": "10.1007/s10817-015-9350-4",
    "page": "187-217",
    "page-first": "187",
    "volume": "57",
    "issue": "3",
    "language": "en-US",
    "_line": "FormalReview.bib:2892"
  },
  "boldo_round-off_2017": {
    "id": "boldo_round-off_2017",
    "type": "paper-conference",
    "author": [
      {
        "family": "Boldo",
        "given": "Sylvie"
      },
      {
        "family": "Faissole",
        "given": "Florian"
      },
      {
        "family": "Chapoutot",
        "given": "Alexandre"
      }
    ],
    "title": "Round-off Error Analysis of Explicit One-Step Numerical Integration Methods",
    "container-title": "24th IEEE Symposium on Computer Arithmetic",
    "issued": {
      "date-parts": [
        [
          "2017",
          "7"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "abstract": "Ordinary differential equations are ubiquitous in scientific computing. Solving exactly these equations is usually not possible, except for special cases, hence the use of numerical schemes to get a discretized solution. We are interested in such numerical integration methods, for instance Euler's method or the Runge-Kutta methods. As they are implemented using floating-point arithmetic, round-off errors occur. In order to guarantee their accuracy, we aim at providing bounds on the round-off errors of explicit one-step numerical integration methods. Our methodology is to apply a fine-grained analysis to these numerical algorithms. Our originality is that our floating-point analysis takes advantage of the linear stability of the scheme, a mathematical property that vouches the scheme is well-behaved.",
    "keywords": "Floating-Point, Numerical Integration, Ordinary Differential Equation, Round-Off Error, Runge-Kutta Methods, Stability",
    "URL": "https://hal.archives-ouvertes.fr/hal-01581794",
    "DOI": "10.1109/ARITH.2017.22",
    "publisher-place": "London, United Kingdom",
    "_line": "FormalReview.bib:2910"
  },
  "boldo_round-off_2018": {
    "id": "boldo_round-off_2018",
    "type": "manuscript",
    "author": [
      {
        "family": "Boldo",
        "given": "Sylvie"
      },
      {
        "family": "Faissole",
        "given": "Florian"
      },
      {
        "family": "Chapoutot",
        "given": "Alexandre"
      }
    ],
    "title": "Round-off error and exceptional behavior analysis of explicit Runge-Kutta methods",
    "issued": {
      "date-parts": [
        [
          "2018",
          "9"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "abstract": "Numerical integration schemes are mandatory to understand complex behaviors of dynamical systems described by ordinary differential equations. Implementation of these numerical methods involve floating-point computations and propagation of round-off errors. This paper presents a new fine-grained analysis of round-off errors in explicit Runge-Kutta integration methods, taking into account exceptional behaviors, such as underflow and overflow. Linear stability properties play a central role in the proposed approach. For a large class of Runge-Kutta methods applied on linear problems, a tight bound of the round-off errors is provided. A simple test is defined and ensures the absence of underflow and a tighter round-off error bound. The absence of overflow is guaranteed as linear stability properties imply that (computed) solutions are non-increasing.",
    "keywords": "Linear stability, Numerical integration, Overflow, Round-off error, Runge-Kutta method, Underflow",
    "URL": "https://hal.archives-ouvertes.fr/hal-01883843",
    "_line": "FormalReview.bib:2924"
  },
  "immler_verified_2018": {
    "id": "immler_verified_2018",
    "type": "article-journal",
    "author": [
      {
        "family": "Immler",
        "given": "Fabian"
      }
    ],
    "title": "A Verified ODE Solver and the Lorenz Attractor",
    "container-title": "J Autom Reasoning",
    "issued": {
      "date-parts": [
        [
          "2018",
          "6",
          "1"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "issn": "1573-0670",
    "abstract": "A rigorous numerical algorithm, formally verified with Isabelle/HOL, is used to certify the computations that Tucker used to prove chaos for the Lorenz attractor. The verification is based on a formalization of a diverse variety of mathematics and algorithms. Formalized mathematics include ordinary differential equations and Poincaré maps. Algorithms include low level approximation schemes based on Runge–Kutta methods and affine arithmetic. On a high level, reachability analysis is guided by static hybridization and adaptive step-size control and splitting. The algorithms are systematically refined towards an implementation that can be executed on Tucker’s original input data.",
    "keywords": "Isabelle/HOL, Lorenz attractor, Ordinary differential equation, Poincaré map, Rigorous numerics",
    "URL": "https://doi.org/10.1007/s10817-017-9448-y",
    "DOI": "10.1007/s10817-017-9448-y",
    "page": "73-111",
    "page-first": "73",
    "volume": "61",
    "issue": "1",
    "language": "en-US",
    "_line": "FormalReview.bib:2935"
  },
  "boldo_coquelicot:_2013": {
    "id": "boldo_coquelicot:_2013",
    "type": "no-type",
    "author": [
      {
        "family": "Boldo",
        "given": "Sylvie"
      },
      {
        "family": "Lelay",
        "given": "Catherine"
      },
      {
        "family": "Melquiond",
        "given": "Guillaume"
      }
    ],
    "title": "Coquelicot: A User-Friendly Library of Real Analysis for Coq",
    "container-title-short": "Coquelicot",
    "title-short": "Coquelicot",
    "issued": {
      "date-parts": [
        [
          "2013",
          "9",
          "10"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "abstract": "Real analysis is pervasive to many applications, if only because it is a suitable tool for modeling physical or socio-economical systems. As such, its support is warranted in proof assistants, so that the users have a way to formally verify mathematical theorems and correctness of critical systems. The Coq system comes with an axiomatization of standard real numbers and a library of theorems on real analysis. Unfortunately, this standard library is lacking some widely used results. For instance, power series are not developed further than their definition. Moreover, the definitions of integrals and derivatives are based on dependent types, which make them especially cumbersome to use in practice. To palliate these inadequacies, we have designed a user-friendly library: Coquelicot. An easier way of writing formulas and theorem statements is achieved by relying on total functions in place of dependent types for limits, derivatives, integrals, power series, and so on. To help with the proof process, the library comes with a comprehensive set of theorems that cover not only these notions, but also some extensions such as parametric integrals, two-dimensional differentiability, asymptotic behaviors. It also offers some automations for performing differentiability proofs. Moreover, Coquelicot is a conservative extension of Coq's standard library and we provide correspondence theorems between the two libraries. We have exercised the library on several use cases: in an exam at university entry level, for the definitions and properties of Bessel functions, and for the solution of the one-dimensional wave equation.",
    "URL": "https://hal.inria.fr/hal-00860648/document",
    "language": "en-US",
    "_line": "FormalReview.bib:2953"
  },
  "boldo_formalization_2016": {
    "id": "boldo_formalization_2016",
    "type": "article-journal",
    "author": [
      {
        "family": "Boldo",
        "given": "Sylvie"
      },
      {
        "family": "Lelay",
        "given": "Catherine"
      },
      {
        "family": "Melquiond",
        "given": "Guillaume"
      }
    ],
    "title": "Formalization of Real Analysis: A Survey of Proof Assistants and Libraries",
    "container-title": "Mathematical Structures in Computer Science",
    "container-title-short": "Formalization of Real Analysis",
    "title-short": "Formalization of Real Analysis",
    "issued": {
      "date-parts": [
        [
          "2016",
          "10"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "abstract": "In the recent years, numerous proof systems have improved enough to be used for formally verifying non-trivial mathematical results. They, however, have different purposes and it is not always easy to choose which one is adapted to undertake a formalization effort. In this survey, we focus on properties related to real analysis: real numbers, arithmetic operators, limits, differentiability, integrability, and so on. We have chosen to look into the formalizations provided in standard by the following systems: Coq, HOL4, HOL Light, Isabelle/HOL, Mizar, ProofPower-HOL, and PVS. We have also accounted for large developments that play a similar role or extend standard libraries: ACL2(r) for ACL2, C-CoRN/MathClasses for Coq, and the NASA PVS library. This survey presents how real numbers have been defined in these various provers and how the notions of real analysis described above have been formalized. We also look at the methods of automation these systems provide for real analysis.",
    "URL": "https://hal.inria.fr/hal-00806920/document",
    "DOI": "10.1017/S0960129514000437",
    "page": "1196-1233",
    "page-first": "1196",
    "volume": "26",
    "issue": "7",
    "language": "en-US",
    "_line": "FormalReview.bib:2965"
  },
  "holzl_type_2013": {
    "id": "holzl_type_2013",
    "type": "paper-conference",
    "author": [
      {
        "family": "Hölzl",
        "given": "Johannes"
      },
      {
        "family": "Immler",
        "given": "Fabian"
      },
      {
        "family": "Huffman",
        "given": "Brian"
      }
    ],
    "editor": [
      {
        "family": "Blazy",
        "given": "Sandrine"
      },
      {
        "family": "Paulin-Mohring",
        "given": "Christine"
      },
      {
        "family": "Pichardie",
        "given": "David"
      }
    ],
    "title": "Type Classes and Filters for Mathematical Analysis in Isabelle/HOL",
    "container-title": "Interactive Theorem Proving",
    "collection-title": "Lecture Notes in Computer Science",
    "issued": {
      "date-parts": [
        [
          "2013"
        ]
      ]
    },
    "publisher": "Springer Berlin Heidelberg",
    "isbn": "978-3-642-39634-2",
    "abstract": "The theory of analysis in Isabelle/HOL derives from earlier formalizations that were limited to specific concrete types: ℝ, ℂ and ℝ n . Isabelle’s new analysis theory unifies and generalizes these earlier efforts. The improvements are centered on two primary contributions: a generic theory of limits based on filters, and a new hierarchy of type classes that includes various topological, metric, vector, and algebraic spaces. These let us apply many results in multivariate analysis to types which are not Euclidean spaces, such as the extended real numbers, bounded continuous functions, or finite maps.",
    "keywords": "Euclidean vector spaces, Filters, Isabelle/HOL, Limits, Mathematical analysis, Topology, Type classes",
    "page": "279-294",
    "page-first": "279",
    "language": "en-US",
    "_line": "FormalReview.bib:2982"
  },
  "krebbers_type_2011": {
    "id": "krebbers_type_2011",
    "type": "article-journal",
    "author": [
      {
        "family": "Krebbers",
        "given": "Robbert"
      },
      {
        "family": "Spitters",
        "given": "Bas"
      }
    ],
    "title": "Type classes for efficient exact real arithmetic in Coq",
    "container-title": "arXiv:1106.3448 \\[cs, math\\]",
    "issued": {
      "date-parts": [
        [
          "2011",
          "6",
          "17"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "abstract": "Floating point operations are fast, but require continuous effort on the part of the user in order to ensure that the results are correct. This burden can be shifted away from the user by providing a library of exact analysis in which the computer handles the error estimates. Previously, we \\[Krebbers/Spitters 2011\\] provided a fast implementation of the exact real numbers in the Coq proof assistant. Our implementation improved on an earlier implementation by O'Connor by using type classes to describe an abstract specification of the underlying dense set from which the real numbers are built. In particular, we used dyadic rationals built from Coq's machine integers to obtain a 100 times speed up of the basic operations already. This article is a substantially expanded version of \\[Krebbers/Spitters 2011\\] in which the implementation is extended in the various ways. First, we implement and verify the sine and cosine function. Secondly, we create an additional implementation of the dense set based on Coq's fast rational numbers. Thirdly, we extend the hierarchy to capture order on undecidable structures, while it was limited to decidable structures before. This hierarchy, based on type classes, allows us to share theory on the naturals, integers, rationals, dyadics, and reals in a convenient way. Finally, we obtain another dramatic speed-up by avoiding evaluation of termination proofs at runtime.",
    "keywords": "Computer Science - Logic in Computer Science, D.2.4, F.4.1, G.1, Mathematics - Numerical Analysis",
    "URLtext": "1106.3448",
    "URLpretext": "[arXiv:]{.etype}",
    "eprint-type": "arxiv",
    "eprint": "1106.3448",
    "URL": "http://arxiv.org/abs/1106.3448",
    "DOI": "10.2168/LMCS-9(1:01)2013",
    "_line": "FormalReview.bib:2998"
  },
  "shrobe_trust-management_2009": {
    "id": "shrobe_trust-management_2009",
    "type": "article-journal",
    "author": [
      {
        "family": "Shrobe",
        "given": "Howard"
      },
      {
        "family": "DeHon",
        "given": "Andre"
      },
      {
        "family": "Knight",
        "given": "Thomas"
      }
    ],
    "title": "Trust-Management, Intrusion-Tolerance, Accountability, and Reconstitution Architecture (TIARA)",
    "issued": {
      "date-parts": [
        [
          "2009",
          "12"
        ]
      ]
    },
    "abstract": "This report describes the Trust-management, Intrusion-tolerance, Accountability, and Reconstitution Architecture (TIARA) system,\na broad design effort including novel computer architecture, operating system and application middleware. TIARA illustrates that a\nhighly secure computer system can be designed without sacrificing performance. TIARA involves three major sub-efforts: A\nhardware security tagged architecture (STA) that tags each word of the computer’s memory with metadata such as the data type and\ncompartment of the data. The STA hardware enforces access rules controlling which principals are allowed to perform which\noperations on which data. This allows the construction of a novel Zero-kernel Operating System (ZKOS) that has no single all\nprivileged kernel and that provides strong guarantees against penetration. Finally TIARA provides a level of application middleware\nthat enforces architectural level constraints and maintains the provenance of application data. All common exploits are preventable\nby the TIARA architecture and this incurs only a minor increase in chip area.",
    "URL": "https://apps.dtic.mil/dtic/tr/fulltext/u2/a511350.pdf",
    "page": "133",
    "page-first": "133",
    "language": "en-US",
    "_line": "FormalReview.bib:3013"
  },
  "azevedo_de_amorim_verified_2014": {
    "id": "azevedo_de_amorim_verified_2014",
    "type": "paper-conference",
    "author": [
      {
        "family": "Azevedo de Amorim",
        "given": "Arthur"
      },
      {
        "family": "Collins",
        "given": "Nathan"
      },
      {
        "family": "DeHon",
        "given": "André"
      },
      {
        "family": "Demange",
        "given": "Delphine"
      },
      {
        "family": "Hriţcu",
        "given": "Cătălin"
      },
      {
        "family": "Pichardie",
        "given": "David"
      },
      {
        "family": "Pierce",
        "given": "Benjamin C."
      },
      {
        "family": "Pollack",
        "given": "Randy"
      },
      {
        "family": "Tolmach",
        "given": "Andrew"
      }
    ],
    "title": "A Verified Information-flow Architecture",
    "container-title": "Proceedings of the 41st ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages",
    "collection-title": "POPL '14",
    "issued": {
      "date-parts": [
        [
          "2014"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "publisher": "ACM",
    "isbn": "978-1-4503-2544-8",
    "abstract": "SAFE is a clean-slate design for a highly secure computer system, with pervasive mechanisms for tracking and limiting information flows. At the lowest level, the SAFE hardware supports fine-grained programmable tags, with efficient and flexible propagation and combination of tags as instructions are executed. The operating system virtualizes these generic facilities to present an information-flow abstract machine that allows user programs to label sensitive data with rich confidentiality policies. We present a formal, machine-checked model of the key hardware and software mechanisms used to control information flow in SAFE and an end-to-end proof of noninterference for this model.",
    "keywords": "clean-slate design, formal verification, information-flow control, refinement, security, tagged architecture",
    "URL": "http://doi.acm.org/10.1145/2535838.2535839",
    "DOI": "10.1145/2535838.2535839",
    "publisher-place": "New York, NY, USA",
    "page": "165-178",
    "page-first": "165",
    "_line": "FormalReview.bib:3033"
  },
  "amorim_verified_2013": {
    "id": "amorim_verified_2013",
    "type": "book",
    "author": [
      {
        "family": "Amorim",
        "given": "Arthur Azevedo de"
      },
      {
        "family": "Collins",
        "given": "Nathan"
      },
      {
        "family": "DeHon",
        "given": "André"
      },
      {
        "family": "Demange",
        "given": "Delphine"
      },
      {
        "family": "Hritcu",
        "given": "Cătălin"
      },
      {
        "family": "Pichardie",
        "given": "David"
      },
      {
        "family": "Pierce",
        "given": "Benjamin C."
      },
      {
        "family": "Pollack",
        "given": "Randy"
      },
      {
        "family": "Tolmach",
        "given": "Andrew"
      }
    ],
    "title": "A Verified Information-Flow Architecture (Long version)",
    "issued": {
      "date-parts": [
        [
          "2013"
        ]
      ]
    },
    "abstract": "SAFE is a clean-slate effort to build a highly secure computer system, including pervasive mechanisms for tracking and limiting information flows. At the lowest level, the SAFE hardware supports fine-grained programmable tags, with efficient and flexible propagation and combination of tags as instructions are executed. The operating system virtualizes these generic facilities to present an information-flow abstract machine, on which user programs can label sensitive data with rich confidentiality and integrity policies. We present a formal, machine-checked model of the key information-flow mechanisms of the SAFE hardware and software, together with an end-to-end proof of noninterference for this model.",
    "_line": "FormalReview.bib:3051"
  },
  "andrew_oracle_2008": {
    "id": "andrew_oracle_2008",
    "type": "book",
    "author": [
      {
        "family": "Andrew",
        "given": "Advisor"
      }
    ],
    "title": "Oracle Semantics Aquinas Hobor",
    "issued": {
      "date-parts": [
        [
          "2008"
        ]
      ]
    },
    "abstract": "We define a Concurrent Separation Logic with first-class locks and threads for the C language, and prove its soundness in Coq with re-spect to a compilable operataional semantics. We define the language Concurrent C minor, an extension of the C minor language of Leroy. C minor was designed as the highest-level intermediate language in the CompCert certified ANSI C compiler, and we add to it lock, unlock, and fork statements to make Concurrent C minor, giving it a standard Pthreads style of concurrency. We define a Concurrent Separation Logic for Concurrent C minor, which extends the original Concurrent Separation Logic of O’Hearn to handle first-class locks and threads. We then prove the soundness of the logic with respect to the opera-tional semantics of the language. First, we define an erased concurrent operational semantics for Concurrent C minor that is a reasonable ab-",
    "_line": "FormalReview.bib:3059"
  },
  "berdine_smallfoot:_2006": {
    "id": "berdine_smallfoot:_2006",
    "type": "paper-conference",
    "author": [
      {
        "family": "Berdine",
        "given": "Josh"
      },
      {
        "family": "Calcagno",
        "given": "Cristiano"
      },
      {
        "family": "O’Hearn",
        "given": "Peter W."
      }
    ],
    "editor": [
      {
        "family": "Boer",
        "given": "Frank S.",
        "dropping-particle": "de"
      },
      {
        "family": "Bonsangue",
        "given": "Marcello M."
      },
      {
        "family": "Graf",
        "given": "Susanne"
      },
      {
        "family": "Roever",
        "given": "Willem-Paul",
        "dropping-particle": "de"
      }
    ],
    "title": "Smallfoot: Modular Automatic Assertion Checking with Separation Logic",
    "container-title": "Formal Methods for Components and Objects",
    "container-title-short": "Smallfoot",
    "collection-title": "Lecture Notes in Computer Science",
    "title-short": "Smallfoot",
    "issued": {
      "date-parts": [
        [
          "2006"
        ]
      ]
    },
    "publisher": "Springer Berlin Heidelberg",
    "isbn": "978-3-540-36750-5",
    "abstract": "Separation logic is a program logic for reasoning about programs that manipulate pointer data structures. We describe Smallfoot, a tool for checking certain lightweight separation logic specifications. The assertions describe the shapes of data structures rather than their detailed contents, and this allows reasoning to be fully automatic. The presentation in the paper is tutorial in style. We illustrate what the tool can do via examples which are oriented toward novel aspects of separation logic, namely: avoidance of frame axioms (which say what a procedure does not change); embracement of “dirty” features such as memory disposal and address arithmetic; information hiding in the presence of pointers; and modular reasoning about concurrent programs.",
    "keywords": "Free List, Information Hiding, Separation Logic, Symbolic Execution, Tree Predicate",
    "page": "115-137",
    "page-first": "115",
    "language": "en-US",
    "_line": "FormalReview.bib:3067"
  },
  "ohearn_local_2001": {
    "id": "ohearn_local_2001",
    "type": "chapter",
    "author": [
      {
        "family": "O’Hearn",
        "given": "Peter"
      },
      {
        "family": "Reynolds",
        "given": "John"
      },
      {
        "family": "Yang",
        "given": "Hongseok"
      }
    ],
    "editor": [
      {
        "family": "Fribourg",
        "given": "Laurent"
      }
    ],
    "title": "Local Reasoning about Programs that Alter Data Structures",
    "container-title": "Computer Science Logic",
    "collection-title": "Lecture Notes in Computer Science",
    "issued": {
      "date-parts": [
        [
          "2001"
        ]
      ]
    },
    "publisher": "Springer Berlin Heidelberg",
    "isbn": "978-3-540-44802-0",
    "abstract": "We describe an extension of Hoare’s logic for reasoning about programs that alter data structures. We consider a low-level storage model based on a heap with associated lookup, update, allocation and deallocation operations, and unrestricted address arithmetic. The assertion language is based on a possible worlds model of the logic of bunched implications, and includes spatial conjunction and implication connectives alongside those of classical logic. Heap operations are axiomatized using what we call the “small axioms”, each of which mentions only those cells accessed by a particular command. Through these and a number of examples we show that the formalism supports local reasoning: A specification and proof can concentrate on only those cells in memory that a program accesses.This paper builds on earlier work by Burstall, Reynolds, Ishtiaq and O’Hearn on reasoning about data structures.",
    "keywords": "Frame Problem, Hoare Logic, Local Reasoning, Memory Fault, Weak Precondition",
    "page": "1-19",
    "page-first": "1",
    "language": "en-US",
    "_line": "FormalReview.bib:3084"
  },
  "hermanns_local_2006": {
    "id": "hermanns_local_2006",
    "type": "chapter",
    "author": [
      {
        "family": "Distefano",
        "given": "Dino"
      },
      {
        "family": "O’Hearn",
        "given": "Peter W."
      },
      {
        "family": "Yang",
        "given": "Hongseok"
      }
    ],
    "editor": [
      {
        "family": "Hermanns",
        "given": "Holger"
      },
      {
        "family": "Palsberg",
        "given": "Jens"
      }
    ],
    "title": "A Local Shape Analysis Based on Separation Logic",
    "container-title": "Tools and Algorithms for the Construction and Analysis of Systems",
    "issued": {
      "date-parts": [
        [
          "2006"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "publisher": "Springer Berlin Heidelberg",
    "isbn": "978-3-540-33056-1 978-3-540-33057-8",
    "abstract": "We describe a program analysis for linked list programs where the abstract domain uses formulae from separation logic.",
    "URL": "http://link.springer.com/10.1007/11691372_19",
    "DOI": "10.1007/11691372_19",
    "publisher-place": "Berlin, Heidelberg",
    "page": "287-302",
    "page-first": "287",
    "volume": "3920",
    "language": "en-US",
    "_line": "FormalReview.bib:3100"
  },
  "calcagno_moving_nodate": {
    "id": "calcagno_moving_nodate",
    "type": "webpage",
    "author": [
      {
        "family": "Calcagno",
        "given": "Cristiano"
      },
      {
        "family": "Distefano",
        "given": "Dino"
      },
      {
        "family": "Dubreil",
        "given": "Jeremy"
      },
      {
        "family": "O'Hearn",
        "given": "Peter"
      }
    ],
    "title": "Moving Fast with Software Verification.Facebook Research",
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "abstract": "For organisations like Facebook, high quality software is important. However, the pace of change and increasing complexity of modern code makes it difficult to produce error free software. Available tools are often lacking in helping programmers develop more reliable and secure applications.",
    "URL": "https://research.fb.com/publications/moving-fast-with-software-verification",
    "language": "en-US",
    "_line": "FormalReview.bib:3119"
  }
}