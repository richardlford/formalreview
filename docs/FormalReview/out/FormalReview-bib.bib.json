{
  "_preamble": "",
  "_comments": "",
  "calcagno_compositional_2011": {
    "id": "calcagno_compositional_2011",
    "type": "article-journal",
    "author": [
      {
        "family": "Calcagno",
        "given": "Cristiano"
      },
      {
        "family": "Distefano",
        "given": "Dino"
      },
      {
        "family": "O’Hearn",
        "given": "Peter W."
      },
      {
        "family": "Yang",
        "given": "Hongseok"
      }
    ],
    "title": "Compositional Shape Analysis by Means of Bi-Abduction",
    "container-title": "Journal of the ACM",
    "issued": {
      "date-parts": [
        [
          "2011",
          "12",
          "1"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "1",
          "30"
        ]
      ]
    },
    "issn": "00045411",
    "URL": "http://dl.acm.org/citation.cfm?doid=2049697.2049700",
    "DOI": "10.1145/2049697.2049700",
    "page": "1-66",
    "page-first": "1",
    "volume": "58",
    "issue": "6",
    "language": "en-US",
    "_line": "FormalReview.bib:2"
  },
  "krishnan_modelling_2018": {
    "id": "krishnan_modelling_2018",
    "type": "paper-conference",
    "author": [
      {
        "family": "Krishnan",
        "given": "Ranjani"
      },
      {
        "family": "Lalithambika",
        "given": "V R"
      }
    ],
    "title": "Modelling and validating 1553B protocol using the SPIN model checker",
    "container-title": "2018 10th International Conference on Communication Systems &amp; Networks (COMSNETS)",
    "event-title": "2018 10th International Conference on Communication Systems &amp; Networks (COMSNETS)",
    "issued": {
      "date-parts": [
        [
          "2018",
          "1"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "1",
          "31"
        ]
      ]
    },
    "publisher": "IEEE",
    "isbn": "978-1-5386-1182-1",
    "URL": "http://ieeexplore.ieee.org/document/8328247/",
    "DOI": "10.1109/COMSNETS.2018.8328247",
    "publisher-place": "Bengaluru",
    "page": "472-475",
    "page-first": "472",
    "note": "1553B/08328247.pdf",
    "_line": "FormalReview.bib:18"
  },
  "jung_rustbelt:_2017": {
    "id": "jung_rustbelt:_2017",
    "type": "article-journal",
    "author": [
      {
        "family": "Jung",
        "given": "Ralf"
      },
      {
        "family": "Jourdan",
        "given": "Jacques-Henri"
      },
      {
        "family": "Krebbers",
        "given": "Robbert"
      },
      {
        "family": "Dreyer",
        "given": "Derek"
      }
    ],
    "title": "RustBelt: securing the foundations of the rust programming language",
    "container-title": "Proceedings of the ACM on Programming Languages",
    "container-title-short": "RustBelt",
    "title-short": "RustBelt",
    "issued": {
      "date-parts": [
        [
          "2017",
          "12",
          "27"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "1",
          "31"
        ]
      ]
    },
    "issn": "24751421",
    "URL": "http://dl.acm.org/citation.cfm?doid=3177123.3158154",
    "DOI": "10.1145/3158154",
    "page": "1-34",
    "page-first": "1",
    "volume": "2",
    "language": "en-US",
    "_line": "FormalReview.bib:34"
  },
  "ohearn_separation_2019": {
    "id": "ohearn_separation_2019",
    "type": "article-journal",
    "author": [
      {
        "family": "O'Hearn",
        "given": "Peter"
      }
    ],
    "title": "Separation logic",
    "container-title": "Communications of the ACM",
    "issued": {
      "date-parts": [
        [
          "2019",
          "1",
          "28"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "1",
          "31"
        ]
      ]
    },
    "issn": "00010782",
    "URL": "http://dl.acm.org/citation.cfm?doid=3310134.3211968",
    "DOI": "10.1145/3211968",
    "page": "86-95",
    "page-first": "86",
    "volume": "62",
    "issue": "2",
    "language": "en-US",
    "_line": "FormalReview.bib:51"
  },
  "ohearn_peter_nodate": {
    "id": "ohearn_peter_nodate",
    "type": "no-type",
    "author": [
      {
        "family": "O'Hearn",
        "given": "Peter W."
      }
    ],
    "title": "Peter W O'hearn - acm profile",
    "URL": "https://dl.acm.org/author_page.cfm?id=81332519314&coll=DL&dl=ACM&trk=0",
    "_line": "FormalReview.bib:66"
  },
  "gorogiannis_true_2019": {
    "id": "gorogiannis_true_2019",
    "type": "article-journal",
    "author": [
      {
        "family": "Gorogiannis",
        "given": "Nikos"
      },
      {
        "family": "O'Hearn",
        "given": "Peter W."
      },
      {
        "family": "Sergey",
        "given": "Ilya"
      }
    ],
    "title": "A true positives theorem for a static race detector",
    "container-title": "Proceedings of the ACM on Programming Languages",
    "issued": {
      "date-parts": [
        [
          "2019",
          "1",
          "2"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "1",
          "31"
        ]
      ]
    },
    "issn": "24751421",
    "URL": "http://dl.acm.org/citation.cfm?doid=3302515.3290370",
    "DOI": "10.1145/3290370",
    "page": "1-29",
    "page-first": "1",
    "volume": "3",
    "language": "en-US",
    "_line": "FormalReview.bib:72"
  },
  "ohearn_continuous_2018": {
    "id": "ohearn_continuous_2018",
    "type": "paper-conference",
    "author": [
      {
        "family": "O'Hearn",
        "given": "Peter W."
      }
    ],
    "title": "Continuous Reasoning: Scaling the impact of formal methods",
    "container-title": "Proceedings of the 33rd Annual ACM/IEEE Symposium on Logic in Computer Science  - LICS '18",
    "container-title-short": "Continuous Reasoning",
    "title-short": "Continuous Reasoning",
    "event-title": "the 33rd Annual ACM/IEEE Symposium",
    "issued": {
      "date-parts": [
        [
          "2018"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "1",
          "31"
        ]
      ]
    },
    "publisher": "ACM Press",
    "isbn": "978-1-4503-5583-4",
    "URL": "http://dl.acm.org/citation.cfm?doid=3209108.3209109",
    "DOI": "10.1145/3209108.3209109",
    "publisher-place": "Oxford, United Kingdom",
    "page": "13-25",
    "page-first": "13",
    "language": "en-US",
    "_line": "FormalReview.bib:88"
  },
  "brookes_concurrent_2016": {
    "id": "brookes_concurrent_2016",
    "type": "article-journal",
    "author": [
      {
        "family": "Brookes",
        "given": "Stephen"
      },
      {
        "family": "O'Hearn",
        "given": "Peter W."
      }
    ],
    "title": "Concurrent Separation Logic",
    "container-title": "ACM SIGLOG News",
    "issued": {
      "date-parts": [
        [
          "2016",
          "8"
        ]
      ]
    },
    "issn": "2372-3491",
    "URL": "http://doi.acm.org/10.1145/2984450.2984457",
    "DOI": "10.1145/2984450.2984457",
    "page": "47-65",
    "page-first": "47",
    "volume": "3",
    "issue": "3",
    "_line": "FormalReview.bib:106"
  },
  "brookes_semantics_2007": {
    "id": "brookes_semantics_2007",
    "type": "article-journal",
    "author": [
      {
        "family": "Brookes",
        "given": "Stephen"
      }
    ],
    "title": "A semantics for concurrent separation logic",
    "container-title": "Theoretical Computer Science",
    "issued": {
      "date-parts": [
        [
          "2007",
          "5"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "1",
          "31"
        ]
      ]
    },
    "issn": "03043975",
    "URL": "https://linkinghub.elsevier.com/retrieve/pii/S0304397506009248",
    "DOI": "10.1016/j.tcs.2006.12.034",
    "page": "227-270",
    "page-first": "227",
    "volume": "375",
    "issue": "1",
    "language": "en-US",
    "_line": "FormalReview.bib:119"
  },
  "ohearn_categorical_2015": {
    "id": "ohearn_categorical_2015",
    "type": "paper-conference",
    "author": [
      {
        "family": "O'Hearn",
        "given": "Peter"
      }
    ],
    "title": "From Categorical Logic to Facebook Engineering",
    "container-title": "Proceedings of the 2015 30th Annual ACM/IEEE Symposium on Logic in Computer Science (LICS)",
    "collection-title": "LICS '15",
    "issued": {
      "date-parts": [
        [
          "2015"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "1",
          "31"
        ]
      ]
    },
    "publisher": "IEEE Computer Society",
    "isbn": "978-1-4799-8875-4",
    "URL": "https://doi.org/10.1109/LICS.2015.11",
    "DOI": "10.1109/LICS.2015.11",
    "publisher-place": "Washington, DC, USA",
    "page": "17-20",
    "page-first": "17",
    "_line": "FormalReview.bib:135"
  },
  "wikipedia_category:formal_2017": {
    "id": "wikipedia_category:formal_2017",
    "type": "entry-encyclopedia",
    "author": [
      {
        "family": "Wikipedia"
      }
    ],
    "title": "Category:Formal methods people",
    "container-title": "Wikipedia",
    "container-title-short": "Category",
    "title-short": "Category",
    "issued": {
      "date-parts": [
        [
          "2017",
          "11",
          "29"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "1",
          "31"
        ]
      ]
    },
    "abstract": "People involved with formal methods.",
    "URL": "https://en.wikipedia.org/w/index.php?title=Category:Formal_methods_people&oldid=812800009",
    "note": "Page Version ID: 812800009",
    "language": "en-US",
    "_line": "FormalReview.bib:151"
  },
  "qureshi_formal_nodate": {
    "id": "qureshi_formal_nodate",
    "type": "article-journal",
    "author": [
      {
        "family": "Qureshi",
        "given": "Zahid H"
      }
    ],
    "title": "Formal Modelling and Analysis of Mission-Critical Software in Military Avionics Systems",
    "container-title": "11th Australian Workshop on Safety Related Programmable Systems (SCS’06)",
    "abstract": "A typical avionics mission system of a military aircraft is a complex real-time system consisting of a mission control computer, different kinds of sensors, navigation and communication subsystems, and various displays and stores; all interconnected by a number of serial data buses. The mission capability is increasingly implemented in the mission-critical software and the robustness of this software is vital for mission success. The complexity and real-time requirements of mission systems represent major challenges to the Australian Defence Force during new acquisitions, upgrades and maintenance. This paper describes the experiences on a joint research project between the University of South Australia and Australia’s Defence Science and Technology Organisation into the modelling and analysis of avionics mission systems. The paper provides a summary of the key aspects of our previous research work on the modelling of a generic mission system using Coloured Petri Nets and the analysis of task scheduling on the mission computer. Finally, the paper briefly discusses the extension of the generic model to obtain a formal model of the mission system of the AP3C Orion maritime surveillance aircraft..",
    "URL": "http://crpit.com/confpapers/CRPITV69Qureshi.pdf",
    "page": "11",
    "page-first": "11",
    "language": "en-US",
    "_line": "FormalReview.bib:166"
  },
  "conchon_alt-ergo_2018": {
    "id": "conchon_alt-ergo_2018",
    "type": "paper-conference",
    "author": [
      {
        "family": "Conchon",
        "given": "Sylvain"
      },
      {
        "family": "Coquereau",
        "given": "Albin"
      },
      {
        "family": "Iguernlala",
        "given": "Mohamed"
      },
      {
        "family": "Mebsout",
        "given": "Alain"
      }
    ],
    "title": "Alt-Ergo 2.2",
    "container-title": "SMT Workshop: International Workshop on Satisfiability Modulo Theories",
    "issued": {
      "date-parts": [
        [
          "2018",
          "7"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "1",
          "31"
        ]
      ]
    },
    "abstract": "Alt-Ergo is an SMT solver jointly developed by Université Paris-Sud and the OCamlPro company. The first version was released in 2006. Since then, its architecture has been continuously adapted for proving formulas generated by software development frameworks. As type systems with polymorphism arise naturally is such platforms, the design of Alt-Ergo has been guided (and constrained) by a native-and non SMT-LIB compliant-input language for a polymorphic first-order logic. In this paper, we present the last version of Alt-Ergo, its architecture and main features. The main recent work is a support for a conservative polymorphic extension of the SMT-LIB 2 standard. We measure Alt-Ergo's performances with this new frontend on a set of benchmarks coming from the deductive program verification systems Frama-C, SPARK 2014, Why3 and Atelier-B, as well as from the SMT-LIB benchmarks library.",
    "URL": "https://hal.inria.fr/hal-01960203",
    "publisher-place": "Oxford, United Kingdom",
    "note": "alt-ergo/Alt-Ergo-2.2&ndash;SMT-Workshop-2018.pdf",
    "_line": "FormalReview.bib:177"
  },
  "conchon_increasing_2016": {
    "id": "conchon_increasing_2016",
    "type": "paper-conference",
    "author": [
      {
        "family": "Conchon",
        "given": "Sylvain"
      },
      {
        "family": "Iguernlala",
        "given": "Mohamed"
      }
    ],
    "editor": [
      {
        "family": "Lecomte",
        "given": "Thierry"
      },
      {
        "family": "Pinger",
        "given": "Ralf"
      },
      {
        "family": "Romanovsky",
        "given": "Alexander"
      }
    ],
    "title": "Increasing Proofs Automation Rate of Atelier-B Thanks to Alt-Ergo",
    "container-title": "Reliability, Safety, and Security of Railway Systems. Modelling, Analysis, Verification, and Certification",
    "collection-title": "Lecture Notes in Computer Science",
    "issued": {
      "date-parts": [
        [
          "2016"
        ]
      ]
    },
    "publisher": "Springer International Publishing",
    "isbn": "978-3-319-33951-1",
    "abstract": "In this paper, we report on our recent improvements in the Alt-Ergo SMT solver to make it effective in discharging proof obligations (POs) translated from the Atelier-B framework. In particular, we made important modifications in its internal data structures to boost performances of its core decision procedures, we improved quantifiers instantiation heuristics, and enhanced the interaction between the SAT solver and the decision procedures. We also introduced a new plugin architecture to facilitate experiments with different SAT engines, and implemented a profiling plugin to track and identify “bottlenecks” when a formula requires a long time to be discharged, or makes the solver timeout. Experiments made with more than 10,000 POs generated from real industrial B projects show significant improvements compared to both previous versions of Alt-Ergo and Atelier-B’s automatic main prover.",
    "keywords": "B method, B proof obligations, SMT solvers",
    "page": "243-253",
    "page-first": "243",
    "note": "alt-ergo/Alt-Ergo&ndash;Atelier-B&ndash;RSSR-2016.pdf",
    "language": "en-US",
    "_line": "FormalReview.bib:190"
  },
  "altenkirch_quotient_2018": {
    "id": "altenkirch_quotient_2018",
    "type": "article-journal",
    "author": [
      {
        "family": "Altenkirch",
        "given": "Thorsten"
      },
      {
        "family": "Capriotti",
        "given": "Paolo"
      },
      {
        "family": "Dijkstra",
        "given": "Gabe"
      },
      {
        "family": "Kraus",
        "given": "Nicolai"
      },
      {
        "family": "Forsberg",
        "given": "Fredrik Nordvall"
      }
    ],
    "title": "Quotient inductive-inductive types",
    "container-title": "arXiv:1612.02346 \\[cs\\]",
    "issued": {
      "date-parts": [
        [
          "2018"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "1",
          "31"
        ]
      ]
    },
    "abstract": "Higher inductive types (HITs) in Homotopy Type Theory (HoTT) allow the definition of datatypes which have constructors for equalities over the defined type. HITs generalise quotient types and allow to define types which are not sets in the sense of HoTT (i.e. do not satisfy uniqueness of equality proofs) such as spheres, suspensions and the torus. However, there are also interesting uses of HITs to define sets, such as the Cauchy reals, the partiality monad, and the internal, total syntax of type theory. In each of these examples we define several types that depend on each other mutually, i.e. they are inductive-inductive definitions. We call those HITs quotient inductive-inductive types (QIITs). Although there has been recent progress on the general theory of HITs, there isn't yet a theoretical foundation of the combination of equality constructors and induction-induction, despite having many interesting applications. In the present paper we present a first step towards a semantic definition of QIITs. In particular, we give an initial-algebra semantics and show that this is equivalent to the section induction principle, which justifies the intuitively expected elimination rules.",
    "keywords": "03B15 (Primary) 18C10 (Secondary), Computer Science - Logic in Computer Science",
    "URLtext": "1612.02346,",
    "URLpretext": "[arXiv:]{.etype}",
    "eprint-type": "arxiv",
    "eprint": "1612.02346,",
    "URL": "http://arxiv.org/abs/1612.02346",
    "DOI": "10.1007/978-3-319-89366-2_16",
    "page": "293-310",
    "page-first": "293",
    "volume": "10803",
    "note": "altenkirch/Quotient&underscore;inductive-inductive&underscore;types.pdf",
    "_line": "FormalReview.bib:207"
  },
  "hritcu_micro-policies:_2015": {
    "id": "hritcu_micro-policies:_2015",
    "type": "paper-conference",
    "author": [
      {
        "family": "Hriţcu",
        "given": "Cǎtǎlin"
      }
    ],
    "title": "Micro-Policies: Formally Verified, Tag-Based Security Monitors",
    "container-title": "Proceedings of the 10th ACM Workshop on Programming Languages and Analysis for Security - PLAS'15",
    "container-title-short": "Micro-Policies",
    "title-short": "Micro-Policies",
    "event-title": "the 10th ACM Workshop",
    "issued": {
      "date-parts": [
        [
          "2015"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "1",
          "31"
        ]
      ]
    },
    "publisher": "ACM Press",
    "isbn": "978-1-4503-3661-1",
    "URL": "http://dl.acm.org/citation.cfm?doid=2786558.2786560",
    "DOI": "10.1145/2786558.2786560",
    "publisher-place": "Prague, Czech Republic",
    "page": "1-1",
    "page-first": "1",
    "note": "amorim/nicro-policies.pdf",
    "language": "en-US",
    "_line": "FormalReview.bib:225"
  },
  "hobor_theory_2010": {
    "id": "hobor_theory_2010",
    "type": "paper-conference",
    "author": [
      {
        "family": "Hobor",
        "given": "Aquinas"
      },
      {
        "family": "Dockins",
        "given": "Robert"
      },
      {
        "family": "Appel",
        "given": "Andrew W."
      }
    ],
    "title": "A Theory of Indirection via Approximation",
    "container-title": "Proceedings of the 37th Annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages",
    "collection-title": "POPL '10",
    "issued": {
      "date-parts": [
        [
          "2010"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "1",
          "31"
        ]
      ]
    },
    "publisher": "ACM",
    "isbn": "978-1-60558-479-9",
    "abstract": "Building semantic models that account for various kinds of indirect reference has traditionally been a difficult problem. Indirect reference can appear in many guises, such as heap pointers, higher-order functions, object references, and shared-memory mutexes. We give a general method to construct models containing indirect reference by presenting a \"theory of indirection\". Our method can be applied in a wide variety of settings and uses only simple, elementary mathematics. In addition to various forms of indirect reference, the resulting models support powerful features such as impredicative quantification and equirecursion; moreover they are compatible with the kind of powerful substructural accounting required to model (higher-order) separation logic. In contrast to previous work, our model is easy to apply to new settings and has a simple axiomatization, which is complete in the sense that all models of it are isomorphic. Our proofs are machine-checked in Coq.",
    "keywords": "indirection theory, step-indexed models",
    "URL": "http://doi.acm.org/10.1145/1706299.1706322",
    "DOI": "10.1145/1706299.1706322",
    "publisher-place": "New York, NY, USA",
    "page": "171-184",
    "page-first": "171",
    "_line": "FormalReview.bib:243"
  },
  "cao_vst-floyd:_2018": {
    "id": "cao_vst-floyd:_2018",
    "type": "article-journal",
    "author": [
      {
        "family": "Cao",
        "given": "Qinxiang"
      },
      {
        "family": "Beringer",
        "given": "Lennart"
      },
      {
        "family": "Gruetter",
        "given": "Samuel"
      },
      {
        "family": "Dodds",
        "given": "Josiah"
      },
      {
        "family": "Appel",
        "given": "Andrew W."
      }
    ],
    "title": "VST-Floyd: A Separation Logic Tool to Verify Correctness of C Programs",
    "container-title": "J. Autom. Reason.",
    "container-title-short": "VST-Floyd",
    "title-short": "VST-Floyd",
    "issued": {
      "date-parts": [
        [
          "2018",
          "6"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "1",
          "31"
        ]
      ]
    },
    "issn": "0168-7433",
    "abstract": "The Verified Software Toolchain builds foundational machine-checked proofs of the functional correctness of C programs. Its program logic, Verifiable C, is a shallowly embedded higher-order separation Hoare logic which is proved sound in Coq with respect to the operational semantics of CompCert Clight. This paper introduces VST-Floyd, a verification assistant which offers a set of semiautomatic tactics helping users build functional correctness proofs for C programs using Verifiable C.",
    "keywords": "Program verification, Proof automation, Separation logic, Symbolic execution",
    "URL": "https://doi.org/10.1007/s10817-018-9457-5",
    "DOI": "10.1007/s10817-018-9457-5",
    "page": "367-422",
    "page-first": "367",
    "volume": "61",
    "issue": "1",
    "_line": "FormalReview.bib:261"
  },
  "hutchison_verified_2014": {
    "id": "hutchison_verified_2014",
    "type": "chapter",
    "author": [
      {
        "family": "Beringer",
        "given": "Lennart"
      },
      {
        "family": "Stewart",
        "given": "Gordon"
      },
      {
        "family": "Dockins",
        "given": "Robert"
      },
      {
        "family": "Appel",
        "given": "Andrew W."
      }
    ],
    "editor": [
      {
        "family": "Shao",
        "given": "Zhong"
      }
    ],
    "title": "Verified Compilation for Shared-Memory C",
    "container-title": "Programming Languages and Systems",
    "issued": {
      "date-parts": [
        [
          "2014"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "1",
          "31"
        ]
      ]
    },
    "publisher": "Springer Berlin Heidelberg",
    "isbn": "978-3-642-54832-1 978-3-642-54833-8",
    "URL": "http://link.springer.com/10.1007/978-3-642-54833-8_7",
    "DOI": "10.1007/978-3-642-54833-8_7,",
    "publisher-place": "Berlin, Heidelberg",
    "page": "107-127",
    "page-first": "107",
    "volume": "8410",
    "note": "appel/shmemc.pdf is a preview",
    "_line": "FormalReview.bib:279"
  },
  "appel_verifiabble_2014": {
    "id": "appel_verifiabble_2014",
    "type": "book",
    "author": [
      {
        "family": "Appel",
        "given": "Andrew W."
      },
      {
        "family": "Dockins",
        "given": "Robert"
      },
      {
        "family": "Hobor",
        "given": "Aquinas"
      },
      {
        "family": "Beringer",
        "given": "Lennart"
      },
      {
        "family": "Dodds",
        "given": "Josiah"
      },
      {
        "family": "Stewart",
        "given": "Gordon"
      },
      {
        "family": "Blazy",
        "given": "Sandrine"
      },
      {
        "family": "Leroy",
        "given": "Xavier"
      }
    ],
    "title": "Verifiabble C, Version 2.2",
    "issued": {
      "date-parts": [
        [
          "2014"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "1",
          "31"
        ]
      ]
    },
    "publisher": "Cambridge University Press",
    "isbn": "978-1-107-25655-2",
    "URL": "http://ebooks.cambridge.org/ref/id/CBO9781107256552",
    "DOI": "10.1017/CBO9781107256552",
    "publisher-place": "Cambridge",
    "language": "en-US",
    "_line": "FormalReview.bib:299"
  },
  "appel_verification_2015": {
    "id": "appel_verification_2015",
    "type": "article-journal",
    "author": [
      {
        "family": "Appel",
        "given": "Andrew W."
      }
    ],
    "title": "Verification of a Cryptographic Primitive: SHA-256",
    "container-title": "ACM Trans. Program. Lang. Syst.",
    "container-title-short": "Verification of a Cryptographic Primitive",
    "title-short": "Verification of a Cryptographic Primitive",
    "issued": {
      "date-parts": [
        [
          "2015",
          "4"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "1",
          "31"
        ]
      ]
    },
    "issn": "0164-0925",
    "abstract": "This article presents a full formal machine-checked verification of a C program: the OpenSSL implementation of SHA-256. This is an interactive proof of functional correctness in the Coq proof assistant, using the Verifiable C program logic. Verifiable C is a separation logic for the C language, proved sound with respect to the operational semantics for C, connected to the CompCert verified optimizing C compiler.",
    "keywords": "Cryptography",
    "URL": "http://doi.acm.org/10.1145/2701415",
    "DOI": "10.1145/2701415",
    "page": "7:1-7:31",
    "page-first": "7",
    "volume": "37",
    "issue": "2",
    "_line": "FormalReview.bib:313"
  },
  "jouannaud_verismall:_2011": {
    "id": "jouannaud_verismall:_2011",
    "type": "chapter",
    "author": [
      {
        "family": "Appel",
        "given": "Andrew W."
      }
    ],
    "editor": [
      {
        "family": "Jouannaud",
        "given": "Jean-Pierre"
      },
      {
        "family": "Shao",
        "given": "Zhong"
      }
    ],
    "title": "VeriSmall: Verified Smallfoot Shape Analysis",
    "container-title": "Certified Programs and Proofs",
    "container-title-short": "VeriSmall",
    "title-short": "VeriSmall",
    "issued": {
      "date-parts": [
        [
          "2011"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "1",
          "31"
        ]
      ]
    },
    "publisher": "Springer Berlin Heidelberg",
    "isbn": "978-3-642-25378-2 978-3-642-25379-9",
    "URL": "http://link.springer.com/10.1007/978-3-642-25379-9_18",
    "DOI": "10.1007/978-3-642-25379-9_18",
    "publisher-place": "Berlin, Heidelberg",
    "page": "231-246",
    "page-first": "231",
    "volume": "7086",
    "_line": "FormalReview.bib:331"
  },
  "stewart_verified_2012": {
    "id": "stewart_verified_2012",
    "type": "paper-conference",
    "author": [
      {
        "family": "Stewart",
        "given": "Gordon"
      },
      {
        "family": "Beringer",
        "given": "Lennart"
      },
      {
        "family": "Appel",
        "given": "Andrew W."
      }
    ],
    "title": "Verified Heap Theorem Prover by Paramodulation",
    "container-title": "Proceedings of the 17th ACM SIGPLAN International Conference on Functional Programming",
    "collection-title": "ICFP '12",
    "issued": {
      "date-parts": [
        [
          "2012"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "1",
          "31"
        ]
      ]
    },
    "publisher": "ACM",
    "isbn": "978-1-4503-1054-3",
    "abstract": "We present VeriStar, a verified theorem prover for a decidable subset of separation logic. Together with VeriSmall \\[3\\], a proved-sound Smallfoot-style program analysis for C minor, VeriStar demonstrates that fully machine-checked static analyses equipped with efficient theorem provers are now within the reach of formal methods. As a pair, VeriStar and VeriSmall represent the first application of the Verified Software Toolchain \\[4\\], a tightly integrated collection of machine-verified program logics and compilers giving foundational correctness guarantees. VeriStar is (1) purely functional, (2) machine-checked, (3) end-to-end, (4) efficient and (5) modular. By purely functional, we mean it is implemented in Gallina, the pure functional programming language embedded in the Coq theorem prover. By machine-checked, we mean it has a proof in Coq that when the prover says \"valid\", the checked entailment holds in a proved-sound separation logic for C minor. By end-to-end, we mean that when the static analysis+theorem prover says a C minor program is safe, the program will be compiled to a semantically equivalent assembly program that runs on real hardware. By efficient, we mean that the prover implements a state-of-the-art algorithm for deciding heap entailments and uses highly tuned verified functional data structures. By modular, we mean that VeriStar can be retrofitted to other static analyses as a plug-compatible entailment checker and its soundness proof can easily be ported to other separation logics.",
    "keywords": "paramodulation, separation logic, theorem proving",
    "URL": "http://doi.acm.org/10.1145/2364527.2364531",
    "DOI": "10.1145/2364527.2364531",
    "publisher-place": "New York, NY, USA",
    "page": "3-14",
    "page-first": "3",
    "_line": "FormalReview.bib:349"
  },
  "appel_verified_2012": {
    "id": "appel_verified_2012",
    "type": "paper-conference",
    "author": [
      {
        "family": "Appel",
        "given": "Andrew W."
      }
    ],
    "title": "Verified Software Toolchain",
    "container-title": "Proceedings of the 4th International Conference on NASA Formal Methods",
    "collection-title": "NFM'12",
    "issued": {
      "date-parts": [
        [
          "2012"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "1",
          "31"
        ]
      ]
    },
    "publisher": "Springer-Verlag",
    "isbn": "978-3-642-28890-6",
    "abstract": "The software toolchain includes static analyzers to check assertions about programs; optimizing compilers to translate programs to machine language; operating systems and libraries to supply context for programs. Our Verified Software Toolchain verifies with machine-checked proofs that the assertions claimed at the top of the toolchain really hold in the machine-language program, running in the operating-system context, on a weakly-consistent-shared-memory machine. Our verification approach is modular, in that proofs about operating systems or concurrency libraries are oblivious of the programming language or machine language, proofs about compilers are oblivious of the program logic used to verify static analyzers, and so on. The approach is scalable, in that each component is verified in the semantic idiom most natural for that component. Finally, the verification is foundational: the trusted base for proofs of observable properties of the machine-language program includes only the operational semantics of the machine language, not the source language, the compiler, the program logic, or any other part of the toolchain&ndash;even when these proofs are carried out by source-level static analyzers. In this paper I explain the construction of a a verified toolchain, using the Coq proof assistant. I will illustrate with shape analysis for C programs based on separation logic.",
    "URL": "http://dx.doi.org/10.1007/978-3-642-28891-3_2",
    "DOI": "10.1007/978-3-642-28891-3_2",
    "publisher-place": "Berlin, Heidelberg",
    "page": "2-2",
    "page-first": "2",
    "_line": "FormalReview.bib:367"
  },
  "kastner_program_2015": {
    "id": "kastner_program_2015",
    "type": "paper-conference",
    "author": [
      {
        "family": "Kästner",
        "given": "Daniel"
      },
      {
        "family": "Pohland",
        "given": "Jan"
      }
    ],
    "editor": [
      {
        "family": "Roy",
        "given": "Matthieu"
      }
    ],
    "title": "Program Analysis on Evolving Software",
    "container-title": "CARS 2015 - Critical Automotive applications: Robustness &amp; Safety",
    "issued": {
      "date-parts": [
        [
          "2015",
          "9"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "1",
          "31"
        ]
      ]
    },
    "abstract": "Static analysis is well-suited for continuous verification during the software development stage since it only works on the source code and does not require a running system for testing. However, applying the program analysis during software development means that the analysis has to cope with evolving software and evolving analyzer configurations, especially in a model-based development process. In this article we present a unique history-aware concept for program analysis that has been developed for the static analyzer Astrée. It not only provides the ability to backtrack and access previous versions of the analysis configuration, it can also automatically determine the differences between two analysis configurations and relate them to the correct source code versions. Users can explicitly create a revision, i.e. a snapshot of the analysis project; changes of the source code, analysis options, analysis directives and results in different revisions are automatically detected and highlighted. The analyzer provides automatic correctness checks for all specified analysis directives, e.g., to tune the precision of the analyzer or provide information about the environment. This makes software verification applicable during the implementation stage, significantly reduces the effort to adapt the analyzer configuration to new source code versions, and makes analysis results on previous software versions easily reproducible.",
    "URL": "https://hal.archives-ouvertes.fr/hal-01192985",
    "publisher-place": "Paris, France",
    "_line": "FormalReview.bib:384"
  },
  "monniaux_parallel_2005": {
    "id": "monniaux_parallel_2005",
    "type": "article-journal",
    "author": [
      {
        "family": "Monniaux",
        "given": "David"
      }
    ],
    "title": "The parallel implementation of the Astr&bslash;'&lcurly;e&rcurly;e static analyzer",
    "container-title": "arXiv:cs/0701191",
    "issued": {
      "date-parts": [
        [
          "2005"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "1",
          "31"
        ]
      ]
    },
    "abstract": "The Astr&bslash;'&lcurly;e&rcurly;e static analyzer is a specialized tool that can prove the absence of runtime errors, including arithmetic overflows, in large critical programs. Keeping analysis times reasonable for industrial use is one of the design objectives. In this paper, we discuss the parallel implementation of the analysis.",
    "keywords": "Computer Science - Performance, Computer Science - Programming Languages, D.2.4",
    "URLtext": "cs/0701191",
    "URLpretext": "[arXiv:]{.etype}",
    "eprint-type": "arxiv",
    "eprint": "cs/0701191",
    "URL": "http://arxiv.org/abs/cs/0701191",
    "DOI": "10.1007/11575467_7",
    "page": "86-96",
    "page-first": "86",
    "volume": "3780",
    "_line": "FormalReview.bib:397"
  },
  "kastner_astree:_nodate": {
    "id": "kastner_astree:_nodate",
    "type": "article-journal",
    "author": [
      {
        "family": "Kästner",
        "given": "D"
      },
      {
        "family": "Wilhelm",
        "given": "S"
      },
      {
        "family": "Nenova",
        "given": "S"
      },
      {
        "family": "Miné",
        "given": "A"
      },
      {
        "family": "Rival",
        "given": "X"
      },
      {
        "family": "Mauborgne",
        "given": "L"
      },
      {
        "family": "Feret",
        "given": "J"
      },
      {
        "family": "Cousot",
        "given": "P"
      },
      {
        "family": "Cousot",
        "given": "R"
      }
    ],
    "title": "Astree: Proving the Absence of Runtime Errors",
    "abstract": "Safety-critical embedded software has to satisfy stringent quality requirements. Testing and validation consumes a large – and growing – fraction of development cost. The last years have seen the emergence of semantics-based static analysis tools in various application areas, from runtime error analysis to worst-case execution time prediction. Their appeal is that they have the potential to reduce testing eﬀort while providing 100&perc; coverage, thus enhancing safety. Static runtime error analysis is applicable to large industryscale projects and produces a list of deﬁnite runtime errors and of potential runtime errors which might be true errors or false alarms. In the past, often only the deﬁnite errors were ﬁxed because manually inspecting each alarm was too time-consuming due to a large number of false alarms. Therefore no proof of the absence of runtime errors could be given. In this article the parameterizable static analyzer Astr´ee is presented. By specialization and parameterization Astr´ee can be adapted to the software under analysis. This enables Astr´ee to eﬃciently compute precise results. Astr´ee has successfully been used to analyze large-scale safety-critical avionics software with zero false alarms.",
    "URL": "https://www.di.ens.fr/~rival/papers/erts10.pdf",
    "page": "9",
    "page-first": "9",
    "note": "astree/astee-proving-absence-rte.pdf",
    "language": "en-US",
    "_line": "FormalReview.bib:414"
  },
  "mine_taking_2016": {
    "id": "mine_taking_2016",
    "type": "paper-conference",
    "author": [
      {
        "family": "Miné",
        "given": "Antoine"
      },
      {
        "family": "Mauborgne",
        "given": "Laurent"
      },
      {
        "family": "Rival",
        "given": "Xavier"
      },
      {
        "family": "Feret",
        "given": "Jerome"
      },
      {
        "family": "Cousot",
        "given": "Patrick"
      },
      {
        "family": "Kästner",
        "given": "Daniel"
      },
      {
        "family": "Wilhelm",
        "given": "Stephan"
      },
      {
        "family": "Ferdinand",
        "given": "Christian"
      }
    ],
    "title": "Taking Static Analysis to the Next Level: Proving the Absence of Run-Time Errors and Data Races with Astrée",
    "container-title": "8th European Congress on Embedded Real Time Software and Systems (ERTS 2016)",
    "container-title-short": "Taking Static Analysis to the Next Level",
    "title-short": "Taking Static Analysis to the Next Level",
    "issued": {
      "date-parts": [
        [
          "2016",
          "1"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "1",
          "31"
        ]
      ]
    },
    "abstract": "We present an extension of Astrée to concurrent C software. Astrée is a sound static analyzer for run-time errors previously limited to sequential C software. Our extension employs a scalable abstraction which covers all possible thread interleavings, and soundly reports all run-time errors and data races: when the analyzer does not report any alarm, the program is proven free from those classes of errors. We show how this extension is able to support a variety of operating systems (such as POSIX threads, ARINC 653, OSEK/AUTOSAR) and report on experimental results obtained on concurrent software from different domains, including large industrial software.",
    "URL": "https://hal.archives-ouvertes.fr/hal-01271552",
    "publisher-place": "Toulouse, France",
    "_line": "FormalReview.bib:425"
  },
  "bedford_coqatoo:_nodate": {
    "id": "bedford_coqatoo:_nodate",
    "type": "article-journal",
    "author": [
      {
        "family": "Bedford",
        "given": "Andrew"
      }
    ],
    "title": "Coqatoo: Generating Natural Language Versions of Coq Proofs - Slides",
    "page": "16",
    "page-first": "16",
    "language": "en-US",
    "_line": "FormalReview.bib:438"
  },
  "bedford_coqatoo:_2017": {
    "id": "bedford_coqatoo:_2017",
    "type": "article-journal",
    "author": [
      {
        "family": "Bedford",
        "given": "Andrew"
      }
    ],
    "title": "Coqatoo: Generating Natural Language Versions of Coq Proofs",
    "container-title": "arXiv:1712.03894 \\[cs\\]",
    "container-title-short": "Coqatoo",
    "title-short": "Coqatoo",
    "issued": {
      "date-parts": [
        [
          "2017",
          "12",
          "11"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "1",
          "31"
        ]
      ]
    },
    "abstract": "Due to their numerous advantages, formal proofs and proof assistants, such as Coq, are becoming increasingly popular. However, one disadvantage of using proof assistants is that the resulting proofs can sometimes be hard to read and understand, particularly for less-experienced users. To address this issue, we have implemented a tool capable of generating natural language versions of Coq proofs called Coqatoo, which we present in this paper.",
    "keywords": "Computer Science - Programming Languages",
    "URLtext": "1712.03894",
    "URLpretext": "[arXiv:]{.etype}",
    "eprint-type": "arxiv",
    "eprint": "1712.03894",
    "URL": "http://arxiv.org/abs/1712.03894",
    "_line": "FormalReview.bib:446"
  },
  "sherman_making_2017": {
    "id": "sherman_making_2017",
    "type": "thesis",
    "genre": "Master of Science",
    "author": [
      {
        "family": "Sherman",
        "given": "Benjamin"
      }
    ],
    "title": "Making Discrete Decisions Based on Continuous Values",
    "issued": {
      "date-parts": [
        [
          "2017",
          "6"
        ]
      ]
    },
    "publisher": "MIT",
    "number-of-pages": "105",
    "abstract": "Many safety-critical software systems are cyber-physical systems that compute with continuous values; confirming their safety requires guaranteeing the accuracy of their computations. It is impossible for these systems to compute (total and deterministic) discrete computations (e.g., decisions) based on connected input spaces such as R. We propose a programming language based on constructive topology, whose types are spaces and programs are executable continuous maps, that facilitates making formal guarantees of accuracy of computed results. We demonstrate that discrete decisions can be made based on continuous values by permitting nondeterminism. This thesis describes variants of the programming language allowing nondeterminism and/or partiality, and introduces two tools for creating nondeterministic programs on spaces. Overlapping pattern matching is a generalization of pattern matching in functional programming, where patterns need not represent decidable predicates and also may overlap, allowing potentially nondeterministic behavior in overlapping regions. Binary covers, which are pairs of predicates such that at least one of them holds, yield a formal logic for constructing approximate decision procedures.",
    "URL": "http://adam.chlipala.net/theses/sherman_sm.pdf",
    "publisher-place": "Cambridge, MA",
    "note": "ben-sherman/sm-thesis.pdf",
    "language": "en-US",
    "_line": "FormalReview.bib:461"
  },
  "boulier_next_2017": {
    "id": "boulier_next_2017",
    "type": "paper-conference",
    "author": [
      {
        "family": "Boulier",
        "given": "Simon"
      },
      {
        "family": "Pédrot",
        "given": "Pierre-Marie"
      },
      {
        "family": "Tabareau",
        "given": "Nicolas"
      }
    ],
    "title": "The next 700 syntactical models of type theory",
    "event-title": "Certified Programs and Proofs (CPP 2017)",
    "issued": {
      "date-parts": [
        [
          "2017",
          "1",
          "16"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "1",
          "31"
        ]
      ]
    },
    "abstract": "A family of syntactic models for the calculus of construction with universes (CC ω) is described, all of them preserving conversion of the calculus definitionally, and thus giving rise directly to a program transformation of CC ω into itself. Those models are based on the remark that negative type constructors (e.g., dependent product, coinductive types or universes) are underspecified in type theory—which leaves some freedom on extra intensional specifications. The model construction can be seen as a compilation phase from a complex type theory into a simpler type theory. Such models can be used to derive (the negative part of) independence results with respect to CC ω , such as functional extensional-ity, propositional extensionality, univalence or the fact that bisimulation on a coinductive type may not coincide with equality. They can also be used to add new principles to the theory, which we illustrate by defining a version of CC ω with ad-hoc polymorphism that shows in particular that para-metricity is not an implicit requirement of type theory. The correctness of some of the models/program transformations have been checked in the COQ proof assistant and have been instrumented as a COQ plugin.",
    "URL": "https://hal.inria.fr/hal-01445835/document",
    "DOI": "10.1145/3018610.3018620",
    "page": "182 - 194",
    "page-first": "182",
    "language": "en-US",
    "_line": "FormalReview.bib:476"
  },
  "bowman_j1:_nodate": {
    "id": "bowman_j1:_nodate",
    "type": "book",
    "author": [
      {
        "family": "Bowman",
        "given": "James"
      }
    ],
    "title": "J1: a small Forth CPU Core for FPGAs",
    "container-title-short": "J1",
    "title-short": "J1",
    "abstract": "Abstract—This paper describes a 16-bit Forth CPU core, intended for FPGAs. The instruction set closely matches the Forth programming language, simplifying cross-compilation. Because it has higher throughput than comparable CPU cores, it can stream uncompressed video over Ethernet using a simple software loop.The entire system (source Verilog,cross compiler, and TCP/IP networking code) is published under the BSD license. The core is less than 200 lines of Verilog, and operates reliably at 80 MHz in a Xilinx Spartan R○-3E FPGA, delivering approximately 100 ANS Forth MIPS. I.",
    "_line": "FormalReview.bib:490"
  },
  "gu_deep_2015": {
    "id": "gu_deep_2015",
    "type": "paper-conference",
    "author": [
      {
        "family": "Gu",
        "given": "Ronghui"
      },
      {
        "family": "Koenig",
        "given": "Jérémie"
      },
      {
        "family": "Ramananandro",
        "given": "Tahina"
      },
      {
        "family": "Shao",
        "given": "Zhong"
      },
      {
        "family": "Wu",
        "given": "Xiongnan (Newman)"
      },
      {
        "family": "Weng",
        "given": "Shu-Chun"
      },
      {
        "family": "Zhang",
        "given": "Haozhong"
      },
      {
        "family": "Guo",
        "given": "Yu"
      }
    ],
    "title": "Deep Specifications and Certified Abstraction Layers",
    "container-title": "Proceedings of the 42Nd Annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages",
    "collection-title": "POPL '15",
    "issued": {
      "date-parts": [
        [
          "2015"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "1",
          "31"
        ]
      ]
    },
    "publisher": "ACM",
    "isbn": "978-1-4503-3300-9",
    "abstract": "Modern computer systems consist of a multitude of abstraction layers (e.g., OS kernels, hypervisors, device drivers, network protocols), each of which defines an interface that hides the implementation details of a particular set of functionality. Client programs built on top of each layer can be understood solely based on the interface, independent of the layer implementation. Despite their obvious importance, abstraction layers have mostly been treated as a system concept; they have almost never been formally specified or verified. This makes it difficult to establish strong correctness properties, and to scale program verification across multiple layers. In this paper, we present a novel language-based account of abstraction layers and show that they correspond to a strong form of abstraction over a particularly rich class of specifications which we call deep specifications. Just as data abstraction in typed functional languages leads to the important representation independence property, abstraction over deep specification is characterized by an important implementation independence property: any two implementations of the same deep specification must have contextually equivalent behaviors. We present a new layer calculus showing how to formally specify, program, verify, and compose abstraction layers. We show how to instantiate the layer calculus in realistic programming languages such as C and assembly, and how to adapt the CompCert verified compiler to compile certified C layers such that they can be linked with assembly layers. Using these new languages and tools, we have successfully developed multiple certified OS kernels in the Coq proof assistant, the most realistic of which consists of 37 abstraction layers, took less than one person year to develop, and can boot a version of Linux as a guest.",
    "keywords": "abstraction layer, certified compilers, certified os kernels, deep specification, modularity, program verification",
    "URL": "http://doi.acm.org/10.1145/2676726.2676975",
    "DOI": "10.1145/2676726.2676975",
    "publisher-place": "New York, NY, USA",
    "page": "595-608",
    "page-first": "595",
    "_line": "FormalReview.bib:498"
  },
  "murawski_invitation_2016": {
    "id": "murawski_invitation_2016",
    "type": "article-journal",
    "author": [
      {
        "family": "Murawski",
        "given": "Andrzej S."
      },
      {
        "family": "Tzevelekos",
        "given": "Nikos"
      }
    ],
    "title": "An Invitation to Game Semantics",
    "container-title": "ACM SIGLOG News",
    "issued": {
      "date-parts": [
        [
          "2016",
          "5"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "1",
          "31"
        ]
      ]
    },
    "issn": "2372-3491",
    "abstract": "Game semantics is a flexible semantic theory that has led in recent years to an unprecedented number of full abstraction results for various programming paradigms. We present a gentle introduction to the subject, focussing on high-level ideas and examples with a view to providing a bridge to more technical literature.",
    "URL": "http://doi.acm.org/10.1145/2948896.2948902",
    "DOI": "10.1145/2948896.2948902",
    "page": "56-67",
    "page-first": "56",
    "volume": "3",
    "issue": "2",
    "_line": "FormalReview.bib:516"
  },
  "herlihy_linearizability:_1990": {
    "id": "herlihy_linearizability:_1990",
    "type": "article-journal",
    "author": [
      {
        "family": "Herlihy",
        "given": "Maurice P."
      },
      {
        "family": "Wing",
        "given": "Jeannette M."
      }
    ],
    "title": "Linearizability: A Correctness Condition for Concurrent Objects",
    "container-title": "ACM Trans. Program. Lang. Syst.",
    "container-title-short": "Linearizability",
    "title-short": "Linearizability",
    "issued": {
      "date-parts": [
        [
          "1990",
          "7"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "1",
          "31"
        ]
      ]
    },
    "issn": "0164-0925",
    "abstract": "A concurrent object is a data object shared by concurrent processes. Linearizability is a correctness condition for concurrent objects that exploits the semantics of abstract data types. It permits a high degree of concurrency, yet it permits programmers to specify and reason about concurrent objects using known techniques from the sequential domain. Linearizability provides the illusion that each operation applied by concurrent processes takes effect instantaneously at some point between its invocation and its response, implying that the meaning of a concurrent object's operations can be given by pre- and post-conditions. This paper defines linearizability, compares it to other correctness conditions, presents and demonstrates a method for proving the correctness of implementations, and shows how to reason about concurrent objects, given they are linearizable.",
    "URL": "http://doi.acm.org/10.1145/78969.78972",
    "DOI": "10.1145/78969.78972",
    "page": "463-492",
    "page-first": "463",
    "volume": "12",
    "issue": "3",
    "_line": "FormalReview.bib:532"
  },
  "gu_certikos:_2016": {
    "id": "gu_certikos:_2016",
    "type": "paper-conference",
    "author": [
      {
        "family": "Gu",
        "given": "Ronghui"
      },
      {
        "family": "Shao",
        "given": "Zhong"
      },
      {
        "family": "Chen",
        "given": "Hao"
      },
      {
        "family": "Wu",
        "given": "Xiongnan"
      },
      {
        "family": "Kim",
        "given": "Jieung"
      },
      {
        "family": "Sjöberg",
        "given": "Vilhelm"
      },
      {
        "family": "Costanzo",
        "given": "David"
      }
    ],
    "title": "CertiKOS: An Extensible Architecture for Building Certified Concurrent OS Kernels",
    "container-title": "Proceedings of the 12th USENIX Conference on Operating Systems Design and Implementation",
    "container-title-short": "CertiKOS",
    "collection-title": "OSDI'16",
    "title-short": "CertiKOS",
    "issued": {
      "date-parts": [
        [
          "2016"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "1",
          "31"
        ]
      ]
    },
    "publisher": "USENIX Association",
    "isbn": "978-1-931971-33-1",
    "abstract": "Complete formal verification of a non-trivial concurrent OS kernel is widely considered a grand challenge. We present a novel compositional approach for building certified concurrent OS kernels. Concurrency allows interleaved execution of kernel/user modules across different layers of abstraction. Each such layer can have a different set of observable events. We insist on formally specifying these layers and their observable events, and then verifying each kernel module at its proper abstraction level. To support certified linking with other CPUs or threads, we prove a strong contextual refinement property for every kernel function, which states that the implementation of each such function will behave like its specification under any kernel/user context with any valid interleaving. We have successfully developed a practical concurrent OS kernel and verified its (contextual) functional correctness in Coq. Our certified kernel is written in 6500 lines of C and x86 assembly and runs on stock x86 multicore machines. To our knowledge, this is the first proof of functional correctness of a complete, general-purpose concurrent OS kernel with fine-grained locking.",
    "URL": "http://dl.acm.org/citation.cfm?id=3026877.3026928",
    "publisher-place": "Berkeley, CA, USA",
    "page": "653-669",
    "page-first": "653",
    "_line": "FormalReview.bib:549"
  },
  "costanzo_end--end_nodate": {
    "id": "costanzo_end--end_nodate",
    "type": "article-journal",
    "author": [
      {
        "family": "Costanzo",
        "given": "David"
      },
      {
        "family": "Shao",
        "given": "Zhong"
      },
      {
        "family": "Gu",
        "given": "Ronghui"
      }
    ],
    "title": "End-to-End Veriﬁcation of Information-Flow Security for C and Assembly Programs - Tech Report",
    "abstract": "Protecting the conﬁdentiality of information manipulated by a computing system is one of the most important challenges facing today’s cybersecurity community. A promising step toward conquering this challenge is to formally verify that the end-to-end behavior of the computing system really satisﬁes various information-ﬂow policies. Unfortunately, because today’s system software still consists of both C and assembly programs, the end-to-end veriﬁcation necessarily requires that we not only prove the security properties of individual components, but also carefully preserve these properties through compilation and cross-language linking.",
    "URL": "http://flint.cs.yale.edu/certikos/publications/security-tr.pdf",
    "page": "21",
    "page-first": "21",
    "note": "certikos/pldi16-certikos-security-tr.pdf",
    "language": "en-US",
    "_line": "FormalReview.bib:566"
  },
  "costanzo_end--end_2016": {
    "id": "costanzo_end--end_2016",
    "type": "paper-conference",
    "author": [
      {
        "family": "Costanzo",
        "given": "David"
      },
      {
        "family": "Shao",
        "given": "Zhong"
      },
      {
        "family": "Gu",
        "given": "Ronghui"
      }
    ],
    "title": "End-to-end Verification of Information-flow Security for C and Assembly Programs",
    "container-title": "Proceedings of the 37th ACM SIGPLAN Conference on Programming Language Design and Implementation",
    "collection-title": "PLDI '16",
    "issued": {
      "date-parts": [
        [
          "2016"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "1",
          "31"
        ]
      ]
    },
    "publisher": "ACM",
    "isbn": "978-1-4503-4261-2",
    "abstract": "Protecting the confidentiality of information manipulated by a computing system is one of the most important challenges facing today's cybersecurity community. A promising step toward conquering this challenge is to formally verify that the end-to-end behavior of the computing system really satisfies various information-flow policies. Unfortunately, because today's system software still consists of both C and assembly programs, the end-to-end verification necessarily requires that we not only prove the security properties of individual components, but also carefully preserve these properties through compilation and cross-language linking. In this paper, we present a novel methodology for formally verifying end-to-end security of a software system that consists of both C and assembly programs. We introduce a general definition of observation function that unifies the concepts of policy specification, state indistinguishability, and whole-execution behaviors. We show how to use different observation functions for different levels of abstraction, and how to link different security proofs across abstraction levels using a special kind of simulation that is guaranteed to preserve state indistinguishability. To demonstrate the effectiveness of our new methodology, we have successfully constructed an end-to-end security proof, fully formalized in the Coq proof assistant, of a nontrivial operating system kernel (running on an extended CompCert x86 assembly machine model). Some parts of the kernel are written in C and some are written in assembly; we verify all of the code, regardless of language.",
    "keywords": "Certified OS Kernels, Information Flow Control, Program Verification, Security Policy Specification, Security-Preserving Simulation",
    "URL": "http://doi.acm.org/10.1145/2908080.2908100",
    "DOI": "10.1145/2908080.2908100",
    "publisher-place": "New York, NY, USA",
    "page": "648-664",
    "page-first": "648",
    "_line": "FormalReview.bib:577"
  },
  "gu_certified_2018": {
    "id": "gu_certified_2018",
    "type": "paper-conference",
    "author": [
      {
        "family": "Gu",
        "given": "Ronghui"
      },
      {
        "family": "Shao",
        "given": "Zhong"
      },
      {
        "family": "Kim",
        "given": "Jieung"
      },
      {
        "family": "Wu",
        "given": "Xiongnan (Newman)"
      },
      {
        "family": "Koenig",
        "given": "Jérémie"
      },
      {
        "family": "Sjöberg",
        "given": "Vilhelm"
      },
      {
        "family": "Chen",
        "given": "Hao"
      },
      {
        "family": "Costanzo",
        "given": "David"
      },
      {
        "family": "Ramananandro",
        "given": "Tahina"
      }
    ],
    "title": "Certified Concurrent Abstraction Layers",
    "container-title": "Proceedings of the 39th ACM SIGPLAN Conference on Programming Language Design and Implementation",
    "collection-title": "PLDI 2018",
    "issued": {
      "date-parts": [
        [
          "2018"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "1",
          "31"
        ]
      ]
    },
    "publisher": "ACM",
    "isbn": "978-1-4503-5698-5",
    "abstract": "Concurrent abstraction layers are ubiquitous in modern computer systems because of the pervasiveness of multithreaded programming and multicore hardware. Abstraction layers are used to hide the implementation details (e.g., fine-grained synchronization) and reduce the complex dependencies among components at different levels of abstraction. Despite their obvious importance, concurrent abstraction layers have not been treated formally. This severely limits the applicability of layer-based techniques and makes it difficult to scale verification across multiple concurrent layers.   In this paper, we present CCAL&mdash;a fully mechanized programming toolkit developed under the CertiKOS project&mdash;for specifying, composing, compiling, and linking certified concurrent abstraction layers. CCAL consists of three technical novelties: a new game-theoretical, strategy-based compositional semantic model for concurrency (and its associated program verifiers), a set of formal linking theorems for composing multithreaded and multicore concurrent layers, and a new CompCertX compiler that supports certified thread-safe compilation and linking. The CCAL toolkit is implemented in Coq and supports layered concurrent programming in both C and assembly. It has been successfully applied to build a fully certified concurrent OS kernel with fine-grained locking.",
    "keywords": "abstraction layer, certified compilers, modularity, certified OS kernels, concurrency, Verification",
    "URL": "http://doi.acm.org/10.1145/3192366.3192381",
    "DOI": "10.1145/3192366.3192381",
    "publisher-place": "New York, NY, USA",
    "page": "646-661",
    "page-first": "646",
    "_line": "FormalReview.bib:595"
  },
  "chargueraud_program_2010": {
    "id": "chargueraud_program_2010",
    "type": "paper-conference",
    "author": [
      {
        "family": "Charguéraud",
        "given": "Arthur"
      }
    ],
    "title": "Program Verification Through Characteristic Formulae",
    "container-title": "Proceedings of the 15th ACM SIGPLAN International Conference on Functional Programming",
    "collection-title": "ICFP '10",
    "issued": {
      "date-parts": [
        [
          "2010"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "1",
          "31"
        ]
      ]
    },
    "publisher": "ACM",
    "isbn": "978-1-60558-794-3",
    "abstract": "This paper describes CFML, the first program verification tool based on characteristic formulae. Given the source code of a pure Caml program, this tool generates a logical formula that implies any valid post-condition for that program. One can then prove that the program satisfies a given specification by reasoning interactively about the characteristic formula using a proof assistant such as Coq. Our characteristic formulae improve over Honda et al's total characteristic assertion pairs in that they are expressible in standard higher-order logic, allowing to exploit them in practice to verify programs using existing proof assistants. Our technique has been applied to formally verify more than half of the content of Okasaki's Purely Functional Data Structures reference book",
    "keywords": "characteristic formula, functional program, total correctness",
    "URL": "http://doi.acm.org/10.1145/1863543.1863590",
    "DOI": "10.1145/1863543.1863590",
    "publisher-place": "New York, NY, USA",
    "page": "321-332",
    "page-first": "321",
    "_line": "FormalReview.bib:613"
  },
  "chargueraud_characteristic_2011": {
    "id": "chargueraud_characteristic_2011",
    "type": "paper-conference",
    "author": [
      {
        "family": "Charguéraud",
        "given": "Arthur"
      }
    ],
    "title": "Characteristic Formulae for the Verification of Imperative Programs",
    "container-title": "Proceedings of the 16th ACM SIGPLAN International Conference on Functional Programming",
    "collection-title": "ICFP '11",
    "issued": {
      "date-parts": [
        [
          "2011"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "1",
          "31"
        ]
      ]
    },
    "publisher": "ACM",
    "isbn": "978-1-4503-0865-6",
    "abstract": "In previous work, we introduced an approach to program verification based on characteristic formulae. The approach consists of generating a higher-order logic formula from the source code of a program. This characteristic formula is constructed in such a way that it gives a sound and complete description of the semantics of that program. The formula can thus be exploited in an interactive proof assistant to formally verify that the program satisfies a particular specification. This previous work was, however, only concerned with purely-functional programs. In the present paper, we describe the generalization of characteristic formulae to an imperative programming language. In this setting, characteristic formulae involve specifications expressed in the style of Separation Logic. They also integrate the frame rule, which enables local reasoning. We have implemented a tool based on characteristic formulae. This tool, called CFML, supports the verification of imperative Caml programs using the Coq proof assistant. Using CFML, we have formally verified nontrivial imperative algorithms, as well as CPS functions, higher-order iterators, and programs involving higher-order stores.",
    "keywords": "characteristic formula, total correctness, interactive verification",
    "URL": "http://doi.acm.org/10.1145/2034773.2034828",
    "DOI": "10.1145/2034773.2034828",
    "publisher-place": "New York, NY, USA",
    "page": "418-430",
    "page-first": "418",
    "_line": "FormalReview.bib:631"
  },
  "chargueraud_characteristic_2010": {
    "id": "chargueraud_characteristic_2010",
    "type": "thesis",
    "genre": "phdthesis",
    "author": [
      {
        "family": "Charguéraud",
        "given": "Arthur"
      }
    ],
    "title": "Characteristic Formulae for Mechanized Program Verification",
    "issued": {
      "date-parts": [
        [
          "2010",
          "12",
          "16"
        ]
      ]
    },
    "publisher": "UNIVERSITÉ PARIS.DIDEROT",
    "number-of-pages": "185",
    "abstract": "This dissertation describes a new approach to program veri cation,\nbased on characteristic formulae. The characteristic formula of a program\nis a higher-order logic formula that describes the behavior of that\nprogram, in the sense that it is sound and complete with respect to\nthe semantics. This formula can be exploited in an interactive theorem\nprover to establish that the program satis es a speci cation expressed\nin the style of Separation Logic, with respect to total correctness.\nThe characteristic formula of a program is automatically generated\nfrom its source code alone. In particular, there is no need to annotate the\nsource code with speci cations or loop invariants, as such information\ncan be given in interactive proof scripts. One key feature of characteristic\nformulae is that they are of linear size and that they can be prettyprinted\nin a way that closely resemble the source code they describe, even\nthough they do not refer to the syntax of the programming language.\nCharacteristic formulae serve as a basis for a tool, called CFML, that\nsupports the veri cation of Caml programs using the Coq proof assistant.\nCFML has been employed to verify about half of the content of\nOkasaki's book on purely functional data structures, and to verify several\nimperative data structures such as mutable lists, sparse arrays and\nunion- nd. CFML also supports reasoning on higher-order imperative\nfunctions, such as functions in CPS form and higher-order iterators",
    "publisher-place": "Paris, France",
    "note": "chargueraud/chargueraud&underscore;thesis&underscore;final.pdf",
    "language": "en-US",
    "_line": "FormalReview.bib:649"
  },
  "chlipala_introduction_nodate": {
    "id": "chlipala_introduction_nodate",
    "type": "article-journal",
    "author": [
      {
        "family": "Chlipala",
        "given": "Adam"
      }
    ],
    "title": "An Introduction to Programming and Proving with Dependent Types in Coq",
    "container-title": "Journal of Formalized Reasoning",
    "abstract": "Computer proof assistants vary along many dimensions. Among the mature implementations, the Coq system is distinguished by two key features. First, we have support for programming with\ndependent types in the tradition of type theory, based on dependent function types and inductive type families. Second, we have a domain-specific language for coding correct-by-construction proof automation. Though the Coq user community has grown quite large, neither of the aspects\nI highlight is widely used. In this tutorial, I aim to provide a pragmatic introduction to both, showing how they can bring significant improvements in productivity.",
    "page": "93",
    "page-first": "93",
    "volume": "3",
    "note": "chlipala/1978-4445-1-PB.pdf",
    "issue": "2",
    "language": "en-US",
    "_line": "FormalReview.bib:683"
  },
  "chlipala_certified_2013": {
    "id": "chlipala_certified_2013",
    "type": "book",
    "author": [
      {
        "family": "Chlipala",
        "given": "Adam"
      }
    ],
    "title": "Certified programming with dependent types: a pragmatic introduction to the Coq proof assistant",
    "container-title-short": "Certified programming with dependent types",
    "title-short": "Certified programming with dependent types",
    "issued": {
      "date-parts": [
        [
          "2013"
        ]
      ]
    },
    "publisher": "The MIT Press",
    "number-of-pages": "424",
    "isbn": "978-0-262-02665-9",
    "keywords": "Automatic theorem proving, Computer programming, Computer programs, Coq (Electronic resource)",
    "URL": "http://adam.chlipala.net/cpdt/",
    "publisher-place": "Cambridge, MA",
    "_line": "FormalReview.bib:698"
  },
  "chlipala_certied_nodate": {
    "id": "chlipala_certied_nodate",
    "type": "article-journal",
    "author": [
      {
        "family": "Chlipala",
        "given": "Adam"
      }
    ],
    "title": "Certiﬁed Programming with Dependent Types",
    "page": "369",
    "page-first": "369",
    "language": "en-US",
    "_line": "FormalReview.bib:711"
  },
  "chlipala_formal_2019": {
    "id": "chlipala_formal_2019",
    "type": "book",
    "author": [
      {
        "family": "Chlipala",
        "given": "Adam"
      }
    ],
    "title": "Formal Reasoning About Programs - Github",
    "issued": {
      "date-parts": [
        [
          "2019",
          "1",
          "31"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "1",
          "31"
        ]
      ]
    },
    "URL": "https://github.com/achlipala/frap",
    "note": "original-date: 2016-02-02T18:43:56Z",
    "_line": "FormalReview.bib:719"
  },
  "pit-claudel_extensible_nodate": {
    "id": "pit-claudel_extensible_nodate",
    "type": "article-journal",
    "author": [
      {
        "family": "Pit-Claudel",
        "given": "Clément"
      },
      {
        "family": "Wang",
        "given": "Peng"
      },
      {
        "family": "Delaware",
        "given": "Benjamin"
      },
      {
        "family": "Gross",
        "given": "Jason"
      },
      {
        "family": "Chlipala",
        "given": "Adam"
      }
    ],
    "title": "Extensible Extraction of Efﬁcient Imperative Programs with Foreign Functions, Manually Managed Memory, and Proofs",
    "abstract": "We present an original approach to sound program extraction in a proof assistant, using syntax-driven automation to derive correct-by-construction imperative programs from nondeterministic functional source code. Our approach does not require committing to a single inﬂexible compilation strategy and instead makes it straightforward to create domainspeciﬁc code translators. In addition to a small set of core definitions, our framework is a large, user-extensible collection of compilation rules each phrased to handle speciﬁc language constructs, code patterns, or data manipulations. By mixing and matching these pieces of logic, users can easily tailor extraction to their own domains and programs, getting maximum performance and ensuring correctness of the resulting assembly code. Using this approach, we complete the ﬁrst proof-generating pipeline that goes automatically from high-level speciﬁcations to assembly code. In our main case study, the original speciﬁcations are phrased to resemble SQL-style queries, while the ﬁnal assembly code does manual memory management, calls out to foreign data structures and functions, and is suitable to deploy on resource-constrained platforms. The pipeline runs entirely within the Coq proof assistant, leading to ﬁnal, linked assembly code inside Coq with overall full-functional-correctness proofs in separation logic.",
    "URL": "http://pit-claudel.fr/clement/papers/fiat-to-facade.pdf",
    "page": "14",
    "page-first": "14",
    "note": "clement/fiat-to-facade.pdg",
    "language": "en-US",
    "_line": "FormalReview.bib:729"
  },
  "feng_correct-by-construction_2018": {
    "id": "feng_correct-by-construction_2018",
    "type": "chapter",
    "author": [
      {
        "family": "Zhang",
        "given": "Teng"
      },
      {
        "family": "Wiegley",
        "given": "John"
      },
      {
        "family": "Giannakopoulos",
        "given": "Theophilos"
      },
      {
        "family": "Eakman",
        "given": "Gregory"
      },
      {
        "family": "Pit-Claudel",
        "given": "Clément"
      },
      {
        "family": "Lee",
        "given": "Insup"
      },
      {
        "family": "Sokolsky",
        "given": "Oleg"
      }
    ],
    "editor": [
      {
        "family": "Feng",
        "given": "Xinyu"
      },
      {
        "family": "Müller-Olm",
        "given": "Markus"
      },
      {
        "family": "Yang",
        "given": "Zijiang"
      }
    ],
    "title": "Correct-by-Construction Implementation of Runtime Monitors Using Stepwise Refinement",
    "container-title": "Dependable Software Engineering. Theories, Tools, and Applications",
    "issued": {
      "date-parts": [
        [
          "2018"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "1",
          "31"
        ]
      ]
    },
    "publisher": "Springer International Publishing",
    "isbn": "978-3-319-99932-6 978-3-319-99933-3",
    "URL": "http://link.springer.com/10.1007/978-3-319-99933-3_3",
    "DOI": "10.1007/978-3-319-99933-3_3",
    "publisher-place": "Cham",
    "page": "31-49",
    "page-first": "31",
    "volume": "10998",
    "_line": "FormalReview.bib:740"
  },
  "martin_mastering_2013": {
    "id": "martin_mastering_2013",
    "type": "book",
    "author": [
      {
        "family": "Martin",
        "given": "Ken"
      },
      {
        "family": "Hoffman",
        "given": "Bill"
      },
      {
        "family": "Cedilnik",
        "given": "Andy"
      }
    ],
    "title": "Mastering CMake: a cross-platform build system ; covers installing and running CMake ; details converting existing build processes to CMake ; create powerful cross-platform build scripts",
    "container-title-short": "Mastering CMake",
    "title-short": "Mastering CMake",
    "issued": {
      "date-parts": [
        [
          "2013"
        ]
      ]
    },
    "publisher": "Kitware",
    "number-of-pages": "640",
    "edition": "6. ed",
    "isbn": "978-1-930934-26-9",
    "publisher-place": "Clifton Park, NY",
    "note": "OCLC: 869872480",
    "_line": "FormalReview.bib:757"
  },
  "absint_compcert_nodate": {
    "id": "absint_compcert_nodate",
    "type": "webpage",
    "author": [
      {
        "family": "Absint"
      }
    ],
    "title": "CompCert - Publications",
    "accessed": {
      "date-parts": [
        [
          "2019",
          "1",
          "31"
        ]
      ]
    },
    "URL": "http://compcert.inria.fr/publi.html",
    "_line": "FormalReview.bib:771"
  },
  "chaudhuri_trigger_2016": {
    "id": "chaudhuri_trigger_2016",
    "type": "chapter",
    "author": [
      {
        "family": "Leino",
        "given": "K. R. M."
      },
      {
        "family": "Pit-Claudel",
        "given": "Clément"
      }
    ],
    "editor": [
      {
        "family": "Chaudhuri",
        "given": "Swarat"
      },
      {
        "family": "Farzan",
        "given": "Azadeh"
      }
    ],
    "title": "Trigger Selection Strategies to Stabilize Program Verifiers",
    "container-title": "Computer Aided Verification",
    "issued": {
      "date-parts": [
        [
          "2016"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "1",
          "31"
        ]
      ]
    },
    "publisher": "Springer International Publishing",
    "isbn": "978-3-319-41527-7 978-3-319-41528-4",
    "URL": "http://link.springer.com/10.1007/978-3-319-41528-4_20",
    "DOI": "10.1007/978-3-319-41528-4_20",
    "publisher-place": "Cham",
    "page": "361-381",
    "page-first": "361",
    "volume": "9779",
    "_line": "FormalReview.bib:779"
  },
  "pit-claudel_clement_nodate": {
    "id": "pit-claudel_clement_nodate",
    "type": "webpage",
    "author": [
      {
        "family": "Pit-Claudel",
        "given": "Clément"
      }
    ],
    "title": "Clément Pit-Claudel",
    "accessed": {
      "date-parts": [
        [
          "2019",
          "1",
          "31"
        ]
      ]
    },
    "URL": "http://pit-claudel.fr/clement/",
    "_line": "FormalReview.bib:796"
  },
  "bertot_interactive_2004": {
    "id": "bertot_interactive_2004",
    "type": "book",
    "author": [
      {
        "family": "Bertot",
        "given": "Yves"
      },
      {
        "family": "Castéran",
        "given": "P."
      }
    ],
    "title": "Interactive theorem proving and program development: Coq'Art: the calculus of inductive constructions",
    "container-title-short": "Interactive theorem proving and program development",
    "collection-title": "Texts in theoretical computer science",
    "title-short": "Interactive theorem proving and program development",
    "issued": {
      "date-parts": [
        [
          "2004"
        ]
      ]
    },
    "publisher": "Springer",
    "number-of-pages": "469",
    "isbn": "978-3-540-20854-9",
    "keywords": "Automatic theorem proving, Computer programming",
    "URL": "http://www.labri.fr/perso/casteran/CoqArt/index.html",
    "publisher-place": "Berlin ; New York",
    "note": "OCLC: ocm55514299",
    "_line": "FormalReview.bib:804"
  },
  "casteran_pierre_nodate": {
    "id": "casteran_pierre_nodate",
    "type": "webpage",
    "author": [
      {
        "family": "Castéran",
        "given": "Pierre"
      }
    ],
    "title": "Pierre Castéran's Home page",
    "accessed": {
      "date-parts": [
        [
          "2019",
          "1",
          "31"
        ]
      ]
    },
    "URL": "http://www.labri.fr/perso/casteran/index.html",
    "_line": "FormalReview.bib:819"
  },
  "bertot_yves_nodate": {
    "id": "bertot_yves_nodate",
    "type": "webpage",
    "author": [
      {
        "family": "Bertot",
        "given": "Yves"
      }
    ],
    "title": "Yves Bertot",
    "accessed": {
      "date-parts": [
        [
          "2019",
          "1",
          "31"
        ]
      ]
    },
    "URL": "http://www-sop.inria.fr/members/Yves.Bertot/index.html",
    "_line": "FormalReview.bib:827"
  },
  "inria_inria_nodate": {
    "id": "inria_inria_nodate",
    "type": "webpage",
    "author": [
      {
        "family": "Inria"
      }
    ],
    "title": "Inria - Inventors for the digital world.Inria",
    "accessed": {
      "date-parts": [
        [
          "2019",
          "1",
          "31"
        ]
      ]
    },
    "abstract": "Inria is a public research body dedicated to digital science and technology.",
    "URL": "https://www.inria.fr/en",
    "language": "en-US",
    "_line": "FormalReview.bib:835"
  },
  "crary_modules_2017": {
    "id": "crary_modules_2017",
    "type": "paper-conference",
    "author": [
      {
        "family": "Crary",
        "given": "Karl"
      }
    ],
    "title": "Modules, Abstraction, and Parametric Polymorphism",
    "container-title": "Proceedings of the 44th ACM SIGPLAN Symposium on Principles of Programming Languages",
    "collection-title": "POPL 2017",
    "issued": {
      "date-parts": [
        [
          "2017"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "1",
          "31"
        ]
      ]
    },
    "publisher": "ACM",
    "isbn": "978-1-4503-4660-3",
    "abstract": "Reynolds's Abstraction theorem forms the mathematical foundation for data abstraction. His setting was the polymorphic lambda calculus. Today, many modern languages, such as the ML family, employ rich module systems designed to give more expressive support for data abstraction than the polymorphic lambda calculus, but analogues of the Abstraction theorem for such module systems have lagged far behind.   We give an account of the Abstraction theorem for a modern module calculus supporting generative and applicative functors, higher-order functors, sealing, and translucent signatures. The main issues to be overcome are: (1) the fact that modules combine both types and terms, so they must be treated as both simultaneously, (2) the effect discipline that models the distinction between transparent and opaque modules, and (3) a very rich language of type constructors supporting singleton kinds. We define logical equivalence for modules and show that it coincides with contextual equivalence. This substantiates the folk theorem that modules are good for data abstraction. All our proofs are formalized in Coq.",
    "keywords": "Abstraction, logical relations, modules, parametricity",
    "URL": "http://doi.acm.org/10.1145/3009837.3009892",
    "DOI": "10.1145/3009837.3009892",
    "publisher-place": "New York, NY, USA",
    "page": "100-113",
    "page-first": "100",
    "note": "crary/crary-mapp.pdf",
    "_line": "FormalReview.bib:846"
  },
  "platzer_differential_2018": {
    "id": "platzer_differential_2018",
    "type": "chapter",
    "author": [
      {
        "family": "Platzer",
        "given": "André"
      }
    ],
    "container-author": [
      {
        "family": "Platzer",
        "given": "André"
      }
    ],
    "title": "Differential Equations &amp; Differential Invariants",
    "container-title": "Logical Foundations of Cyber-Physical Systems",
    "issued": {
      "date-parts": [
        [
          "2018"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "1",
          "31"
        ]
      ]
    },
    "publisher": "Springer International Publishing",
    "isbn": "978-3-319-63587-3 978-3-319-63588-0",
    "URL": "http://link.springer.com/10.1007/978-3-319-63588-0_10",
    "DOI": "10.1007/978-3-319-63588-0_10",
    "publisher-place": "Cham",
    "page": "287-322",
    "page-first": "287",
    "language": "en-US",
    "_line": "FormalReview.bib:865"
  },
  "platzer_differential_2015": {
    "id": "platzer_differential_2015",
    "type": "article-journal",
    "author": [
      {
        "family": "Platzer",
        "given": "André"
      }
    ],
    "title": "Differential Game Logic",
    "container-title": "ACM Trans. Comput. Logic",
    "issued": {
      "date-parts": [
        [
          "2015",
          "11"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "1",
          "31"
        ]
      ]
    },
    "issn": "1529-3785",
    "abstract": "Differential game logic (dGL) is a logic for specifying and verifying properties of hybrid games, i.e., games that combine discrete, continuous, and adversarial dynamics. Unlike hybrid systems, hybrid games allow choices in the system dynamics to be resolved adversarially by different players with different objectives. The logic dGL can be used to study the existence of winning strategies for such hybrid games, i.e., ways of resolving the player’s choices in some way so that he wins by achieving his objective for all choices of the opponent. Hybrid games are determined, i.e., from each state, one player has a winning strategy, yet computing their winning regions may take transfinitely many steps. The logic dGL, nevertheless, has a sound and complete axiomatization relative to any expressive logic. Separating axioms are identified that distinguish hybrid games from hybrid systems. Finally, dGL is proved to be strictly more expressive than the corresponding logic of hybrid systems by characterizing the expressiveness of both.",
    "keywords": "axiomatization, expressiveness, Game logic, hybrid games",
    "URL": "http://doi.acm.org/10.1145/2817824",
    "DOI": "10.1145/2817824",
    "page": "1:1-1:51",
    "page-first": "1",
    "volume": "17",
    "issue": "1",
    "_line": "FormalReview.bib:882"
  },
  "platzer_differential_2008": {
    "id": "platzer_differential_2008",
    "type": "article-journal",
    "author": [
      {
        "family": "Platzer",
        "given": "André"
      }
    ],
    "title": "Differential Dynamic Logic for Hybrid Systems",
    "container-title": "Journal of Automated Reasoning",
    "issued": {
      "date-parts": [
        [
          "2008",
          "8"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "1",
          "31"
        ]
      ]
    },
    "issn": "0168-7433, 1573-0670",
    "URL": "http://link.springer.com/10.1007/s10817-008-9103-8",
    "DOI": "10.1007/s10817-008-9103-8",
    "page": "143-189",
    "page-first": "143",
    "volume": "41",
    "issue": "2",
    "language": "en-US",
    "_line": "FormalReview.bib:899"
  },
  "hutchison_verifying_2007": {
    "id": "hutchison_verifying_2007",
    "type": "chapter",
    "author": [
      {
        "family": "Ahrendt",
        "given": "Wolfgang"
      },
      {
        "family": "Beckert",
        "given": "Bernhard"
      },
      {
        "family": "Hähnle",
        "given": "Reiner"
      },
      {
        "family": "Rümmer",
        "given": "Philipp"
      },
      {
        "family": "Schmitt",
        "given": "Peter H."
      }
    ],
    "editor": [
      {
        "family": "Boer",
        "given": "Frank S.",
        "dropping-particle": "de"
      },
      {
        "family": "Bonsangue",
        "given": "Marcello M."
      },
      {
        "family": "Graf",
        "given": "Susanne"
      },
      {
        "family": "Roever",
        "given": "Willem-Paul",
        "dropping-particle": "de"
      }
    ],
    "title": "Verifying Object-Oriented Programs with KeY: A Tutorial",
    "container-title": "Formal Methods for Components and Objects",
    "container-title-short": "Verifying Object-Oriented Programs with KeY",
    "title-short": "Verifying Object-Oriented Programs with KeY",
    "issued": {
      "date-parts": [
        [
          "2007"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "1",
          "31"
        ]
      ]
    },
    "publisher": "Springer Berlin Heidelberg",
    "isbn": "978-3-540-74791-8 978-3-540-74792-5",
    "abstract": "This paper is a tutorial on performing formal speciﬁcation and semi-automatic veriﬁcation of Java programs with the formal software development tool KeY. This tutorial aims to ﬁll the gap between elementary introductions using toy examples and state-of-art case studies by going through a self-contained, yet non-trivial, example. It is hoped that this contributes to explain the problems encountered in veriﬁcation of imperative, object-oriented programs to a readership outside the limited community of active researchers.",
    "URL": "http://link.springer.com/10.1007/978-3-540-74792-5_4",
    "DOI": "10.1007/978-3-540-74792-5_4",
    "publisher-place": "Berlin, Heidelberg",
    "page": "70-101",
    "page-first": "70",
    "volume": "4709",
    "language": "en-US",
    "_line": "FormalReview.bib:915"
  },
  "platzer_logical_2018": {
    "id": "platzer_logical_2018",
    "type": "book",
    "author": [
      {
        "family": "Platzer",
        "given": "Andre"
      }
    ],
    "title": "Logical Foundations of Cyber-Physical Systems",
    "issued": {
      "date-parts": [
        [
          "2018"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "1",
          "31"
        ]
      ]
    },
    "publisher": "Springer International Publishing",
    "isbn": "978-3-319-63587-3",
    "abstract": "Cyber-physical systems (CPSs) combine cyber capabilities, such as computation or communication, with physical capabilities, such as motion or other physical processes. Cars, aircraft, and robots are prime examples, because they move physically in space in a way that is determined by discrete computerized control algorithms. Designing these algorithms is challenging due to their tight coupling with physical behavior, while it is vital that these algorithms be correct because we rely on them for safety-critical tasks. This textbook teaches undergraduate students the core principles behind CPSs. It shows them how to develop models and controls; identify safety specifications and critical properties; reason rigorously about CPS models; leverage multi-dynamical systems compositionality to tame CPS complexity; identify required control constraints; verify CPS models of appropriate scale in logic; and develop an intuition for operational effects. The book is supported with homework exercises, lecture videos, and slides.",
    "URL": "https://www.springer.com/gp/book/9783319635873",
    "language": "en-US",
    "_line": "FormalReview.bib:937"
  },
  "platzer_keymaera_nodate": {
    "id": "platzer_keymaera_nodate",
    "type": "webpage",
    "author": [
      {
        "family": "Platzer",
        "given": "André"
      }
    ],
    "title": "KeYmaera X: Documentation",
    "accessed": {
      "date-parts": [
        [
          "2019",
          "1",
          "31"
        ]
      ]
    },
    "URL": "http://www.ls.cs.cmu.edu/KeYmaeraX/documentation.html",
    "_line": "FormalReview.bib:950"
  },
  "felty_keymaera_2015": {
    "id": "felty_keymaera_2015",
    "type": "chapter",
    "author": [
      {
        "family": "Fulton",
        "given": "Nathan"
      },
      {
        "family": "Mitsch",
        "given": "Stefan"
      },
      {
        "family": "Quesel",
        "given": "Jan-David"
      },
      {
        "family": "Völp",
        "given": "Marcus"
      },
      {
        "family": "Platzer",
        "given": "André"
      }
    ],
    "editor": [
      {
        "family": "Felty",
        "given": "Amy P."
      },
      {
        "family": "Middeldorp",
        "given": "Aart"
      }
    ],
    "title": "KeYmaera X: An Axiomatic Tactical Theorem Prover for Hybrid Systems",
    "container-title": "Automated Deduction - CADE-25",
    "container-title-short": "KeYmaera X",
    "title-short": "KeYmaera X",
    "issued": {
      "date-parts": [
        [
          "2015"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "1",
          "31"
        ]
      ]
    },
    "publisher": "Springer International Publishing",
    "isbn": "978-3-319-21400-9 978-3-319-21401-6",
    "abstract": "KeYmaera X is a theorem prover for differential dynamic logic (dL), a logic for specifying and verifying properties of hybrid systems. Reasoning about complicated hybrid systems models requires support for sophisticated proof techniques, efﬁcient computation, and a user interface that crystallizes salient properties of the system. KeYmaera X allows users to specify custom proof search techniques as tactics, execute these tactics in parallel, and interface with partial proofs via an extensible user interface.",
    "URL": "http://link.springer.com/10.1007/978-3-319-21401-6_36",
    "DOI": "10.1007/978-3-319-21401-6_36",
    "publisher-place": "Cham",
    "page": "527-538",
    "page-first": "527",
    "volume": "9195",
    "language": "en-US",
    "_line": "FormalReview.bib:958"
  },
  "platzer_logical_2018-1": {
    "id": "platzer_logical_2018-1",
    "type": "book",
    "author": [
      {
        "family": "Platzer",
        "given": "André"
      }
    ],
    "title": "Logical Foundations of Cyber-Physical Systems - Slides",
    "issued": {
      "date-parts": [
        [
          "2018"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "1",
          "31"
        ]
      ]
    },
    "publisher": "Springer International Publishing",
    "isbn": "978-3-319-63587-3 978-3-319-63588-0",
    "URL": "http://link.springer.com/10.1007/978-3-319-63588-0",
    "DOI": "10.1007/978-3-319-63588-0",
    "publisher-place": "Cham",
    "language": "en-US",
    "_line": "FormalReview.bib:978"
  },
  "platzer_complete_2017": {
    "id": "platzer_complete_2017",
    "type": "article-journal",
    "author": [
      {
        "family": "Platzer",
        "given": "André"
      }
    ],
    "title": "A Complete Uniform Substitution Calculus for Differential Dynamic Logic",
    "container-title": "Journal of Automated Reasoning",
    "issued": {
      "date-parts": [
        [
          "2017",
          "8"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "1",
          "31"
        ]
      ]
    },
    "issn": "0168-7433, 1573-0670",
    "abstract": "This article introduces a relatively complete proof calculus for differential dynamic logic (dL) that is entirely based on uniform substitution, a proof rule that substitutes a formula for a predicate symbol everywhere. Uniform substitutions make it possible to use axioms instead of axiom schemata, thereby substantially simplifying implementations. Instead of subtle schema variables and soundness-critical side conditions on the occurrence patterns of logical variables to restrict infinitely many axiom schema instances to sound ones, the resulting calculus adopts only a finite number of ordinary dL formulas as axioms, which uniform substitutions instantiate soundly. The static semantics of differential dynamic logic and the soundness-critical restrictions it imposes on proof steps is captured exclusively in uniform substitutions and variable renamings as opposed to being spread in delicate ways across the prover implementation. In addition to sound uniform substitutions, this article introduces differential forms for differential dynamic logic that make it possible to internalize differential invariants, differential substitutions, and derivatives as first-class axioms to reason about differential equations axiomatically. The resulting axiomatization of differential dynamic logic is proved to be sound and relatively complete.",
    "keywords": "Computer Science - Logic in Computer Science, Computer Science - Programming Languages, 03F03, 03B70, 34A38, F.3.1, F.3.2, F.4.1, I.2.3, Mathematics - Logic",
    "URLtext": "1601.06183",
    "URLpretext": "[arXiv:]{.etype}",
    "eprint-type": "arxiv",
    "eprint": "1601.06183",
    "URL": "http://arxiv.org/abs/1601.06183",
    "DOI": "10.1007/s10817-016-9385-1",
    "page": "219-265",
    "page-first": "219",
    "volume": "59",
    "issue": "2",
    "_line": "FormalReview.bib:992"
  },
  "beckert_verification_2006": {
    "id": "beckert_verification_2006",
    "type": "book",
    "editor": [
      {
        "family": "Beckert",
        "given": "Bernhard"
      },
      {
        "family": "Hähnle",
        "given": "Reiner"
      },
      {
        "family": "Schmitt",
        "given": "Peter H."
      }
    ],
    "title": "Verification of Object-Oriented Software. The KeY Approach",
    "collection-title": "Lecture Notes in Computer Science",
    "issued": {
      "date-parts": [
        [
          "2006"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "1",
          "31"
        ]
      ]
    },
    "publisher": "Springer Berlin Heidelberg",
    "isbn": "978-3-540-68977-5",
    "URL": "http://link.springer.com/10.1007/978-3-540-69061-0",
    "DOI": "10.1007/978-3-540-69061-0",
    "publisher-place": "Berlin, Heidelberg",
    "volume": "4334",
    "language": "en-US",
    "_line": "FormalReview.bib:1011"
  },
  "bohrer_veriphy:_2018": {
    "id": "bohrer_veriphy:_2018",
    "type": "paper-conference",
    "author": [
      {
        "family": "Bohrer",
        "given": "Brandon"
      },
      {
        "family": "Tan",
        "given": "Yong Kiam"
      },
      {
        "family": "Mitsch",
        "given": "Stefan"
      },
      {
        "family": "Myreen",
        "given": "Magnus O."
      },
      {
        "family": "Platzer",
        "given": "André"
      }
    ],
    "title": "VeriPhy: verified controller executables from verified cyber-physical system models",
    "container-title": "Proceedings of the 39th ACM SIGPLAN Conference on Programming Language Design and Implementation  - PLDI 2018",
    "container-title-short": "VeriPhy",
    "title-short": "VeriPhy",
    "event-title": "the 39th ACM SIGPLAN Conference",
    "issued": {
      "date-parts": [
        [
          "2018"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "1",
          "31"
        ]
      ]
    },
    "publisher": "ACM Press",
    "isbn": "978-1-4503-5698-5",
    "URL": "http://dl.acm.org/citation.cfm?doid=3192366.3192406",
    "DOI": "10.1145/3192366.3192406",
    "publisher-place": "Philadelphia, PA, USA",
    "page": "617-630",
    "page-first": "617",
    "language": "en-US",
    "_line": "FormalReview.bib:1027"
  },
  "ahrendt_deductive_nodate": {
    "id": "ahrendt_deductive_nodate",
    "type": "webpage",
    "author": [
      {
        "family": "Ahrendt",
        "given": "Wolfgang"
      }
    ],
    "title": "Deductive Software Verification – The KeY BookFrom Theory to Practice – The KeY Project",
    "accessed": {
      "date-parts": [
        [
          "2019",
          "1",
          "31"
        ]
      ]
    },
    "URL": "https://www.key-project.org/thebook2/",
    "note": "cyber-physical/KeY directory has pdfs for the chapters.",
    "language": "en-US",
    "_line": "FormalReview.bib:1044"
  },
  "czajka_coqhammer:_nodate": {
    "id": "czajka_coqhammer:_nodate",
    "type": "webpage",
    "author": [
      {
        "family": "Czajka",
        "given": "Lukasz"
      },
      {
        "family": "Kaliszyk",
        "given": "Cezary"
      }
    ],
    "title": "CoqHammer: Strong Automation for Program Verification - CoqPL 2018",
    "accessed": {
      "date-parts": [
        [
          "2019",
          "1",
          "31"
        ]
      ]
    },
    "abstract": "We present CoqHammer: the first full hammer system for\nthe Coq proof assistant. The system translates Coq logic\nto untyped first-order logic and uses external automated\ntheorem provers (ATPs) to prove the translations of user\ngiven conjectures. Based on the output of the ATPs, the\nconjecture is then re-proved in the logic of Coq using an\neauto-type proof search algorithm. Together with machinelearning\nbased selection of relevant premises this constitutes\na full hammer system.\nThe performance of the overall procedure has been evaluated\nin a bootstrapping scenario emulating the development\nof the Coq standard library. Over 40&perc; of the theorems in\nthe Coq standard library can be proved in a push-button\nmode in about 40 seconds of real time on a 8-CPU system.\nThis offers a huge saving of human work in programming\nlanguage formalizations.",
    "URL": "https://popl18.sigplan.org/event/coqpl-2018-coqhammer-strong-automation-for-program-verification",
    "_line": "FormalReview.bib:1054"
  },
  "acm_coqpl_nodate": {
    "id": "acm_coqpl_nodate",
    "type": "webpage",
    "author": [
      {
        "family": "",
        "dropping-particle": "acm"
      }
    ],
    "title": "CoqPL 2019 The Fifth International Workshop on Coq for Programming Languages - POPL 2019",
    "accessed": {
      "date-parts": [
        [
          "2019",
          "1",
          "31"
        ]
      ]
    },
    "URL": "https://popl19.sigplan.org/track/CoqPL-2019#program",
    "_line": "FormalReview.bib:1078"
  },
  "acm_coqpl_nodate-1": {
    "id": "acm_coqpl_nodate-1",
    "type": "webpage",
    "author": [
      {
        "family": "",
        "dropping-particle": "acm"
      }
    ],
    "title": "CoqPL 2018 The Fourth International Workshop on Coq for Programming Languages - POPL 2018",
    "accessed": {
      "date-parts": [
        [
          "2019",
          "1",
          "31"
        ]
      ]
    },
    "URL": "https://popl18.sigplan.org/track/CoqPL-2018",
    "_line": "FormalReview.bib:1086"
  },
  "acm_coq_nodate": {
    "id": "acm_coq_nodate",
    "type": "webpage",
    "author": [
      {
        "family": "",
        "dropping-particle": "acm"
      }
    ],
    "title": "Coq for PL conference series - CoqPL 2019",
    "accessed": {
      "date-parts": [
        [
          "2019",
          "1",
          "31"
        ]
      ]
    },
    "URL": "https://popl18.sigplan.org/series/CoqPL",
    "_line": "FormalReview.bib:1094"
  },
  "acm_popl_nodate": {
    "id": "acm_popl_nodate",
    "type": "webpage",
    "author": [
      {
        "family": "",
        "dropping-particle": "acm"
      }
    ],
    "title": "POPL conference series - POPL 2020",
    "accessed": {
      "date-parts": [
        [
          "2019",
          "1",
          "31"
        ]
      ]
    },
    "URL": "https://popl18.sigplan.org/series/POPL",
    "_line": "FormalReview.bib:1102"
  },
  "polikarpova_structuring_2019": {
    "id": "polikarpova_structuring_2019",
    "type": "article-journal",
    "author": [
      {
        "family": "Polikarpova",
        "given": "Nadia"
      },
      {
        "family": "Sergey",
        "given": "Ilya"
      }
    ],
    "title": "Structuring the Synthesis of Heap-manipulating Programs",
    "container-title": "Proc. ACM Program. Lang.",
    "issued": {
      "date-parts": [
        [
          "2019",
          "1"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "1",
          "31"
        ]
      ]
    },
    "issn": "2475-1421",
    "abstract": "This paper describes a deductive approach to synthesizing imperative programs with pointers from declarative specifications expressed in Separation Logic. Our synthesis algorithm takes as input a pair of assertions—a pre- and a postcondition—which describe two states of the symbolic heap, and derives a program that transforms one state into the other, guided by the shape of the heap. Our approach to program synthesis is grounded in proof theory: we introduce the novel framework of Synthetic Separation Logic (SSL), which generalises the classical notion of heap entailment P ⊢ Q to incorporate a possibility of transforming a heap satisfying an assertion P into a heap satisfying an assertion Q. A synthesized program represents a proof term for a transforming entailment statement P ↝ Q, and the synthesis procedure corresponds to a proof search. The derived programs are, thus, correct by construction, in the sense that they satisfy the ascribed pre/postconditions, and are accompanied by complete proof derivations, which can be checked independently.  We have implemented a proof search engine for SSL in a form of the program synthesizer called SuSLik. For efficiency, the engine exploits properties of SSL rules, such as invertibility and commutativity of rule applications on separate heaps, to prune the space of derivations it has to consider. We explain and showcase the use of SSL on characteristic examples, describe the design of SuSLik, and report on our experience of using it to synthesize a series of benchmark programs manipulating heap-based linked data structures.",
    "keywords": "Program Synthesis, Proof Systems, Separation Logic, Type Theory",
    "URL": "http://doi.acm.org/10.1145/3290385",
    "DOI": "10.1145/3290385",
    "page": "72:1-72:30",
    "page-first": "72",
    "volume": "3",
    "_line": "FormalReview.bib:1128"
  },
  "leino_assertional_2015": {
    "id": "leino_assertional_2015",
    "type": "article-journal",
    "author": [
      {
        "family": "Leino",
        "given": "K. Rustan M."
      },
      {
        "family": "Lucio",
        "given": "Paqui"
      }
    ],
    "title": "An Assertional Proof of the Stability and Correctness of Natural Mergesort",
    "container-title": "ACM Trans. Comput. Logic",
    "issued": {
      "date-parts": [
        [
          "2015",
          "11"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "1",
          "31"
        ]
      ]
    },
    "issn": "1529-3785",
    "abstract": "We present a mechanically verified implementation of the sorting algorithm Natural Mergesort that consists of a few methods specified by their contracts of pre/post conditions. Methods are annotated with assertions that allow the automatic verification of the contract satisfaction. This program-proof is made using the state-of-the-art verifier Dafny. We verify not only the standard sortedness property, but also that the algorithm performs a stable sort. Throughout the article, we provide and explain the complete text of the program-proof.",
    "keywords": "theorem proving, dafny, formal methods, natural mergesort, software engineering, sorting, stability, Verification",
    "URL": "http://doi.acm.org/10.1145/2814571",
    "DOI": "10.1145/2814571",
    "page": "6:1-6:22",
    "page-first": "6",
    "volume": "17",
    "issue": "1",
    "_line": "FormalReview.bib:1145"
  },
  "christakis_collaborative_2012": {
    "id": "christakis_collaborative_2012",
    "type": "paper-conference",
    "author": [
      {
        "family": "Christakis",
        "given": "Maria"
      },
      {
        "family": "Müller",
        "given": "Peter"
      },
      {
        "family": "Wüstholz",
        "given": "Valentin"
      }
    ],
    "editor": [
      {
        "family": "Giannakopoulou",
        "given": "Dimitra"
      },
      {
        "family": "Méry",
        "given": "Dominique"
      }
    ],
    "title": "Collaborative Verification and Testing with Explicit Assumptions",
    "container-title": "FM 2012: Formal Methods",
    "collection-title": "Lecture Notes in Computer Science",
    "issued": {
      "date-parts": [
        [
          "2012"
        ]
      ]
    },
    "publisher": "Springer Berlin Heidelberg",
    "isbn": "978-3-642-32759-9",
    "abstract": "Many mainstream static code checkers make a number of compromises to improve automation, performance, and accuracy. These compromises include not checking certain program properties as well as making implicit, unsound assumptions. Consequently, the results of such static checkers do not provide definite guarantees about program correctness, which makes it unclear which properties remain to be tested. We propose a technique for collaborative verification and testing that makes compromises of static checkers explicit such that they can be compensated for by complementary checkers or testing. Our experiments suggest that our technique finds more errors and proves more properties than static checking alone, testing alone, and combinations that do not explicitly document the compromises made by static checkers. Our technique is also useful to obtain small test suites for partially-verified programs.",
    "keywords": "Static Checker, Symbolic Execution, Test Case Generation, Testing Tool, Tool Chain",
    "page": "132-146",
    "page-first": "132",
    "language": "en-US",
    "_line": "FormalReview.bib:1162"
  },
  "leino_co-induction_2013": {
    "id": "leino_co-induction_2013",
    "type": "article-journal",
    "author": [
      {
        "family": "Leino",
        "given": "Rustan"
      },
      {
        "family": "Moskal",
        "given": "Michal"
      }
    ],
    "title": "Co-Induction Simply: Automatic Co-Inductive Proofs in a Program Verifier",
    "container-title-short": "Co-Induction Simply",
    "title-short": "Co-Induction Simply",
    "issued": {
      "date-parts": [
        [
          "2013",
          "7",
          "12"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "1",
          "31"
        ]
      ]
    },
    "abstract": "Program verification relies heavily on induction, which has received decades of attention in mechanical verification tools. When program correctness is best described by infinite structures, program verification is usefully aided also by co-induction, which has not benefited from the same degree of tool support. Co-induction is complicated to work with in interactive proof assistants and …",
    "URL": "https://www.microsoft.com/en-us/research/publication/co-induction-simply-automatic-co-inductive-proofs-in-a-program-verifier/",
    "language": "en-US",
    "_line": "FormalReview.bib:1178"
  },
  "amin_computing_2016": {
    "id": "amin_computing_2016",
    "type": "article-journal",
    "author": [
      {
        "family": "Amin",
        "given": "Nada"
      },
      {
        "family": "Leino",
        "given": "Rustan"
      },
      {
        "family": "Rompf",
        "given": "Tiark"
      }
    ],
    "title": "Computing with an SMT Solver",
    "issued": {
      "date-parts": [
        [
          "2016",
          "12",
          "28"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "1",
          "31"
        ]
      ]
    },
    "abstract": "Satisfiability modulo theories (SMT) solvers that support quantifier instantiations via matching triggers can be programmed to give practical support for user-defined theories. Care must be taken to avoid so-called matching loops, which may prevent termination of the solver. By design, such avoidance limits the extent to which the SMT solver is able to apply the …",
    "URL": "https://www.microsoft.com/en-us/research/publication/computing-smt-solver/",
    "volume": "8570",
    "language": "en-US",
    "_line": "FormalReview.bib:1190"
  },
  "hatcliff_behavioral_2012": {
    "id": "hatcliff_behavioral_2012",
    "type": "article-journal",
    "author": [
      {
        "family": "Hatcliff",
        "given": "John"
      },
      {
        "family": "Leavens",
        "given": "Gary T."
      },
      {
        "family": "Leino",
        "given": "K. Rustan M."
      },
      {
        "family": "Müller",
        "given": "Peter"
      },
      {
        "family": "Parkinson",
        "given": "Matthew"
      }
    ],
    "title": "Behavioral Interface Specification Languages",
    "container-title": "ACM Comput. Surv.",
    "issued": {
      "date-parts": [
        [
          "2012",
          "6"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "1",
          "31"
        ]
      ]
    },
    "issn": "0360-0300",
    "abstract": "Behavioral interface specification languages provide formal code-level annotations, such as preconditions, postconditions, invariants, and assertions that allow programmers to express the intended behavior of program modules. Such specifications are useful for precisely documenting program behavior, for guiding implementation, and for facilitating agreement between teams of programmers in modular development of software. When used in conjunction with automated analysis and program verification tools, such specifications can support detection of common code vulnerabilities, capture of light-weight application-specific semantic properties, generation of test cases and test oracles, and full formal program verification. This article surveys behavioral interface specification languages with a focus toward automatic program verification and with a view towards aiding the Verified Software Initiative—a fifteen-year, cooperative, international project directed at the scientific challenges of large-scale software verification.",
    "keywords": "separation logic, Abstraction, assertion, behavioral subtyping, frame conditions, interface specification language, invariant, JML, postcondition, precondition, SPARK, Spec&hash;",
    "URL": "http://doi.acm.org/10.1145/2187671.2187678",
    "DOI": "10.1145/2187671.2187678",
    "page": "16:1-16:58",
    "page-first": "16",
    "volume": "44",
    "issue": "3",
    "_line": "FormalReview.bib:1202"
  },
  "leino_verification_2016": {
    "id": "leino_verification_2016",
    "type": "article-journal",
    "author": [
      {
        "family": "Leino",
        "given": "Rustan"
      },
      {
        "family": "Müller",
        "given": "Peter"
      },
      {
        "family": "Smans",
        "given": "Jan"
      }
    ],
    "title": "Verification of Concurrent Programs with Chalice",
    "issued": {
      "date-parts": [
        [
          "2016",
          "12",
          "29"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "1",
          "31"
        ]
      ]
    },
    "abstract": "A program verifier is a tool that allows developers to prove that their code satisfies its specification for every possible input and every thread schedule. These lecture notes describe a verifier for concurrent programs called Chalice. Chalice’s verification methodology centers around permissions and permission transfer. In particular, a memory location may be accessed by a …",
    "URL": "https://www.microsoft.com/en-us/research/publication/verification-concurrent-programs-chalice/",
    "language": "en-US",
    "_line": "FormalReview.bib:1219"
  },
  "leino_stepwise_2016": {
    "id": "leino_stepwise_2016",
    "type": "article-journal",
    "author": [
      {
        "family": "Leino",
        "given": "Rustan"
      },
      {
        "family": "Yessenov",
        "given": "Kuat"
      }
    ],
    "title": "Stepwise Refinement of Heap-Manipulating Code in Chalice",
    "issued": {
      "date-parts": [
        [
          "2016",
          "12",
          "29"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "1",
          "31"
        ]
      ]
    },
    "abstract": "Stepwise refinement is a well-studied technique for developing a program from an abstract description to a concrete implementation. This paper describes a system with automated tool support for refinement, powered by a stateof-the-art verification engine that uses an SMT solver. Unlike previous refinement systems, users of the presented system interact only via declarations in the …",
    "URL": "https://www.microsoft.com/en-us/research/publication/stepwise-refinement-heap-manipulating-code-chalice/",
    "language": "en-US",
    "_line": "FormalReview.bib:1230"
  },
  "leino_fine-grained_2016": {
    "id": "leino_fine-grained_2016",
    "type": "article-journal",
    "author": [
      {
        "family": "Leino",
        "given": "Rustan"
      },
      {
        "family": "Wüstholz",
        "given": "Valentin"
      }
    ],
    "title": "Fine-grained Caching of Verification Results",
    "issued": {
      "date-parts": [
        [
          "2016",
          "12",
          "28"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "1",
          "31"
        ]
      ]
    },
    "abstract": "Developing provably correct programs is an incremental process that often involves a series of interactions with a program verifier. To increase the responsiveness of the program verifier during such interactions, we designed a system for fine-grained caching of verification results. The caching system uses the program’s call graph and control-flow graph to focus the verification …",
    "URL": "https://www.microsoft.com/en-us/research/publication/fine-grained-caching-verification-results/",
    "volume": "9206",
    "language": "en-US",
    "_line": "FormalReview.bib:1241"
  },
  "koenig_programming_2016": {
    "id": "koenig_programming_2016",
    "type": "article-journal",
    "author": [
      {
        "family": "Koenig",
        "given": "Jason"
      },
      {
        "family": "Leino",
        "given": "Rustan"
      }
    ],
    "title": "Programming Language Features for Refinement",
    "issued": {
      "date-parts": [
        [
          "2016",
          "12",
          "28"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "1",
          "31"
        ]
      ]
    },
    "abstract": "Algorithmic and data refinement are well studied topics that provide a mathematically rigorous approach to gradually introducing details in the implementation of software. Program refinements are performed in the context of some programming language, but mainstream languages lack features for recording the sequence of refinement steps in the program text. To experiment with the combination …",
    "URL": "https://www.microsoft.com/en-us/research/publication/programming-language-features-refinement/",
    "language": "en-US",
    "_line": "FormalReview.bib:1253"
  },
  "leino_compiling_2016": {
    "id": "leino_compiling_2016",
    "type": "article-journal",
    "author": [
      {
        "family": "Leino",
        "given": "Rustan"
      }
    ],
    "title": "Compiling Hilbert's epsilon Operator",
    "container-title": "LPAR-20. 20th International Conferences on Logic for Programming, Artificial Intelligence and Reasoning",
    "issued": {
      "date-parts": [
        [
          "2016",
          "12",
          "28"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "1",
          "31"
        ]
      ]
    },
    "abstract": "Hilbert’s epsilon (ϵ) operator is a binder that picks an arbitrary element from a nonempty set. The operator is typically used in logics and proof engines. This paper contributes a discussion of considerations in supporting this operator in a programming language. More specifically, the paper presents the design choices made around supporting this operator in …",
    "URL": "https://www.microsoft.com/en-us/research/publication/compiling-hilberts-%cf%b5-operator/",
    "volume": "35",
    "language": "en-US",
    "_line": "FormalReview.bib:1264"
  },
  "parkinson_relationship_nodate": {
    "id": "parkinson_relationship_nodate",
    "type": "article-journal",
    "author": [
      {
        "family": "Parkinson",
        "given": "Matthew J"
      },
      {
        "family": "Summers",
        "given": "Alexander J"
      }
    ],
    "title": "The Relationship between Separation Logic and Implicit Dynamic Frames",
    "container-title": "LNCS",
    "abstract": "Separation logic is a concise method for specifying programs that manipulate dynamically allocated storage. Partially inspired by separation logic, Implicit Dynamic Frames has recently been proposed, aiming at ﬁrst-order tool support. In this paper, we provide a total heap semantics for a standard separation logic, and prove it equivalent to the standard model. With small adaptations, we then show how to give a direct semantics to implicit dynamic frames and show this semantics correctly captures the existing deﬁnitions. This precisely connects the two logics. As a consequence of this connection, we show that a fragment of separation logic can be faithfully encoded in a ﬁrst-order automatic veriﬁcation tool (Chalice).",
    "page": "439-458",
    "page-first": "439",
    "volume": "6602",
    "note": "ESOP 2011",
    "language": "en-US",
    "_line": "FormalReview.bib:1277"
  },
  "leino_verified_2016": {
    "id": "leino_verified_2016",
    "type": "article-journal",
    "author": [
      {
        "family": "Leino",
        "given": "Rustan"
      },
      {
        "family": "Polikarpova",
        "given": "Nadia"
      }
    ],
    "title": "Verified Calculations",
    "issued": {
      "date-parts": [
        [
          "2016",
          "12",
          "28"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "1",
          "31"
        ]
      ]
    },
    "abstract": "Calculational proofs—proofs by stepwise formula manipulation—are praised for their rigor, readability, and elegance. It seems desirable to reuse this style, often employed on paper, in the context of mechanized reasoning, and in particular, program verification. This work leverages the power of SMT solvers to machine-check calculational proofs at the level of detail they are usually …",
    "URL": "https://www.microsoft.com/en-us/research/publication/verified-calculations/",
    "language": "en-US",
    "_line": "FormalReview.bib:1289"
  },
  "leino_well-founded_2016": {
    "id": "leino_well-founded_2016",
    "type": "article-journal",
    "author": [
      {
        "family": "Leino",
        "given": "Rustan"
      }
    ],
    "title": "Well-Founded Functions and Extreme Predicates in Dafny: A Tutorial",
    "container-title-short": "Well-Founded Functions and Extreme Predicates in Dafny",
    "title-short": "Well-Founded Functions and Extreme Predicates in Dafny",
    "issued": {
      "date-parts": [
        [
          "2016",
          "12",
          "28"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "1",
          "31"
        ]
      ]
    },
    "abstract": "A recursive function is well defined if its every recursive call corresponds a decrease in some well-founded order. Such well-founded functions are useful for example in computer programs when computing a value from some input. A boolean function can also be defined as an extreme solution to a recurrence relation, that is, as a least …",
    "URL": "https://www.microsoft.com/en-us/research/publication/well-founded-functions-extreme-predicates-dafny-tutorial/",
    "volume": "40",
    "language": "en-US",
    "_line": "FormalReview.bib:1300"
  },
  "acm_acm_nodate": {
    "id": "acm_acm_nodate",
    "type": "webpage",
    "author": [
      {
        "family": "",
        "dropping-particle": "acm"
      }
    ],
    "title": "ACM Classification Codes",
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "URL": "https://cran.r-project.org/web/classifications/ACM.html",
    "_line": "FormalReview.bib:1313"
  },
  "acm_msc2010_nodate": {
    "id": "acm_msc2010_nodate",
    "type": "webpage",
    "author": [
      {
        "family": "",
        "dropping-particle": "acm"
      }
    ],
    "title": "MSC2010 database",
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "URL": "https://mathscinet.ams.org/msc/msc2010.html",
    "_line": "FormalReview.bib:1321"
  },
  "sozeau_typed_nodate": {
    "id": "sozeau_typed_nodate",
    "type": "webpage",
    "author": [
      {
        "family": "Sozeau",
        "given": "Matthieu"
      }
    ],
    "title": "Typed Template Coq - POPL 2018",
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "URL": "https://popl18.sigplan.org/event/coqpl-2018-typed-template-coq",
    "_line": "FormalReview.bib:1329"
  },
  "anand_typed_nodate": {
    "id": "anand_typed_nodate",
    "type": "article-journal",
    "author": [
      {
        "family": "Anand",
        "given": "Abhishek"
      },
      {
        "family": "Tabareau",
        "given": "Simon Boulier Nicolas"
      },
      {
        "family": "Sozeau",
        "given": "Matthieu"
      }
    ],
    "title": "Typed Template Coq",
    "abstract": "Template-Coq1 is a plugin for Coq, originally implemented by Malecha \\[7\\], which provides a reifier for Coq terms and global declarations, as represented in the Coq kernel, as well as a denotation command. Initially, it was developed for the purpose of writing functions on Coq’s AST in Gallina. Recently, its use was extended for the needs of the CertiCoq certified compiler project \\[2\\], which uses it as its front-end language and to derive parametricity properties \\[1\\], and the work of \\[5\\] on extracting Coq terms to a CBV λ-calculus. However, the syntax currently lacks semantics, be it typing semantics or operational semantics, which should reflect, as formal specifications in Coq, the semantics of Coq itself. This is an issue for CertiCoq where both a non-deterministic small step semantics and a deterministic call-by-value big step semantics had to be defined and preserved, without an “official” reference specification to refer to. Our hope with this work is to remedy this situation and provide a formal semantics of Coq’s implemented type theory, that can independently be refined and studied. By implementing a (partial) independent checker in Coq, we can also help formalize certified translations from Coq to Coq (Section 3).",
    "page": "2",
    "page-first": "2",
    "language": "en-US",
    "_line": "FormalReview.bib:1337"
  },
  "sozeau_typed_nodate-1": {
    "id": "sozeau_typed_nodate-1",
    "type": "article-journal",
    "author": [
      {
        "family": "Sozeau",
        "given": "Matthieu"
      }
    ],
    "title": "Typed Template Coq - Slides",
    "page": "11",
    "page-first": "11",
    "language": "en-US",
    "_line": "FormalReview.bib:1346"
  },
  "appel_certicoq:_nodate": {
    "id": "appel_certicoq:_nodate",
    "type": "webpage",
    "author": [
      {
        "family": "Appel",
        "given": "Andrew W."
      }
    ],
    "title": "CertiCoq: A verified compiler for Coq - POPL 2017",
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "URL": "https://popl17.sigplan.org/event/main-certicoq-a-verified-compiler-for-coq",
    "_line": "FormalReview.bib:1354"
  },
  "adewale_implementing_nodate": {
    "id": "adewale_implementing_nodate",
    "type": "webpage",
    "author": [
      {
        "family": "Adewale",
        "given": "Oluwatosin"
      }
    ],
    "title": "Implementing a high-performance key-value store using a trie of B+-Trees with cursors &bar; Computer Science Department at Princeton University",
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "abstract": "Abstract\nIn this paper, we discuss the implementation of a serial main-memory key-value store based on Masstree\\[6\\]. Similar to Masstree, the key-value store is implemented as a trie-like tree of B+-Trees, where each B+-Tree is responsible for a xed-length slice of a variable-length key. However, one of the major dierences between our key-value store and Masstree is that our B+-tree implementation (a component of the key-value store) takes linear time to insert a set of sorted records. This is compared to a traditional B+-tree implementation that would take linearithmic time. Moreover, partially sorting a sequence of operation leads to substantial performance gains. This is made possible using a data structure for navigating B+-trees called a B+-tree cursor. As our next operation is amortized constant time, our B+-tree does not need to maintain cross links between leaf nodes. We also briefy show that this same data structure can be extended to the trie of B+-Trees to ensure amortized linear time for bulk insertion of key-value pairs in the key-value store. We were inspired with this idea of B+-Tree cursors from the SQLite \\[5\\] B-tree source code.",
    "URL": "https://www.cs.princeton.edu/research/techreps/TR-004-18",
    "_line": "FormalReview.bib:1362"
  },
  "barriere_vst_nodate": {
    "id": "barriere_vst_nodate",
    "type": "article-journal",
    "author": [
      {
        "family": "Barriere",
        "given": "Aurele"
      },
      {
        "family": "Appel",
        "given": "Andrew"
      }
    ],
    "title": "VST Veriﬁcation of B+Trees with Cursors",
    "abstract": "The DeepSpecDB project aims to deﬁne, specify and verify a high-performance concurrent in-memory database system. Based on MassTree, it uses B+Trees, a well-studied key-value data structure. Our sequential B+Trees library uses cursors, introduced in the database engine SQLite. Such cursors reduce the complexity of operations when dealing with partially sorted data. We deﬁne a Coq formal model for such trees, then use it to specify and prove the correctness of the C implementation using the Veriﬁed Software Toolchain.",
    "page": "19",
    "page-first": "19",
    "language": "en-US",
    "_line": "FormalReview.bib:1372"
  },
  "appel_deepspecdb_2019": {
    "id": "appel_deepspecdb_2019",
    "type": "book",
    "author": [
      {
        "family": "Appel",
        "given": "Andrew W."
      }
    ],
    "title": "DeepSpecDB - github",
    "issued": {
      "date-parts": [
        [
          "2019",
          "1",
          "31"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "publisher": "PrincetonUniversity",
    "URL": "https://github.com/PrincetonUniversity/DeepSpecDB",
    "note": "original-date: 2017-11-30T14:24:30Z",
    "_line": "FormalReview.bib:1381"
  },
  "chen_project_nodate": {
    "id": "chen_project_nodate",
    "type": "article-journal",
    "author": [
      {
        "family": "Chen",
        "given": "Yixuan"
      }
    ],
    "title": "Project Report on DeepSpecDB",
    "abstract": "Recent years have witnessed a rapid development of mainmemory database systems thanks to the growingly aﬀordable memory. DeepSpecDB is another main-memory database management system implemented in C with deep speciﬁcation and end-to-end veriﬁcation guaranteeing the correctness of the system.",
    "page": "35",
    "page-first": "35",
    "language": "en-US",
    "_line": "FormalReview.bib:1392"
  },
  "sozeau_equations:_2010": {
    "id": "sozeau_equations:_2010",
    "type": "paper-conference",
    "author": [
      {
        "family": "Sozeau",
        "given": "Matthieu"
      }
    ],
    "editor": [
      {
        "family": "Kaufmann",
        "given": "Matt"
      },
      {
        "family": "Paulson",
        "given": "Lawrence C."
      }
    ],
    "title": "Equations: A Dependent Pattern-Matching Compiler",
    "container-title": "Interactive Theorem Proving",
    "container-title-short": "Equations",
    "collection-title": "Lecture Notes in Computer Science",
    "title-short": "Equations",
    "issued": {
      "date-parts": [
        [
          "2010"
        ]
      ]
    },
    "publisher": "Springer Berlin Heidelberg",
    "isbn": "978-3-642-14052-5",
    "abstract": "We present a compiler for definitions made by pattern matching on inductive families in the Coq system. It allows to write structured, recursive dependently-typed functions as a set of equations, automatically find their realization in the core type theory and generate proofs to ease reasoning on them. It provides a complete package to define and reason on functions in the proof assistant, substantially reducing the boilerplate code and proofs one usually has to write, also hiding the intricacies related to the use of dependent types and complex recursion schemes.",
    "keywords": "Type Theory, Proof Assistant, Recursive Call, Split Node, User Node",
    "page": "419-434",
    "page-first": "419",
    "language": "en-US",
    "_line": "FormalReview.bib:1401"
  },
  "delaware_fiat:_2015": {
    "id": "delaware_fiat:_2015",
    "type": "paper-conference",
    "author": [
      {
        "family": "Delaware",
        "given": "Benjamin"
      },
      {
        "family": "Pit-Claudel",
        "given": "Clément"
      },
      {
        "family": "Gross",
        "given": "Jason"
      },
      {
        "family": "Chlipala",
        "given": "Adam"
      }
    ],
    "title": "Fiat: Deductive Synthesis of Abstract Data Types in a Proof Assistant",
    "container-title": "Proceedings of the 42Nd Annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages",
    "container-title-short": "Fiat",
    "collection-title": "POPL '15",
    "title-short": "Fiat",
    "issued": {
      "date-parts": [
        [
          "2015"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "publisher": "ACM",
    "isbn": "978-1-4503-3300-9",
    "abstract": "We present Fiat, a library for the Coq proof assistant supporting refinement of declarative specifications into efficient functional programs with a high degree of automation. Each refinement process leaves a proof trail, checkable by the normal Coq kernel, justifying its soundness. We focus on the synthesis of abstract data types that package methods with private data. We demonstrate the utility of our framework by applying it to the synthesis of query structures &ndash; abstract data types with SQL-like query and insert operations. Fiat includes a library for writing specifications of query structures in SQL-inspired notation, expressing operations over relations (tables) in terms of mathematical sets. This library includes a suite of tactics for automating the refinement of specifications into efficient, correct-by-construction OCaml code. Using these tactics, a programmer can generate such an implementation completely automatically by only specifying the equivalent of SQL indexes, data structures capturing useful views of the abstract data. Throughout we speculate on the new programming modularity possibilities enabled by an automated refinement system with proved-correct rules.",
    "keywords": "deductive synthesis, mechanized derivation of abstract data types",
    "URL": "http://doi.acm.org/10.1145/2676726.2677006",
    "DOI": "10.1145/2676726.2677006",
    "publisher-place": "New York, NY, USA",
    "page": "689-700",
    "page-first": "689",
    "_line": "FormalReview.bib:1418"
  },
  "chlipala_end_nodate": {
    "id": "chlipala_end_nodate",
    "type": "webpage",
    "author": [
      {
        "family": "Chlipala",
        "given": "Adam"
      },
      {
        "family": "Delaware",
        "given": "Benjamin"
      },
      {
        "family": "Duchovni",
        "given": "Samuel"
      },
      {
        "family": "Gross",
        "given": "Jason"
      },
      {
        "family": "Pit-Claudel",
        "given": "Clément"
      },
      {
        "family": "Suriyakarn",
        "given": "Sorawit"
      },
      {
        "family": "Wang",
        "given": "Peng"
      },
      {
        "family": "ye",
        "given": "Katherine"
      }
    ],
    "title": "THE END OF HISTORY? USING A PROOF ASSISTANT TO REPLACE LANGUAGE DESIGN WITH LIBRARY DESIGN",
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "abstract": "Functionality of software systems has exploded in part because of advances in programming-language support for packaging reusable functionality as libraries. Developers benefit from the uniformity that comes of exposing many interfaces in the same language, as opposed to stringing together hodgepodges of command-line tools. Domain-specific languages may be viewed as an evolution of the power of reusable interfaces, when those interfaces become so flexible as to deserve to be called programming languages. However, common approaches to domain-specific languages give up many of the hard-won advantages of library-building in a rich common language, and even the traditional approach poses significant challenges in learning new APIs. We suggest that instead of continuing to develop new domain-specific languages, our community should embrace library-based ecosystems within very expressive languages that mix programming and theorem proving. Our prototype framework Fiat, a library for the Coq proof assistant, turns languages into easily comprehensible libraries via the key idea of modularizing functionality and performance away from each other, the former via macros that desugar into higher-order logic and the latter via optimization scripts that derive efficient code from logical programs.",
    "URL": "https://snapl.org/2017/abstracts/Chlipala.html",
    "_line": "FormalReview.bib:1437"
  },
  "gonthier_formal_2008": {
    "id": "gonthier_formal_2008",
    "type": "article-journal",
    "author": [
      {
        "family": "Gonthier",
        "given": "Georges"
      }
    ],
    "title": "Formal Proof—The Four- Color Theorem",
    "issued": {
      "date-parts": [
        [
          "2008"
        ]
      ]
    },
    "page": "12",
    "page-first": "12",
    "volume": "55",
    "issue": "11",
    "language": "en-US",
    "_line": "FormalReview.bib:1446"
  },
  "wiedijk_formal_2008": {
    "id": "wiedijk_formal_2008",
    "type": "article-journal",
    "author": [
      {
        "family": "Wiedijk",
        "given": "Freek"
      }
    ],
    "title": "Formal Proof—Getting Started",
    "issued": {
      "date-parts": [
        [
          "2008"
        ]
      ]
    },
    "page": "7",
    "page-first": "7",
    "volume": "55",
    "issue": "11",
    "language": "en-US",
    "_line": "FormalReview.bib:1457"
  },
  "harrison_formal_2008": {
    "id": "harrison_formal_2008",
    "type": "article-journal",
    "author": [
      {
        "family": "Harrison",
        "given": "John"
      }
    ],
    "title": "Formal Proof—Theory and Practice",
    "issued": {
      "date-parts": [
        [
          "2008"
        ]
      ]
    },
    "page": "12",
    "page-first": "12",
    "volume": "55",
    "issue": "11",
    "language": "en-US",
    "_line": "FormalReview.bib:1468"
  },
  "petcher_foundational_2015": {
    "id": "petcher_foundational_2015",
    "type": "paper-conference",
    "author": [
      {
        "family": "Petcher",
        "given": "Adam"
      },
      {
        "family": "Morrisett",
        "given": "Greg"
      }
    ],
    "editor": [
      {
        "family": "Focardi",
        "given": "Riccardo"
      },
      {
        "family": "Myers",
        "given": "Andrew"
      }
    ],
    "title": "The Foundational Cryptography Framework",
    "container-title": "Principles of Security and Trust",
    "collection-title": "Lecture Notes in Computer Science",
    "issued": {
      "date-parts": [
        [
          "2015"
        ]
      ]
    },
    "publisher": "Springer Berlin Heidelberg",
    "isbn": "978-3-662-46666-7",
    "abstract": "We present the Foundational Cryptography Framework (FCF) for developing and checking complete proofs of security for cryptographic schemes within a proof assistant. This is a general-purpose framework that is capable of modeling and reasoning about a wide range of cryptographic schemes, security definitions, and assumptions. Security is proven in the computational model, and the proof provides concrete bounds as well as asymptotic conclusions. FCF provides a language for probabilistic programs, a theory that is used to reason about programs, and a library of tactics and definitions that are useful in proofs about cryptography. The framework is designed to leverage fully the existing theory and capabilities of the Coq proof assistant in order to reduce the effort required to develop proofs.",
    "keywords": "Cryptography, Coq, Proof Assistant, Protocol Verification",
    "URL": "http://www.cs.cornell.edu/~jgm/papers/FCF.pdf",
    "page": "53-72",
    "page-first": "53",
    "language": "en-US",
    "_line": "FormalReview.bib:1479"
  },
  "fisher_kathleen_hacms_2017": {
    "id": "fisher_kathleen_hacms_2017",
    "type": "article-journal",
    "author": [
      {
        "family": "Fisher Kathleen"
      },
      {
        "family": "Launchbury John"
      },
      {
        "family": "Richards Raymond"
      }
    ],
    "title": "The HACMS program: using formal methods to eliminate exploitable bugs",
    "container-title": "Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences",
    "container-title-short": "The HACMS program",
    "title-short": "The HACMS program",
    "issued": {
      "date-parts": [
        [
          "2017",
          "10",
          "13"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "abstract": "For decades, formal methods have offered the promise of verified software that does not have exploitable bugs. Until recently, however, it has not been possible to verify software of sufficient complexity to be useful. Recently, that situation has changed. SeL4 is an open-source operating system microkernel efficient enough to be used in a wide range of practical applications. Its designers proved it to be fully functionally correct, ensuring the absence of buffer overflows, null pointer exceptions, use-after-free errors, etc., and guaranteeing integrity and confidentiality. The CompCert Verifying C Compiler maps source C programs to provably equivalent assembly language, ensuring the absence of exploitable bugs in the compiler. A number of factors have enabled this revolution, including faster processors, increased automation, more extensive infrastructure, specialized logics and the decision to co-develop code and correctness proofs rather than verify existing artefacts. In this paper, we explore the promise and limitations of current formal-methods techniques. We discuss these issues in the context of DARPA’s HACMS program, which had as its goal the creation of high-assurance software for vehicles, including quadcopters, helicopters and automobiles.This article is part of the themed issue ‘Verified trustworthy software systems’.",
    "URL": "https://royalsocietypublishing.org/doi/10.1098/rsta.2015.0401",
    "DOI": "10.1098/rsta.2015.0401",
    "page": "20150401",
    "page-first": "20150401",
    "volume": "375",
    "issue": "2104",
    "_line": "FormalReview.bib:1496"
  },
  "royalsociety_philosophical_nodate": {
    "id": "royalsociety_philosophical_nodate",
    "type": "webpage",
    "author": [
      {
        "family": "",
        "dropping-particle": "royalsociety"
      }
    ],
    "title": "Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences",
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "URL": "https://royalsocietypublishing.org/journal/rsta",
    "_line": "FormalReview.bib:1512"
  },
  "royalsociety_proceedings_nodate": {
    "id": "royalsociety_proceedings_nodate",
    "type": "webpage",
    "author": [
      {
        "family": "",
        "dropping-particle": "royalsociety"
      }
    ],
    "title": "Proceedings of the Royal Society A: Mathematical, Physical and Engineering Sciences",
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "URL": "https://royalsocietypublishing.org/journal/rspa",
    "_line": "FormalReview.bib:1520"
  },
  "choi_kami:_2017": {
    "id": "choi_kami:_2017",
    "type": "article-journal",
    "author": [
      {
        "family": "Choi",
        "given": "Joonwon"
      },
      {
        "family": "Vijayaraghavan",
        "given": "Muralidaran"
      },
      {
        "family": "Sherman",
        "given": "Benjamin"
      },
      {
        "family": "Chlipala",
        "given": "Adam"
      },
      {
        "family": "Arvind"
      }
    ],
    "title": "Kami: A Platform for High-level Parametric Hardware Specification and Its Modular Verification",
    "container-title": "Proc. ACM Program. Lang.",
    "container-title-short": "Kami",
    "title-short": "Kami",
    "issued": {
      "date-parts": [
        [
          "2017",
          "8"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "issn": "2475-1421",
    "abstract": "It has become fairly standard in the programming-languages research world to verify functional programs in proof assistants using induction, algebraic simplification, and rewriting. In this paper, we introduce Kami, a Coq library that enables similar expressive and modular reasoning for hardware designs expressed in the style of the Bluespec language. We can specify, implement, and verify realistic designs entirely within Coq, ending with automatic extraction into a pipeline that bottoms out in FPGAs. Our methodology, using labeled transition systems, has been evaluated in a case study verifying an infinite family of multicore systems, with cache-coherent shared memory and pipelined cores implementing (the base integer subset of) the RISC-V instruction set.",
    "keywords": "formal verification, hardware, proof assistants",
    "URL": "http://doi.acm.org/10.1145/3110268",
    "DOI": "10.1145/3110268",
    "page": "24:1-24:30",
    "page-first": "24",
    "volume": "1",
    "_line": "FormalReview.bib:1528"
  },
  "delaware_narcissus:_2018": {
    "id": "delaware_narcissus:_2018",
    "type": "article-journal",
    "author": [
      {
        "family": "Delaware",
        "given": "Benjamin"
      },
      {
        "family": "Suriyakarn",
        "given": "Sorawit"
      },
      {
        "family": "Pit&ndash;Claudel",
        "given": "Clément"
      },
      {
        "family": "Ye",
        "given": "Qianchuan"
      },
      {
        "family": "Chlipala",
        "given": "Adam"
      }
    ],
    "title": "Narcissus: Deriving Correct-By-Construction Decoders and Encoders from Binary Formats",
    "container-title-short": "Narcissus",
    "title-short": "Narcissus",
    "issued": {
      "date-parts": [
        [
          "2018",
          "3",
          "13"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "abstract": "It is a neat result from functional programming that libraries of parser\ncombinators can support rapid construction of decoders for quite a range of\nformats. With a little more work, the same combinator program can denote both a\ndecoder and an encoder. Unfortunately, the real world is full of gnarly\nformats, as with the packet formats that make up the standard Internet protocol\nstack. Most past parser-combinator approaches cannot handle these formats, and\nthe few exceptions require redundancy &ndash; one part of the natural grammar needs\nto be hand-translated into hints in multiple parts of a parser program. We show\nhow to recover very natural and nonredundant format specifications, covering\nall popular network packet formats and generating both decoders and encoders\nautomatically. The catch is that we use the Coq proof assistant to derive both\nkinds of artifacts using tactics, automatically, in a way that guarantees that\nthey form inverses of each other. We used our approach to reimplement packet\nprocessing for a full Internet protocol stack, inserting our replacement into\nthe OCaml-based MirageOS unikernel, resulting in minimal performance\ndegradation.",
    "URL": "https://arxiv.org/abs/1803.04870v2",
    "language": "en-US",
    "_line": "FormalReview.bib:1546"
  },
  "klein_gerwin_provably_2017": {
    "id": "klein_gerwin_provably_2017",
    "type": "article-journal",
    "author": [
      {
        "family": "Klein Gerwin"
      },
      {
        "family": "Andronick June"
      },
      {
        "family": "Keller Gabriele"
      },
      {
        "family": "Matichuk Daniel"
      },
      {
        "family": "Murray Toby"
      },
      {
        "family": "O'Connor Liam"
      }
    ],
    "title": "Provably trustworthy systems",
    "container-title": "Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences",
    "issued": {
      "date-parts": [
        [
          "2017",
          "10",
          "13"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "abstract": "We present recent work on building and scaling trustworthy systems with formal, machine-checkable proof from the ground up, including the operating system kernel, at the level of binary machine code. We first give a brief overview of the seL4 microkernel verification and how it can be used to build verified systems. We then show two complementary techniques for scaling these methods to larger systems: proof engineering, to estimate verification effort; and code/proof co-generation, for scalable development of provably trustworthy applications.This article is part of the themed issue ‘Verified trustworthy software systems’.",
    "URL": "https://royalsocietypublishing.org/doi/10.1098/rsta.2015.0404",
    "DOI": "10.1098/rsta.2015.0404",
    "page": "20150404",
    "page-first": "20150404",
    "volume": "375",
    "issue": "2104",
    "_line": "FormalReview.bib:1573"
  },
  "batty_mark_compositional_2017": {
    "id": "batty_mark_compositional_2017",
    "type": "article-journal",
    "author": [
      {
        "family": "Batty Mark"
      }
    ],
    "title": "Compositional relaxed concurrency",
    "container-title": "Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences",
    "issued": {
      "date-parts": [
        [
          "2017",
          "10",
          "13"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "abstract": "There is a broad design space for concurrent computer processors: they can be optimized for low power, low latency or high throughput. This freedom to tune each processor design to its niche has led to an increasing diversity of machines, from powerful pocketable devices to those responsible for complex and critical tasks, such as car guidance systems. Given this context, academic concurrency research sounds notes of both caution and optimism. Caution because recent work has uncovered flaws in the way we explain the subtle memory behaviour of concurrent systems: specifications have been shown to be incorrect, leading to bugs throughout the many layers of the system. And optimism because our tools and methods for verifying the correctness of concurrent code—although built above an idealized model of concurrency—are becoming more mature. This paper looks at the way we specify the memory behaviour of concurrent systems and suggests a new direction. Currently, there is a siloed approach, with each processor and programming language specified separately in an incomparable way. But this does not match the structure of our programs, which may use multiple processors and languages together. Instead we propose a compositional approach, where program components carry with them a description of the sort of concurrency they rely on, and there is a mechanism for composing these. This will support not only components written for the multiple varied processors found in a modern system but also those that use idealized models of concurrency, providing a sound footing for mature verification techniques.This article is part of the themed issue ‘Verified trustworthy software systems’.",
    "URL": "https://royalsocietypublishing.org/doi/10.1098/rsta.2015.0406",
    "DOI": "10.1098/rsta.2015.0406",
    "page": "20150406",
    "page-first": "20150406",
    "volume": "375",
    "issue": "2104",
    "_line": "FormalReview.bib:1588"
  },
  "appel_andrew_w._position_2017": {
    "id": "appel_andrew_w._position_2017",
    "type": "article-journal",
    "author": [
      {
        "family": "Appel Andrew W."
      },
      {
        "family": "Beringer Lennart"
      },
      {
        "family": "Chlipala Adam"
      },
      {
        "family": "Pierce Benjamin C."
      },
      {
        "family": "Shao Zhong"
      },
      {
        "family": "Weirich Stephanie"
      },
      {
        "family": "Zdancewic Steve"
      }
    ],
    "title": "Position paper: the science of deep specification",
    "container-title": "Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences",
    "container-title-short": "Position paper",
    "title-short": "Position paper",
    "issued": {
      "date-parts": [
        [
          "2017",
          "10",
          "13"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "abstract": "We introduce our efforts within the project ‘The science of deep specification’ to work out the key formal underpinnings of industrial-scale formal specifications of software and hardware components, anticipating a world where large verified systems are routinely built out of smaller verified components that are also used by many other projects. We identify an important class of specification that has already been used in a few experiments that connect strong component-correctness theorems across the work of different teams. To help popularize the unique advantages of that style, we dub it deep specification, and we say that it encompasses specifications that are rich, two-sided, formal and live (terms that we define in the article). Our core team is developing a proof-of-concept system (based on the Coq proof assistant) whose specification and verification work is divided across largely decoupled subteams at our four institutions, encompassing hardware microarchitecture, compilers, operating systems and applications, along with cross-cutting principles and tools for effective specification. We also aim to catalyse interest in the approach, not just by basic researchers but also by users in industry.This article is part of the themed issue ‘Verified trustworthy software systems’.",
    "URL": "https://royalsocietypublishing.org/doi/10.1098/rsta.2016.0331",
    "DOI": "10.1098/rsta.2016.0331",
    "page": "20160331",
    "page-first": "20160331",
    "volume": "375",
    "issue": "2104",
    "_line": "FormalReview.bib:1603"
  },
  "david_cristina_program_2017": {
    "id": "david_cristina_program_2017",
    "type": "article-journal",
    "author": [
      {
        "family": "David Cristina"
      },
      {
        "family": "Kroening Daniel"
      }
    ],
    "title": "Program synthesis: challenges and opportunities",
    "container-title": "Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences",
    "container-title-short": "Program synthesis",
    "title-short": "Program synthesis",
    "issued": {
      "date-parts": [
        [
          "2017",
          "10",
          "13"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "abstract": "Program synthesis is the mechanized construction of software, dubbed ‘self-writing code’. Synthesis tools relieve the programmer from thinking about how the problem is to be solved; instead, the programmer only provides a description of what is to be achieved. Given a specification of what the program should do, the synthesizer generates an implementation that provably satisfies this specification. From a logical point of view, a program synthesizer is a solver for second-order existential logic. Owing to the expressiveness of second-order logic, program synthesis has an extremely broad range of applications. We survey some of these applications as well as recent trends in the algorithms that solve the program synthesis problem. In particular, we focus on an approach that has raised the profile of program synthesis and ushered in a generation of new synthesis tools, namely counter-example-guided inductive synthesis (CEGIS). We provide a description of the CEGIS architecture, followed by recent algorithmic improvements. We conjecture that the capacity of program synthesis engines will see further step change, in a manner that is transparent to the applications, which will open up an even broader range of use-cases.This article is part of the themed issue ‘Verified trustworthy software systems’.",
    "URL": "https://royalsocietypublishing.org/doi/10.1098/rsta.2015.0403",
    "DOI": "10.1098/rsta.2015.0403",
    "page": "20150403",
    "page-first": "20150403",
    "volume": "375",
    "issue": "2104",
    "_line": "FormalReview.bib:1619"
  },
  "white_neil_formal_2017": {
    "id": "white_neil_formal_2017",
    "type": "article-journal",
    "author": [
      {
        "family": "White Neil"
      },
      {
        "family": "Matthews Stuart"
      },
      {
        "family": "Chapman Roderick"
      }
    ],
    "title": "Formal verification: will the seedling ever flower?",
    "container-title": "Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences",
    "container-title-short": "Formal verification",
    "title-short": "Formal verification",
    "issued": {
      "date-parts": [
        [
          "2017",
          "10",
          "13"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "abstract": "In one sense, formal specification and verification have been highly successful: techniques have been developed in pioneering academic research, transferred to software companies through training and partnerships, and successfully deployed in systems with national significance. Altran UK has been in the vanguard of this movement. This paper summarizes some of our key deployments of formal techniques over the past 20 years, including both security- and safety-critical systems. The impact of formal techniques, however, remains within an industrial niche, and while government and suppliers across industry search for solutions to the problems of poor-quality software, the wider software industry remains resistant to adoption of this proven solution. We conclude by reflecting on some of the challenges we face as a community in ensuring that formal techniques achieve their true potential impact on society.This article is part of the themed issue ‘Verified trustworthy software systems’.",
    "URL": "https://royalsocietypublishing.org/doi/10.1098/rsta.2015.0402",
    "DOI": "10.1098/rsta.2015.0402",
    "page": "20150402",
    "page-first": "20150402",
    "volume": "375",
    "issue": "2104",
    "_line": "FormalReview.bib:1635"
  },
  "hunt_warren_a._industrial_2017": {
    "id": "hunt_warren_a._industrial_2017",
    "type": "article-journal",
    "author": [
      {
        "family": "Hunt Warren A."
      },
      {
        "family": "Kaufmann Matt"
      },
      {
        "family": "Moore J Strother"
      },
      {
        "family": "Slobodova Anna"
      }
    ],
    "title": "Industrial hardware and software verification with ACL2",
    "container-title": "Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences",
    "issued": {
      "date-parts": [
        [
          "2017",
          "10",
          "13"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "abstract": "The ACL2 theorem prover has seen sustained industrial use since the mid-1990s. Companies that have used ACL2 regularly include AMD, Centaur Technology, IBM, Intel, Kestrel Institute, Motorola/Freescale, Oracle and Rockwell Collins. This paper introduces ACL2 and focuses on how and why ACL2 is used in industry. ACL2 is well-suited to its industrial application to numerous software and hardware systems, because it is an integrated programming/proof environment supporting a subset of the ANSI standard Common Lisp programming language. As a programming language ACL2 permits the coding of efficient and robust programs; as a prover ACL2 can be fully automatic but provides many features permitting domain-specific human-supplied guidance at various levels of abstraction. ACL2 specifications and models often serve as efficient execution engines for the modelled artefacts while permitting formal analysis and proof of properties. Crucially, ACL2 also provides support for the development and verification of other formal analysis tools. However, ACL2 did not find its way into industrial use merely because of its technical features. The core ACL2 user/development community has a shared vision of making mechanized verification routine when appropriate and has been committed to this vision for the quarter century since the Computational Logic, Inc., Verified Stack. The community has focused on demonstrating the viability of the tool by taking on industrial projects (often at the expense of not being able to publish much).This article is part of the themed issue ‘Verified trustworthy software systems’.",
    "URL": "https://royalsocietypublishing.org/doi/10.1098/rsta.2015.0399",
    "DOI": "10.1098/rsta.2015.0399",
    "page": "20150399",
    "page-first": "20150399",
    "volume": "375",
    "issue": "2104",
    "_line": "FormalReview.bib:1651"
  },
  "ekici_smtcoq:_2017": {
    "id": "ekici_smtcoq:_2017",
    "type": "paper-conference",
    "author": [
      {
        "family": "Ekici",
        "given": "Burak"
      },
      {
        "family": "Mebsout",
        "given": "Alain"
      },
      {
        "family": "Tinelli",
        "given": "Cesare"
      },
      {
        "family": "Keller",
        "given": "Chantal"
      },
      {
        "family": "Katz",
        "given": "Guy"
      },
      {
        "family": "Reynolds",
        "given": "Andrew"
      },
      {
        "family": "Barrett",
        "given": "Clark"
      }
    ],
    "editor": [
      {
        "family": "Majumdar",
        "given": "Rupak"
      },
      {
        "family": "Kunčak",
        "given": "Viktor"
      }
    ],
    "title": "SMTCoq: A Plug-In for Integrating SMT Solvers into Coq",
    "container-title": "Computer Aided Verification",
    "container-title-short": "SMTCoq",
    "collection-title": "Lecture Notes in Computer Science",
    "title-short": "SMTCoq",
    "issued": {
      "date-parts": [
        [
          "2017"
        ]
      ]
    },
    "publisher": "Springer International Publishing",
    "isbn": "978-3-319-63390-9",
    "abstract": "This paper describes SMTCoq, a plug-in for the integration of external solvers into the Coq proof assistant. Based on a checker for generic first-order proof certificates fully implemented and proved correct in Coq, SMTCoq offers facilities to check answers from external SAT and SMT solvers and to increase Coq’s automation using such solvers, all in a safe way. The current version supports proof certificates produced by the SAT solver ZChaff, for propositional logic, and the SMT solvers veriT and CVC4, for the quantifier-free fragment of the combined theory of fixed-size bit vectors, functional arrays with extensionality, linear integer arithmetic, and uninterpreted function symbols.",
    "page": "126-133",
    "page-first": "126",
    "language": "en-US",
    "_line": "FormalReview.bib:1666"
  },
  "anand_towards_nodate": {
    "id": "anand_towards_nodate",
    "type": "webpage",
    "author": [
      {
        "family": "Anand",
        "given": "Abhishek"
      },
      {
        "family": "Boulier",
        "given": "Simon"
      },
      {
        "family": "Cohen",
        "given": "Cyril"
      },
      {
        "family": "Sozeau",
        "given": "Matthieu"
      },
      {
        "family": "Tabareau",
        "given": "Nicolas"
      }
    ],
    "title": "Towards Certified Meta-Programming with Typed Template-Coq &bar; SpringerLink",
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "abstract": "Template-Coq (https://template-coq.github.io/template-coq) is a plugin for Coq, originally implemented by Malecha \\[18\\], which provides a reifier for Coq terms and global declarations, as represented in the Coq kernel, as well as a denotation command. Initially, it was developed for the purpose of writing functions on Coq’s AST in Gallina. Recently, it was used in the CertiCoq certified compiler project \\[4\\], as its front-end language, to derive parametricity properties \\[3\\], and to extract Coq terms to a CBV   𝜆 -calculus \\[13\\]. However, the syntax lacked semantics, be it typing semantics or operational semantics, which should reflect, as formal specifications in Coq, the semantics of Coq’s type theory itself. The tool was also rather bare bones, providing only rudimentary quoting and unquoting commands. We generalize it to handle the entire Calculus of Inductive Constructions (CIC), as implemented by Coq, including the kernel’s declaration structures for definitions and inductives, and implement a monad for general manipulation of Coq’s logical environment. We demonstrate how this setup allows Coq users to define many kinds of general purpose plugins, whose correctness can be readily proved in the system itself, and that can be run efficiently after extraction. We give a few examples of implemented plugins, including a parametricity translation. We also advocate the use of Template-Coq as a foundation for higher-level tools.",
    "URL": "https://link.springer.com/chapter/10.1007%2F978-3-319-94821-8_2",
    "_line": "FormalReview.bib:1682"
  },
  "malecha_reflection_2018": {
    "id": "malecha_reflection_2018",
    "type": "book",
    "author": [
      {
        "family": "Malecha",
        "given": "Gregory"
      }
    ],
    "title": "Reflection library for Coq. Contribute to gmalecha/template-coq development by creating an account on GitHub",
    "issued": {
      "date-parts": [
        [
          "2018",
          "3",
          "2"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "URL": "https://github.com/gmalecha/template-coq",
    "note": "original-date: 2014-07-09T20:13:52Z",
    "_line": "FormalReview.bib:1691"
  },
  "sozeau_metacoq_2019": {
    "id": "sozeau_metacoq_2019",
    "type": "book",
    "author": [
      {
        "family": "Sozeau",
        "given": "Matthieu"
      }
    ],
    "title": "MetaCoq - Metaprogramming in Coq (Was template-coq)",
    "issued": {
      "date-parts": [
        [
          "2019",
          "1",
          "22"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "publisher": "MetaCoq",
    "URL": "https://github.com/MetaCoq/metacoq",
    "note": "original-date: 2017-10-19T11:10:54Z",
    "_line": "FormalReview.bib:1701"
  },
  "parigot_logic_2000": {
    "id": "parigot_logic_2000",
    "type": "book",
    "author": [
      {
        "family": "Parigot",
        "given": "Michel"
      },
      {
        "family": "Voronkov",
        "given": "Andrei"
      }
    ],
    "title": "Logic for Programming and Automated Reasoning: 7th International Conference, LPAR 2000 Reunion Island, France, November 6-10, 2000 Proceedings",
    "container-title-short": "Logic for Programming and Automated Reasoning",
    "title-short": "Logic for Programming and Automated Reasoning",
    "issued": {
      "date-parts": [
        [
          "2000"
        ]
      ]
    },
    "publisher": "Springer Berlin Heidelberg",
    "isbn": "978-3-540-41285-4 978-3-540-44404-6",
    "abstract": "This book constitutes the refereed proceedings of the 7th International Conference on Logic for Programming and Automated Reasoning, LPAR 2000, held in Reunion Island, France in November 2000. The 26 revised full papers presented together with four invited contributions were carefully reviewed and selected from 65 submissions. The papers are organized in topical sections on nonmonotonic reasoning, descriptive complexity, specification and automatic proof-assistants, theorem proving, verification, logic programming and constraint logic programming, nonclassical logics and the lambda calculus, logic and databases, program analysis, mu-calculus, planning and reasoning about actions.",
    "publisher-place": "Berlin, Heidelberg",
    "note": "OCLC: 851805469",
    "_line": "FormalReview.bib:1712"
  },
  "parigot_tactic_2000": {
    "id": "parigot_tactic_2000",
    "type": "chapter",
    "author": [
      {
        "family": "Delahaye",
        "given": "David"
      }
    ],
    "editor": [
      {
        "family": "Parigot",
        "given": "Michel"
      },
      {
        "family": "Voronkov",
        "given": "Andrei"
      }
    ],
    "title": "A Tactic Language for the System Coq",
    "container-title": "Logic for Programming and Automated Reasoning",
    "issued": {
      "date-parts": [
        [
          "2000"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "publisher": "Springer Berlin Heidelberg",
    "isbn": "978-3-540-41285-4",
    "URL": "http://link.springer.com/10.1007/3-540-44404-1_7",
    "DOI": "10.1007/3-540-44404-1_7",
    "publisher-place": "Berlin, Heidelberg",
    "page": "85-95",
    "page-first": "85",
    "volume": "1955",
    "language": "en-US",
    "_line": "FormalReview.bib:1724"
  },
  "bate_fundamentals_1971": {
    "id": "bate_fundamentals_1971",
    "type": "book",
    "author": [
      {
        "family": "Bate",
        "given": "Roger R."
      },
      {
        "family": "Mueller",
        "given": "Donald D."
      },
      {
        "family": "White",
        "given": "Jerry E."
      }
    ],
    "title": "Fundamentals of astrodynamics",
    "issued": {
      "date-parts": [
        [
          "1971"
        ]
      ]
    },
    "publisher": "Dover Publications",
    "number-of-pages": "455",
    "isbn": "978-0-486-60061-1",
    "keywords": "Astrodynamics",
    "publisher-place": "New York",
    "_line": "FormalReview.bib:1742"
  },
  "fowler_deriving_nodate": {
    "id": "fowler_deriving_nodate",
    "type": "webpage",
    "author": [
      {
        "family": "Fowler",
        "given": "Michael"
      }
    ],
    "title": "Deriving Kepler’s Laws from the Inverse-Square Law",
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "URL": "http://galileo.phys.virginia.edu/classes/152.mf1i.spring02/KeplersLaws.htm",
    "_line": "FormalReview.bib:1754"
  },
  "lancaster_unified_1969": {
    "id": "lancaster_unified_1969",
    "type": "article-journal",
    "author": [
      {
        "family": "Lancaster",
        "given": "E R"
      },
      {
        "family": "Blanchard",
        "given": "R C"
      }
    ],
    "title": "A unified form of lambert's theorem",
    "container-title": "NASA Technical Note",
    "issued": {
      "date-parts": [
        [
          "1969",
          "9"
        ]
      ]
    },
    "page": "18",
    "page-first": "18",
    "volume": "{TN} D-5368",
    "language": "en-US",
    "_line": "FormalReview.bib:1762"
  },
  "protzenko_verified_2017": {
    "id": "protzenko_verified_2017",
    "type": "article-journal",
    "author": [
      {
        "family": "Protzenko",
        "given": "Jonathan"
      },
      {
        "family": "Zinzindohoué",
        "given": "Jean-Karim"
      },
      {
        "family": "Rastogi",
        "given": "Aseem"
      },
      {
        "family": "Ramananandro",
        "given": "Tahina"
      },
      {
        "family": "Wang",
        "given": "Peng"
      },
      {
        "family": "Zanella-Béguelin",
        "given": "Santiago"
      },
      {
        "family": "Delignat-Lavaud",
        "given": "Antoine"
      },
      {
        "family": "Hriţcu",
        "given": "Cătălin"
      },
      {
        "family": "Bhargavan",
        "given": "Karthikeyan"
      },
      {
        "family": "Fournet",
        "given": "Cédric"
      },
      {
        "family": "Swamy",
        "given": "Nikhil"
      }
    ],
    "title": "Verified Low-level Programming Embedded in F\\*",
    "container-title": "Proc. ACM Program. Lang.",
    "issued": {
      "date-parts": [
        [
          "2017",
          "8"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "issn": "2475-1421",
    "abstract": "We present Low\\*, a language for low-level programming and verification, and its application to high-assurance optimized cryptographic libraries. Low\\* is a shallow embedding of a small, sequential, well-behaved subset of C in F\\*, a dependently- typed variant of ML aimed at program verification. Departing from ML, Low\\* does not involve any garbage collection or implicit heap allocation; instead, it has a structured memory model à la CompCert, and it provides the control required for writing efficient low-level security-critical code.   By virtue of typing, any Low\\* program is memory safe. In addition, the programmer can make full use of the verification power of F\\* to write high-level specifications and verify the functional correctness of Low\\* code using a combination of SMT automation and sophisticated manual proofs. At extraction time, specifications and proofs are erased, and the remaining code enjoys a predictable translation to C. We prove that this translation preserves semantics and side-channel resistance.   We provide a new compiler back-end from Low\\* to C and, to evaluate our approach, we implement and verify various cryptographic algorithms, constructions, and tools for a total of about 28,000 lines of code. We show that our Low\\* code delivers performance competitive with existing (unverified) C cryptographic libraries, suggesting our approach may be applicable to larger-scale low-level software.",
    "keywords": "Compilers, Functional languages, Semantics, Software verifcation, Source code generation, Type theory, źSoftware and its engineering ź Correctness, źTheory of computation ź Hoare logic",
    "URL": "http://doi.acm.org/10.1145/3110261",
    "DOI": "10.1145/3110261",
    "page": "17:1-17:29",
    "page-first": "17",
    "volume": "1",
    "_line": "FormalReview.bib:1773"
  },
  "delignat-lavaud_implementing_2017": {
    "id": "delignat-lavaud_implementing_2017",
    "type": "article-journal",
    "author": [
      {
        "family": "Delignat-Lavaud",
        "given": "Antoine"
      },
      {
        "family": "Fournet",
        "given": "Cédric"
      },
      {
        "family": "Kohlweiss",
        "given": "Markulf"
      },
      {
        "family": "Protzenko",
        "given": "Jonathan"
      },
      {
        "family": "Rastogi",
        "given": "Aseem"
      },
      {
        "family": "Swamy",
        "given": "Nikhil"
      },
      {
        "family": "Zanella-Beguelin",
        "given": "Santiago"
      },
      {
        "family": "Bhargavan",
        "given": "Karthikeyan"
      },
      {
        "family": "Pan",
        "given": "Jianyang"
      },
      {
        "family": "Zinzindohoue",
        "given": "Jean Karim"
      }
    ],
    "title": "Implementing and Proving the TLS 1.3 Record Layer",
    "issued": {
      "date-parts": [
        [
          "2017",
          "8",
          "17"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "abstract": "The record layer is the main bridge between TLS applications and internal sub-protocols. Its core functionality is an elaborate form of authenticated encryption: streams of messages for each sub-protocol (handshake, alert, and application data) are fragmented, multiplexed, and encrypted with optional padding to hide their lengths. Conversely, the sub-protocols may provide fresh keys or signal …",
    "URL": "https://www.microsoft.com/en-us/research/publication/implementing-proving-tls-1-3-record-layer/",
    "language": "en-US",
    "_line": "FormalReview.bib:1790"
  },
  "cea_frama-c_nodate": {
    "id": "cea_frama-c_nodate",
    "type": "webpage",
    "author": [
      {
        "family": "",
        "dropping-particle": "cea"
      }
    ],
    "title": "Frama-C",
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "URL": "https://frama-c.com/",
    "_line": "FormalReview.bib:1801"
  },
  "brahmi_formalise_2018": {
    "id": "brahmi_formalise_2018",
    "type": "paper-conference",
    "author": [
      {
        "family": "Brahmi",
        "given": "Abderrahmane"
      },
      {
        "family": "Delmas",
        "given": "David"
      },
      {
        "family": "Essoussi",
        "given": "Mohamed Habib"
      },
      {
        "family": "Randimbivololona",
        "given": "Famantanantsoa"
      },
      {
        "family": "Atki",
        "given": "Abdellatif"
      },
      {
        "family": "Marie",
        "given": "Thomas"
      }
    ],
    "title": "Formalise to automate: deployment of a safe and cost-efficient process for avionics software",
    "container-title": "9th European Congress on Embedded Real Time Software and Systems (ERTS 2018)",
    "container-title-short": "Formalise to automate",
    "title-short": "Formalise to automate",
    "issued": {
      "date-parts": [
        [
          "2018",
          "1"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "abstract": "For over a decade, Airbus have been introducing formal techniques into the verification processes of some of their avionics software products, to cope with the steady increase of the size and complexity of related avionics systems. These techniques have come of age for large-scale industrial deployment. All design and verification processes are currently being revised to take maximum advantage from them, i.e. improve industrial efficiency while maintaining the safety and reliability of avionics systems. To achieve this goal, all human-engineered design artefacts are being formalised using languages with well-defined syntaxes and semantics, in order to allow for the automatic generation of all subsequent, computable design or verification artefacts, and the preparation of the input data for non computable activities. To this aim, several domain-specific languages and related compilers have been developed internally, which cover all design activities, and bridge the gaps to integrate external tools into the overall development processes, e.g. sound, semantics-based, static analysis tools. For instance, the formalisation of detailed designs in the form of function contracts expressed in a first-order logic-based language allows for a hybrid approach to unit verification. Designs may be compiled down to ACSL \\[5\\] contracts, allowing for program proof with Frama-C \\[22\\], or they may be compiled down to test contracts, allowing for semi-automatic unit tests.",
    "keywords": "formal methods, avionics software, compilation, design, development process, DO-178C, domain-specific languages, formalisation, industrial application, static analysis",
    "URL": "https://hal.archives-ouvertes.fr/hal-01708332",
    "publisher-place": "Toulouse, France",
    "_line": "FormalReview.bib:1809"
  },
  "brahmi_formalise_nodate": {
    "id": "brahmi_formalise_nodate",
    "type": "article-journal",
    "author": [
      {
        "family": "Brahmi",
        "given": "Abderrahmane"
      },
      {
        "family": "Delmas",
        "given": "David"
      },
      {
        "family": "Essoussi",
        "given": "Mohamed Habib"
      },
      {
        "family": "Randimbivololona",
        "given": "Famantanantsoa"
      },
      {
        "family": "Informatics",
        "given": "CEPRESY"
      },
      {
        "family": "Nauzere",
        "given": "La"
      },
      {
        "family": "Atki",
        "given": "Abdellatif"
      },
      {
        "family": "Marie",
        "given": "Thomas"
      }
    ],
    "title": "Formalise to automate: deployment of a safe and cost-efﬁcient process for avionics software -Extended",
    "abstract": "For over a decade, Airbus have been introducing formal techniques into the veriﬁcation processes of some of their avionics software products, to cope with the steady increase of the size and complexity of related avionics systems. These techniques have come of age for large-scale industrial deployment. All design and veriﬁcation processes are currently being revised to take maximum advantage from them, i.e. improve industrial efﬁciency while maintaining the safety and reliability of avionics systems.",
    "page": "17",
    "page-first": "17",
    "language": "en-US",
    "_line": "FormalReview.bib:1823"
  },
  "jeannet_apron_nodate": {
    "id": "jeannet_apron_nodate",
    "type": "webpage",
    "author": [
      {
        "family": "Jeannet",
        "given": "Bertrand"
      },
      {
        "family": "Miné",
        "given": "Antoine"
      }
    ],
    "title": "APRON numerical abstract domain library",
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "URL": "http://apron.cri.ensmp.fr/library/",
    "_line": "FormalReview.bib:1832"
  },
  "blanchard_concurrent_2017": {
    "id": "blanchard_concurrent_2017",
    "type": "article-journal",
    "author": [
      {
        "family": "Blanchard",
        "given": "Allan"
      },
      {
        "family": "Loulergue",
        "given": "Frédéric"
      },
      {
        "family": "Kosmatov",
        "given": "Nikolai"
      }
    ],
    "title": "From Concurrent Programs to Simulating Sequential Programs: Correctness of a Transformation",
    "container-title": "Electronic Proceedings in Theoretical Computer Science",
    "container-title-short": "From Concurrent Programs to Simulating Sequential Programs",
    "title-short": "From Concurrent Programs to Simulating Sequential Programs",
    "issued": {
      "date-parts": [
        [
          "2017",
          "8",
          "23"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "issn": "2075-2180",
    "abstract": "Frama-C is a software analysis framework that provides a common infrastructure and a common behavioral specification language to plugins that implement various static and dynamic analyses of C programs. Most plugins do not support concurrency. We have proposed Conc2Seq, a Frama-C plugin based on program transformation, capable to leverage the existing huge code base of plugins and to handle concurrent C programs. In this paper we formalize and sketch the proof of correctness of the program transformation principle behind Conc2Seq, and present an effort towards the full mechanization of both the formalization and proofs with the proof assistant Coq.",
    "keywords": "Computer Science - Programming Languages",
    "URLtext": "1708.07226",
    "URLpretext": "[arXiv:]{.etype}",
    "eprint-type": "arxiv",
    "eprint": "1708.07226",
    "URL": "http://arxiv.org/abs/1708.07226",
    "DOI": "10.4204/EPTCS.253.9",
    "page": "109-123",
    "page-first": "109",
    "volume": "253",
    "_line": "FormalReview.bib:1840"
  },
  "petiot_how_2018": {
    "id": "petiot_how_2018",
    "type": "article-journal",
    "author": [
      {
        "family": "Petiot",
        "given": "Guillaume"
      },
      {
        "family": "Kosmatov",
        "given": "Nikolai"
      },
      {
        "family": "Botella",
        "given": "Bernard"
      },
      {
        "family": "Giorgetti",
        "given": "Alain"
      },
      {
        "family": "Julliand",
        "given": "Jacques"
      }
    ],
    "title": "How testing helps to diagnose proof failures",
    "container-title": "Form Asp Comp",
    "issued": {
      "date-parts": [
        [
          "2018",
          "11",
          "1"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "issn": "1433-299X",
    "abstract": "Applying deductive verification to formally prove that a program respects its formal specification is a very complex and time-consuming task due in particular to the lack of feedback in case of proof failures. Along with a non-compliance between the code and its specification (due to an error in at least one of them), possible reasons of a proof failure include a missing or too weak specification for a called function or a loop, and lack of time or simply incapacity of the prover to finish a particular proof. This work proposes a methodology where test generation helps to identify the reason of a proof failure and to exhibit a counterexample clearly illustrating the issue. We define the categories of proof failures, introduce two subcategories of contract weaknesses (single and global ones), and examine their properties. We describe how to transform a C program formally specified in an executable specification language into C code suitable for testing, and illustrate the benefits of the method on comprehensive examples. The method has been implemented in StaDy, a plugin of the software analysis platform Frama-C. Initial experiments show that detecting non-compliances and contract weaknesses allows to precisely diagnose most proof failures.",
    "keywords": "Deductive verification, Frama-C, Proof debugging, Specification, Test generation",
    "URL": "https://doi.org/10.1007/s00165-018-0456-4",
    "DOI": "10.1007/s00165-018-0456-4",
    "page": "629-657",
    "page-first": "629",
    "volume": "30",
    "issue": "6",
    "language": "en-US",
    "_line": "FormalReview.bib:1859"
  },
  "petiot_your_2015": {
    "id": "petiot_your_2015",
    "type": "article-journal",
    "author": [
      {
        "family": "Petiot",
        "given": "Guillaume"
      },
      {
        "family": "Kosmatov",
        "given": "Nikolai"
      },
      {
        "family": "Botella",
        "given": "Bernard"
      },
      {
        "family": "Giorgetti",
        "given": "Alain"
      },
      {
        "family": "Julliand",
        "given": "Jacques"
      }
    ],
    "title": "Your Proof Fails? Testing Helps to Find the Reason",
    "container-title": "arXiv:1508.01691 \\[cs\\]",
    "container-title-short": "Your Proof Fails?",
    "title-short": "Your Proof Fails?",
    "issued": {
      "date-parts": [
        [
          "2015",
          "8",
          "7"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "abstract": "Applying deductive verification to formally prove that a program respects its formal specification is a very complex and time-consuming task due in particular to the lack of feedback in case of proof failures. Along with a non-compliance between the code and its specification (due to an error in at least one of them), possible reasons of a proof failure include a missing or too weak specification for a called function or a loop, and lack of time or simply incapacity of the prover to finish a particular proof. This work proposes a new methodology where test generation helps to identify the reason of a proof failure and to exhibit a counter-example clearly illustrating the issue. We describe how to transform an annotated C program into C code suitable for testing and illustrate the benefits of the method on comprehensive examples. The method has been implemented in STADY, a plugin of the software analysis platform FRAMA-C. Initial experiments show that detecting non-compliances and contract weaknesses allows to precisely diagnose most proof failures.",
    "keywords": "D.2.4, Computer Science - Software Engineering, D.2.5",
    "URLtext": "1508.01691",
    "URLpretext": "[arXiv:]{.etype}",
    "eprint-type": "arxiv",
    "eprint": "1508.01691",
    "URL": "http://arxiv.org/abs/1508.01691",
    "_line": "FormalReview.bib:1877"
  },
  "blatter_static_2018": {
    "id": "blatter_static_2018",
    "type": "paper-conference",
    "author": [
      {
        "family": "Blatter",
        "given": "Lionel"
      },
      {
        "family": "Kosmatov",
        "given": "Nikolai"
      },
      {
        "family": "Le Gall",
        "given": "Pascale"
      },
      {
        "family": "Prevosto",
        "given": "Virgile"
      },
      {
        "family": "Petiot",
        "given": "Guillaume"
      }
    ],
    "editor": [
      {
        "family": "Dubois",
        "given": "Catherine"
      },
      {
        "family": "Wolff",
        "given": "Burkhart"
      }
    ],
    "title": "Static and Dynamic Verification of Relational Properties on Self-composed C Code",
    "container-title": "Tests and Proofs",
    "collection-title": "Lecture Notes in Computer Science",
    "issued": {
      "date-parts": [
        [
          "2018"
        ]
      ]
    },
    "publisher": "Springer International Publishing",
    "isbn": "978-3-319-92994-1",
    "abstract": "Function contracts are a well-established way of formally specifying the intended behavior of a function. However, they usually only describe what should happen during a single call. Relational properties, on the other hand, link several function calls. They include such properties as non-interference, continuity and monotonicity. Other examples relate sequences of function calls, for instance, to show that decrypting an encrypted message with the appropriate key gives back the original message. Such properties cannot be expressed directly in the traditional setting of modular deductive verification, but are amenable to verification through self-composition. This paper presents a verification technique dedicated to relational properties in C programs and its implementation in the form of a Frama-C plugin called RPP and based on self-composition. It supports functions with side effects and recursive functions. The proposed approach makes it possible to prove a relational property, to check it at runtime, to generate a counterexample using testing and to use it as a hypothesis in the subsequent verification. Our initial experiments on existing benchmarks confirm that the proposed technique is helpful for static and dynamic analysis of relational properties.",
    "keywords": "Deductive verification, Frama-C, Specification, Dynamic verification, Relational properties, Self-composition",
    "page": "44-62",
    "page-first": "44",
    "language": "en-US",
    "_line": "FormalReview.bib:1892"
  },
  "melquiond_why3_nodate": {
    "id": "melquiond_why3_nodate",
    "type": "webpage",
    "author": [
      {
        "family": "Melquiond",
        "given": "Guillaume"
      }
    ],
    "title": "Why3",
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "URL": "http://why3.lri.fr/",
    "_line": "FormalReview.bib:1908"
  },
  "dijkstra_guarded_1975": {
    "id": "dijkstra_guarded_1975",
    "type": "article-journal",
    "author": [
      {
        "family": "Dijkstra",
        "given": "Edsger W."
      }
    ],
    "title": "Guarded Commands, Nondeterminacy and Formal Derivation of Programs",
    "container-title": "Commun. ACM",
    "issued": {
      "date-parts": [
        [
          "1975",
          "8"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "issn": "0001-0782",
    "abstract": "So-called “guarded commands” are introduced as a building block for alternative and repetitive constructs that allow nondeterministic program components for which at least the activity evoked, but possibly even the final state, is not necessarily uniquely determined by the initial state. For the formal derivation of programs expressed in terms of these constructs, a calculus will be be shown.",
    "keywords": "case-construction, correctness proof, derivation of programs, nondeterminancy, program semantics, programming language semantics, programming languages, programming methodology, repetition, sequencing primitives, termination",
    "URL": "http://doi.acm.org/10.1145/360933.360975",
    "DOI": "10.1145/360933.360975",
    "page": "453-457",
    "page-first": "453",
    "volume": "18",
    "issue": "8",
    "_line": "FormalReview.bib:1916"
  },
  "swamy_verifying_2013": {
    "id": "swamy_verifying_2013",
    "type": "article-journal",
    "author": [
      {
        "family": "Swamy",
        "given": "Nikhil"
      },
      {
        "family": "Chen",
        "given": "Juan"
      },
      {
        "family": "Livshits",
        "given": "Ben"
      }
    ],
    "title": "Verifying Higher-order Programs with the Dijkstra Monad",
    "issued": {
      "date-parts": [
        [
          "2013",
          "6",
          "1"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "abstract": "Modern programming languages, ranging from Haskell and ML, to JavaScript, C&hash; and Java, all make extensive use of higher-order state. This paper advocates a new verification methodology for higher-order stateful programs, based on a new monad of predicate transformers called the Dijkstra monad. Using the Dijkstra monad has a number of benefits. First, the monad …",
    "URL": "https://www.microsoft.com/en-us/research/publication/verifying-higher-order-programs-with-the-dijkstra-monad/",
    "language": "en-US",
    "_line": "FormalReview.bib:1933"
  },
  "swamy_dependent_2016": {
    "id": "swamy_dependent_2016",
    "type": "paper-conference",
    "author": [
      {
        "family": "Swamy",
        "given": "Nikhil"
      },
      {
        "family": "Hriţcu",
        "given": "Cătălin"
      },
      {
        "family": "Keller",
        "given": "Chantal"
      },
      {
        "family": "Rastogi",
        "given": "Aseem"
      },
      {
        "family": "Delignat-Lavaud",
        "given": "Antoine"
      },
      {
        "family": "Forest",
        "given": "Simon"
      },
      {
        "family": "Bhargavan",
        "given": "Karthikeyan"
      },
      {
        "family": "Fournet",
        "given": "Cédric"
      },
      {
        "family": "Strub",
        "given": "Pierre-Yves"
      },
      {
        "family": "Kohlweiss",
        "given": "Markulf"
      },
      {
        "family": "Zinzindohoue",
        "given": "Jean-Karim"
      },
      {
        "family": "Zanella-Béguelin",
        "given": "Santiago"
      }
    ],
    "title": "Dependent Types and Multi-monadic Effects in F\\*",
    "container-title": "Proceedings of the 43rd Annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages",
    "collection-title": "POPL '16",
    "issued": {
      "date-parts": [
        [
          "2016"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "publisher": "ACM",
    "isbn": "978-1-4503-3549-2",
    "abstract": "We present a new, completely redesigned, version of F\\*, a language that works both as a proof assistant as well as a general-purpose, verification-oriented, effectful programming language. In support of these complementary roles, F\\* is a dependently typed, higher-order, call-by-value language with &underscore;primitive&underscore; effects including state, exceptions, divergence and IO. Although primitive, programmers choose the granularity at which to specify effects by equipping each effect with a monadic, predicate transformer semantics. F\\* uses this to efficiently compute weakest preconditions and discharges the resulting proof obligations using a combination of SMT solving and manual proofs. Isolated from the effects, the core of F\\* is a language of pure functions used to write specifications and proof terms&mdash;its consistency is maintained by a semantic termination check based on a well-founded order. We evaluate our design on more than 55,000 lines of F\\* we have authored in the last year, focusing on three main case studies. Showcasing its use as a general-purpose programming language, F\\* is programmed (but not verified) in F\\*, and bootstraps in both OCaml and F&hash;. Our experience confirms F\\*'s pay-as-you-go cost model: writing idiomatic ML-like code with no finer specifications imposes no user burden. As a verification-oriented language, our most significant evaluation of F\\* is in verifying several key modules in an implementation of the TLS-1.2 protocol standard. For the modules we considered, we are able to prove more properties, with fewer annotations using F\\* than in a prior verified implementation of TLS-1.2. Finally, as a proof assistant, we discuss our use of F\\* in mechanizing the metatheory of a range of lambda calculi, starting from the simply typed lambda calculus to System F-omega and even micro-F\\*, a sizeable fragment of F\\* itself&mdash;these proofs make essential use of F\\*'s flexible combination of SMT automation and constructive proofs, enabling a tactic-free style of programming and proving at a relatively large scale.",
    "keywords": "proof assistants, effectful programming, verification",
    "URL": "http://doi.acm.org/10.1145/2837614.2837655",
    "DOI": "10.1145/2837614.2837655",
    "publisher-place": "New York, NY, USA",
    "page": "256-270",
    "page-first": "256",
    "_line": "FormalReview.bib:1944"
  },
  "ahman_dijkstra_2017": {
    "id": "ahman_dijkstra_2017",
    "type": "paper-conference",
    "author": [
      {
        "family": "Ahman",
        "given": "Danel"
      },
      {
        "family": "Hriţcu",
        "given": "Cătălin"
      },
      {
        "family": "Maillard",
        "given": "Kenji"
      },
      {
        "family": "Martínez",
        "given": "Guido"
      },
      {
        "family": "Plotkin",
        "given": "Gordon"
      },
      {
        "family": "Protzenko",
        "given": "Jonathan"
      },
      {
        "family": "Rastogi",
        "given": "Aseem"
      },
      {
        "family": "Swamy",
        "given": "Nikhil"
      }
    ],
    "title": "Dijkstra Monads for Free",
    "container-title": "Proceedings of the 44th ACM SIGPLAN Symposium on Principles of Programming Languages",
    "collection-title": "POPL 2017",
    "issued": {
      "date-parts": [
        [
          "2017"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "publisher": "ACM",
    "isbn": "978-1-4503-4660-3",
    "abstract": "Dijkstra monads enable a dependent type theory to be enhanced with support for specifying and verifying effectful code via weakest preconditions. Together with their closely related counterparts, Hoare monads, they provide the basis on which verification tools like F\\*, Hoare Type Theory (HTT), and Ynot are built. We show that Dijkstra monads can be derived \"for free\" by applying a continuation-passing style (CPS) translation to the standard monadic definitions of the underlying computational effects. Automatically deriving Dijkstra monads in this way provides a correct-by-construction and efficient way of reasoning about user-defined effects in dependent type theories. We demonstrate these ideas in EMF\\*, a new dependently typed calculus, validating it via both formal proof and a prototype implementation within F\\*. Besides equipping F\\* with a more uniform and extensible effect system, EMF\\* enables a novel mixture of intrinsic and extrinsic proofs within F\\*.",
    "keywords": "proof assistants, effectful programming, verification, dependent types",
    "URL": "http://doi.acm.org/10.1145/3009837.3009878",
    "DOI": "10.1145/3009837.3009878",
    "publisher-place": "New York, NY, USA",
    "page": "515-529",
    "page-first": "515",
    "_line": "FormalReview.bib:1962"
  },
  "hritcu_quest_nodate": {
    "id": "hritcu_quest_nodate",
    "type": "article-journal",
    "author": [
      {
        "family": "Hriţcu",
        "given": "Cătălin"
      }
    ],
    "title": "The Quest for Formally Secure Compartmentalizing Compilation",
    "abstract": "Severe low-level vulnerabilities abound in today’s computer systems, allowing cyber-attackers to remotely gain full control. This happens in big part because our programming languages, compilation chains, and architectures too often trade o security for e ciency. The semantics of mainstream low-level languages like C is inherently insecure, and even for safer languages, all guarantees are lost when interacting with low-level code, for instance when using low-level libraries. This habilitation presents my ongoing quest to build formally secure compartmentalizing compilation chains that defend against such attacks. In particular, we propose several formal de nitions that characterize what it means for a compartmentalizing compilation chain to be secure, both in the case of safe and of unsafe source languages.",
    "page": "96",
    "page-first": "96",
    "language": "en-US",
    "_line": "FormalReview.bib:1980"
  },
  "ahman_recalling_2017": {
    "id": "ahman_recalling_2017",
    "type": "article-journal",
    "author": [
      {
        "family": "Ahman",
        "given": "Danel"
      },
      {
        "family": "Fournet",
        "given": "Cédric"
      },
      {
        "family": "Hriţcu",
        "given": "Cătălin"
      },
      {
        "family": "Maillard",
        "given": "Kenji"
      },
      {
        "family": "Rastogi",
        "given": "Aseem"
      },
      {
        "family": "Swamy",
        "given": "Nikhil"
      }
    ],
    "title": "Recalling a Witness: Foundations and Applications of Monotonic State",
    "container-title": "Proc. ACM Program. Lang.",
    "container-title-short": "Recalling a Witness",
    "title-short": "Recalling a Witness",
    "issued": {
      "date-parts": [
        [
          "2017",
          "12"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "issn": "2475-1421",
    "abstract": "We provide a way to ease the verification of programs whose state evolves monotonically. The main idea is that a property witnessed in a prior state can be soundly recalled in the current state, provided (1) state evolves according to a given preorder, and (2) the property is preserved by this preorder. In many scenarios, such monotonic reasoning yields concise modular proofs, saving the need for explicit program invariants. We distill our approach into the monotonic-state monad, a general yet compact interface for Hoare-style reasoning about monotonic state in a dependently typed language. We prove the soundness of the monotonic-state monad and use it as a unified foundation for reasoning about monotonic state in the F⋆ verification system. Based on this foundation, we build libraries for various mutable data structures like monotonic references and apply these libraries at scale to the verification of several distributed applications.",
    "keywords": "Program Verification, Formal Foundations, Hoare Logic, Modular Reasoning, Monotonic References, Monotonic-State Monad, Secure File Transfer, State Continuity",
    "URL": "http://doi.acm.org/10.1145/3158153",
    "DOI": "10.1145/3158153",
    "page": "65:1-65:30",
    "page-first": "65",
    "volume": "2",
    "_line": "FormalReview.bib:1989"
  },
  "syme_fsharp_2019": {
    "id": "syme_fsharp_2019",
    "type": "book",
    "author": [
      {
        "family": "Syme",
        "given": "Don"
      }
    ],
    "title": "Fsharp design: RFCs and docs related to the F&hash; language design process,",
    "container-title-short": "RFCs and docs related to the F&hash; language design process, see https",
    "title-short": "RFCs and docs related to the F&hash; language design process, see https",
    "issued": {
      "date-parts": [
        [
          "2019",
          "1",
          "29"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "publisher": "F&hash; Software Foundation Repositories",
    "URL": "https://github.com/fsharp/fslang-design",
    "note": "original-date: 2014-06-25T13:07:35Z",
    "_line": "FormalReview.bib:2007"
  },
  "syme_fsharp_2019-1": {
    "id": "syme_fsharp_2019-1",
    "type": "book",
    "author": [
      {
        "family": "Syme",
        "given": "Don"
      }
    ],
    "title": "The Fsharp Compiler, Core Library &amp; Tools (F&hash; Software Foundation Repository): fsharp/fsharp",
    "container-title-short": "The F&hash; Compiler, Core Library &amp; Tools (F&hash; Software Foundation Repository)",
    "title-short": "The F&hash; Compiler, Core Library &amp; Tools (F&hash; Software Foundation Repository)",
    "issued": {
      "date-parts": [
        [
          "2019",
          "1",
          "30"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "publisher": "F&hash; Software Foundation Repositories",
    "URL": "https://github.com/fsharp/fsharp",
    "note": "original-date: 2010-12-13T00:19:52Z",
    "_line": "FormalReview.bib:2018"
  },
  "filinski_representing_1994": {
    "id": "filinski_representing_1994",
    "type": "paper-conference",
    "author": [
      {
        "family": "Filinski",
        "given": "Andrzej"
      }
    ],
    "title": "Representing Monads",
    "container-title": "Proceedings of the 21st ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages",
    "collection-title": "POPL '94",
    "issued": {
      "date-parts": [
        [
          "1994"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "publisher": "ACM",
    "isbn": "978-0-89791-636-3",
    "abstract": "We show that any monad whose unit and extension operations are expressible as purely functional terms can be embedded in a call-by-value language with “composable continuations”. As part of the development, we extend Meyer and Wand's characterization of the relationship between continuation-passing and direct style to one for continuation-passing vs. general “monadic” style. We further show that the composable-continuations construct can itself be represented using ordinary, non-composable first-class continuations and a single piece of state. Thus, in the presence of two specific computational effects - storage and escapes - any expressible monadic structure (e.g., nondeterminism as represented by the list monad) can be added as a purely definitional extension, without requiring a reinterpretation of the whole language. The paper includes an implementation of the construction (in Standard ML with some New Jersey extensions) and several examples.",
    "URL": "http://doi.acm.org/10.1145/174675.178047",
    "DOI": "10.1145/174675.178047",
    "publisher-place": "New York, NY, USA",
    "page": "446-457",
    "page-first": "446",
    "_line": "FormalReview.bib:2045"
  },
  "filinski_representing_1999": {
    "id": "filinski_representing_1999",
    "type": "paper-conference",
    "author": [
      {
        "family": "Filinski",
        "given": "Andrzej"
      }
    ],
    "title": "Representing Layered Monads",
    "container-title": "Proceedings of the 26th ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages",
    "collection-title": "POPL '99",
    "issued": {
      "date-parts": [
        [
          "1999"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "publisher": "ACM",
    "isbn": "978-1-58113-095-9",
    "abstract": "There has already been considerable research on constructing modular, monad-based specifications of computational effects (state, exceptions, nondeterminism, etc.) in programming languages. We present a simple framework in this tradition, based on a Church-style effect-typing system for an ML-like language. The semantics of this language is formally defined by a series of monadic translations, each one expanding away a layer of effects. Such a layered specification is easy to reason about, but its direct implementation (whether by parameterized interpretation or by actual translation) is often prohibitively inefficient.By exploiting deeper semantic properties of monads, however, it is also possible to derive a vastly more efficient implementation: we show that each layer of effects can be uniformly simulated by continuation-passing, and further that multiple such layers can themselves be simulated by a standard semantics for call/cc and mutable state. Thus, even multi-effect programs can be executed in Scheme or SML/NJ at full native speed, generalizing an earlier single-effect result. As an example, we show how a simple resumption-based semantics of concurrency allows us to directly simulate a shared-state program across all possible dynamic interleavings of execution threads.",
    "URL": "http://doi.acm.org/10.1145/292540.292557",
    "DOI": "10.1145/292540.292557",
    "publisher-place": "New York, NY, USA",
    "page": "175-188",
    "page-first": "175",
    "_line": "FormalReview.bib:2062"
  },
  "gonthier_introduction_2010": {
    "id": "gonthier_introduction_2010",
    "type": "article-journal",
    "author": [
      {
        "family": "Gonthier",
        "given": "Georges"
      },
      {
        "family": "Mahboubi",
        "given": "Assia"
      }
    ],
    "title": "An introduction to small scale reflection in Coq",
    "container-title": "Journal of Formalized Reasoning",
    "issued": {
      "date-parts": [
        [
          "2010"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "issn": "1972-5787",
    "abstract": "This tutorial presents the SSReflect extension to the Coq system. This extension consists of an extension to the Coq language of script, and of a set of libraries, originating from the formal proof of the Four Color theorem. This tutorial proposes a guided tour in some of the basic libraries distributed in the SSReflect package. It focuses on the application of the small scale reflection methodology to the formalization of finite objects in intuitionistic type theory.",
    "URL": "https://jfr.unibo.it/article/view/1979",
    "DOI": "10.6092/issn.1972-5787/1979",
    "page": "95-152",
    "page-first": "95",
    "volume": "3",
    "issue": "2",
    "language": "en-US",
    "_line": "FormalReview.bib:2079"
  },
  "gonthier_how_2011": {
    "id": "gonthier_how_2011",
    "type": "paper-conference",
    "author": [
      {
        "family": "Gonthier",
        "given": "Georges"
      },
      {
        "family": "Ziliani",
        "given": "Beta"
      },
      {
        "family": "Nanevski",
        "given": "Aleksandar"
      },
      {
        "family": "Dreyer",
        "given": "Derek"
      }
    ],
    "title": "How to Make Ad Hoc Proof Automation Less Ad Hoc",
    "container-title": "Proceedings of the 16th ACM SIGPLAN International Conference on Functional Programming",
    "collection-title": "ICFP '11",
    "issued": {
      "date-parts": [
        [
          "2011"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "publisher": "ACM",
    "isbn": "978-1-4503-0865-6",
    "abstract": "Most interactive theorem provers provide support for some form of user-customizable proof automation. In a number of popular systems, such as Coq and Isabelle, this automation is achieved primarily through tactics, which are programmed in a separate language from that of the prover's base logic. While tactics are clearly useful in practice, they can be difficult to maintain and compose because, unlike lemmas, their behavior cannot be specified within the expressive type system of the prover itself. We propose a novel approach to proof automation in Coq that allows the user to specify the behavior of custom automated routines in terms of Coq's own type system. Our approach involves a sophisticated application of Coq's canonical structures, which generalize Haskell type classes and facilitate a flexible style of dependently-typed logic programming. Specifically, just as Haskell type classes are used to infer the canonical implementation of an overloaded term at a given type, canonical structures can be used to infer the canonical proof of an overloaded lemma for a given instantiation of its parameters. We present a series of design patterns for canonical structure programming that enable one to carefully and predictably coax Coq's type inference engine into triggering the execution of user-supplied algorithms during unification, and we illustrate these patterns through several realistic examples drawn from Hoare Type Theory. We assume no prior knowledge of Coq and describe the relevant aspects of Coq type inference from first principles.",
    "keywords": "canonical structures, coq, custom proof automation, hoare type theory, interactive theorem proving, tactics, type classes",
    "URL": "http://doi.acm.org/10.1145/2034773.2034798",
    "DOI": "10.1145/2034773.2034798",
    "publisher-place": "New York, NY, USA",
    "page": "163-175",
    "page-first": "163",
    "_line": "FormalReview.bib:2097"
  },
  "mokhov_algebraic_2017": {
    "id": "mokhov_algebraic_2017",
    "type": "paper-conference",
    "author": [
      {
        "family": "Mokhov",
        "given": "Andrey"
      }
    ],
    "title": "Algebraic Graphs with Class (Functional Pearl)",
    "container-title": "Proceedings of the 10th ACM SIGPLAN International Symposium on Haskell",
    "collection-title": "Haskell 2017",
    "issued": {
      "date-parts": [
        [
          "2017"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "publisher": "ACM",
    "isbn": "978-1-4503-5182-9",
    "abstract": "The paper presents a minimalistic and elegant approach to working with graphs in Haskell. It is built on a rigorous mathematical foundation &mdash; an algebra of graphs &mdash; that allows us to apply equational reasoning for proving the correctness of graph transformation algorithms. Algebraic graphs let us avoid partial functions typically caused by 'malformed graphs' that contain an edge referring to a non-existent vertex. This helps to liberate APIs of existing graph libraries from partial functions.   The algebra of graphs can represent directed, undirected, reflexive and transitive graphs, as well as hypergraphs, by appropriately choosing the set of underlying axioms. The flexibility of the approach is demonstrated by developing a library for constructing and transforming polymorphic graphs.",
    "keywords": "algebra, graph theory, Haskell",
    "URL": "http://doi.acm.org/10.1145/3122955.3122956",
    "DOI": "10.1145/3122955.3122956",
    "publisher-place": "New York, NY, USA",
    "page": "2-13",
    "page-first": "2",
    "_line": "FormalReview.bib:2115"
  },
  "ramsey_applicative_2006": {
    "id": "ramsey_applicative_2006",
    "type": "article-journal",
    "author": [
      {
        "family": "Ramsey",
        "given": "Norman"
      },
      {
        "family": "Dias",
        "given": "João"
      }
    ],
    "title": "An Applicative Control-Flow Graph Based on Huet's Zipper",
    "container-title": "Electronic Notes in Theoretical Computer Science",
    "collection-title": "Proceedings of the ACM-SIGPLAN Workshop on ML (ML 2005)",
    "issued": {
      "date-parts": [
        [
          "2006",
          "3",
          "24"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "issn": "1571-0661",
    "abstract": "We are using ML to build a compiler that does low-level optimization. To support optimizations in classic imperative style, we built a control-flow graph using mutable pointers and other mutable state in the nodes. This decision proved unfortunate: the mutable flow graph was big and complex, and it led to many bugs. We have replaced it by a smaller, simpler, applicative flow graph based on Huet's \\[Huet, Gérard, 1997. The Zipper. Journal of Functional Programming, 7(5):549–554. Functional Pearl\\] zipper. The new flow graph is a success; this paper presents its design and shows how it leads to a gratifyingly simple implementation of the dataflow framework developed by \\[Lerner, Sorin, David Grove, and Craig Chambers. 2002. Composing dataflow analyses and transformations. Conference Record of the 29th Annual ACM Symposium on Principles of Programming Languages, in SIGPLAN Notices, 31(1):270–282\\].",
    "keywords": "applicative data structures, compilers, control-flow graphs, dataflow analysis, optimization",
    "URL": "http://www.sciencedirect.com/science/article/pii/S1571066106001289",
    "DOI": "10.1016/j.entcs.2005.11.042",
    "page": "105-126",
    "page-first": "105",
    "volume": "148",
    "issue": "2",
    "_line": "FormalReview.bib:2133"
  },
  "harper_framework_1993": {
    "id": "harper_framework_1993",
    "type": "article-journal",
    "author": [
      {
        "family": "Harper",
        "given": "Robert"
      },
      {
        "family": "Honsell",
        "given": "Furio"
      },
      {
        "family": "Plotkin",
        "given": "Gordon"
      }
    ],
    "title": "A Framework for Defining Logics",
    "container-title": "J. ACM",
    "issued": {
      "date-parts": [
        [
          "1993",
          "1"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "issn": "0004-5411",
    "abstract": "The Edinburgh Logical Framework (LF) provides a means to define (or present) logics. It is based on a general treatment of syntax, rules, and proofs by means of a typed &amp;lgr;-calculus with dependent types. Syntax is treated in a style similar to, but more general than, Martin-Lo¨f's system of arities. The treatment of rules and proofs focuses on his notion of a judgment. Logics are represented in LF via a new principle, the judgments as types principle, whereby each judgment is identified with the type of its proofs. This allows for a smooth treatment of discharge and variable occurence conditions and leads to a uniform treatment of rules and proofs whereby rules are viewed as proofs of higher-order judgments and proof checking is reduced to type checking. The practical benefit of our treatment of formal systems is that logic-independent tools, such as proof editors and proof checkers, can be constructed.",
    "keywords": "interactive theorem proving, formal systems, proof checking, typed lambda calculus",
    "URL": "http://doi.acm.org/10.1145/138027.138060",
    "DOI": "10.1145/138027.138060",
    "page": "143-184",
    "page-first": "143",
    "volume": "40",
    "issue": "1",
    "_line": "FormalReview.bib:2151"
  },
  "harrison_hol_2013": {
    "id": "harrison_hol_2013",
    "type": "article-journal",
    "author": [
      {
        "family": "Harrison",
        "given": "John"
      }
    ],
    "title": "The HOL Light Theory of Euclidean Space",
    "container-title": "Journal of Automated Reasoning",
    "issued": {
      "date-parts": [
        [
          "2013",
          "2"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "issn": "0168-7433, 1573-0670",
    "URL": "http://link.springer.com/10.1007/s10817-012-9250-9",
    "DOI": "10.1007/s10817-012-9250-9",
    "page": "173-190",
    "page-first": "173",
    "volume": "50",
    "issue": "2",
    "language": "en-US",
    "_line": "FormalReview.bib:2168"
  },
  "spector-zabusky_total_2018": {
    "id": "spector-zabusky_total_2018",
    "type": "paper-conference",
    "author": [
      {
        "family": "Spector-Zabusky",
        "given": "Antal"
      },
      {
        "family": "Breitner",
        "given": "Joachim"
      },
      {
        "family": "Rizkallah",
        "given": "Christine"
      },
      {
        "family": "Weirich",
        "given": "Stephanie"
      }
    ],
    "title": "Total Haskell is Reasonable Coq",
    "container-title": "Proceedings of the 7th ACM SIGPLAN International Conference on Certified Programs and Proofs",
    "collection-title": "CPP 2018",
    "issued": {
      "date-parts": [
        [
          "2018"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "publisher": "ACM",
    "isbn": "978-1-4503-5586-5",
    "abstract": "We would like to use the Coq proof assistant to mechanically verify properties of Haskell programs. To that end, we present a tool, named &lt;tt&gt;hs-to-coq&lt;/tt&gt;, that translates total Haskell programs into Coq programs via a shallow embedding. We apply our tool in three case studies – a lawful &lt;tt&gt;Monad&lt;/tt&gt; instance, “Hutton’s razor”, and an existing data structure library – and prove their correctness. These examples show that this approach is viable: both that &lt;tt&gt;hs-to-coq&lt;/tt&gt; applies to existing Haskell code, and that the output it produces is amenable to verification.",
    "keywords": "Coq, verification, Haskell",
    "URL": "http://doi.acm.org/10.1145/3167092",
    "DOI": "10.1145/3167092",
    "publisher-place": "New York, NY, USA",
    "page": "14-27",
    "page-first": "14",
    "_line": "FormalReview.bib:2184"
  },
  "hutchison_fresh_2009": {
    "id": "hutchison_fresh_2009",
    "type": "chapter",
    "author": [
      {
        "family": "Dockins",
        "given": "Robert"
      },
      {
        "family": "Hobor",
        "given": "Aquinas"
      },
      {
        "family": "Appel",
        "given": "Andrew W."
      }
    ],
    "editor": [
      {
        "family": "Hu",
        "given": "Zhenjiang"
      }
    ],
    "title": "A Fresh Look at Separation Algebras and Share Accounting",
    "container-title": "Programming Languages and Systems",
    "issued": {
      "date-parts": [
        [
          "2009"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "publisher": "Springer Berlin Heidelberg",
    "isbn": "978-3-642-10671-2 978-3-642-10672-9",
    "abstract": "Separation Algebras serve as models of Separation Logics; Share Accounting allows reasoning about concurrent-read/exclusive-write resources in Separation Logic. In designing a Concurrent Separation Logic and in mechanizing proofs of its soundness, we found previous axiomatizations of separation algebras and previous systems of share accounting to be useful but ﬂawed. We adjust the axioms of separation algebras; we demonstrate an operator calculus for constructing new separation algebras; we present a more powerful system of share accounting with a new, simple model; and we provide a reusable Coq development.",
    "URL": "http://link.springer.com/10.1007/978-3-642-10672-9_13",
    "DOI": "10.1007/978-3-642-10672-9_13",
    "publisher-place": "Berlin, Heidelberg",
    "page": "161-177",
    "page-first": "161",
    "volume": "5904",
    "language": "en-US",
    "_line": "FormalReview.bib:2202"
  },
  "swamy_project_nodate": {
    "id": "swamy_project_nodate",
    "type": "webpage",
    "author": [
      {
        "family": "Swamy",
        "given": "Nikhil"
      }
    ],
    "title": "Project Everest - Verified Secure Implementations of the HTTPS Ecosystem.Microsoft Research",
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "abstract": "This project proposes to deﬁnitively solve the problem of a brittle HTTPS ecosystem by constructing a more secure, high performance, standards-compliant, veriﬁed implementation of the full HTTPS ecosystem. Unlike other veriﬁed software projects, our expedition aims to deploy Everest within existing software as a drop-in replacement in mainstream web browsers, servers, and other popular tools.",
    "URL": "https://www.microsoft.com/en-us/research/project/project-everest-verified-secure-implementations-https-ecosystem/",
    "language": "en-US",
    "_line": "FormalReview.bib:2223"
  },
  "fournet_deploying_nodate": {
    "id": "fournet_deploying_nodate",
    "type": "article-journal",
    "author": [
      {
        "family": "Fournet",
        "given": "Cedric"
      },
      {
        "family": "Hawblitzel",
        "given": "Chris"
      },
      {
        "family": "Parno",
        "given": "Bryan"
      },
      {
        "family": "Swamy",
        "given": "Nikhil"
      }
    ],
    "title": "Deploying a Veriﬁed Secure Implementation of the HTTPS Ecosystem",
    "page": "10",
    "page-first": "10",
    "language": "en-US",
    "_line": "FormalReview.bib:2234"
  },
  "hawblitzel_ironclad_nodate": {
    "id": "hawblitzel_ironclad_nodate",
    "type": "article-journal",
    "author": [
      {
        "family": "Hawblitzel",
        "given": "Chris"
      },
      {
        "family": "Howell",
        "given": "Jon"
      },
      {
        "family": "Lorch",
        "given": "Jacob R"
      },
      {
        "family": "Narayan",
        "given": "Arjun"
      },
      {
        "family": "Parno",
        "given": "Bryan"
      },
      {
        "family": "Zhang",
        "given": "Danfeng"
      },
      {
        "family": "Zill",
        "given": "Brian"
      }
    ],
    "title": "Ironclad Apps: End-to-End Security via Automated Full-System Veriﬁcation",
    "abstract": "An Ironclad App lets a user securely transmit her data to a remote machine with the guarantee that every instruction executed on that machine adheres to a formal abstract speciﬁcation of the app’s behavior. This does more than eliminate implementation vulnerabilities such as buffer overﬂows, parsing errors, or data leaks; it tells the user exactly how the app will behave at all times. We provide these guarantees via complete, low-level software veriﬁcation. We then use cryptography and secure hardware to enable secure channels from the veriﬁed software to remote users. To achieve such complete veriﬁcation, we developed a set of new and modiﬁed tools, a collection of techniques and engineering disciplines, and a methodology focused on rapid development of veriﬁed systems software. We describe our methodology, formal results, and lessons we learned from building a full stack of veriﬁed software. That software includes a veriﬁed kernel; veriﬁed drivers; veriﬁed system and crypto libraries including SHA, HMAC, and RSA; and four Ironclad Apps.",
    "page": "18",
    "page-first": "18",
    "language": "en-US",
    "_line": "FormalReview.bib:2242"
  },
  "hawblitzel_ironfleet:_2015": {
    "id": "hawblitzel_ironfleet:_2015",
    "type": "paper-conference",
    "author": [
      {
        "family": "Hawblitzel",
        "given": "Chris"
      },
      {
        "family": "Howell",
        "given": "Jon"
      },
      {
        "family": "Kapritsos",
        "given": "Manos"
      },
      {
        "family": "Lorch",
        "given": "Jacob R."
      },
      {
        "family": "Parno",
        "given": "Bryan"
      },
      {
        "family": "Roberts",
        "given": "Michael L."
      },
      {
        "family": "Setty",
        "given": "Srinath"
      },
      {
        "family": "Zill",
        "given": "Brian"
      }
    ],
    "title": "IronFleet: Proving Practical Distributed Systems Correct",
    "container-title": "Proceedings of the 25th Symposium on Operating Systems Principles",
    "container-title-short": "IronFleet",
    "collection-title": "SOSP '15",
    "title-short": "IronFleet",
    "issued": {
      "date-parts": [
        [
          "2015"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "publisher": "ACM",
    "isbn": "978-1-4503-3834-9",
    "abstract": "Distributed systems are notorious for harboring subtle bugs. Verification can, in principle, eliminate these bugs a priori, but verification has historically been difficult to apply at full-program scale, much less distributed-system scale. We describe a methodology for building practical and provably correct distributed systems based on a unique blend of TLA-style state-machine refinement and Hoare-logic verification. We demonstrate the methodology on a complex implementation of a Paxos-based replicated state machine library and a lease-based sharded key-value store. We prove that each obeys a concise safety specification, as well as desirable liveness requirements. Each implementation achieves performance competitive with a reference system. With our methodology and lessons learned, we aim to raise the standard for distributed systems from \"tested\" to \"correct.\"",
    "URL": "http://doi.acm.org/10.1145/2815400.2815428",
    "DOI": "10.1145/2815400.2815428",
    "publisher-place": "New York, NY, USA",
    "page": "1-17",
    "page-first": "1",
    "_line": "FormalReview.bib:2251"
  },
  "hawblitzel_automated_2015": {
    "id": "hawblitzel_automated_2015",
    "type": "paper-conference",
    "author": [
      {
        "family": "Hawblitzel",
        "given": "Chris"
      },
      {
        "family": "Petrank",
        "given": "Erez"
      },
      {
        "family": "Qadeer",
        "given": "Shaz"
      },
      {
        "family": "Tasiran",
        "given": "Serdar"
      }
    ],
    "title": "Automated and Modular Refinement Reasoning for Concurrent Programs",
    "container-title": "Computer Aided Verification",
    "event-title": "International Conference on Computer Aided Verification",
    "issued": {
      "date-parts": [
        [
          "2015",
          "7",
          "18"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "publisher": "Springer, Cham",
    "abstract": "We present civl, a language and verifier for concurrent programs based on automated and modular refinement reasoning. civlsupports reasoning about a concurrent program at many levels of abstraction....",
    "URL": "https://link.springer.com/chapter/10.1007/978-3-319-21668-3_26",
    "DOI": "10.1007/978-3-319-21668-3_26",
    "page": "449-465",
    "page-first": "449",
    "language": "en-US",
    "_line": "FormalReview.bib:2269"
  },
  "lahiri_automatic_2015": {
    "id": "lahiri_automatic_2015",
    "type": "paper-conference",
    "author": [
      {
        "family": "Lahiri",
        "given": "Shuvendu K."
      },
      {
        "family": "Sinha",
        "given": "Rohit"
      },
      {
        "family": "Hawblitzel",
        "given": "Chris"
      }
    ],
    "editor": [
      {
        "family": "Kroening",
        "given": "Daniel"
      },
      {
        "family": "Păsăreanu",
        "given": "Corina S."
      }
    ],
    "title": "Automatic Rootcausing for Program Equivalence Failures in Binaries",
    "container-title": "Computer Aided Verification",
    "collection-title": "Lecture Notes in Computer Science",
    "issued": {
      "date-parts": [
        [
          "2015"
        ]
      ]
    },
    "publisher": "Springer International Publishing",
    "isbn": "978-3-319-21690-4",
    "abstract": "Equivalence checking of imperative programs has several applications including compiler validation and cross-version verification. Debugging equivalence failures can be tedious for large examples, especially for low-level binary programs. In this paper, we formalize a simple yet precise notion of verifiable rootcause for equivalence failures that leverages semantic similarity between two programs. Unlike existing works on program repair, our definition of rootcause avoids the need for a template of fixes or the need for a complete repair to ensure equivalence. We show progressively weaker checks for detecting rootcauses that can be applicable even when multiple fixes are required to make the two programs equivalent. We provide optimizations based on Maximum Satisfiability (MAXSAT) and binary search to prune the search space of such rootcauses. We have implemented the techniques in SymDiff and provide an evaluation on a set of real-world compiler validation binary benchmarks.",
    "page": "362-379",
    "page-first": "362",
    "language": "en-US",
    "_line": "FormalReview.bib:2285"
  },
  "yang_safe_2011": {
    "id": "yang_safe_2011",
    "type": "article-journal",
    "author": [
      {
        "family": "Yang",
        "given": "Jean"
      },
      {
        "family": "Hawblitzel",
        "given": "Chris"
      }
    ],
    "title": "Safe to the last instruction: automated verification of a type-safe operating system",
    "container-title": "Communications of the ACM",
    "container-title-short": "Safe to the last instruction",
    "title-short": "Safe to the last instruction",
    "issued": {
      "date-parts": [
        [
          "2011",
          "12",
          "1"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "issn": "00010782",
    "URL": "http://dl.acm.org/citation.cfm?doid=2043174.2043197",
    "DOI": "10.1145/2043174.2043197",
    "page": "123",
    "page-first": "123",
    "volume": "54",
    "issue": "12",
    "language": "en-US",
    "_line": "FormalReview.bib:2300"
  },
  "lahiri_symdiff:_2012": {
    "id": "lahiri_symdiff:_2012",
    "type": "paper-conference",
    "author": [
      {
        "family": "Lahiri",
        "given": "Shuvendu K."
      },
      {
        "family": "Hawblitzel",
        "given": "Chris"
      },
      {
        "family": "Kawaguchi",
        "given": "Ming"
      },
      {
        "family": "Rebêlo",
        "given": "Henrique"
      }
    ],
    "editor": [
      {
        "family": "Madhusudan",
        "given": "P."
      },
      {
        "family": "Seshia",
        "given": "Sanjit A."
      }
    ],
    "title": "SYMDIFF: A Language-Agnostic Semantic Diff Tool for Imperative Programs",
    "container-title": "Computer Aided Verification",
    "container-title-short": "SYMDIFF",
    "collection-title": "Lecture Notes in Computer Science",
    "title-short": "SYMDIFF",
    "issued": {
      "date-parts": [
        [
          "2012"
        ]
      ]
    },
    "publisher": "Springer Berlin Heidelberg",
    "isbn": "978-3-642-31424-7",
    "abstract": "In this paper, we describe SymDiff, a language-agnostic tool for equivalence checking and displaying semantic (behavioral) differences over imperative programs. The tool operates on an intermediate verification language Boogie, for which translations exist from various source languages such as C, C&hash; and x86. We discuss the tool and the front-end interface to target various source languages. Finally, we provide a brief description of the front-end for C programs.",
    "keywords": "Symbolic Execution, Equivalence Check, Imperative Language, Imperative Program, Source Language",
    "page": "712-717",
    "page-first": "712",
    "language": "en-US",
    "_line": "FormalReview.bib:2317"
  },
  "adams_common_2015": {
    "id": "adams_common_2015",
    "type": "article-journal",
    "author": [
      {
        "family": "Adams",
        "given": "Mark"
      }
    ],
    "title": "The Common HOL Platform",
    "container-title": "Electronic Proceedings in Theoretical Computer Science",
    "issued": {
      "date-parts": [
        [
          "2015",
          "7",
          "30"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "issn": "2075-2180",
    "abstract": "The Common HOL project aims to facilitate porting source code and proofs between members of the HOL family of theorem provers. At the heart of the project is the Common HOL Platform, which defines a standard HOL theory and API that aims to be compatible with all HOL systems. So far, HOL Light and hol90 have been adapted for conformance, and HOL Zero was originally developed to conform. In this paper we provide motivation for a platform, give an overview of the Common HOL Platform's theory and API components, and show how to adapt legacy systems. We also report on the platform's successful application in the hand-translation of a few thousand lines of source code from HOL Light to HOL Zero.",
    "keywords": "Computer Science - Logic in Computer Science, Computer Science - Digital Libraries",
    "URLtext": "1507.08718",
    "URLpretext": "[arXiv:]{.etype}",
    "eprint-type": "arxiv",
    "eprint": "1507.08718",
    "URL": "http://arxiv.org/abs/1507.08718",
    "DOI": "10.4204/EPTCS.186.6",
    "page": "42-56",
    "page-first": "42",
    "volume": "186",
    "_line": "FormalReview.bib:2334"
  },
  "shulman_hott_2013": {
    "id": "shulman_hott_2013",
    "type": "webpage",
    "author": [
      {
        "family": "Shulman",
        "given": "Mike"
      }
    ],
    "title": "The HoTT Book.Homotopy Type Theory",
    "issued": {
      "date-parts": [
        [
          "2013",
          "3",
          "12"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "abstract": "Homotopy Type Theory: Univalent Foundations of Mathematics The Univalent Foundations Program Institute for Advanced Study Buy a hardcover copy for &dollar;22.05. \\[620 pages, 6″ × 9″ size, hard…",
    "URL": "https://homotopytypetheory.org/book/",
    "language": "en-US",
    "_line": "FormalReview.bib:2352"
  },
  "voevodsky_homotopy_nodate": {
    "id": "voevodsky_homotopy_nodate",
    "type": "article-journal",
    "author": [
      {
        "family": "Voevodsky",
        "given": "Vladimir"
      }
    ],
    "title": "Homotopy Type Theory: Univalent Foundations of Mathematics",
    "page": "490",
    "page-first": "490",
    "language": "en-US",
    "_line": "FormalReview.bib:2364"
  },
  "nelson_hyperkernel:_2017": {
    "id": "nelson_hyperkernel:_2017",
    "type": "paper-conference",
    "author": [
      {
        "family": "Nelson",
        "given": "Luke"
      },
      {
        "family": "Sigurbjarnarson",
        "given": "Helgi"
      },
      {
        "family": "Zhang",
        "given": "Kaiyuan"
      },
      {
        "family": "Johnson",
        "given": "Dylan"
      },
      {
        "family": "Bornholt",
        "given": "James"
      },
      {
        "family": "Torlak",
        "given": "Emina"
      },
      {
        "family": "Wang",
        "given": "Xi"
      }
    ],
    "title": "Hyperkernel: Push-Button Verification of an OS Kernel",
    "container-title": "Proceedings of the 26th Symposium on Operating Systems Principles",
    "container-title-short": "Hyperkernel",
    "collection-title": "SOSP '17",
    "title-short": "Hyperkernel",
    "issued": {
      "date-parts": [
        [
          "2017"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "publisher": "ACM",
    "isbn": "978-1-4503-5085-3",
    "abstract": "This paper describes an approach to designing, implementing, and formally verifying the functional correctness of an OS kernel, named Hyperkernel, with a high degree of proof automation and low proof burden. We base the design of Hyperkernel's interface on xv6, a Unix-like teaching operating system. Hyperkernel introduces three key ideas to achieve proof automation: it finitizes the kernel interface to avoid unbounded loops or recursion; it separates kernel and user address spaces to simplify reasoning about virtual memory; and it performs verification at the LLVM intermediate representation level to avoid modeling complicated C semantics. We have verified the implementation of Hyperkernel with the Z3 SMT solver, checking a total of 50 system calls and other trap handlers. Experience shows that Hyperkernel can avoid bugs similar to those found in xv6, and that the verification of Hyperkernel can be achieved with a low proof burden.",
    "URL": "http://doi.acm.org/10.1145/3132747.3132748",
    "DOI": "10.1145/3132747.3132748",
    "publisher-place": "New York, NY, USA",
    "page": "252-269",
    "page-first": "252",
    "_line": "FormalReview.bib:2372"
  },
  "nelson_hyperkernel:_2017-1": {
    "id": "nelson_hyperkernel:_2017-1",
    "type": "paper-conference",
    "author": [
      {
        "family": "Nelson",
        "given": "Luke"
      },
      {
        "family": "Sigurbjarnarson",
        "given": "Helgi"
      },
      {
        "family": "Zhang",
        "given": "Kaiyuan"
      },
      {
        "family": "Johnson",
        "given": "Dylan"
      },
      {
        "family": "Bornholt",
        "given": "James"
      },
      {
        "family": "Torlak",
        "given": "Emina"
      },
      {
        "family": "Wang",
        "given": "Xi"
      }
    ],
    "title": "Hyperkernel: Push-Button Verification of an OS Kernel - Slides",
    "container-title": "Proceedings of the 26th Symposium on Operating Systems Principles  - SOSP '17",
    "container-title-short": "Hyperkernel",
    "title-short": "Hyperkernel",
    "event-title": "the 26th Symposium",
    "issued": {
      "date-parts": [
        [
          "2017"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "publisher": "ACM Press",
    "isbn": "978-1-4503-5085-3",
    "URL": "http://dl.acm.org/citation.cfm?doid=3132747.3132748",
    "DOI": "10.1145/3132747.3132748",
    "publisher-place": "Shanghai, China",
    "page": "252-269",
    "page-first": "252",
    "language": "en-US",
    "_line": "FormalReview.bib:2390"
  },
  "jung_iris_nodate": {
    "id": "jung_iris_nodate",
    "type": "webpage",
    "author": [
      {
        "family": "Jung",
        "given": "Ralf"
      }
    ],
    "title": "Iris Project",
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "URL": "https://iris-project.org/",
    "_line": "FormalReview.bib:2408"
  },
  "birkedal_iris_nodate": {
    "id": "birkedal_iris_nodate",
    "type": "webpage",
    "author": [
      {
        "family": "Birkedal",
        "given": "Lars"
      },
      {
        "family": "Bizjak",
        "given": "Aleš"
      }
    ],
    "title": "Iris Tutorial",
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "URL": "https://iris-project.org/tutorial-material.html",
    "_line": "FormalReview.bib:2416"
  },
  "jung_iris_2018": {
    "id": "jung_iris_2018",
    "type": "article-journal",
    "author": [
      {
        "family": "Jung",
        "given": "Ralf"
      },
      {
        "family": "Krebbers",
        "given": "Robbert"
      },
      {
        "family": "Jourdan",
        "given": "Jacques-Henri"
      },
      {
        "family": "Bizjak",
        "given": "Aleš"
      },
      {
        "family": "Birkedal",
        "given": "Lars"
      },
      {
        "family": "Dreyer",
        "given": "Derek"
      }
    ],
    "title": "Iris from the ground up: A modular foundation for higher-order concurrent separation logic",
    "container-title": "Journal of Functional Programming",
    "container-title-short": "Iris from the ground up",
    "title-short": "Iris from the ground up",
    "issued": {
      "date-parts": [
        [
          "2018"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "issn": "0956-7968, 1469-7653",
    "abstract": "Iris is a framework for higher-order concurrent separation logic, which has been implemented in the Coq proof assistant and deployed very effectively in a wide variety of verification projects. Iris was designed with the express goal of simplifying and consolidating the foundations of modern separation logics, but it has evolved over time, and the design and semantic foundations of Iris itself have yet to be fully written down and explained together properly in one place. Here, we attempt to fill this gap, presenting a reasonably complete picture of the latest version of Iris (version 3.1), from first principles and in one coherent narrative.",
    "URL": "https://www.cambridge.org/core/journals/journal-of-functional-programming/article/iris-from-the-ground-up-a-modular-foundation-for-higherorder-concurrent-separation-logic/26301B518CE2C52796BFA12B8BAB5B5F",
    "DOI": "10.1017/S0956796818000151",
    "volume": "28",
    "language": "en-US",
    "_line": "FormalReview.bib:2424"
  },
  "paulson_foundation_2000": {
    "id": "paulson_foundation_2000",
    "type": "article-journal",
    "author": [
      {
        "family": "Paulson",
        "given": "Lawrence C."
      }
    ],
    "title": "The Foundation of a Generic Theorem Prover",
    "container-title": "arXiv:cs/9301105",
    "issued": {
      "date-parts": [
        [
          "2000",
          "10",
          "30"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "abstract": "Isabelle is an interactive theorem prover that supports a variety of logics. It represents rules as propositions (not as functions) and builds proofs by combining rules. These operations constitute a meta-logic (or 'logical framework') in which the object-logics are formalized. Isabelle is now based on higher-order logic &ndash; a precise and well-understood foundation. Examples illustrate use of this meta-logic to formalize logics and proofs. Axioms for first-order logic are shown sound and complete. Backwards proof is formalized by meta-reasoning about object-level entailment. Higher-order logic has several practical advantages over other meta-logics. Many proof techniques are known, such as Huet's higher-order unification procedure.",
    "keywords": "Computer Science - Logic in Computer Science, F.3.1, F.4.1",
    "URLtext": "cs/9301105",
    "URLpretext": "[arXiv:]{.etype}",
    "eprint-type": "arxiv",
    "eprint": "cs/9301105",
    "URL": "http://arxiv.org/abs/cs/9301105",
    "_line": "FormalReview.bib:2440"
  },
  "wenzel_isabelle/isar_2018": {
    "id": "wenzel_isabelle/isar_2018",
    "type": "article-journal",
    "author": [
      {
        "family": "Wenzel",
        "given": "Markus"
      }
    ],
    "title": "The Isabelle/Isar Reference Manual",
    "issued": {
      "date-parts": [
        [
          "2018"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "abstract": "Intelligible semi-automated reasoning (Isar) is a generic approach to readable formal proof documents. It sets out to bridge the semantic gap between any internal notions of proof based on primitive inferences and tactics, and an appropriate level of abstraction for user-level work. The Isar formal proof language has been designed to satisfy quite contradictory requirements, being both &amp;quot;declarative&amp;quot; and immediately &amp;quot;executable&amp;quot;, by virtue of the Isar/VM  interpreter. The Isabelle/Isar system provides an interpreter for the Isar formal proof language. The input may consist either of proper document constructors, or improper auxiliary commands (for diagnostics, exploration etc.). Proof texts consisting of proper elements only admit a purely static reading, thus being intelligible later without requiring dynamic replay that is so typical for traditional proof scripts. Any of the Isabelle/Isar commands may be executed in single-steps, so basically the interpreter has a proof text debugger ..",
    "URL": "https://core.ac.uk/display/22830292",
    "language": "en-US",
    "_line": "FormalReview.bib:2454"
  },
  "ishtiaq_bi_2011": {
    "id": "ishtiaq_bi_2011",
    "type": "article-journal",
    "author": [
      {
        "family": "Ishtiaq",
        "given": "Samin"
      },
      {
        "family": "O'Hearn",
        "given": "Peter W."
      }
    ],
    "title": "BI As an Assertion Language for Mutable Data Structures",
    "container-title": "SIGPLAN Not.",
    "issued": {
      "date-parts": [
        [
          "2011",
          "5"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "issn": "0362-1340",
    "abstract": "Reynolds has developed a logic for reasoning about mutable data structures in which the pre- and postconditions are written in an intuitionistic logic enriched with a spatial form of conjunction. We investigate the approach from the point of view of the logic BI of bunched implications of O'Hearn and Pym. We begin by giving a model in which the law of the excluded middle holds, thus showing that the approach is compatible with classical logic. The relationship between the intuitionistic and classical versions of the system is established by a translation, analogous to a translation from intuitionistic logic into the modal logic S4. We also consider the question of completeness of the axioms. BI's spatial implication is used to express weakest preconditions for object-component assignments, and an axiom for allocating a cons cell is shown to be complete under an interpretation of triples that allows a command to be applied to states with dangling pointers. We make this latter a feature, by incorporating an operation, and axiom, for disposing of memory. Finally, we describe a local character enjoyed by specifications in the logic, and show how this enables a class of frame axioms, which say what parts of the heap don't change, to be inferred automatically.",
    "URL": "http://doi.acm.org/10.1145/1988042.1988050",
    "DOI": "10.1145/1988042.1988050",
    "page": "84-96",
    "page-first": "84",
    "volume": "46",
    "issue": "4",
    "_line": "FormalReview.bib:2465"
  },
  "hutchison_seloger:_2013": {
    "id": "hutchison_seloger:_2013",
    "type": "chapter",
    "author": [
      {
        "family": "Haase",
        "given": "Christoph"
      },
      {
        "family": "Ishtiaq",
        "given": "Samin"
      },
      {
        "family": "Ouaknine",
        "given": "Joël"
      },
      {
        "family": "Parkinson",
        "given": "Matthew J."
      }
    ],
    "editor": [
      {
        "family": "Sharygina",
        "given": "Natasha"
      },
      {
        "family": "Veith",
        "given": "Helmut"
      }
    ],
    "title": "SeLoger: A Tool for Graph-Based Reasoning in Separation Logic",
    "container-title": "Computer Aided Verification",
    "container-title-short": "SeLoger",
    "title-short": "SeLoger",
    "issued": {
      "date-parts": [
        [
          "2013"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "publisher": "Springer Berlin Heidelberg",
    "isbn": "978-3-642-39798-1 978-3-642-39799-8",
    "abstract": "This paper introduces the tool SeLoger, which is a reasoner for satisﬁability and entailment in a fragment of separation logic with pointers and linked lists. SeLoger builds upon and extends graphbased algorithms that have recently been introduced in order to settle both decision problems in polynomial time. Running SeLoger on standard benchmarks shows that the tool outperforms current state-of-theart tools by orders of magnitude.",
    "URL": "http://link.springer.com/10.1007/978-3-642-39799-8_55",
    "DOI": "10.1007/978-3-642-39799-8_55",
    "publisher-place": "Berlin, Heidelberg",
    "page": "790-795",
    "page-first": "790",
    "volume": "8044",
    "language": "en-US",
    "_line": "FormalReview.bib:2481"
  },
  "crick_share_2014": {
    "id": "crick_share_2014",
    "type": "article-journal",
    "author": [
      {
        "family": "Crick",
        "given": "Tom"
      },
      {
        "family": "Hall",
        "given": "Benjamin A."
      },
      {
        "family": "Ishtiaq",
        "given": "Samin"
      },
      {
        "family": "Takeda",
        "given": "Kenji"
      }
    ],
    "title": "\"Share and Enjoy\": Publishing Useful and Usable Scientific Models",
    "container-title": "arXiv:1409.0367 \\[cs\\]",
    "container-title-short": "\"Share and Enjoy\"",
    "title-short": "\"Share and Enjoy\"",
    "issued": {
      "date-parts": [
        [
          "2014",
          "9",
          "1"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "abstract": "The reproduction and replication of reported scientific results is a hot topic within the academic community. The retraction of numerous studies from a wide range of disciplines, from climate science to bioscience, has drawn the focus of many commentators, but there exists a wider socio-cultural problem that pervades the scientific community. Sharing code, data and models often requires extra effort; this is currently seen as a significant overhead that may not be worth the time investment. Automated systems, which allow easy reproduction of results, offer the potential to incentivise a culture change and drive the adoption of new techniques to improve the efficiency of scientific exploration. In this paper, we discuss the value of improved access and sharing of the two key types of results arising from work done in the computational sciences: models and algorithms. We propose the development of an integrated cloud-based system underpinning computational science, linking together software and data repositories, toolchains, workflows and outputs, providing a seamless automated infrastructure for the verification and validation of scientific models and in particular, performance benchmarks.",
    "keywords": "Computer Science - Computational Engineering, Finance, and Science",
    "URLtext": "1409.0367",
    "URLpretext": "[arXiv:]{.etype}",
    "eprint-type": "arxiv",
    "eprint": "1409.0367",
    "URL": "http://arxiv.org/abs/1409.0367",
    "_line": "FormalReview.bib:2503"
  },
  "brockschmidt_t2:_2016": {
    "id": "brockschmidt_t2:_2016",
    "type": "paper-conference",
    "author": [
      {
        "family": "Brockschmidt",
        "given": "Marc"
      },
      {
        "family": "Cook",
        "given": "Byron"
      },
      {
        "family": "Ishtiaq",
        "given": "Samin"
      },
      {
        "family": "Khlaaf",
        "given": "Heidy"
      },
      {
        "family": "Piterman",
        "given": "Nir"
      }
    ],
    "editor": [
      {
        "family": "Chechik",
        "given": "Marsha"
      },
      {
        "family": "Raskin",
        "given": "Jean-François"
      }
    ],
    "title": "T2: Temporal Property Verification",
    "container-title": "Tools and Algorithms for the Construction and Analysis of Systems",
    "container-title-short": "T2",
    "collection-title": "Lecture Notes in Computer Science",
    "title-short": "T2",
    "issued": {
      "date-parts": [
        [
          "2016"
        ]
      ]
    },
    "publisher": "Springer Berlin Heidelberg",
    "isbn": "978-3-662-49674-9",
    "abstract": "We present the open-source tool T2, the first public release from the TERMINATOR project \\[9\\]. T2 has been extended over the past decade to support automatic temporal-logic proving techniques and to handle a general class of user-provided liveness and safety properties. Input can be provided in a native format and in C, via the support of the LLVM compiler framework. We briefly discuss T2’s architecture, its underlying techniques, and conclude with an experimental illustration of its competitiveness and directions for future extensions.",
    "page": "387-393",
    "page-first": "387",
    "language": "en-US",
    "_line": "FormalReview.bib:2518"
  },
  "arias_jscoq:_2017": {
    "id": "arias_jscoq:_2017",
    "type": "article-journal",
    "author": [
      {
        "family": "Arias",
        "given": "Emilio Jesús Gallego"
      },
      {
        "family": "Pin",
        "given": "Benoît"
      },
      {
        "family": "Jouvelot",
        "given": "Pierre"
      }
    ],
    "title": "jsCoq: Towards Hybrid Theorem Proving Interfaces",
    "container-title": "Electronic Proceedings in Theoretical Computer Science",
    "container-title-short": "jsCoq",
    "title-short": "jsCoq",
    "issued": {
      "date-parts": [
        [
          "2017",
          "1",
          "24"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "issn": "2075-2180",
    "abstract": "We describe jsCcoq, a new platform and user environment for the Coq interactive proof assistant. The jsCoq system targets the HTML5-ECMAScript 2015 specification, and it is typically run inside a standards-compliant browser, without the need of external servers or services. Targeting educational use, jsCoq allows the user to start interaction with proof scripts right away, thanks to its self-contained nature. Indeed, a full Coq environment is packed along the proof scripts, easing distribution and installation. Starting to use jsCoq is as easy as clicking on a link. The current release ships more than 10 popular Coq libraries, and supports popular books such as Software Foundations or Certified Programming with Dependent Types. The new target platform has opened up new interaction and display possibilities. It has also fostered the development of some new Coq-related technology. In particular, we have implemented a new serialization-based protocol for interaction with the proof assistant, as well as a new package format for library distribution.",
    "keywords": "Computer Science - Logic in Computer Science, Computer Science - Programming Languages, Computer Science - Human-Computer Interaction, Computer Science - Machine Learning",
    "URLtext": "1701.07125",
    "URLpretext": "[arXiv:]{.etype}",
    "eprint-type": "arxiv",
    "eprint": "1701.07125",
    "URL": "http://arxiv.org/abs/1701.07125",
    "DOI": "10.4204/EPTCS.239.2",
    "page": "15-27",
    "page-first": "15",
    "volume": "239",
    "_line": "FormalReview.bib:2534"
  },
  "kaiser_destruct_nodate": {
    "id": "kaiser_destruct_nodate",
    "type": "webpage",
    "author": [
      {
        "family": "Kaiser",
        "given": "Jan-Oliver"
      },
      {
        "family": "Ziliani",
        "given": "Beta"
      }
    ],
    "title": "A “destruct” Tactic for Mtac2 - POPL 2018",
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "URL": "https://popl18.sigplan.org/event/coqpl-2018-a-destruct-tactic-for-mtac2",
    "_line": "FormalReview.bib:2553"
  },
  "hathhorn_defining_2015": {
    "id": "hathhorn_defining_2015",
    "type": "paper-conference",
    "author": [
      {
        "family": "Hathhorn",
        "given": "Chris"
      },
      {
        "family": "Ellison",
        "given": "Chucky"
      },
      {
        "family": "Roşu",
        "given": "Grigore"
      }
    ],
    "title": "Defining the Undefinedness of C",
    "container-title": "Proceedings of the 36th ACM SIGPLAN Conference on Programming Language Design and Implementation",
    "collection-title": "PLDI '15",
    "issued": {
      "date-parts": [
        [
          "2015"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "publisher": "ACM",
    "isbn": "978-1-4503-3468-6",
    "abstract": "We present a \"negative\" semantics of the C11 language&mdash;a semantics that does not just give meaning to correct programs, but also rejects undefined programs. We investigate undefined behavior in C and discuss the techniques and special considerations needed for formally specifying it. We have used these techniques to modify and extend a semantics of C into one that captures undefined behavior. The amount of semantic infrastructure and effort required to achieve this was unexpectedly high, in the end nearly doubling the size of the original semantics. From our semantics, we have automatically extracted an undefinedness checker, which we evaluate against other popular analysis tools, using our own test suite in addition to a third-party test suite. Our checker is capable of detecting examples of all 77 categories of core language undefinedness appearing in the C11 standard, more than any other tool we considered. Based on this evaluation, we argue that our work is the most comprehensive and complete semantic treatment of undefined behavior in C, and thus of the C language itself.",
    "keywords": "C11, K Framework, Programming language semantics, Undefined behavior",
    "URL": "http://doi.acm.org/10.1145/2737924.2737979",
    "DOI": "10.1145/2737924.2737979",
    "publisher-place": "New York, NY, USA",
    "page": "336-345",
    "page-first": "336",
    "_line": "FormalReview.bib:2561"
  },
  "kubota_foundations_nodate": {
    "id": "kubota_foundations_nodate",
    "type": "webpage",
    "author": [
      {
        "family": "Kubota",
        "given": "Ken"
      }
    ],
    "title": "Foundations of Mathematics – Owl of Minerva Press",
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "URL": "http://owlofminerva.net/foundations-of-mathematics/",
    "language": "en-US",
    "_line": "FormalReview.bib:2579"
  },
  "kubota_foundations_2016": {
    "id": "kubota_foundations_2016",
    "type": "article-journal",
    "author": [
      {
        "family": "Kubota",
        "given": "Ken"
      }
    ],
    "title": "Foundations of Mathematics",
    "issued": {
      "date-parts": [
        [
          "2016"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "URL": "http://www.owlofminerva.net/doi/10.4444/100/111/",
    "DOI": "10.4444/100.111",
    "language": "en-US",
    "_line": "FormalReview.bib:2588"
  },
  "lamport_specifying_nodate": {
    "id": "lamport_specifying_nodate",
    "type": "webpage",
    "author": [
      {
        "family": "Lamport",
        "given": "Leslie"
      }
    ],
    "title": "Specifying Systems",
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "URL": "https://lamport.azurewebsites.net/tla/book.html",
    "_line": "FormalReview.bib:2599"
  },
  "wikibook_latex_nodate": {
    "id": "wikibook_latex_nodate",
    "type": "webpage",
    "author": [
      {
        "family": "",
        "dropping-particle": "wikibook"
      }
    ],
    "title": "LaTeX - Wikibooks, open books for an open world",
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "URL": "https://en.wikibooks.org/wiki/LaTeX",
    "_line": "FormalReview.bib:2607"
  },
  "pakin_comprehensive_nodate": {
    "id": "pakin_comprehensive_nodate",
    "type": "article-journal",
    "author": [
      {
        "family": "Pakin",
        "given": "Scott"
      }
    ],
    "title": "The Comprehensive LaTeX Symbol List",
    "abstract": "This document lists 14283 symbols and the corresponding LATEX commands that produce them. Some of these symbols are guaranteed to be available in every LATEX 2������ system; others require fonts and packages that may not accompany a given distribution and that therefore need to be installed. All of the fonts and packages used to prepare this document—as well as this document itself—are freely available from the Comprehensive TEX Archive Network (http://www.ctan.org/).",
    "page": "358",
    "page-first": "358",
    "language": "en-US",
    "_line": "FormalReview.bib:2615"
  },
  "ebner_metaprogramming_2017": {
    "id": "ebner_metaprogramming_2017",
    "type": "article-journal",
    "author": [
      {
        "family": "Ebner",
        "given": "Gabriel"
      },
      {
        "family": "Ullrich",
        "given": "Sebastian"
      },
      {
        "family": "Roesch",
        "given": "Jared"
      },
      {
        "family": "Avigad",
        "given": "Jeremy"
      },
      {
        "family": "Moura",
        "given": "Leonardo",
        "dropping-particle": "de"
      }
    ],
    "title": "A Metaprogramming Framework for Formal Verification",
    "container-title": "Proc. ACM Program. Lang.",
    "issued": {
      "date-parts": [
        [
          "2017",
          "8"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "issn": "2475-1421",
    "abstract": "We describe the metaprogramming framework currently used in Lean, an interactive theorem prover based on dependent type theory. This framework extends Lean's object language with an API to some of Lean's internal structures and procedures, and provides ways of reflecting object-level expressions into the metalanguage. We provide evidence to show that our implementation is performant, and that it provides a convenient and flexible way of writing not only small-scale interactive tactics, but also more substantial kinds of automation.",
    "keywords": "theorem proving, dependent type theory, metaprogramming, tactic language",
    "URL": "http://doi.acm.org/10.1145/3110278",
    "DOI": "10.1145/3110278",
    "page": "34:1-34:29",
    "page-first": "34",
    "volume": "1",
    "_line": "FormalReview.bib:2624"
  },
  "letouzey_certified_nodate": {
    "id": "letouzey_certified_nodate",
    "type": "webpage",
    "author": [
      {
        "family": "Letouzey",
        "given": "Pierre"
      }
    ],
    "title": "Certified functional programming : Program extraction within Coq proof assistant.ResearchGate",
    "container-title-short": "(8) (PDF) Certified functional programming",
    "title-short": "(8) (PDF) Certified functional programming",
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "abstract": "NOTA: THIS IS THE ENGLISH TRANSLATION OF MY FRENCH PHD MANUSCRIPT. This work concerns the generation of programs which are certified to be correct by construction. These programs are obtained by extracting relevant information from constructive proofs made with the Coq proof assistant. Such a translation, named \"extraction\", of constructive proofs into functional programs is not new, and corresponds to an isomorphism known as Curry-Howard's. An extraction tool has been part of Coq assistant for a long time. But this old extraction tool suffered from several limitations: in particular, some Coq proofs were refused by it, whereas some others led to incorrect programs. In order to overcome these limitations, we built a completely new extraction tool for Coq, including both a new theory and a new implementation. Concerning theory, we developed new correctness proofs for this extraction mechanism. These new proofs are both complex and original. Concerning implementation, we focused on the generation of efficient and realistic code, which can be integrated in large-scale software developments, using modules and interfaces. Finally, we also present several case studies illustrating the capabilities of our new extraction. For example, we describe the certification of a modular library of finite set structures, and the production of programs about real exact arithmetic, starting from a formalization of constructive real analysis. These examples show the progress already achieved, even if the situation is not perfect yet, in particular in the last study.",
    "URL": "https://www.researchgate.net/publication/280790704_Certified_functional_programming_Program_extraction_within_Coq_proof_assistant",
    "language": "en-US",
    "_line": "FormalReview.bib:2641"
  },
  "kang_crellvm:_2018": {
    "id": "kang_crellvm:_2018",
    "type": "paper-conference",
    "author": [
      {
        "family": "Kang",
        "given": "Jeehoon"
      },
      {
        "family": "Kim",
        "given": "Yoonseung"
      },
      {
        "family": "Song",
        "given": "Youngju"
      },
      {
        "family": "Lee",
        "given": "Juneyoung"
      },
      {
        "family": "Park",
        "given": "Sanghoon"
      },
      {
        "family": "Shin",
        "given": "Mark Dongyeon"
      },
      {
        "family": "Kim",
        "given": "Yonghyun"
      },
      {
        "family": "Cho",
        "given": "Sungkeun"
      },
      {
        "family": "Choi",
        "given": "Joonwon"
      },
      {
        "family": "Hur",
        "given": "Chung-Kil"
      },
      {
        "family": "Yi",
        "given": "Kwangkeun"
      }
    ],
    "title": "Crellvm: Verified Credible Compilation for LLVM",
    "container-title": "Proceedings of the 39th ACM SIGPLAN Conference on Programming Language Design and Implementation",
    "container-title-short": "Crellvm",
    "collection-title": "PLDI 2018",
    "title-short": "Crellvm",
    "issued": {
      "date-parts": [
        [
          "2018"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "publisher": "ACM",
    "isbn": "978-1-4503-5698-5",
    "abstract": "Production compilers such as GCC and LLVM are large complex software systems, for which achieving a high level of reliability is hard. Although testing is an effective method for finding bugs, it alone cannot guarantee a high level of reliability. To provide a higher level of reliability, many approaches that examine compilers' internal logics have been proposed. However, none of them have been successfully applied to major optimizations of production compilers. This paper presents Crellvm: a verified credible compilation framework for LLVM, which can be used as a systematic way of providing a high level of reliability for major optimizations in LLVM. Specifically, we augment an LLVM optimizer to generate translation results together with their correctness proofs, which can then be checked by a proof checker formally verified in Coq. As case studies, we applied our approach to two major optimizations of LLVM: register promotion mem2reg and global value numbering gvn, having found four new miscompilation bugs (two in each).",
    "keywords": "Coq, compiler verification, credible compilation, LLVM, relational Hoare logic, translation validation",
    "URL": "http://doi.acm.org/10.1145/3192366.3192377",
    "DOI": "10.1145/3192366.3192377",
    "publisher-place": "New York, NY, USA",
    "page": "631-645",
    "page-first": "631",
    "_line": "FormalReview.bib:2653"
  },
  "luo_extended_nodate": {
    "id": "luo_extended_nodate",
    "type": "webpage",
    "author": [
      {
        "family": "Luo",
        "given": "Zhaohui"
      }
    ],
    "title": "An Extended Calculus of Constructions",
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "URL": "http://www.lfcs.inf.ed.ac.uk/reports/90/ECS-LFCS-90-118/",
    "_line": "FormalReview.bib:2672"
  },
  "patterson_compositional_nodate": {
    "id": "patterson_compositional_nodate",
    "type": "webpage",
    "author": [
      {
        "family": "Patterson",
        "given": "Daniel"
      },
      {
        "family": "Ahmed",
        "given": "Amal"
      }
    ],
    "title": "On Compositional Compiler Correctness and Fully Abstract Compilation - POPL 2018",
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "URL": "https://popl18.sigplan.org/event/prisc-2018-on-compositional-compiler-correctness-and-fully-abstract-compilation",
    "_line": "FormalReview.bib:2680"
  },
  "patterson_compositional_nodate-1": {
    "id": "patterson_compositional_nodate-1",
    "type": "article-journal",
    "author": [
      {
        "family": "Patterson",
        "given": "Daniel"
      },
      {
        "family": "Ahmed",
        "given": "Amal"
      }
    ],
    "title": "On Compositional Compiler Correctness and Fully Abstract Compilation",
    "URL": "https://popl18.sigplan.org/event/prisc-2018-on-compositional-compiler-correctness-and-fully-abstract-compilation",
    "page": "3",
    "page-first": "3",
    "language": "en-US",
    "_line": "FormalReview.bib:2688"
  },
  "gasser_building_1988": {
    "id": "gasser_building_1988",
    "type": "book",
    "author": [
      {
        "family": "Gasser",
        "given": "Morrie"
      }
    ],
    "title": "Building a secure computer system",
    "issued": {
      "date-parts": [
        [
          "1988"
        ]
      ]
    },
    "publisher": "Van Nostrand Reinhold Co",
    "number-of-pages": "288",
    "isbn": "978-0-442-23022-7",
    "keywords": "Computer security, System design",
    "publisher-place": "New York",
    "_line": "FormalReview.bib:2697"
  },
  "costan_sanctum:_2016": {
    "id": "costan_sanctum:_2016",
    "type": "paper-conference",
    "author": [
      {
        "family": "Costan",
        "given": "Victor"
      },
      {
        "family": "Lebedev",
        "given": "Ilia"
      },
      {
        "family": "Devadas",
        "given": "Srinivas"
      }
    ],
    "title": "Sanctum: Minimal Hardware Extensions for Strong Software Isolation",
    "container-title-short": "Sanctum",
    "title-short": "Sanctum",
    "event-title": "25th &lcurly;USENIX&rcurly; Security Symposium (&lcurly;USENIX&rcurly; Security 16)",
    "issued": {
      "date-parts": [
        [
          "2016"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "URL": "https://www.usenix.org/conference/usenixsecurity16/technical-sessions/presentation/costan",
    "page": "857-874",
    "page-first": "857",
    "language": "en-US",
    "_line": "FormalReview.bib:2709"
  },
  "costan_secure_2017": {
    "id": "costan_secure_2017",
    "type": "article-journal",
    "author": [
      {
        "family": "Costan",
        "given": "Victor"
      },
      {
        "family": "Lebedev",
        "given": "Ilia"
      },
      {
        "family": "Devadas",
        "given": "Srinivas"
      }
    ],
    "title": "Secure Processors Part I: Background, Taxonomy for Secure Enclaves and Intel SGX Architecture",
    "container-title": "Foundations and Trends® in Electronic Design Automation",
    "container-title-short": "Secure Processors Part I",
    "title-short": "Secure Processors Part I",
    "issued": {
      "date-parts": [
        [
          "2017"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "issn": "1551-3939, 1551-3947",
    "URL": "http://www.nowpublishers.com/article/Details/EDA-051",
    "DOI": "10.1561/1000000051",
    "page": "1-248",
    "page-first": "1",
    "volume": "11",
    "issue": "1",
    "language": "en-US",
    "_line": "FormalReview.bib:2722"
  },
  "costan_secure_2017-1": {
    "id": "costan_secure_2017-1",
    "type": "article-journal",
    "author": [
      {
        "family": "Costan",
        "given": "Victor"
      },
      {
        "family": "Lebedev",
        "given": "Ilia"
      },
      {
        "family": "Devadas",
        "given": "Srinivas"
      }
    ],
    "title": "Secure Processors Part II: Intel SGX Security Analysis and MIT Sanctum Architecture",
    "container-title": "Foundations and Trends® in Electronic Design Automation",
    "container-title-short": "Secure Processors Part II",
    "title-short": "Secure Processors Part II",
    "issued": {
      "date-parts": [
        [
          "2017"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "issn": "1551-3939, 1551-3947",
    "URL": "http://www.nowpublishers.com/article/Details/EDA-052",
    "DOI": "10.1561/1000000052",
    "page": "249-361",
    "page-first": "249",
    "volume": "11",
    "issue": "3",
    "language": "en-US",
    "_line": "FormalReview.bib:2739"
  },
  "pottier_menhir_nodate": {
    "id": "pottier_menhir_nodate",
    "type": "webpage",
    "author": [
      {
        "family": "Pottier",
        "given": "Francois"
      },
      {
        "family": "REgis-Gianas",
        "given": "Yan"
      }
    ],
    "title": "Menhir Reference Manual (version 20181113)",
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "URL": "http://gallium.inria.fr/~fpottier/menhir/manual.html",
    "_line": "FormalReview.bib:2756"
  },
  "jacobs_verifast/verifast:_2019": {
    "id": "jacobs_verifast/verifast:_2019",
    "type": "book",
    "author": [
      {
        "family": "Jacobs",
        "given": "Bart"
      }
    ],
    "title": "verifast/verifast: Research prototype tool for modular formal verification of C and Java programs",
    "container-title-short": "Research prototype tool for modular formal verification of C and Java programs",
    "title-short": "Research prototype tool for modular formal verification of C and Java programs",
    "issued": {
      "date-parts": [
        [
          "2019",
          "1",
          "25"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "publisher": "verifast",
    "URL": "https://github.com/verifast/verifast",
    "note": "original-date: 2013-11-19T08:57:02Z",
    "_line": "FormalReview.bib:2764"
  },
  "jacobs_featherweight_2015": {
    "id": "jacobs_featherweight_2015",
    "type": "article-journal",
    "author": [
      {
        "family": "Jacobs",
        "given": "Bart"
      },
      {
        "family": "Vogels",
        "given": "Frédéric"
      },
      {
        "family": "Piessens",
        "given": "Frank"
      }
    ],
    "title": "Featherweight VeriFast",
    "container-title": "Logical Methods in Computer Science",
    "issued": {
      "date-parts": [
        [
          "2015",
          "9",
          "22"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "issn": "18605974",
    "abstract": "VeriFast is a leading research prototype tool for the sound modular verification of safety and correctness properties of single-threaded and multithreaded C and Java programs. It has been used as a vehicle for exploration and validation of novel program verification techniques and for industrial case studies; it has served well at a number of program verification competitions; and it has been used for teaching by multiple teachers independent of the authors. However, until now, while VeriFast's operation has been described informally in a number of publications, and specific verification techniques have been formalized, a clear and precise exposition of how VeriFast works has not yet appeared. In this article we present for the first time a formal definition and soundness proof of a core subset of the VeriFast program verification approach. The exposition aims to be both accessible and rigorous: the text is based on lecture notes for a graduate course on program verification, and it is backed by an executable machine-readable definition and machine-checked soundness proof in Coq.",
    "keywords": "Computer Science - Logic in Computer Science",
    "URLtext": "1507.07697",
    "URLpretext": "[arXiv:]{.etype}",
    "eprint-type": "arxiv",
    "eprint": "1507.07697",
    "URL": "http://arxiv.org/abs/1507.07697",
    "DOI": "10.2168/LMCS-11(3:19)2015",
    "volume": "11",
    "issue": "3",
    "_line": "FormalReview.bib:2776"
  },
  "jacobs_verifast_2008": {
    "id": "jacobs_verifast_2008",
    "type": "report",
    "author": [
      {
        "family": "Jacobs",
        "given": "Bart"
      },
      {
        "family": "Piessens",
        "given": "Frank"
      }
    ],
    "title": "The VeriFast program verifier",
    "issued": {
      "date-parts": [
        [
          "2008"
        ]
      ]
    },
    "abstract": "This note describes a separation-logic-based approach for the spec-ification and verification of safety properties of pointer-manipulating imperative programs. We describe the approach for the C language. The safety properties to be verified are specified as annotations in the source code, in the form of function preconditions and post-conditions expressed as separation logic assertions. To enable rich specifications, the user may include additional annotations that de-fine inductive datatypes, primitive recursive pure functions over these datatypes, and abstract predicates (i.e. named, parameterized assertions). A restricted form of existential quantification is sup-ported in assertions in the form of pattern matching. Verification is based on forward symbolic execution, where memory is represented as a separate conjunction of points-to as-sertions and abstract predicate assertions, and data values are rep-",
    "_line": "FormalReview.bib:2794"
  },
  "jacobs_verifast_2017": {
    "id": "jacobs_verifast_2017",
    "type": "article-journal",
    "author": [
      {
        "family": "Jacobs",
        "given": "Bart"
      },
      {
        "family": "Smans",
        "given": "Jan"
      },
      {
        "family": "Piessens",
        "given": "Frank"
      }
    ],
    "title": "The VeriFast Program Veriﬁer: A Tutorial",
    "issued": {
      "date-parts": [
        [
          "2017",
          "11",
          "28"
        ]
      ]
    },
    "page": "102",
    "page-first": "102",
    "language": "en-US",
    "_line": "FormalReview.bib:2802"
  },
  "leroy_ocaml_nodate": {
    "id": "leroy_ocaml_nodate",
    "type": "webpage",
    "author": [
      {
        "family": "Leroy",
        "given": "Xavier"
      }
    ],
    "title": "OCaml Home Page",
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "URL": "https://ocaml.org/",
    "_line": "FormalReview.bib:2811"
  },
  "minsky_real_nodate": {
    "id": "minsky_real_nodate",
    "type": "webpage",
    "author": [
      {
        "family": "Minsky",
        "given": "Yaron"
      },
      {
        "family": "Madhavapeddy",
        "given": "Anil"
      },
      {
        "family": "Hickey",
        "given": "Jason"
      }
    ],
    "title": "Real World OCaml",
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "URL": "http://dev.realworldocaml.org/",
    "_line": "FormalReview.bib:2819"
  },
  "lampson_abcds_2001": {
    "id": "lampson_abcds_2001",
    "type": "paper-conference",
    "author": [
      {
        "family": "Lampson",
        "given": "Butler"
      }
    ],
    "title": "The ABCD's of Paxos",
    "container-title": "Proceedings of the Twentieth Annual ACM Symposium on Principles of Distributed Computing",
    "collection-title": "PODC '01",
    "issued": {
      "date-parts": [
        [
          "2001"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "publisher": "ACM",
    "isbn": "978-1-58113-383-7",
    "abstract": "We explain how consensus is used to implement replicated state machines, the general mechanism for fault-tolerance. We describe an abstract version of Lamport's Paxos algorithm for asynchronous consensus. Then we derive the Byzantine, classic, and disk versions of Paxos from the abstract one, show how they are related to each other, and discuss the safety, liveness, and performance of each one.",
    "URL": "http://doi.acm.org/10.1145/383962.383969",
    "DOI": "10.1145/383962.383969",
    "publisher-place": "New York, NY, USA",
    "page": "13-",
    "page-first": "13",
    "_line": "FormalReview.bib:2827"
  },
  "van_renesse_paxos_2015": {
    "id": "van_renesse_paxos_2015",
    "type": "article-journal",
    "author": [
      {
        "family": "Van Renesse",
        "given": "Robbert"
      },
      {
        "family": "Altinbuken",
        "given": "Deniz"
      }
    ],
    "title": "Paxos Made Moderately Complex",
    "container-title": "ACM Comput. Surv.",
    "issued": {
      "date-parts": [
        [
          "2015",
          "2"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "issn": "0360-0300",
    "abstract": "This article explains the full reconfigurable multidecree Paxos (or multi-Paxos) protocol. Paxos is by no means a simple protocol, even though it is based on relatively simple invariants. We provide pseudocode and explain it guided by invariants. We initially avoid optimizations that complicate comprehension. Next we discuss liveness, list various optimizations that make the protocol practical, and present variants of the protocol.",
    "keywords": "consensus, Replicated state machines, voting",
    "URL": "http://doi.acm.org/10.1145/2673577",
    "DOI": "10.1145/2673577",
    "page": "42:1-42:36",
    "page-first": "42",
    "volume": "47",
    "issue": "3",
    "_line": "FormalReview.bib:2844"
  },
  "hutchison_improving_2012": {
    "id": "hutchison_improving_2012",
    "type": "chapter",
    "author": [
      {
        "family": "Boldo",
        "given": "Sylvie"
      },
      {
        "family": "Lelay",
        "given": "Catherine"
      },
      {
        "family": "Melquiond",
        "given": "Guillaume"
      }
    ],
    "editor": [
      {
        "family": "Hawblitzel",
        "given": "Chris"
      },
      {
        "family": "Miller",
        "given": "Dale"
      }
    ],
    "title": "Improving Real Analysis in Coq: A User-Friendly Approach to Integrals and Derivatives",
    "container-title": "Certified Programs and Proofs",
    "container-title-short": "Improving Real Analysis in Coq",
    "title-short": "Improving Real Analysis in Coq",
    "issued": {
      "date-parts": [
        [
          "2012"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "publisher": "Springer Berlin Heidelberg",
    "isbn": "978-3-642-35307-9 978-3-642-35308-6",
    "abstract": "Veriﬁcation of numerical analysis programs requires dealing with derivatives and integrals. High conﬁdence in this process can be achieved using a formal proof checker, such as Coq. Its standard library provides an axiomatization of real numbers and various lemmas about real analysis, which may be used for this purpose. Unfortunately, its deﬁnitions of derivative and integral are unpractical as they are partial functions that demand a proof term. This proof term makes the handling of mathematical formulas cumbersome and does not conform to traditional analysis. Other proof assistants usually do not suﬀer from this issue; for instance, they may rely on Hilbert’s epsilon to get total operators. In this paper, we propose a way to deﬁne total operators for derivative and integral without having to extend Coq’s standard axiomatization of real numbers. We proved the compatibility of our deﬁnitions with the standard library’s in order to leverage existing results. We also greatly improved automation for real analysis proofs that use Coq standard deﬁnitions. We exercised our approach on lemmas involving iterated partial derivatives and diﬀerentiation under the integral sign, that were missing from the formal proof of a numerical program solving the wave equation.",
    "URL": "http://link.springer.com/10.1007/978-3-642-35308-6_22",
    "DOI": "10.1007/978-3-642-35308-6_22",
    "publisher-place": "Berlin, Heidelberg",
    "page": "289-304",
    "page-first": "289",
    "volume": "7679",
    "language": "en-US",
    "_line": "FormalReview.bib:2861"
  },
  "martin-dorel_proving_2016": {
    "id": "martin-dorel_proving_2016",
    "type": "article-journal",
    "author": [
      {
        "family": "Martin-Dorel",
        "given": "Érik"
      },
      {
        "family": "Melquiond",
        "given": "Guillaume"
      }
    ],
    "title": "Proving Tight Bounds on Univariate Expressions with Elementary Functions in Coq",
    "container-title": "J Autom Reasoning",
    "issued": {
      "date-parts": [
        [
          "2016",
          "10",
          "1"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "issn": "1573-0670",
    "abstract": "The verification of floating-point mathematical libraries requires computing numerical bounds on approximation errors. Due to the tightness of these bounds and the peculiar structure of approximation errors, such a verification is out of the reach of generic tools such as computer algebra systems. In fact, the inherent difficulty of computing such bounds often mandates a formal proof of them. In this paper, we present a tactic for the Coq proof assistant that is designed to automatically and formally prove bounds on univariate expressions. It is based on a formalization of floating-point and interval arithmetic, associated with an on-the-fly computation of Taylor expansions. All the computations are performed inside Coq’s logic, in a reflexive setting. This paper also compares our tactic with various existing tools on a large set of examples.",
    "keywords": "Coq proof assistant, Decision procedure, Floating-point arithmetic, Formal proof, Interval arithmetic, Nonlinear arithmetic",
    "URL": "https://doi.org/10.1007/s10817-015-9350-4",
    "DOI": "10.1007/s10817-015-9350-4",
    "page": "187-217",
    "page-first": "187",
    "volume": "57",
    "issue": "3",
    "language": "en-US",
    "_line": "FormalReview.bib:2883"
  },
  "boldo_round-off_2017": {
    "id": "boldo_round-off_2017",
    "type": "paper-conference",
    "author": [
      {
        "family": "Boldo",
        "given": "Sylvie"
      },
      {
        "family": "Faissole",
        "given": "Florian"
      },
      {
        "family": "Chapoutot",
        "given": "Alexandre"
      }
    ],
    "title": "Round-off Error Analysis of Explicit One-Step Numerical Integration Methods",
    "container-title": "24th IEEE Symposium on Computer Arithmetic",
    "issued": {
      "date-parts": [
        [
          "2017",
          "7"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "abstract": "Ordinary differential equations are ubiquitous in scientific computing. Solving exactly these equations is usually not possible, except for special cases, hence the use of numerical schemes to get a discretized solution. We are interested in such numerical integration methods, for instance Euler's method or the Runge-Kutta methods. As they are implemented using floating-point arithmetic, round-off errors occur. In order to guarantee their accuracy, we aim at providing bounds on the round-off errors of explicit one-step numerical integration methods. Our methodology is to apply a fine-grained analysis to these numerical algorithms. Our originality is that our floating-point analysis takes advantage of the linear stability of the scheme, a mathematical property that vouches the scheme is well-behaved.",
    "keywords": "Floating-Point, Numerical Integration, Ordinary Differential Equation, Round-Off Error, Runge-Kutta Methods, Stability",
    "URL": "https://hal.archives-ouvertes.fr/hal-01581794",
    "DOI": "10.1109/ARITH.2017.22",
    "publisher-place": "London, United Kingdom",
    "_line": "FormalReview.bib:2901"
  },
  "boldo_round-off_2018": {
    "id": "boldo_round-off_2018",
    "type": "manuscript",
    "author": [
      {
        "family": "Boldo",
        "given": "Sylvie"
      },
      {
        "family": "Faissole",
        "given": "Florian"
      },
      {
        "family": "Chapoutot",
        "given": "Alexandre"
      }
    ],
    "title": "Round-off error and exceptional behavior analysis of explicit Runge-Kutta methods",
    "issued": {
      "date-parts": [
        [
          "2018",
          "9"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "abstract": "Numerical integration schemes are mandatory to understand complex behaviors of dynamical systems described by ordinary differential equations. Implementation of these numerical methods involve floating-point computations and propagation of round-off errors. This paper presents a new fine-grained analysis of round-off errors in explicit Runge-Kutta integration methods, taking into account exceptional behaviors, such as underflow and overflow. Linear stability properties play a central role in the proposed approach. For a large class of Runge-Kutta methods applied on linear problems, a tight bound of the round-off errors is provided. A simple test is defined and ensures the absence of underflow and a tighter round-off error bound. The absence of overflow is guaranteed as linear stability properties imply that (computed) solutions are non-increasing.",
    "keywords": "Linear stability, Numerical integration, Overflow, Round-off error, Runge-Kutta method, Underflow",
    "URL": "https://hal.archives-ouvertes.fr/hal-01883843",
    "_line": "FormalReview.bib:2915"
  },
  "immler_verified_2018": {
    "id": "immler_verified_2018",
    "type": "article-journal",
    "author": [
      {
        "family": "Immler",
        "given": "Fabian"
      }
    ],
    "title": "A Verified ODE Solver and the Lorenz Attractor",
    "container-title": "J Autom Reasoning",
    "issued": {
      "date-parts": [
        [
          "2018",
          "6",
          "1"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "issn": "1573-0670",
    "abstract": "A rigorous numerical algorithm, formally verified with Isabelle/HOL, is used to certify the computations that Tucker used to prove chaos for the Lorenz attractor. The verification is based on a formalization of a diverse variety of mathematics and algorithms. Formalized mathematics include ordinary differential equations and Poincaré maps. Algorithms include low level approximation schemes based on Runge–Kutta methods and affine arithmetic. On a high level, reachability analysis is guided by static hybridization and adaptive step-size control and splitting. The algorithms are systematically refined towards an implementation that can be executed on Tucker’s original input data.",
    "keywords": "Isabelle/HOL, Lorenz attractor, Ordinary differential equation, Poincaré map, Rigorous numerics",
    "URL": "https://doi.org/10.1007/s10817-017-9448-y",
    "DOI": "10.1007/s10817-017-9448-y",
    "page": "73-111",
    "page-first": "73",
    "volume": "61",
    "issue": "1",
    "language": "en-US",
    "_line": "FormalReview.bib:2926"
  },
  "boldo_coquelicot:_2013": {
    "id": "boldo_coquelicot:_2013",
    "type": "no-type",
    "author": [
      {
        "family": "Boldo",
        "given": "Sylvie"
      },
      {
        "family": "Lelay",
        "given": "Catherine"
      },
      {
        "family": "Melquiond",
        "given": "Guillaume"
      }
    ],
    "title": "Coquelicot: A User-Friendly Library of Real Analysis for Coq",
    "container-title-short": "Coquelicot",
    "title-short": "Coquelicot",
    "issued": {
      "date-parts": [
        [
          "2013",
          "9",
          "10"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "abstract": "Real analysis is pervasive to many applications, if only because it is a suitable tool for modeling physical or socio-economical systems. As such, its support is warranted in proof assistants, so that the users have a way to formally verify mathematical theorems and correctness of critical systems. The Coq system comes with an axiomatization of standard real numbers and a library of theorems on real analysis. Unfortunately, this standard library is lacking some widely used results. For instance, power series are not developed further than their definition. Moreover, the definitions of integrals and derivatives are based on dependent types, which make them especially cumbersome to use in practice. To palliate these inadequacies, we have designed a user-friendly library: Coquelicot. An easier way of writing formulas and theorem statements is achieved by relying on total functions in place of dependent types for limits, derivatives, integrals, power series, and so on. To help with the proof process, the library comes with a comprehensive set of theorems that cover not only these notions, but also some extensions such as parametric integrals, two-dimensional differentiability, asymptotic behaviors. It also offers some automations for performing differentiability proofs. Moreover, Coquelicot is a conservative extension of Coq's standard library and we provide correspondence theorems between the two libraries. We have exercised the library on several use cases: in an exam at university entry level, for the definitions and properties of Bessel functions, and for the solution of the one-dimensional wave equation.",
    "URL": "https://hal.inria.fr/hal-00860648/document",
    "language": "en-US",
    "_line": "FormalReview.bib:2944"
  },
  "boldo_formalization_2016": {
    "id": "boldo_formalization_2016",
    "type": "article-journal",
    "author": [
      {
        "family": "Boldo",
        "given": "Sylvie"
      },
      {
        "family": "Lelay",
        "given": "Catherine"
      },
      {
        "family": "Melquiond",
        "given": "Guillaume"
      }
    ],
    "title": "Formalization of Real Analysis: A Survey of Proof Assistants and Libraries",
    "container-title": "Mathematical Structures in Computer Science",
    "container-title-short": "Formalization of Real Analysis",
    "title-short": "Formalization of Real Analysis",
    "issued": {
      "date-parts": [
        [
          "2016",
          "10"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "abstract": "In the recent years, numerous proof systems have improved enough to be used for formally verifying non-trivial mathematical results. They, however, have different purposes and it is not always easy to choose which one is adapted to undertake a formalization effort. In this survey, we focus on properties related to real analysis: real numbers, arithmetic operators, limits, differentiability, integrability, and so on. We have chosen to look into the formalizations provided in standard by the following systems: Coq, HOL4, HOL Light, Isabelle/HOL, Mizar, ProofPower-HOL, and PVS. We have also accounted for large developments that play a similar role or extend standard libraries: ACL2(r) for ACL2, C-CoRN/MathClasses for Coq, and the NASA PVS library. This survey presents how real numbers have been defined in these various provers and how the notions of real analysis described above have been formalized. We also look at the methods of automation these systems provide for real analysis.",
    "URL": "https://hal.inria.fr/hal-00806920/document",
    "DOI": "10.1017/S0960129514000437",
    "page": "1196-1233",
    "page-first": "1196",
    "volume": "26",
    "issue": "7",
    "language": "en-US",
    "_line": "FormalReview.bib:2956"
  },
  "holzl_type_2013": {
    "id": "holzl_type_2013",
    "type": "paper-conference",
    "author": [
      {
        "family": "Hölzl",
        "given": "Johannes"
      },
      {
        "family": "Immler",
        "given": "Fabian"
      },
      {
        "family": "Huffman",
        "given": "Brian"
      }
    ],
    "editor": [
      {
        "family": "Blazy",
        "given": "Sandrine"
      },
      {
        "family": "Paulin-Mohring",
        "given": "Christine"
      },
      {
        "family": "Pichardie",
        "given": "David"
      }
    ],
    "title": "Type Classes and Filters for Mathematical Analysis in Isabelle/HOL",
    "container-title": "Interactive Theorem Proving",
    "collection-title": "Lecture Notes in Computer Science",
    "issued": {
      "date-parts": [
        [
          "2013"
        ]
      ]
    },
    "publisher": "Springer Berlin Heidelberg",
    "isbn": "978-3-642-39634-2",
    "abstract": "The theory of analysis in Isabelle/HOL derives from earlier formalizations that were limited to specific concrete types: ℝ, ℂ and ℝ n . Isabelle’s new analysis theory unifies and generalizes these earlier efforts. The improvements are centered on two primary contributions: a generic theory of limits based on filters, and a new hierarchy of type classes that includes various topological, metric, vector, and algebraic spaces. These let us apply many results in multivariate analysis to types which are not Euclidean spaces, such as the extended real numbers, bounded continuous functions, or finite maps.",
    "keywords": "Isabelle/HOL, Euclidean vector spaces, Filters, Limits, Mathematical analysis, Topology, Type classes",
    "page": "279-294",
    "page-first": "279",
    "language": "en-US",
    "_line": "FormalReview.bib:2973"
  },
  "krebbers_type_2011": {
    "id": "krebbers_type_2011",
    "type": "article-journal",
    "author": [
      {
        "family": "Krebbers",
        "given": "Robbert"
      },
      {
        "family": "Spitters",
        "given": "Bas"
      }
    ],
    "title": "Type classes for efficient exact real arithmetic in Coq",
    "container-title": "arXiv:1106.3448 \\[cs, math\\]",
    "issued": {
      "date-parts": [
        [
          "2011",
          "6",
          "17"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "abstract": "Floating point operations are fast, but require continuous effort on the part of the user in order to ensure that the results are correct. This burden can be shifted away from the user by providing a library of exact analysis in which the computer handles the error estimates. Previously, we \\[Krebbers/Spitters 2011\\] provided a fast implementation of the exact real numbers in the Coq proof assistant. Our implementation improved on an earlier implementation by O'Connor by using type classes to describe an abstract specification of the underlying dense set from which the real numbers are built. In particular, we used dyadic rationals built from Coq's machine integers to obtain a 100 times speed up of the basic operations already. This article is a substantially expanded version of \\[Krebbers/Spitters 2011\\] in which the implementation is extended in the various ways. First, we implement and verify the sine and cosine function. Secondly, we create an additional implementation of the dense set based on Coq's fast rational numbers. Thirdly, we extend the hierarchy to capture order on undecidable structures, while it was limited to decidable structures before. This hierarchy, based on type classes, allows us to share theory on the naturals, integers, rationals, dyadics, and reals in a convenient way. Finally, we obtain another dramatic speed-up by avoiding evaluation of termination proofs at runtime.",
    "keywords": "Computer Science - Logic in Computer Science, D.2.4, F.4.1, G.1, Mathematics - Numerical Analysis",
    "URLtext": "1106.3448",
    "URLpretext": "[arXiv:]{.etype}",
    "eprint-type": "arxiv",
    "eprint": "1106.3448",
    "URL": "http://arxiv.org/abs/1106.3448",
    "DOI": "10.2168/LMCS-9(1:01)2013",
    "_line": "FormalReview.bib:2989"
  },
  "shrobe_trust-management_2009": {
    "id": "shrobe_trust-management_2009",
    "type": "article-journal",
    "author": [
      {
        "family": "Shrobe",
        "given": "Howard"
      },
      {
        "family": "DeHon",
        "given": "Andre"
      },
      {
        "family": "Knight",
        "given": "Thomas"
      }
    ],
    "title": "Trust-Management, Intrusion-Tolerance, Accountability, and Reconstitution Architecture (TIARA)",
    "issued": {
      "date-parts": [
        [
          "2009",
          "12"
        ]
      ]
    },
    "abstract": "This report describes the Trust-management, Intrusion-tolerance, Accountability, and Reconstitution Architecture (TIARA) system,\na broad design effort including novel computer architecture, operating system and application middleware. TIARA illustrates that a\nhighly secure computer system can be designed without sacrificing performance. TIARA involves three major sub-efforts: A\nhardware security tagged architecture (STA) that tags each word of the computer’s memory with metadata such as the data type and\ncompartment of the data. The STA hardware enforces access rules controlling which principals are allowed to perform which\noperations on which data. This allows the construction of a novel Zero-kernel Operating System (ZKOS) that has no single all\nprivileged kernel and that provides strong guarantees against penetration. Finally TIARA provides a level of application middleware\nthat enforces architectural level constraints and maintains the provenance of application data. All common exploits are preventable\nby the TIARA architecture and this incurs only a minor increase in chip area.",
    "URL": "https://apps.dtic.mil/dtic/tr/fulltext/u2/a511350.pdf",
    "page": "133",
    "page-first": "133",
    "language": "en-US",
    "_line": "FormalReview.bib:3004"
  },
  "azevedo_de_amorim_verified_2014": {
    "id": "azevedo_de_amorim_verified_2014",
    "type": "paper-conference",
    "author": [
      {
        "family": "Azevedo de Amorim",
        "given": "Arthur"
      },
      {
        "family": "Collins",
        "given": "Nathan"
      },
      {
        "family": "DeHon",
        "given": "André"
      },
      {
        "family": "Demange",
        "given": "Delphine"
      },
      {
        "family": "Hriţcu",
        "given": "Cătălin"
      },
      {
        "family": "Pichardie",
        "given": "David"
      },
      {
        "family": "Pierce",
        "given": "Benjamin C."
      },
      {
        "family": "Pollack",
        "given": "Randy"
      },
      {
        "family": "Tolmach",
        "given": "Andrew"
      }
    ],
    "title": "A Verified Information-flow Architecture",
    "container-title": "Proceedings of the 41st ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages",
    "collection-title": "POPL '14",
    "issued": {
      "date-parts": [
        [
          "2014"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "publisher": "ACM",
    "isbn": "978-1-4503-2544-8",
    "abstract": "SAFE is a clean-slate design for a highly secure computer system, with pervasive mechanisms for tracking and limiting information flows. At the lowest level, the SAFE hardware supports fine-grained programmable tags, with efficient and flexible propagation and combination of tags as instructions are executed. The operating system virtualizes these generic facilities to present an information-flow abstract machine that allows user programs to label sensitive data with rich confidentiality policies. We present a formal, machine-checked model of the key hardware and software mechanisms used to control information flow in SAFE and an end-to-end proof of noninterference for this model.",
    "keywords": "formal verification, clean-slate design, information-flow control, refinement, security, tagged architecture",
    "URL": "http://doi.acm.org/10.1145/2535838.2535839",
    "DOI": "10.1145/2535838.2535839",
    "publisher-place": "New York, NY, USA",
    "page": "165-178",
    "page-first": "165",
    "_line": "FormalReview.bib:3024"
  },
  "amorim_verified_2013": {
    "id": "amorim_verified_2013",
    "type": "book",
    "author": [
      {
        "family": "Amorim",
        "given": "Arthur Azevedo de"
      },
      {
        "family": "Collins",
        "given": "Nathan"
      },
      {
        "family": "DeHon",
        "given": "André"
      },
      {
        "family": "Demange",
        "given": "Delphine"
      },
      {
        "family": "Hritcu",
        "given": "Cătălin"
      },
      {
        "family": "Pichardie",
        "given": "David"
      },
      {
        "family": "Pierce",
        "given": "Benjamin C."
      },
      {
        "family": "Pollack",
        "given": "Randy"
      },
      {
        "family": "Tolmach",
        "given": "Andrew"
      }
    ],
    "title": "A Verified Information-Flow Architecture (Long version)",
    "issued": {
      "date-parts": [
        [
          "2013"
        ]
      ]
    },
    "abstract": "SAFE is a clean-slate effort to build a highly secure computer system, including pervasive mechanisms for tracking and limiting information flows. At the lowest level, the SAFE hardware supports fine-grained programmable tags, with efficient and flexible propagation and combination of tags as instructions are executed. The operating system virtualizes these generic facilities to present an information-flow abstract machine, on which user programs can label sensitive data with rich confidentiality and integrity policies. We present a formal, machine-checked model of the key information-flow mechanisms of the SAFE hardware and software, together with an end-to-end proof of noninterference for this model.",
    "_line": "FormalReview.bib:3042"
  },
  "andrew_oracle_2008": {
    "id": "andrew_oracle_2008",
    "type": "book",
    "author": [
      {
        "family": "Andrew",
        "given": "Advisor"
      }
    ],
    "title": "Oracle Semantics Aquinas Hobor",
    "issued": {
      "date-parts": [
        [
          "2008"
        ]
      ]
    },
    "abstract": "We define a Concurrent Separation Logic with first-class locks and threads for the C language, and prove its soundness in Coq with re-spect to a compilable operataional semantics. We define the language Concurrent C minor, an extension of the C minor language of Leroy. C minor was designed as the highest-level intermediate language in the CompCert certified ANSI C compiler, and we add to it lock, unlock, and fork statements to make Concurrent C minor, giving it a standard Pthreads style of concurrency. We define a Concurrent Separation Logic for Concurrent C minor, which extends the original Concurrent Separation Logic of O’Hearn to handle first-class locks and threads. We then prove the soundness of the logic with respect to the opera-tional semantics of the language. First, we define an erased concurrent operational semantics for Concurrent C minor that is a reasonable ab-",
    "_line": "FormalReview.bib:3050"
  },
  "berdine_smallfoot:_2006": {
    "id": "berdine_smallfoot:_2006",
    "type": "paper-conference",
    "author": [
      {
        "family": "Berdine",
        "given": "Josh"
      },
      {
        "family": "Calcagno",
        "given": "Cristiano"
      },
      {
        "family": "O’Hearn",
        "given": "Peter W."
      }
    ],
    "editor": [
      {
        "family": "Boer",
        "given": "Frank S.",
        "dropping-particle": "de"
      },
      {
        "family": "Bonsangue",
        "given": "Marcello M."
      },
      {
        "family": "Graf",
        "given": "Susanne"
      },
      {
        "family": "Roever",
        "given": "Willem-Paul",
        "dropping-particle": "de"
      }
    ],
    "title": "Smallfoot: Modular Automatic Assertion Checking with Separation Logic",
    "container-title": "Formal Methods for Components and Objects",
    "container-title-short": "Smallfoot",
    "collection-title": "Lecture Notes in Computer Science",
    "title-short": "Smallfoot",
    "issued": {
      "date-parts": [
        [
          "2006"
        ]
      ]
    },
    "publisher": "Springer Berlin Heidelberg",
    "isbn": "978-3-540-36750-5",
    "abstract": "Separation logic is a program logic for reasoning about programs that manipulate pointer data structures. We describe Smallfoot, a tool for checking certain lightweight separation logic specifications. The assertions describe the shapes of data structures rather than their detailed contents, and this allows reasoning to be fully automatic. The presentation in the paper is tutorial in style. We illustrate what the tool can do via examples which are oriented toward novel aspects of separation logic, namely: avoidance of frame axioms (which say what a procedure does not change); embracement of “dirty” features such as memory disposal and address arithmetic; information hiding in the presence of pointers; and modular reasoning about concurrent programs.",
    "keywords": "Separation Logic, Symbolic Execution, Free List, Information Hiding, Tree Predicate",
    "page": "115-137",
    "page-first": "115",
    "language": "en-US",
    "_line": "FormalReview.bib:3058"
  },
  "ohearn_local_2001": {
    "id": "ohearn_local_2001",
    "type": "chapter",
    "author": [
      {
        "family": "O’Hearn",
        "given": "Peter"
      },
      {
        "family": "Reynolds",
        "given": "John"
      },
      {
        "family": "Yang",
        "given": "Hongseok"
      }
    ],
    "editor": [
      {
        "family": "Fribourg",
        "given": "Laurent"
      }
    ],
    "title": "Local Reasoning about Programs that Alter Data Structures",
    "container-title": "Computer Science Logic",
    "collection-title": "Lecture Notes in Computer Science",
    "issued": {
      "date-parts": [
        [
          "2001"
        ]
      ]
    },
    "publisher": "Springer Berlin Heidelberg",
    "isbn": "978-3-540-44802-0",
    "abstract": "We describe an extension of Hoare’s logic for reasoning about programs that alter data structures. We consider a low-level storage model based on a heap with associated lookup, update, allocation and deallocation operations, and unrestricted address arithmetic. The assertion language is based on a possible worlds model of the logic of bunched implications, and includes spatial conjunction and implication connectives alongside those of classical logic. Heap operations are axiomatized using what we call the “small axioms”, each of which mentions only those cells accessed by a particular command. Through these and a number of examples we show that the formalism supports local reasoning: A specification and proof can concentrate on only those cells in memory that a program accesses.This paper builds on earlier work by Burstall, Reynolds, Ishtiaq and O’Hearn on reasoning about data structures.",
    "keywords": "Hoare Logic, Frame Problem, Local Reasoning, Memory Fault, Weak Precondition",
    "page": "1-19",
    "page-first": "1",
    "language": "en-US",
    "_line": "FormalReview.bib:3075"
  },
  "hermanns_local_2006": {
    "id": "hermanns_local_2006",
    "type": "chapter",
    "author": [
      {
        "family": "Distefano",
        "given": "Dino"
      },
      {
        "family": "O’Hearn",
        "given": "Peter W."
      },
      {
        "family": "Yang",
        "given": "Hongseok"
      }
    ],
    "editor": [
      {
        "family": "Hermanns",
        "given": "Holger"
      },
      {
        "family": "Palsberg",
        "given": "Jens"
      }
    ],
    "title": "A Local Shape Analysis Based on Separation Logic",
    "container-title": "Tools and Algorithms for the Construction and Analysis of Systems",
    "issued": {
      "date-parts": [
        [
          "2006"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "publisher": "Springer Berlin Heidelberg",
    "isbn": "978-3-540-33056-1 978-3-540-33057-8",
    "abstract": "We describe a program analysis for linked list programs where the abstract domain uses formulae from separation logic.",
    "URL": "http://link.springer.com/10.1007/11691372_19",
    "DOI": "10.1007/11691372_19",
    "publisher-place": "Berlin, Heidelberg",
    "page": "287-302",
    "page-first": "287",
    "volume": "3920",
    "language": "en-US",
    "_line": "FormalReview.bib:3091"
  },
  "calcagno_moving_nodate": {
    "id": "calcagno_moving_nodate",
    "type": "webpage",
    "author": [
      {
        "family": "Calcagno",
        "given": "Cristiano"
      },
      {
        "family": "Distefano",
        "given": "Dino"
      },
      {
        "family": "Dubreil",
        "given": "Jeremy"
      },
      {
        "family": "O'Hearn",
        "given": "Peter"
      }
    ],
    "title": "Moving Fast with Software Verification.Facebook Research",
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "abstract": "For organisations like Facebook, high quality software is important. However, the pace of change and increasing complexity of modern code makes it difficult to produce error free software. Available tools are often lacking in helping programmers develop more reliable and secure applications.",
    "URL": "https://research.fb.com/publications/moving-fast-with-software-verification",
    "language": "en-US",
    "_line": "FormalReview.bib:3110"
  },
  "sozeau_first-class_2008": {
    "id": "sozeau_first-class_2008",
    "type": "book",
    "author": [
      {
        "family": "Sozeau",
        "given": "Matthieu"
      },
      {
        "family": "Oury",
        "given": "Nicolas"
      }
    ],
    "title": "First-class type classes",
    "issued": {
      "date-parts": [
        [
          "2008"
        ]
      ]
    },
    "abstract": "Abstract. Type Classes have met a large success in Haskell and Isabelle, as a solution for sharing notations by overloading and for specifying with abstract structures by quantification on contexts. However, both systems are limited by second-class implementations of these constructs, and these limitations are only overcomed by ad-hoc extensions to the respective systems. We propose an embedding of type classes into a dependent type theory that is first-class and supports some of the most popular extensions right away. The implementation is correspondingly cheap, general and integrates well inside the system, as we have experimented in Coq. We show how it can be used to help structured programming and proving by way of examples. 1",
    "_line": "FormalReview.bib:3121"
  },
  "mohamed_first-class_2008": {
    "id": "mohamed_first-class_2008",
    "type": "chapter",
    "author": [
      {
        "family": "Sozeau",
        "given": "Matthieu"
      },
      {
        "family": "Oury",
        "given": "Nicolas"
      }
    ],
    "editor": [
      {
        "family": "Mohamed",
        "given": "Otmane Ait"
      },
      {
        "family": "Muñoz",
        "given": "César"
      },
      {
        "family": "Tahar",
        "given": "Sofiène"
      }
    ],
    "title": "First-Class Type Classes - TPHOLs Talk",
    "container-title": "Theorem Proving in Higher Order Logics",
    "issued": {
      "date-parts": [
        [
          "2008"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "1"
        ]
      ]
    },
    "publisher": "Springer Berlin Heidelberg",
    "isbn": "978-3-540-71065-3 978-3-540-71067-7",
    "URL": "http://link.springer.com/10.1007/978-3-540-71067-7_23",
    "DOI": "10.1007/978-3-540-71067-7_23",
    "publisher-place": "Berlin, Heidelberg",
    "page": "278-293",
    "page-first": "278",
    "volume": "5170",
    "language": "en-US",
    "_line": "FormalReview.bib:3129"
  },
  "sozeau_subset_nodate": {
    "id": "sozeau_subset_nodate",
    "type": "article-journal",
    "author": [
      {
        "family": "Sozeau",
        "given": "Matthieu"
      }
    ],
    "title": "Subset coercions in Coq",
    "container-title": "Springer-Verlag LNCS",
    "abstract": "Abstract. We propose a new language for writing programs with de-pendent types on top of the Coq proof assistant. This language permits to establish a phase distinction between writing and proving algorithms in the Coq environment. Concretely, this means allowing to write al-gorithms as easily as in a practical functional programming language whilst giving them as rich a specification as desired and proving that the code meets the specification using the whole Coq proof apparatus. This is achieved by extending conversion to an equivalence which re-lates types and subsets based on them, a technique originating from the “Predicate subtyping ” feature of PVS and following mathematical con-vention. The typing judgements can be translated to the Calculus of (Co-)Inductive Constructions (Cic) by means of an interpretation which inserts coercions at the appropriate places. These coercions can con-tain existential variables representing the propositional parts of the final term, corresponding to proof obligations (or PVS type-checking condi-tions). A prototype implementation of this process is integrated with the Coq environment. 1",
    "page": "237-252",
    "page-first": "237",
    "_line": "FormalReview.bib:3147"
  },
  "gonthier_small_2015": {
    "id": "gonthier_small_2015",
    "type": "report",
    "genre": "report",
    "author": [
      {
        "family": "Gonthier",
        "given": "Georges"
      },
      {
        "family": "Mahboubi",
        "given": "Assia"
      },
      {
        "family": "Tassi",
        "given": "Enrico"
      }
    ],
    "title": "A Small Scale Reflection Extension for the Coq system",
    "issued": {
      "date-parts": [
        [
          "2015"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "5"
        ]
      ]
    },
    "publisher": "Inria Saclay Ile de France",
    "abstract": "This is the user manual of Ssreflect, a set of extensions to the proof scripting language of the Coq proof assistant. While these extensions were developed to support a particular proof methodology - small-scale reflection - most of them actually are of a quite general nature, improving the functionality of Coq in basic areas such as script layout and structuring, proof context management, and rewriting. Consequently, and in spite of the title of this document, most of the extensions described here should be of interest for all Coq users, whether they embrace small-scale reflection or not.",
    "URL": "https://hal.inria.fr/inria-00258384/document",
    "language": "en-US",
    "_line": "FormalReview.bib:3156"
  },
  "ye_verified_2019": {
    "id": "ye_verified_2019",
    "type": "paper-conference",
    "author": [
      {
        "family": "Ye",
        "given": "Qianchuan"
      },
      {
        "family": "Delaware",
        "given": "Benjamin"
      }
    ],
    "title": "A Verified Protocol Buffer Compiler",
    "container-title": "Proceedings of the 8th ACM SIGPLAN International Conference on Certified Programs and Proofs",
    "collection-title": "CPP 2019",
    "issued": {
      "date-parts": [
        [
          "2019"
        ]
      ]
    },
    "publisher": "ACM",
    "isbn": "978-1-4503-6222-1",
    "keywords": "Program verification, Coq, Serialization",
    "URL": "http://doi.acm.org/10.1145/3293880.3294105",
    "DOI": "10.1145/3293880.3294105",
    "publisher-place": "New York, NY, USA",
    "page": "222-233",
    "page-first": "222",
    "_line": "FormalReview.bib:3169"
  },
  "noauthor_lean_nodate": {
    "id": "noauthor_lean_nodate",
    "type": "webpage",
    "title": "Lean Forward: Usable Computer-Checked Proofs and Computations",
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "8"
        ]
      ]
    },
    "URL": "https://lean-forward.github.io/",
    "_line": "FormalReview.bib:3186"
  },
  "urban_roscoq:_2015": {
    "id": "urban_roscoq:_2015",
    "type": "chapter",
    "author": [
      {
        "family": "Anand",
        "given": "Abhishek"
      },
      {
        "family": "Knepper",
        "given": "Ross"
      }
    ],
    "editor": [
      {
        "family": "Urban",
        "given": "Christian"
      },
      {
        "family": "Zhang",
        "given": "Xingyuan"
      }
    ],
    "title": "ROSCoq: Robots Powered by Constructive Reals",
    "container-title": "Interactive Theorem Proving",
    "container-title-short": "ROSCoq",
    "title-short": "ROSCoq",
    "issued": {
      "date-parts": [
        [
          "2015"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "8"
        ]
      ]
    },
    "publisher": "Springer International Publishing",
    "isbn": "978-3-319-22101-4 978-3-319-22102-1",
    "URL": "http://link.springer.com/10.1007/978-3-319-22102-1_3",
    "DOI": "10.1007/978-3-319-22102-1_3",
    "publisher-place": "Cham",
    "page": "34-50",
    "page-first": "34",
    "volume": "9236",
    "_line": "FormalReview.bib:3193"
  },
  "lamport_if_2018": {
    "id": "lamport_if_2018",
    "type": "article-journal",
    "author": [
      {
        "family": "Lamport",
        "given": "Leslie"
      },
      {
        "family": "Distributed Computing &bslash;&amp; Education Column by Juraj Hromkovic",
        "given": "Stefan Schmid"
      }
    ],
    "title": "If You’re Not Writing a Program, Don’t Use a Programming Language",
    "container-title": "Bulletin of EATCS",
    "issued": {
      "date-parts": [
        [
          "2018",
          "6",
          "12"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "8"
        ]
      ]
    },
    "abstract": "The need to handle large programs and to produce ecient compiled codeadds complexity to programming languages and limits their expressiveness.Algorithms are not programs, and they can be expressed in a simpler and more expressive language. That language is the one used by almost every branch of science and engineering to precisely describe and reason about the objects they study: the language of mathematics. Math is useful for describing a more general class of algorithms than are studied in algorithmcourses.",
    "URL": "http://eatcs.org/beatcs/index.php/beatcs/article/view",
    "volume": "2",
    "issue": "125",
    "language": "en-US",
    "_line": "FormalReview.bib:3211"
  },
  "sewell_rems_nodate": {
    "id": "sewell_rems_nodate",
    "type": "webpage",
    "author": [
      {
        "family": "Sewell",
        "given": "Peter"
      }
    ],
    "title": "REMS - Rigorous Engineering of Mainstream Systems",
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "28"
        ]
      ]
    },
    "URL": "https://www.cl.cam.ac.uk/~pes20/rems/index.html",
    "_line": "FormalReview.bib:3226"
  },
  "bishop_engineering_2018": {
    "id": "bishop_engineering_2018",
    "type": "article-journal",
    "author": [
      {
        "family": "Bishop",
        "given": "Steve"
      },
      {
        "family": "Fairbairn",
        "given": "Matthew"
      },
      {
        "family": "Mehnert",
        "given": "Hannes"
      },
      {
        "family": "Norrish",
        "given": "Michael"
      },
      {
        "family": "Ridge",
        "given": "Tom"
      },
      {
        "family": "Sewell",
        "given": "Peter"
      },
      {
        "family": "Smith",
        "given": "Michael"
      },
      {
        "family": "Wansbrough",
        "given": "Keith"
      }
    ],
    "title": "Engineering with Logic: Rigorous Test-Oracle Specification and Validation for TCP/IP and the Sockets API",
    "container-title": "J. ACM",
    "container-title-short": "Engineering with Logic",
    "title-short": "Engineering with Logic",
    "issued": {
      "date-parts": [
        [
          "2018",
          "12"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "28"
        ]
      ]
    },
    "issn": "0004-5411",
    "abstract": "Conventional computer engineering relies on test-and-debug development processes, with the behavior of common interfaces described (at best) with prose specification documents. But prose specifications cannot be used in test-and-debug development in any automated way, and prose is a poor medium for expressing complex (and loose) specifications. The TCP/IP protocols and Sockets API are a good example of this: they play a vital role in modern communication and computation, and interoperability between implementations is essential. But what exactly they are is surprisingly obscure: their original development focused on “rough consensus and running code,” augmented by prose RFC specifications that do not precisely define what it means for an implementation to be correct. Ultimately, the actual standard is the de facto one of the common implementations, including, for example, the 15 000 to 20 000 lines of the BSD implementation—optimized and multithreaded C code, time dependent, with asynchronous event handlers, intertwined with the operating system, and security critical. This article reports on work done in the Netsem project to develop lightweight mathematically rigorous techniques that can be applied to such systems: to specify their behavior precisely (but loosely enough to permit the required implementation variation) and to test whether these specifications and the implementations correspond with specifications that are executable as test oracles. We developed post hoc specifications of TCP, UDP, and the Sockets API, both of the service that they provide to applications (in terms of TCP bidirectional stream connections) and of the internal operation of the protocol (in terms of TCP segments and UDP datagrams), together with a testable abstraction function relating the two. These specifications are rigorous, detailed, readable, with broad coverage, and rather accurate. Working within a general-purpose proof assistant (HOL4), we developed language idioms (within higher-order logic) in which to write the specifications: operational semantics with nondeterminism, time, system calls, monadic relational programming, and so forth. We followed an experimental semantics approach, validating the specifications against several thousand traces captured from three implementations (FreeBSD, Linux, and WinXP). Many differences between these were identified, as were a number of bugs. Validation was done using a special-purpose symbolic model checker programmed above HOL4. Having demonstrated that our logic-based engineering techniques suffice for handling real-world protocols, we argue that similar techniques could be applied to future critical software infrastructure at design time, leading to cleaner designs and (via specification-based testing) more robust and predictable implementations. In cases where specification looseness can be controlled, this should be possible with lightweight techniques, without the need for a general-purpose proof assistant, at relatively little cost.",
    "keywords": "network protocols, Rigorous engineering, specification",
    "URL": "http://doi.acm.org/10.1145/3243650",
    "DOI": "10.1145/3243650",
    "page": "1:1-1:77",
    "page-first": "1",
    "volume": "66",
    "issue": "1",
    "_line": "FormalReview.bib:3234"
  },
  "memarian_exploring_2019": {
    "id": "memarian_exploring_2019",
    "type": "article-journal",
    "author": [
      {
        "family": "Memarian",
        "given": "Kayvan"
      },
      {
        "family": "Gomes",
        "given": "Victor B. F."
      },
      {
        "family": "Davis",
        "given": "Brooks"
      },
      {
        "family": "Kell",
        "given": "Stephen"
      },
      {
        "family": "Richardson",
        "given": "Alexander"
      },
      {
        "family": "Watson",
        "given": "Robert N. M."
      },
      {
        "family": "Sewell",
        "given": "Peter"
      }
    ],
    "title": "Exploring C Semantics and Pointer Provenance",
    "container-title": "Proc. ACM Program. Lang.",
    "issued": {
      "date-parts": [
        [
          "2019",
          "1"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "28"
        ]
      ]
    },
    "issn": "2475-1421",
    "abstract": "The semantics of pointers and memory objects in C has been a vexed question for many years. C values cannot be treated as either purely abstract or purely concrete entities: the language exposes their representations, but compiler optimisations rely on analyses that reason about provenance and initialisation status, not just runtime representations. The ISO WG14 standard leaves much of this unclear, and in some respects differs with de facto standard usage &mdash; which itself is difficult to investigate.   In this paper we explore the possible source-language semantics for memory objects and pointers, in ISO C and in C as it is used and implemented in practice, focussing especially on pointer provenance. We aim to, as far as possible, reconcile the ISO C standard, mainstream compiler behaviour, and the semantics relied on by the corpus of existing C code. We present two coherent proposals, tracking provenance via integers and not; both address many design questions. We highlight some pros and cons and open questions, and illustrate the discussion with a library of test cases. We make our semantics executable as a test oracle, integrating it with the Cerberus semantics for much of the rest of C, which we have made substantially more complete and robust, and equipped with a web-interface GUI. This allows us to experimentally assess our proposals on those test cases. To assess their viability with respect to larger bodies of C code, we analyse the changes required and the resulting behaviour for a port of FreeBSD to CHERI, a research architecture supporting hardware capabilities, which (roughly speaking) traps on the memory safety violations which our proposals deem undefined behaviour. We also develop a new runtime instrumentation tool to detect possible provenance violations in normal C code, and apply it to some of the SPEC benchmarks. We compare our proposal with a source-language variant of the twin-allocation LLVM semantics proposal of Lee et al. Finally, we describe ongoing interactions with WG14, exploring how our proposals could be incorporated into the ISO standard.",
    "keywords": "C",
    "URL": "http://doi.acm.org/10.1145/3290380",
    "DOI": "10.1145/3290380",
    "page": "67:1-67:32",
    "page-first": "67",
    "volume": "3",
    "_line": "FormalReview.bib:3252"
  },
  "armstrong_isa_2019": {
    "id": "armstrong_isa_2019",
    "type": "article-journal",
    "author": [
      {
        "family": "Armstrong",
        "given": "Alasdair"
      },
      {
        "family": "Bauereiss",
        "given": "Thomas"
      },
      {
        "family": "Campbell",
        "given": "Brian"
      },
      {
        "family": "Reid",
        "given": "Alastair"
      },
      {
        "family": "Gray",
        "given": "Kathryn E."
      },
      {
        "family": "Norton",
        "given": "Robert M."
      },
      {
        "family": "Mundkur",
        "given": "Prashanth"
      },
      {
        "family": "Wassell",
        "given": "Mark"
      },
      {
        "family": "French",
        "given": "Jon"
      },
      {
        "family": "Pulte",
        "given": "Christopher"
      },
      {
        "family": "Flur",
        "given": "Shaked"
      },
      {
        "family": "Stark",
        "given": "Ian"
      },
      {
        "family": "Krishnaswami",
        "given": "Neel"
      },
      {
        "family": "Sewell",
        "given": "Peter"
      }
    ],
    "title": "ISA Semantics for ARMv8-a, RISC-v, and CHERI-MIPS",
    "container-title": "Proc. ACM Program. Lang.",
    "issued": {
      "date-parts": [
        [
          "2019",
          "1"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "28"
        ]
      ]
    },
    "issn": "2475-1421",
    "abstract": "Architecture specifications notionally define the fundamental interface between hardware and software: the envelope of allowed behaviour for processor implementations, and the basic assumptions for software development and verification. But in practice, they are typically prose and pseudocode documents, not rigorous or executable artifacts, leaving software and verification on shaky ground.   In this paper, we present rigorous semantic models for the sequential behaviour of large parts of the mainstream ARMv8-A, RISC-V, and MIPS architectures, and the research CHERI-MIPS architecture, that are complete enough to boot operating systems, variously Linux, FreeBSD, or seL4. Our ARMv8-A models are automatically translated from authoritative ARM-internal definitions, and (in one variant) tested against the ARM Architecture Validation Suite.   We do this using a custom language for ISA semantics, Sail, with a lightweight dependent type system, that supports automatic generation of emulator code in C and OCaml, and automatic generation of proof-assistant definitions for Isabelle, HOL4, and (currently only for MIPS) Coq. We use the former for validation, and to assess specification coverage. To demonstrate the usability of the latter, we prove (in Isabelle) correctness of a purely functional characterisation of ARMv8-A address translation. We moreover integrate the RISC-V model into the RMEM tool for (user-mode) relaxed-memory concurrency exploration. We prove (on paper) the soundness of the core Sail type system.   We thereby take a big step towards making the architectural abstraction actually well-defined, establishing foundations for verification and reasoning.",
    "keywords": "Semantics, Instruction Set Architectures, Theorem Proving",
    "URL": "http://doi.acm.org/10.1145/3290384",
    "DOI": "10.1145/3290384",
    "page": "71:1-71:31",
    "page-first": "71",
    "volume": "3",
    "_line": "FormalReview.bib:3269"
  },
  "pulte_simplifying_2017": {
    "id": "pulte_simplifying_2017",
    "type": "article-journal",
    "author": [
      {
        "family": "Pulte",
        "given": "Christopher"
      },
      {
        "family": "Flur",
        "given": "Shaked"
      },
      {
        "family": "Deacon",
        "given": "Will"
      },
      {
        "family": "French",
        "given": "Jon"
      },
      {
        "family": "Sarkar",
        "given": "Susmit"
      },
      {
        "family": "Sewell",
        "given": "Peter"
      }
    ],
    "title": "Simplifying ARM Concurrency: Multicopy-atomic Axiomatic and Operational Models for ARMv8",
    "container-title": "Proc. ACM Program. Lang.",
    "container-title-short": "Simplifying ARM Concurrency",
    "title-short": "Simplifying ARM Concurrency",
    "issued": {
      "date-parts": [
        [
          "2017",
          "12"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "28"
        ]
      ]
    },
    "issn": "2475-1421",
    "abstract": "ARM has a relaxed memory model, previously specified in informal prose for ARMv7 and ARMv8. Over time, and partly due to work building formal semantics for ARM concurrency, it has become clear that some of the complexity of the model is not justified by the potential benefits. In particular, the model was originally non-multicopy-atomic: writes could become visible to some other threads before becoming visible to all — but this has not been exploited in production implementations, the corresponding potential hardware optimisations are thought to have insufficient benefits in the ARM context, and it gives rise to subtle complications when combined with other ARMv8 features. The ARMv8 architecture has therefore been revised: it now has a multicopy-atomic model. It has also been simplified in other respects, including more straightforward notions of dependency, and the architecture now includes a formal concurrency model.  In this paper we detail these changes and discuss their motivation. We define two formal concurrency models: an operational one, simplifying the Flowing model of Flur et al., and the axiomatic model of the revised ARMv8 specification. The models were developed by an academic group and by ARM staff, respectively, and this extended collaboration partly motivated the above changes. We prove the equivalence of the two models. The operational model is integrated into an executable exploration tool with new web interface, demonstrated by exhaustively checking the possible behaviours of a loop-unrolled version of a Linux kernel lock implementation, a previously known bug due to unprevented speculation, and a fixed version.",
    "keywords": "Semantics, Axiomatic, Operational, Relaxed Memory Models",
    "URL": "http://doi.acm.org/10.1145/3158107",
    "DOI": "10.1145/3158107",
    "page": "19:1-19:29",
    "page-first": "19",
    "volume": "2",
    "_line": "FormalReview.bib:3286"
  },
  "nienhuis_operational_2016": {
    "id": "nienhuis_operational_2016",
    "type": "paper-conference",
    "author": [
      {
        "family": "Nienhuis",
        "given": "Kyndylan"
      },
      {
        "family": "Memarian",
        "given": "Kayvan"
      },
      {
        "family": "Sewell",
        "given": "Peter"
      }
    ],
    "title": "An Operational Semantics for C/C++11 Concurrency",
    "container-title": "Proceedings of the 2016 ACM SIGPLAN International Conference on Object-Oriented Programming, Systems, Languages, and Applications",
    "collection-title": "OOPSLA 2016",
    "issued": {
      "date-parts": [
        [
          "2016"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "28"
        ]
      ]
    },
    "publisher": "ACM",
    "isbn": "978-1-4503-4444-9",
    "abstract": "The C/C++11 concurrency model balances two goals: it is relaxed enough to be efficiently implementable and (leaving aside the \"thin-air\" problem) it is strong enough to give useful guarantees to programmers. It is mathematically precise and has been used in verification research and compiler testing. However, the model is expressed in an axiomatic style, as predicates on complete candidate executions. This suffices for computing the set of allowed executions of a small litmus test, but it does not directly support the incremental construction of executions of larger programs. It is also at odds with conventional operational semantics, as used implicitly in the rest of the C/C++ standards.   Our main contribution is the development of an operational model for C/C++11 concurrency. This covers all the features of the previous formalised axiomatic model, and we have a mechanised proof that the two are equivalent, in Isabelle/HOL. We also integrate this semantics with an operational semantics for sequential C (described elsewhere); the combined semantics can incrementally execute programs in a small fragment of C.   Doing this uncovered several new aspects of the C/C++11 model: we show that one cannot build an equivalent operational model that simply follows program order, sequential consistent order, or the synchronises-with order. The first negative result is forced by hardware-observable behaviour, but the latter two are not, and so might be ameliorated by changing C/C++11. More generally, we hope that this work, with its focus on incremental construction of executions, will inform the future design of new concurrency models.",
    "keywords": "C/C++, Concurrency",
    "URL": "http://doi.acm.org/10.1145/2983990.2983997",
    "DOI": "10.1145/2983990.2983997",
    "publisher-place": "New York, NY, USA",
    "page": "111-128",
    "page-first": "111",
    "note": "event-place: Amsterdam, Netherlands",
    "_line": "FormalReview.bib:3304"
  },
  "kell_missing_2016": {
    "id": "kell_missing_2016",
    "type": "paper-conference",
    "author": [
      {
        "family": "Kell",
        "given": "Stephen"
      },
      {
        "family": "Mulligan",
        "given": "Dominic P."
      },
      {
        "family": "Sewell",
        "given": "Peter"
      }
    ],
    "title": "The Missing Link: Explaining ELF Static Linking, Semantically",
    "container-title": "Proceedings of the 2016 ACM SIGPLAN International Conference on Object-Oriented Programming, Systems, Languages, and Applications",
    "container-title-short": "The Missing Link",
    "collection-title": "OOPSLA 2016",
    "title-short": "The Missing Link",
    "issued": {
      "date-parts": [
        [
          "2016"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "28"
        ]
      ]
    },
    "publisher": "ACM",
    "isbn": "978-1-4503-4444-9",
    "abstract": "Beneath the surface, software usually depends on complex linker behaviour to work as intended. Even linking &lt;pre&gt;hello&underscore;world.c&lt;/pre&gt; is surprisingly involved, and systems software such as &lt;pre&gt;libc&lt;/pre&gt; and operating system kernels rely on a host of linker features. But linking is poorly understood by working programmers and has largely been neglected by language researchers.  In this paper we survey the many use-cases that linkers support and the poorly specified linker speak by which they are controlled: metadata in object files, command-line options, and linker-script language. We provide the first validated formalisation of a realistic executable and linkable format (ELF), and capture aspects of the Application Binary Interfaces for four mainstream platforms (AArch64, AMD64, Power64, and IA32). Using these, we develop an executable specification of static linking, covering (among other things) enough to link small C programs (we use the example of bzip2) into a correctly running executable. We provide our specification in Lem and Isabelle/HOL forms. This is the first formal specification of mainstream linking. We have used the Isabelle/HOL version to prove a sample correctness property for one case of AMD64 ABI relocation, demonstrating that the specification supports formal proof, and as a first step towards the much more ambitious goal of verified linking. Our work should enable several novel strands of research, including linker-aware verified compilation and program analysis, and better languages for controlling linking.",
    "keywords": "Executable and Linkable Format (ELF), formal specification, Linking, theorem-proving",
    "URL": "http://doi.acm.org/10.1145/2983990.2983996",
    "DOI": "10.1145/2983990.2983996",
    "publisher-place": "New York, NY, USA",
    "page": "607-623",
    "page-first": "607",
    "note": "event-place: Amsterdam, Netherlands",
    "_line": "FormalReview.bib:3323"
  },
  "mulligan_lem:_2014": {
    "id": "mulligan_lem:_2014",
    "type": "paper-conference",
    "author": [
      {
        "family": "Mulligan",
        "given": "Dominic P."
      },
      {
        "family": "Owens",
        "given": "Scott"
      },
      {
        "family": "Gray",
        "given": "Kathryn E."
      },
      {
        "family": "Ridge",
        "given": "Tom"
      },
      {
        "family": "Sewell",
        "given": "Peter"
      }
    ],
    "title": "Lem: Reusable Engineering of Real-world Semantics",
    "container-title": "Proceedings of the 19th ACM SIGPLAN International Conference on Functional Programming",
    "container-title-short": "Lem",
    "collection-title": "ICFP '14",
    "title-short": "Lem",
    "issued": {
      "date-parts": [
        [
          "2014"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "28"
        ]
      ]
    },
    "publisher": "ACM",
    "isbn": "978-1-4503-2873-9",
    "abstract": "Recent years have seen remarkable successes in rigorous engineering: using mathematically rigorous semantic models (not just idealised calculi) of real-world processors, programming languages, protocols, and security mechanisms, for testing, proof, analysis, and design. Building these models is challenging, requiring experimentation, dialogue with vendors or standards bodies, and validation; their scale adds engineering issues akin to those of programming to the task of writing clear and usable mathematics. But language and tool support for specification is lacking. Proof assistants can be used but bring their own difficulties, and a model produced in one, perhaps requiring many person-years effort and maintained over an extended period, cannot be used by those familiar with another. We introduce Lem, a language for engineering reusable large-scale semantic models. The Lem design takes inspiration both from functional programming languages and from proof assistants, and Lem definitions are translatable into OCaml for testing, Coq, HOL4, and Isabelle/HOL for proof, and LaTeX and HTML for presentation. This requires a delicate balance of expressiveness, careful library design, and implementation of transformations - akin to compilation, but subject to the constraint of producing usable and human-readable code for each target. Lem's effectiveness is demonstrated by its use in practice.",
    "keywords": "proof assistants, lem, real-world semantics, specification languages",
    "URL": "http://doi.acm.org/10.1145/2628136.2628143",
    "DOI": "10.1145/2628136.2628143",
    "publisher-place": "New York, NY, USA",
    "page": "175-188",
    "page-first": "175",
    "note": "event-place: Gothenburg, Sweden",
    "_line": "FormalReview.bib:3343"
  },
  "noauthor_lem_2019": {
    "id": "noauthor_lem_2019",
    "type": "book",
    "title": "Lem semantic definition language.",
    "issued": {
      "date-parts": [
        [
          "2019",
          "2",
          "11"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "28"
        ]
      ]
    },
    "publisher": "REMS",
    "URL": "https://github.com/rems-project/lem",
    "note": "original-date: 2018-01-31T15:35:24Z",
    "_line": "FormalReview.bib:3363"
  },
  "sewell_ott_2019": {
    "id": "sewell_ott_2019",
    "type": "book",
    "author": [
      {
        "family": "Sewell",
        "given": "Peter"
      }
    ],
    "title": "The Ott tool for writing definitions of programming languages and calculi: ott-lang/ott",
    "container-title-short": "The Ott tool for writing definitions of programming languages and calculi",
    "title-short": "The Ott tool for writing definitions of programming languages and calculi",
    "issued": {
      "date-parts": [
        [
          "2019",
          "1",
          "17"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "28"
        ]
      ]
    },
    "publisher": "ott-lang",
    "URL": "https://github.com/ott-lang/ott",
    "note": "original-date: 2016-10-27T15:44:41Z",
    "_line": "FormalReview.bib:3372"
  },
  "noauthor_formalization_2019": {
    "id": "noauthor_formalization_2019",
    "type": "book",
    "title": "Formalization of the Interaction Tree Datatype in Coq: DeepSpec/InteractionTrees",
    "container-title-short": "Formalization of the Interaction Tree Datatype in Coq",
    "title-short": "Formalization of the Interaction Tree Datatype in Coq",
    "issued": {
      "date-parts": [
        [
          "2019",
          "2",
          "27"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "2",
          "28"
        ]
      ]
    },
    "publisher": "DeepSpec",
    "URL": "https://github.com/DeepSpec/InteractionTrees",
    "note": "original-date: 2018-06-21T18:53:18Z",
    "_line": "FormalReview.bib:3384"
  },
  "stewart_verified_nodate": {
    "id": "stewart_verified_nodate",
    "type": "webpage",
    "author": [
      {
        "family": "Stewart",
        "given": "Gordon"
      }
    ],
    "title": "Verified Separate Compilation for C &bar; Computer Science Department at Princeton University",
    "accessed": {
      "date-parts": [
        [
          "2019",
          "3",
          "3"
        ]
      ]
    },
    "URL": "https://www.cs.princeton.edu/research/techreps/TR-980-15",
    "_line": "FormalReview.bib:3395"
  },
  "mckinna_why_2006": {
    "id": "mckinna_why_2006",
    "type": "paper-conference",
    "author": [
      {
        "family": "McKinna",
        "given": "James"
      }
    ],
    "title": "Why Dependent Types Matter",
    "container-title": "Conference Record of the 33rd ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages",
    "collection-title": "POPL '06",
    "issued": {
      "date-parts": [
        [
          "2006"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "3",
          "22"
        ]
      ]
    },
    "publisher": "ACM",
    "isbn": "978-1-59593-027-9",
    "abstract": "Language designers have in recent years proposed a wealth of richer type systems for programming which seek to extend the range of statically enforced guarantees on data and code. Most such proposals have been evolutionary extensions of ML or Haskell, offering programmers a balanced compromise between expressive strength and existing well-understood technology. Typically they revolve around type- or kind-indexed types such as GADTs, supported by limited equality reasoning at the type-checking level, thus separating the dynamic behaviour of programs from the (simpler) static behaviour of indexing information occurring in their types.I want to argue in this talk for a more radical departure from such practice by examining full spectrum type dependency, lifting such restrictions on the data upon which types may depend. Conor McBride and I designed the language EPIGRAM for experiments in programming with inductive families of data (of which GADTs are a special case). Using it for illustration, I will explore some of the possibilities and challenges afforded by full spectrum type dependency at the static and dynamic level: types directly support modelling complex invariants in terms of other data (rather than their types), with a Curry-Howard flavour of data-as-evidence; such complexity is on a 'pay-as-you-go' basis, while keeping type annotations and other syntactic overheads to a minimum; data decomposition steps, e.g. case analysis, furnish more informative interactions between types and values during typechecking; such steps may moreover be abstractly specified by their types, and thus user definable; this supports a style of programming embracing 'learning by testing', views, and Burstall's 'hand simulation plus a little induction'; the absence of a rigid phase distinction need not lead to type-passing or excessive run-time overhead; effectful computation, in particular partiality, can be incorporated via variations on existing ideas such as monads.This talk is based on joint work with Conor McBride, Edwin Brady and Thorsten Altenkirch.",
    "URL": "http://doi.acm.org/10.1145/1111037.1111038",
    "DOI": "10.1145/1111037.1111038",
    "publisher-place": "New York, NY, USA",
    "page": "1-1",
    "page-first": "1",
    "note": "event-place: Charleston, South Carolina, USA",
    "_line": "FormalReview.bib:3403"
  },
  "altenkirch_why_nodate": {
    "id": "altenkirch_why_nodate",
    "type": "article-journal",
    "author": [
      {
        "family": "Altenkirch",
        "given": "Thorsten"
      },
      {
        "family": "McBride",
        "given": "Conor"
      },
      {
        "family": "McKinna",
        "given": "James"
      }
    ],
    "title": "Why Dependent Types Matter",
    "abstract": "We exhibit the rationale behind the design of Epigram, a dependently typed programming language and interactive program development system, using reﬁnements of a well known program—merge sort—as a running example. We discuss its relationship with other proposals to introduce aspects of dependent types into functional programming languages and sketch some topics for further work in this area.",
    "page": "21",
    "page-first": "21",
    "language": "en-US",
    "_line": "FormalReview.bib:3421"
  },
  "strange_loop_proof_nodate": {
    "id": "strange_loop_proof_nodate",
    "type": "motion-picture",
    "author": [
      {
        "family": "Strange Loop"
      }
    ],
    "title": "\"Proof Theory Impressionism: Blurring the Curry-Howard Line\" by Dan Pittman",
    "container-title-short": "\"Proof Theory Impressionism",
    "title-short": "\"Proof Theory Impressionism",
    "accessed": {
      "date-parts": [
        [
          "2019",
          "3",
          "22"
        ]
      ]
    },
    "URL": "https://www.youtube.com/watch?v=jrVPB-Ad5Gc&t=31s",
    "_line": "FormalReview.bib:3430"
  },
  "bansal_holist:_2019": {
    "id": "bansal_holist:_2019",
    "type": "article-journal",
    "author": [
      {
        "family": "Bansal",
        "given": "Kshitij"
      },
      {
        "family": "Loos",
        "given": "Sarah M."
      },
      {
        "family": "Rabe",
        "given": "Markus N."
      },
      {
        "family": "Szegedy",
        "given": "Christian"
      },
      {
        "family": "Wilcox",
        "given": "Stewart"
      }
    ],
    "title": "HOList: An Environment for Machine Learning of Higher-Order Theorem Proving (extended version)",
    "container-title": "arXiv:1904.03241 \\[cs\\]",
    "container-title-short": "HOList",
    "title-short": "HOList",
    "issued": {
      "date-parts": [
        [
          "2019",
          "4",
          "5"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "5",
          "26"
        ]
      ]
    },
    "abstract": "We present an environment, benchmark, and deep learning driven automated theorem prover for higher-order logic. Higher-order interactive theorem provers enable the formalization of arbitrary mathematical theories and thereby present an interesting, open-ended challenge for deep learning. We provide an open-source framework based on the HOL Light theorem prover that can be used as a reinforcement learning environment. HOL Light comes with a broad coverage of basic mathematical theorems on calculus and the formal proof of the Kepler conjecture, from which we derive a challenging benchmark for automated reasoning. We also present a deep reinforcement learning driven automated theorem prover, DeepHOL, with strong initial results on this benchmark.",
    "keywords": "Computer Science - Logic in Computer Science, Computer Science - Machine Learning, Computer Science - Artificial Intelligence",
    "URLtext": "1904.03241",
    "URLpretext": "[arXiv:]{.etype}",
    "eprint-type": "arxiv",
    "eprint": "1904.03241",
    "URL": "http://arxiv.org/abs/1904.03241",
    "_line": "FormalReview.bib:3438"
  },
  "yang_learning_2019": {
    "id": "yang_learning_2019",
    "type": "article-journal",
    "author": [
      {
        "family": "Yang",
        "given": "Kaiyu"
      },
      {
        "family": "Deng",
        "given": "Jia"
      }
    ],
    "title": "Learning to Prove Theorems via Interacting with Proof Assistants",
    "container-title": "arXiv:1905.09381 \\[cs, stat\\]",
    "issued": {
      "date-parts": [
        [
          "2019",
          "5",
          "21"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "5",
          "26"
        ]
      ]
    },
    "abstract": "Humans prove theorems by relying on substantial high-level reasoning and problem-specific insights. Proof assistants offer a formalism that resembles human mathematical reasoning, representing theorems in higher-order logic and proofs as high-level tactics. However, human experts have to construct proofs manually by entering tactics into the proof assistant. In this paper, we study the problem of using machine learning to automate the interaction with proof assistants. We construct CoqGym, a large-scale dataset and learning environment containing 71K human-written proofs from 123 projects developed with the Coq proof assistant. We develop ASTactic, a deep learning-based model that generates tactics as programs in the form of abstract syntax trees (ASTs). Experiments show that ASTactic trained on CoqGym can generate effective tactics and can be used to prove new theorems not previously provable by automated methods. Code is available at https://github.com/princeton-vl/CoqGym.",
    "keywords": "Computer Science - Logic in Computer Science, Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Statistics - Machine Learning",
    "URLtext": "1905.09381",
    "URLpretext": "[arXiv:]{.etype}",
    "eprint-type": "arxiv",
    "eprint": "1905.09381",
    "URL": "http://arxiv.org/abs/1905.09381",
    "_line": "FormalReview.bib:3453"
  },
  "noauthor_learning_2019": {
    "id": "noauthor_learning_2019",
    "type": "book",
    "title": "A Learning Environment for Theorem Proving with the Coq proof assistant: princeton-vl/CoqGym",
    "container-title-short": "A Learning Environment for Theorem Proving with the Coq proof assistant",
    "title-short": "A Learning Environment for Theorem Proving with the Coq proof assistant",
    "issued": {
      "date-parts": [
        [
          "2019",
          "5",
          "26"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "5",
          "26"
        ]
      ]
    },
    "publisher": "Princeton Vision &amp; Learning Lab",
    "URL": "https://github.com/princeton-vl/CoqGym",
    "note": "original-date: 2019-05-24T22:31:20Z",
    "_line": "FormalReview.bib:3467"
  },
  "sozeau_metacoq_nodate": {
    "id": "sozeau_metacoq_nodate",
    "type": "article-journal",
    "author": [
      {
        "family": "Sozeau",
        "given": "Matthieu"
      }
    ],
    "title": "The MetaCoq Project",
    "abstract": "The MetaCoq project1 aims to provide a certiﬁed meta-programming environment in Coq. It builds on Template-Coq, a plugin for Coq originally implemented by Malecha (2014), which provided a reiﬁer for Coq terms and global declarations, as represented in the Coq kernel, as well as a denotation command. Recently, it was used in the CertiCoq certiﬁed compiler project (Anand et al., 2017), as its front-end language, to derive parametricity properties (Anand and Morrisett, 2018). However, the syntax lacked semantics, be it typing semantics or operational semantics, which should reﬂect, as formal speciﬁcations in Coq, the semantics of Coq’s type theory itself. The tool was also rather bare bones, providing only rudimentary quoting and unquoting commands. We generalize it to handle the entire Polymorphic Calculus of Cumulative Inductive Constructions (pCUIC), as implemented by Coq, including the kernel’s declaration structures for deﬁnitions and inductives, and implement a monad for general manipulation of Coq’s logical environment. We demonstrate how this setup allows Coq users to deﬁne many kinds of general purpose plugins, whose correctness can be readily proved in the system itself, and that can be run eﬃciently after extraction. We give a few examples of implemented plugins, including a parametricity translation and a certifying extraction to call-by-value λ-calculus. We also advocate the use of MetaCoq as a foundation for higher-level tools.",
    "page": "39",
    "page-first": "39",
    "language": "en-US",
    "_line": "FormalReview.bib:3478"
  },
  "gilbert_definitional_2019": {
    "id": "gilbert_definitional_2019",
    "type": "article-journal",
    "author": [
      {
        "family": "Gilbert",
        "given": "Gaëtan"
      },
      {
        "family": "Cockx",
        "given": "Jesper"
      },
      {
        "family": "Sozeau",
        "given": "Matthieu"
      },
      {
        "family": "Tabareau",
        "given": "Nicolas"
      }
    ],
    "title": "Definitional Proof-irrelevance Without K",
    "container-title": "Proc. ACM Program. Lang.",
    "issued": {
      "date-parts": [
        [
          "2019",
          "1"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "5",
          "26"
        ]
      ]
    },
    "issn": "2475-1421",
    "abstract": "Definitional equality—or conversion—for a type theory with a decidable type checking is the simplest tool to prove that two objects are the same, letting the system decide just using computation. Therefore, the more things are equal by conversion, the simpler it is to use a language based on type theory. Proof-irrelevance, stating that any two proofs of the same proposition are equal, is a possible way to extend conversion to make a type theory more powerful. However, this new power comes at a price if we integrate it naively, either by making type checking undecidable or by realizing new axioms—such as uniqueness of identity proofs (UIP)—that are incompatible with other extensions, such as univalence. In this paper, taking inspiration from homotopy type theory, we propose a general way to extend a type theory with definitional proof irrelevance, in a way that keeps type checking decidable and is compatible with univalence. We provide a new criterion to decide whether a proposition can be eliminated over a type (correcting and improving the so-called singleton elimination of Coq) by using techniques coming from recent development on dependent pattern matching without UIP. We show the generality of our approach by providing implementations for both Coq and Agda, both of which are planned to be integrated in future versions of those proof assistants.",
    "keywords": "proof assistants, proof irrelevance, type theory",
    "URL": "http://doi.acm.org/10.1145/3290316",
    "DOI": "10.1145/3290316",
    "page": "3:1-3:28",
    "page-first": "3",
    "volume": "3",
    "_line": "FormalReview.bib:3487"
  },
  "timany_cumulative_2018": {
    "id": "timany_cumulative_2018",
    "type": "paper-conference",
    "author": [
      {
        "family": "Timany",
        "given": "Amin"
      },
      {
        "family": "Sozeau",
        "given": "Matthieu"
      }
    ],
    "title": "Cumulative Inductive Types In Coq",
    "container-title": "FSCD",
    "issued": {
      "date-parts": [
        [
          "2018"
        ]
      ]
    },
    "abstract": "In order to avoid well-known paradoxes associated with self-referential definitions, higher-order dependent type theories stratify the theory using a countably infinite hierarchy of universes (also known as sorts), Type0 : Type1 : · · · . Such type systems are called cumulative if for any type A we have that A : Typei implies A : Typei+1. The Predicative Calculus of Inductive Constructions (pCIC) which forms the basis of the Coq proof assistant, is one such system. In this paper we present the Predicative Calculus of Cumulative Inductive Constructions (pCuIC) which extends the cumulativity relation to inductive types. We discuss cumulative inductive types as present in Coq 8.7 and their application to formalization and definitional translations. 2012 ACM Subject Classification Theory of computation → Type theory, Theory of computation → Lambda calculus",
    "keywords": "Calculi, Calculus of constructions, Coq (software), Dependent type, Inductive type, Proof assistant, Type system",
    "DOI": "10.4230/LIPIcs.FSCD.2018.29",
    "_line": "FormalReview.bib:3504"
  },
  "gueneau_formal_nodate": {
    "id": "gueneau_formal_nodate",
    "type": "article-journal",
    "author": [
      {
        "family": "Guéneau",
        "given": "Armaël"
      },
      {
        "family": "Jourdan",
        "given": "Jacques-Henri"
      },
      {
        "family": "Charguéraud",
        "given": "Arthur"
      },
      {
        "family": "Pottier",
        "given": "François"
      }
    ],
    "title": "Formal Proof and Analysis of an Incremental Cycle Detection Algorithm",
    "page": "23",
    "page-first": "23",
    "language": "en-US",
    "_line": "FormalReview.bib:3515"
  },
  "breitner_ready_2018": {
    "id": "breitner_ready_2018",
    "type": "article-journal",
    "author": [
      {
        "family": "Breitner",
        "given": "Joachim"
      },
      {
        "family": "Spector-Zabusky",
        "given": "Antal"
      },
      {
        "family": "Li",
        "given": "Yao"
      },
      {
        "family": "Rizkallah",
        "given": "Christine"
      },
      {
        "family": "Wiegley",
        "given": "John"
      },
      {
        "family": "Weirich",
        "given": "Stephanie"
      }
    ],
    "title": "Ready, Set, Verify! Applying Hs-to-coq to Real-world Haskell Code (Experience Report)",
    "container-title": "Proc. ACM Program. Lang.",
    "issued": {
      "date-parts": [
        [
          "2018",
          "7"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "5",
          "26"
        ]
      ]
    },
    "issn": "2475-1421",
    "abstract": "Good tools can bring mechanical verification to programs written in mainstream functional languages. We use &lt;pre&gt;hs-to-coq&lt;/pre&gt; to translate significant portions of Haskell’s &lt;pre&gt;containers&lt;/pre&gt; library into Coq, and verify it against specifications that we derive from a variety of sources including type class laws, the library’s test suite, and interfaces from Coq’s standard library. Our work shows that it is feasible to verify mature, widely-used, highly optimized, and unmodified Haskell code. We also learn more about the theory of weight-balanced trees, extend &lt;pre&gt;hs-to-coq&lt;/pre&gt; to handle partiality, and – since we found no bugs – attest to the superb quality of well-tested functional code.",
    "keywords": "Coq, verification, Haskell",
    "URL": "http://doi.acm.org/10.1145/3236784",
    "DOI": "10.1145/3236784",
    "page": "89:1-89:16",
    "page-first": "89",
    "volume": "2",
    "_line": "FormalReview.bib:3523"
  },
  "casinghino_combining_2014": {
    "id": "casinghino_combining_2014",
    "type": "thesis",
    "genre": "phdthesis",
    "author": [
      {
        "family": "Casinghino",
        "given": "Chris"
      }
    ],
    "title": "Combining Proofs and Programs",
    "issued": {
      "date-parts": [
        [
          "2014"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "5",
          "26"
        ]
      ]
    },
    "publisher": "University of Pennsylvania",
    "URL": "https://www.seas.upenn.edu/~sweirich/papers/casinghino-thesis.pdf",
    "publisher-place": "Philadelphia, PA, USA",
    "language": "en-US",
    "_line": "FormalReview.bib:3540"
  },
  "casinghino_combining_2014-1": {
    "id": "casinghino_combining_2014-1",
    "type": "paper-conference",
    "author": [
      {
        "family": "Casinghino",
        "given": "Chris"
      },
      {
        "family": "Sjöberg",
        "given": "Vilhelm"
      },
      {
        "family": "Weirich",
        "given": "Stephanie"
      }
    ],
    "title": "Combining Proofs and Programs in a Dependently Typed Language",
    "container-title": "Proceedings of the 41st ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages",
    "collection-title": "POPL '14",
    "issued": {
      "date-parts": [
        [
          "2014"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "5",
          "26"
        ]
      ]
    },
    "publisher": "ACM",
    "isbn": "978-1-4503-2544-8",
    "abstract": "Most dependently-typed programming languages either require that all expressions terminate (e.g. Coq, Agda, and Epigram), or allow infinite loops but are inconsistent when viewed as logics (e.g. Haskell, ATS, Ωmega. Here, we combine these two approaches into a single dependently-typed core language. The language is composed of two fragments that share a common syntax and overlapping semantics: a logic that guarantees total correctness, and a call-by-value programming language that guarantees type safety but not termination. The two fragments may interact: logical expressions may be used as programs; the logic may soundly reason about potentially nonterminating programs; programs can require logical proofs as arguments; and \"mobile\" program values, including proofs computed at runtime, may be used as evidence by the logic. This language allows programmers to work with total and partial functions uniformly, providing a smooth path from functional programming to dependently-typed programming.",
    "keywords": "termination, dependent types, general recursion",
    "URL": "http://doi.acm.org/10.1145/2535838.2535883",
    "DOI": "10.1145/2535838.2535883",
    "publisher-place": "New York, NY, USA",
    "page": "33-45",
    "page-first": "33",
    "note": "event-place: San Diego, California, USA",
    "_line": "FormalReview.bib:3553"
  },
  "eisenberg_dependent_2016": {
    "id": "eisenberg_dependent_2016",
    "type": "thesis",
    "genre": "phdthesis",
    "author": [
      {
        "family": "Eisenberg",
        "given": "Richard A"
      }
    ],
    "title": "DEPENDENT TYPES IN HASKELL: THEORY AND PRACTICE",
    "issued": {
      "date-parts": [
        [
          "2016"
        ]
      ]
    },
    "publisher": "Pennsylvania",
    "number-of-pages": "351",
    "publisher-place": "Philadelphia, PA, USA",
    "language": "en-US",
    "_line": "FormalReview.bib:3572"
  },
  "weirich_specification_2017": {
    "id": "weirich_specification_2017",
    "type": "article-journal",
    "author": [
      {
        "family": "Weirich",
        "given": "Stephanie"
      },
      {
        "family": "Voizard",
        "given": "Antoine"
      },
      {
        "family": "Amorim",
        "given": "Pedro Henrique Azevedo",
        "dropping-particle": "de"
      },
      {
        "family": "Eisenberg",
        "given": "Richard A."
      }
    ],
    "title": "A Specification for Dependent Types in Haskell",
    "container-title": "Proc. ACM Program. Lang.",
    "issued": {
      "date-parts": [
        [
          "2017",
          "8"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "5",
          "26"
        ]
      ]
    },
    "issn": "2475-1421",
    "abstract": "We propose a core semantics for Dependent Haskell, an extension of Haskell with full-spectrum dependent types. Our semantics consists of two related languages. The first is a Curry-style dependently-typed language with nontermination, irrelevant arguments, and equality abstraction. The second, inspired by the Glasgow Haskell Compiler's core language FC, is its explicitly-typed analogue, suitable for implementation in GHC. All of our results&mdash;chiefly, type safety, along with theorems that relate these two languages&mdash;have been formalized using the Coq proof assistant. Because our work is backwards compatible with Haskell, our type safety proof holds in the presence of nonterminating computation. However, unlike other full-spectrum dependently-typed languages, such as Coq, Agda or Idris, because of this nontermination, Haskell's term language does not correspond to a consistent logic.",
    "keywords": "Haskell, Dependent Types",
    "URL": "http://doi.acm.org/10.1145/3110275",
    "DOI": "10.1145/3110275",
    "page": "31:1-31:29",
    "page-first": "31",
    "volume": "1",
    "_line": "FormalReview.bib:3584"
  },
  "de_millo_social_1979": {
    "id": "de_millo_social_1979",
    "type": "article-journal",
    "author": [
      {
        "family": "De Millo",
        "given": "Richard A."
      },
      {
        "family": "Lipton",
        "given": "Richard J."
      },
      {
        "family": "Perlis",
        "given": "Alan J."
      }
    ],
    "title": "Social Processes and Proofs of Theorems and Programs",
    "container-title": "Commun. ACM",
    "issued": {
      "date-parts": [
        [
          "1979",
          "5"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "5",
          "26"
        ]
      ]
    },
    "issn": "0001-0782",
    "abstract": "It is argued that formal verifications of programs, no matter how obtained, will not play the same key role in the development of computer science and software engineering as proofs do in mathematics. Furthermore the absence of continuity, the inevitability of change, and the complexity of specification of significantly many real programs make the formal verification process difficult to justify and manage. It is felt that ease of formal verification should not dominate program language design.",
    "keywords": "program verification, formal mathematics, mathematical proofs, program specification",
    "URL": "http://doi.acm.org/10.1145/359104.359106",
    "DOI": "10.1145/359104.359106",
    "page": "271-280",
    "page-first": "271",
    "volume": "22",
    "issue": "5",
    "_line": "FormalReview.bib:3601"
  },
  "dijkstra_political_1978": {
    "id": "dijkstra_political_1978",
    "type": "article-journal",
    "author": [
      {
        "family": "Dijkstra",
        "given": "Edsger W."
      },
      {
        "family": "DeMillo",
        "given": "R. A."
      },
      {
        "family": "Lipton",
        "given": "R. J."
      },
      {
        "family": "Perlis",
        "given": "A J."
      }
    ],
    "title": "On a Political Pamphlet from the Middle Ages",
    "container-title": "SIGSOFT Softw. Eng. Notes",
    "issued": {
      "date-parts": [
        [
          "1978",
          "4"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "5",
          "26"
        ]
      ]
    },
    "issn": "0163-5948",
    "URL": "http://doi.acm.org/10.1145/1005888.1005890",
    "DOI": "10.1145/1005888.1005890",
    "page": "14-16",
    "page-first": "14",
    "volume": "3",
    "issue": "2",
    "_line": "FormalReview.bib:3618"
  },
  "hedin_perspective_nodate": {
    "id": "hedin_perspective_nodate",
    "type": "article-journal",
    "author": [
      {
        "family": "Hedin",
        "given": "Daniel"
      },
      {
        "family": "Sabelfeld",
        "given": "Andrei"
      }
    ],
    "title": "A Perspective on Information-Flow Control",
    "abstract": "Information-ﬂow control tracks how information propagates through the program during execution to make sure that the program handles the information securely. Secure information ﬂow is comprised of two related aspects: information conﬁdentiality and information integrity — intuitively pertaining to the reading and writing of the information. The prevailing basic semantic notion of secure information ﬂow is noninterference, demanding independence of public (or, in the case of integrity, trusted) output from secret (or, in the case of integrity, untrusted) input. This document gives an account of the state-of-the-art in conﬁdentiality and integrity policies and their enforcement with a systematic formalization of four dominant formulations of noninterference: termination-insensitive, termination-sensitive, progress-insensitive, and progress-sensitive, cast in the setting of two minimal while languages.",
    "page": "29",
    "page-first": "29",
    "language": "en-US",
    "_line": "FormalReview.bib:3633"
  },
  "chiricescu_safe:_2013": {
    "id": "chiricescu_safe:_2013",
    "type": "paper-conference",
    "author": [
      {
        "family": "Chiricescu",
        "given": "Silviu"
      },
      {
        "family": "DeHon",
        "given": "Andre"
      },
      {
        "family": "Demange",
        "given": "Delphine"
      },
      {
        "family": "Iyer",
        "given": "Suraj"
      },
      {
        "family": "Kliger",
        "given": "Aleksey"
      },
      {
        "family": "Morrisett",
        "given": "Greg"
      },
      {
        "family": "Pierce",
        "given": "Benjamin C."
      },
      {
        "family": "Reubenstein",
        "given": "Howard"
      },
      {
        "family": "Smith",
        "given": "Jonathan M."
      },
      {
        "family": "Sullivan",
        "given": "Gregory T."
      },
      {
        "family": "Thomas",
        "given": "Arun"
      },
      {
        "family": "Tov",
        "given": "Jesse"
      },
      {
        "family": "White",
        "given": "Christopher M."
      },
      {
        "family": "Wittenberg",
        "given": "David"
      }
    ],
    "title": "SAFE: A clean-slate architecture for secure systems",
    "container-title": "2013 IEEE International Conference on Technologies for Homeland Security (HST)",
    "container-title-short": "SAFE",
    "title-short": "SAFE",
    "event-title": "2013 IEEE International Conference on Technologies for Homeland Security (HST)",
    "issued": {
      "date-parts": [
        [
          "2013",
          "11"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "5",
          "26"
        ]
      ]
    },
    "publisher": "IEEE",
    "isbn": "978-1-4799-1535-4 978-1-4799-3963-3",
    "abstract": "SAFE is a large-scale, clean-slate co-design project encompassing hardware architecture, programming languages, and operating systems. Funded by DARPA, the goal of SAFE is to create a secure computing system from the ground up. SAFE hardware provides memory safety, dynamic type checking, and native support for dynamic information ﬂow control. The Breeze programming language leverages the security features of the underlying machine, and the “zero kernel” operating system avoids relying on any single privileged component for overall system security. The SAFE project is working towards formally verifying security properties of the runtime software. The SAFE system sets a new high-water mark for system security, allowing secure applications to be built on a solid foundation rather than on the inherently vulnerable conventional platforms available today.",
    "URL": "http://ieeexplore.ieee.org/document/6699066/",
    "DOI": "10.1109/THS.2013.6699066",
    "publisher-place": "Waltham, MA, USA",
    "page": "570-576",
    "page-first": "570",
    "language": "en-US",
    "_line": "FormalReview.bib:3642"
  },
  "sjosten_information_2018": {
    "id": "sjosten_information_2018",
    "type": "paper-conference",
    "author": [
      {
        "family": "Sjösten",
        "given": "Alexander"
      },
      {
        "family": "Hedin",
        "given": "Daniel"
      },
      {
        "family": "Sabelfeld",
        "given": "Andrei"
      }
    ],
    "editor": [
      {
        "family": "Baier",
        "given": "Christel"
      },
      {
        "family": "Caires",
        "given": "Luís"
      }
    ],
    "title": "Information Flow Tracking for Side-Effectful Libraries",
    "container-title": "Formal Techniques for Distributed Objects, Components, and Systems",
    "collection-title": "Lecture Notes in Computer Science",
    "issued": {
      "date-parts": [
        [
          "2018"
        ]
      ]
    },
    "publisher": "Springer International Publishing",
    "isbn": "978-3-319-92612-4",
    "abstract": "Dynamic information flow control is a promising technique for ensuring confidentiality and integrity of applications that manipulate sensitive information. While much progress has been made on increasingly powerful programming languages ranging from low-level machine languages to high-level languages for distributed systems, surprisingly little attention has been devoted to libraries and APIs. The state of the art is largely an all-or-nothing choice: either a shallow or deep library modeling approach. Seeking to break out of this restrictive choice, we formalize a general mechanism that tracks information flow for a language that includes higher-order functions, structured data types and references. A key feature of our approach is the model heap, a part of the memory, where security information is kept to enable the interaction between the labeled program and the unlabeled library. We provide a proof-of-concept implementation and report on experiments with a file system library. The system has been proved correct using Coq.",
    "page": "141-160",
    "page-first": "141",
    "language": "en-US",
    "_line": "FormalReview.bib:3661"
  },
  "jajodia_termination-insensitive_2008": {
    "id": "jajodia_termination-insensitive_2008",
    "type": "chapter",
    "author": [
      {
        "family": "Askarov",
        "given": "Aslan"
      },
      {
        "family": "Hunt",
        "given": "Sebastian"
      },
      {
        "family": "Sabelfeld",
        "given": "Andrei"
      },
      {
        "family": "Sands",
        "given": "David"
      }
    ],
    "editor": [
      {
        "family": "Jajodia",
        "given": "Sushil"
      },
      {
        "family": "Lopez",
        "given": "Javier"
      }
    ],
    "title": "Termination-Insensitive Noninterference Leaks More Than Just a Bit",
    "container-title": "Computer Security - ESORICS 2008",
    "issued": {
      "date-parts": [
        [
          "2008"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "5",
          "26"
        ]
      ]
    },
    "publisher": "Springer Berlin Heidelberg",
    "isbn": "978-3-540-88312-8 978-3-540-88313-5",
    "abstract": "Current tools for analysing information ﬂow in programs build upon ideas going back to Denning’s work from the 70’s. These systems enforce an imperfect notion of information ﬂow which has become known as terminationinsensitive noninterference. Under this version of noninterference, information leaks are permitted if they are transmitted purely by the program’s termination behaviour (i.e., whether it terminates or not). This imperfection is the price to pay for having a security condition which is relatively liberal (e.g. allowing whileloops whose termination may depend on the value of a secret) and easy to check. But what is the price exactly? We argue that, in the presence of output, the price is higher than the “one bit” often claimed informally in the literature, and effectively such programs can leak all of their secrets. In this paper we develop a deﬁnition of termination-insensitive noninterference suitable for reasoning about programs with outputs. We show that the deﬁnition generalises “batch-job” style deﬁnitions from the literature and that it is indeed satisﬁed by a Denning-style program analysis with output. Although more than a bit of information can be leaked by programs satisfying this condition, we show that the best an attacker can do is a brute-force attack, which means that the attacker cannot reliably (in a technical sense) learn the secret in polynomial time in the size of the secret. If we further assume that secrets are uniformly distributed, we show that the advantage the attacker gains when guessing the secret after observing a polynomial amount of output is negligible in the size of the secret.",
    "URL": "http://link.springer.com/10.1007/978-3-540-88313-5_22",
    "DOI": "10.1007/978-3-540-88313-5_22",
    "publisher-place": "Berlin, Heidelberg",
    "page": "333-348",
    "page-first": "333",
    "volume": "5283",
    "language": "en-US",
    "_line": "FormalReview.bib:3676"
  },
  "goguen_unwinding_1984": {
    "id": "goguen_unwinding_1984",
    "type": "paper-conference",
    "author": [
      {
        "family": "Goguen",
        "given": "Joseph A."
      },
      {
        "family": "Meseguer",
        "given": "Jose"
      }
    ],
    "title": "Unwinding and Inference Control",
    "container-title": "1984 IEEE Symposium on Security and Privacy",
    "event-title": "1984 IEEE Symposium on Security and Privacy",
    "issued": {
      "date-parts": [
        [
          "1984",
          "4"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "5",
          "26"
        ]
      ]
    },
    "publisher": "IEEE",
    "isbn": "978-0-8186-0532-1",
    "URL": "http://ieeexplore.ieee.org/document/6234812/",
    "DOI": "10.1109/SP.1984.10019",
    "publisher-place": "Oakland, CA, USA",
    "page": "75-75",
    "page-first": "75",
    "language": "en-US",
    "_line": "FormalReview.bib:3695"
  },
  "lescuyer_provencore:_nodate": {
    "id": "lescuyer_provencore:_nodate",
    "type": "article-journal",
    "author": [
      {
        "family": "Lescuyer",
        "given": "Stéphane"
      }
    ],
    "title": "ProvenCore: Towards a Verified Isolation Micro-Kernel",
    "page": "69",
    "page-first": "69",
    "language": "en-US",
    "_line": "FormalReview.bib:3712"
  },
  "lescuyer_provencore:_2015": {
    "id": "lescuyer_provencore:_2015",
    "type": "manuscript",
    "author": [
      {
        "family": "Lescuyer",
        "given": "Stéphane"
      }
    ],
    "title": "ProvenCore: Towards a Verified Isolation Micro-Kernel",
    "container-title-short": "ProvenCore",
    "title-short": "ProvenCore",
    "issued": {
      "date-parts": [
        [
          "2015",
          "1",
          "20"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "5",
          "26"
        ]
      ]
    },
    "abstract": "We report on an ongoing project aiming at a fully secure micro-kernel named ProvenCore. This operating system is both developed and specified in a single specification language called Smart. The Smart models are used to generate efficient C code and express low- and high-level properties of the implementation, and first among them guarantees of integrity and confidentiality for the various processes running on the kernel. ProvenCore is designed to be used as a secure world operating system in mobile devices, beneath a professional application platform or a Trusted Execution Environment.",
    "keywords": "Certification Toolchain, Formal Proof, Isolation, Separation Kernel,",
    "URL": "https://zenodo.org/record/47990#.XOrmF-tKi24",
    "_line": "FormalReview.bib:3720"
  },
  "montagu_theory_2013": {
    "id": "montagu_theory_2013",
    "type": "paper-conference",
    "author": [
      {
        "family": "Montagu",
        "given": "B."
      },
      {
        "family": "Pierce",
        "given": "B. C."
      },
      {
        "family": "Pollack",
        "given": "R."
      }
    ],
    "title": "A Theory of Information-Flow Labels",
    "container-title": "2013 IEEE 26th Computer Security Foundations Symposium",
    "event-title": "2013 IEEE 26th Computer Security Foundations Symposium",
    "issued": {
      "date-parts": [
        [
          "2013",
          "6"
        ]
      ]
    },
    "abstract": "The security literature offers a multitude of calculi, languages, and systems for information-flow control, each with some set of labels encoding security policies that can be attached to data and computations. The exact form of these labels varies widely, with different systems offering many different combinations of features addressing issues such as confidentiality, integrity, and policy ownership. This variation makes it difficult to compare the expressive power of different information-flow frameworks. To enable such comparisons, we introduce label algebras, an abstract interface for information-flow labels equipped with a notion of authority, and study several notions of embedding between them. The simplest is a straightforward notion of injection between label algebras, but this lacks a clear computational motivation and rejects some reasonable encodings between label models. We obtain a more refined account by defining a space of encodings parameterized by an interpretation of labels and authorities, thus giving a semantic flavor to the definition of encoding. We study the theory of semantic encodings and consider two specific instances, one based on the possible observations of boolean values and one based on the behavior of programs in a small lambda-calculus parameterized over an arbitrary label algebra. We use this framework to define and compare a number of concrete label algebras, including realizations of the familiar taint, endorsement, readers, and distrust models, as well as label algebras based on several existing programming languages and operating systems.",
    "keywords": "Semantics, programming languages, information-flow control, Algebra, Asbestos, Boolean algebra, Boolean values, calculus, computational motivation, decentralized label model (DLM), Design, DIFC, disjunction category model, encoding, Encoding, Flume, HiStar, Information flow control (IFC), information-flow frameworks, information-flow labels, JIF, label algebras, label models, labels encoding security policies, lambda-calculus, Languages, Lattices, LIO, Observers, operating systems, Security, semantic encodings theory, Syntactics, telecommunication security, Theory",
    "DOI": "10.1109/CSF.2013.8",
    "page": "3-17",
    "page-first": "3",
    "_line": "FormalReview.bib:3732"
  },
  "menon_shakti-t:_2017": {
    "id": "menon_shakti-t:_2017",
    "type": "paper-conference",
    "author": [
      {
        "family": "Menon",
        "given": "Arjun"
      },
      {
        "family": "Murugan",
        "given": "Subadra"
      },
      {
        "family": "Rebeiro",
        "given": "Chester"
      },
      {
        "family": "Gala",
        "given": "Neel"
      },
      {
        "family": "Veezhinathan",
        "given": "Kamakoti"
      }
    ],
    "title": "Shakti-T: A RISC-V Processor with Light Weight Security Extensions",
    "container-title": "Proceedings of the Hardware and Architectural Support for Security and Privacy",
    "container-title-short": "Shakti-T",
    "collection-title": "HASP '17",
    "title-short": "Shakti-T",
    "issued": {
      "date-parts": [
        [
          "2017"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "5",
          "26"
        ]
      ]
    },
    "publisher": "ACM",
    "isbn": "978-1-4503-5266-6",
    "abstract": "With increased usage of compute cores for sensitive applications, including e-commerce, there is a need to provide additional hardware support for securing information from memory based attacks. This work presents a unified hardware framework for handling spatial and temporal memory attacks. The paper integrates the proposed hardware framework with a RISC-V based micro-architecture with an enhanced application binary interface that enables software layers to use these features to protect sensitive data. We demonstrate the effectiveness of the proposed scheme through practical case studies in addition to taking the design through a VLSI CAD design flow. The proposed processor reduces the metadata storage overhead up to 4 x in comparison with the existing solutions, while incurring an area overhead of just 1914 LUTs and 2197 flip flops on an FPGA, without affecting the critical path delay of the processor.",
    "keywords": "Buffer Overflow, Memory Security, Secure Processor Architecture, Spatial Attacks, Tagged Architecture, Temporal Attacks",
    "URL": "http://doi.acm.org/10.1145/3092627.3092629",
    "DOI": "10.1145/3092627.3092629",
    "publisher-place": "New York, NY, USA",
    "page": "2:1-2:8",
    "page-first": "2",
    "note": "event-place: Toronto, ON, Canada",
    "_line": "FormalReview.bib:3745"
  },
  "jung_iris_2018-1": {
    "id": "jung_iris_2018-1",
    "type": "article-journal",
    "author": [
      {
        "family": "Jung",
        "given": "Ralf"
      },
      {
        "family": "Krebbers",
        "given": "Robbert"
      },
      {
        "family": "Jourdan",
        "given": "Jacques-Henri"
      },
      {
        "family": "Bizjak",
        "given": "Aleš"
      },
      {
        "family": "Birkedal",
        "given": "Lars"
      },
      {
        "family": "Dreyer",
        "given": "Derek"
      }
    ],
    "title": "Iris from the ground up: A modular foundation for higher-order concurrent separation logic",
    "container-title": "Journal of Functional Programming",
    "container-title-short": "Iris from the ground up",
    "title-short": "Iris from the ground up",
    "issued": {
      "date-parts": [
        [
          "2018"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "5",
          "26"
        ]
      ]
    },
    "issn": "0956-7968, 1469-7653",
    "abstract": "Iris is a framework for higher-order concurrent separation logic, which has been implemented in the Coq proof assistant and deployed very effectively in a wide variety of veriﬁcation projects. Iris was designed with the express goal of simplifying and consolidating the foundations of modern separation logics, but it has evolved over time, and the design and semantic foundations of Iris itself have yet to be fully written down and explained together properly in one place. Here, we attempt to ﬁll this gap, presenting a reasonably complete picture of the latest version of Iris (version 3.1), from ﬁrst principles and in one coherent narrative.",
    "URL": "https://www.cambridge.org/core/product/identifier/S0956796818000151/type/journal_article",
    "DOI": "10.1017/S0956796818000151",
    "volume": "28",
    "language": "en-US",
    "_line": "FormalReview.bib:3765"
  },
  "noauthor_ghc_nodate": {
    "id": "noauthor_ghc_nodate",
    "type": "webpage",
    "title": "GHC User’s Guide — Glasgow Haskell Compiler 8.6.5 User's Guide",
    "accessed": {
      "date-parts": [
        [
          "2019",
          "5",
          "26"
        ]
      ]
    },
    "URL": "https://downloads.haskell.org/~ghc/latest/docs/html/users_guide/index.html",
    "_line": "FormalReview.bib:3781"
  },
  "noauthor_algebraic_nodate": {
    "id": "noauthor_algebraic_nodate",
    "type": "webpage",
    "title": "Algebraic Specification of Stack Effects for Forth Programs.ResearchGate",
    "accessed": {
      "date-parts": [
        [
          "2019",
          "5",
          "26"
        ]
      ]
    },
    "abstract": "ResearchGate is a network dedicated to science and research. Connect, collaborate and discover scientific publications, jobs and conferences. All for free.",
    "URL": "https://www.researchgate.net/publication/269399251_Algebraic_Specification_of_Stack_Effects_for_Forth_Programs",
    "language": "en-US",
    "_line": "FormalReview.bib:3788"
  },
  "poial_forth_nodate": {
    "id": "poial_forth_nodate",
    "type": "article-journal",
    "author": [
      {
        "family": "Poial",
        "given": "Jaanus"
      }
    ],
    "title": "Forth and Formal Language Theory",
    "abstract": "Forth is an excellent programming paradigm, but it is also an interesting object of investigation for formal language theory. With its clear interface based on stacks Forth programs are easily generated by some formal system (e.g. syntax directed translation scheme). Usually it is possible to make such a formal system to generate only \"useful\" programs, but this subset of programs is often very small and does not cover interesting features of the Forth language itself.",
    "page": "6",
    "page-first": "6",
    "language": "en-US",
    "_line": "FormalReview.bib:3797"
  },
  "power_formal_nodate": {
    "id": "power_formal_nodate",
    "type": "book",
    "author": [
      {
        "family": "Power",
        "given": "James F."
      },
      {
        "family": "Sinclair",
        "given": "David"
      }
    ],
    "title": "A Formal Model of Forth Control Words in the Pi-Calculus",
    "abstract": "Abstract: In this paper we develop a formal specification of aspects of the Forth programming language. We describe the operation of the Forth compiler as it translates Forth control words, dealing in particular with the interpretation of immediate words during compilation. Our goal here is to provide a basis for the study of safety properties of embedded systems, many of which are constructed using Forth or Forth-like languages. To this end we construct a model of the Forth compiler in the π-calculus, and have simulated its execution by animating this model using the Pict programming language.",
    "_line": "FormalReview.bib:3806"
  },
  "braibant_formal_2013": {
    "id": "braibant_formal_2013",
    "type": "article-journal",
    "author": [
      {
        "family": "Braibant",
        "given": "Thomas"
      },
      {
        "family": "Chlipala",
        "given": "Adam"
      }
    ],
    "title": "Formal Verification of Hardware Synthesis",
    "container-title": "arXiv:1301.4779 \\[cs\\]",
    "issued": {
      "date-parts": [
        [
          "2013"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "5",
          "26"
        ]
      ]
    },
    "abstract": "We report on the implementation of a certified compiler for a high-level hardware description language (HDL) called Fe-Si (FEatherweight SynthesIs). Fe-Si is a simplified version of Bluespec, an HDL based on a notion of guarded atomic actions. Fe-Si is defined as a dependently typed deep embedding in Coq. The target language of the compiler corresponds to a synthesisable subset of Verilog or VHDL. A key aspect of our approach is that input programs to the compiler can be defined and proved correct inside Coq. Then, we use extraction and a Verilog back-end (written in OCaml) to get a certified version of a hardware design.",
    "keywords": "Computer Science - Programming Languages",
    "URLtext": "1301.4779",
    "URLpretext": "[arXiv:]{.etype}",
    "eprint-type": "arxiv",
    "eprint": "1301.4779",
    "URL": "http://arxiv.org/abs/1301.4779",
    "DOI": "10.1007/978-3-642-39799-8_14",
    "page": "213-228",
    "page-first": "213",
    "volume": "8044",
    "_line": "FormalReview.bib:3813"
  },
  "bidmeshki_vericoq:_2015": {
    "id": "bidmeshki_vericoq:_2015",
    "type": "paper-conference",
    "author": [
      {
        "family": "Bidmeshki",
        "given": "Mohammad-Mahdi"
      },
      {
        "family": "Makris",
        "given": "Yiorgos"
      }
    ],
    "title": "VeriCoq: A Verilog-to-Coq converter for proof-carrying hardware automation",
    "container-title": "2015 IEEE International Symposium on Circuits and Systems (ISCAS)",
    "container-title-short": "VeriCoq",
    "title-short": "VeriCoq",
    "event-title": "2015 IEEE International Symposium on Circuits and Systems (ISCAS)",
    "issued": {
      "date-parts": [
        [
          "2015",
          "5"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "5",
          "26"
        ]
      ]
    },
    "publisher": "IEEE",
    "isbn": "978-1-4799-8391-9",
    "abstract": "Proof carrying hardware intellectual property (PCHIP) introduces a new framework in which a hardware (semiconductor) Intellectual Property (IP) is accompanied by formal proofs of certain security-related properties, ensuring that the acquired IP is trustworthy and free from hardware Trojans. In the PCHIP framework, conversion of the design from a hardware description language (HDL) to a formal representation is an essential step. Towards automating this process, herein we introduce VeriCoq, a converter of designs described in Register Transfer Level (RTL) Verilog to their corresponding representation in the Coq theorem proving language, based on the rules deﬁned in the PCHIP framework. VeriCoq supports most of the synthesizable Verilog constructs and is the ﬁrst step towards automating the entire framework, in order to simplify adoption of PCHIP by hardware IP developers and consumers and, thereby, increase IP trustworthiness.",
    "URL": "http://ieeexplore.ieee.org/document/7168562/",
    "DOI": "10.1109/ISCAS.2015.7168562",
    "publisher-place": "Lisbon, Portugal",
    "page": "29-32",
    "page-first": "29",
    "language": "en-US",
    "_line": "FormalReview.bib:3830"
  },
  "chailloux_developing_2000": {
    "id": "chailloux_developing_2000",
    "type": "book",
    "author": [
      {
        "family": "Chailloux",
        "given": "Emmanuel"
      },
      {
        "family": "Manoury",
        "given": "Pascal"
      },
      {
        "family": "Pagano",
        "given": "Bruno"
      }
    ],
    "title": "Developing Applications with Objective Caml",
    "issued": {
      "date-parts": [
        [
          "2000"
        ]
      ]
    },
    "publisher": "O'Reilly",
    "isbn": "978-2-84177-121-9",
    "publisher-place": "Paris",
    "note": "OCLC: 803160552",
    "language": "en-US",
    "_line": "FormalReview.bib:3849"
  },
  "noauthor_handbook_nodate": {
    "id": "noauthor_handbook_nodate",
    "type": "webpage",
    "title": "Handbook Of Floating Point Arithmetic Download eBook for Free",
    "accessed": {
      "date-parts": [
        [
          "2019",
          "5",
          "26"
        ]
      ]
    },
    "abstract": "Download handbook of floating point arithmetic ebook free in PDF and EPUB Format. handbook of floating point arithmetic also available in docx and mobi. Read handbook of floating point arithmetic online, read in mobile or Kindle.",
    "URL": "http://ebook4scaricare.com/gratis/handbook-of-floating-point-arithmetic/",
    "language": "en-US",
    "_line": "FormalReview.bib:3861"
  },
  "noauthor_ieee_nodate": {
    "id": "noauthor_ieee_nodate",
    "type": "article-journal",
    "title": "IEEE Std 1800™-2012 (Revision of IEEE Std 1800-2009) IEEE Standard for SystemVerilog—Unified Hardware Design, Specification, and Verification Language",
    "abstract": "Abstract: The definition of the language syntax and semantics for SystemVerilog, which is a unified hardware design, specification, and verification language, is provided. This standard includes support for modeling hardware at the behavioral, register transfer level (RTL), and gate-level abstraction levels, and for writing testbenches using coverage, assertions, object-oriented programming, and constrained random verification. The standard also provides application programming interfaces (APIs) to foreign programming languages.",
    "page": "1315",
    "page-first": "1315",
    "language": "en-US",
    "_line": "FormalReview.bib:3870"
  },
  "noauthor_ieee_nodate-1": {
    "id": "noauthor_ieee_nodate-1",
    "type": "report",
    "title": "IEEE Standard for Universal Verification Methodology Language Reference Manual",
    "accessed": {
      "date-parts": [
        [
          "2019",
          "5",
          "26"
        ]
      ]
    },
    "publisher": "IEEE",
    "abstract": "The Universal Verification Methodology (UVM) that can improve interoperability, reduce the cost of using intellectual property (IP) for new projects or electronic design automation (EDA) tools, and make it easier to reuse verification components is provided. Overall, using this standard will lower verification costs and improve design quality throughout the industry. The primary audiences for this standard are the implementors of the UVM base class library, the implementors of tools supporting the UVM base class library, and the users of the UVM base class library.",
    "URL": "http://ieeexplore.ieee.org/document/7932212/",
    "DOI": "10.1109/IEEESTD.2017.7932212",
    "language": "en-US",
    "_line": "FormalReview.bib:3878"
  },
  "noauthor_ieee_nodate-2": {
    "id": "noauthor_ieee_nodate-2",
    "type": "article-journal",
    "title": "IEEE Std 754™-2008 (Revision of IEEE Std 754-1985), IEEE Standard for Floating-Point Arithmetic",
    "abstract": "Abstract: This standard specifies interchange and arithmetic formats and methods for binary and decimal floating-point arithmetic in computer programming environments. This standard specifies exception conditions and their default handling. An implementation of a floating-point system conforming to this standard may be realized entirely in software, entirely in hardware, or in any combination of software and hardware. For operations specified in the normative part of this standard, numerical results and exceptions are uniquely determined by the values of the input data, sequence of operations, and destination formats, all under user control.",
    "page": "70",
    "page-first": "70",
    "language": "en-US",
    "_line": "FormalReview.bib:3889"
  },
  "hughes_why_1989": {
    "id": "hughes_why_1989",
    "type": "article-journal",
    "author": [
      {
        "family": "Hughes",
        "given": "J."
      }
    ],
    "title": "Why Functional Programming Matters",
    "container-title": "The Computer Journal",
    "issued": {
      "date-parts": [
        [
          "1989",
          "2",
          "1"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "5",
          "26"
        ]
      ]
    },
    "issn": "0010-4620, 1460-2067",
    "abstract": "As software becomes more and more complex, it is more and more important to structure it well. Well-structured software is easy to write and to debug, and provides a collection of modules that can be reused to reduce future programming costs. In this paper we show that two features of functional languages in particular, higher-order functions and lazy evaluation, can contribute signiﬁcantly to modularity. As examples, we manipulate lists and trees, program several numerical algorithms, and implement the alpha-beta heuristic (an algorithm from Artiﬁcial Intelligence used in game-playing programs). We conclude that since modularity is the key to successful programming, functional programming oﬀers important advantages for software development.",
    "URL": "https://academic.oup.com/comjnl/article-lookup/doi/10.1093/comjnl/32.2.98",
    "DOI": "10.1093/comjnl/32.2.98",
    "page": "98-107",
    "page-first": "98",
    "volume": "32",
    "issue": "2",
    "language": "en-US",
    "_line": "FormalReview.bib:3897"
  },
  "williams_interactive_nodate": {
    "id": "williams_interactive_nodate",
    "type": "article-journal",
    "author": [
      {
        "family": "Williams",
        "given": "Thomas"
      },
      {
        "family": "Kelley",
        "given": "Colin"
      }
    ],
    "title": "An Interactive Plotting Program",
    "page": "259",
    "page-first": "259",
    "language": "en-US",
    "_line": "FormalReview.bib:3914"
  },
  "da_rocha_pinto_tada:_2014": {
    "id": "da_rocha_pinto_tada:_2014",
    "type": "paper-conference",
    "author": [
      {
        "family": "Rocha Pinto",
        "given": "Pedro",
        "dropping-particle": "da"
      },
      {
        "family": "Dinsdale-Young",
        "given": "Thomas"
      },
      {
        "family": "Gardner",
        "given": "Philippa"
      }
    ],
    "editor": [
      {
        "family": "Jones",
        "given": "Richard"
      }
    ],
    "title": "TaDA: A Logic for Time and Data Abstraction",
    "container-title": "ECOOP 2014 – Object-Oriented Programming",
    "container-title-short": "TaDA",
    "collection-title": "Lecture Notes in Computer Science",
    "title-short": "TaDA",
    "issued": {
      "date-parts": [
        [
          "2014"
        ]
      ]
    },
    "publisher": "Springer Berlin Heidelberg",
    "isbn": "978-3-662-44202-9",
    "abstract": "To avoid data races, concurrent operations should either be at distinct times or on distinct data. Atomicity is the abstraction that an operation takes effect at a single, discrete instant in time, with linearisability being a well-known correctness condition which asserts that concurrent operations appear to behave atomically. Disjointness is the abstraction that operations act on distinct data resource, with concurrent separation logics enabling reasoning about threads that appear to operate independently on disjoint resources.We present TaDA, a program logic that combines the benefits of abstract atomicity and abstract disjointness. Our key contribution is the introduction of atomic triples, which offer an expressive approach to specifying program modules. By building up examples, we show that TaDA supports elegant modular reasoning in a way that was not previously possible.",
    "keywords": "Abstract State, Data Abstraction, Label Transition System, Proof Rule, Shared Region",
    "page": "207-231",
    "page-first": "207",
    "language": "en-US",
    "_line": "FormalReview.bib:3922"
  },
  "koh_c_2019": {
    "id": "koh_c_2019",
    "type": "paper-conference",
    "author": [
      {
        "family": "Koh",
        "given": "Nicolas"
      },
      {
        "family": "Li",
        "given": "Yao"
      },
      {
        "family": "Li",
        "given": "Yishuai"
      },
      {
        "family": "Xia",
        "given": "Li-yao"
      },
      {
        "family": "Beringer",
        "given": "Lennart"
      },
      {
        "family": "Honoré",
        "given": "Wolf"
      },
      {
        "family": "Mansky",
        "given": "William"
      },
      {
        "family": "Pierce",
        "given": "Benjamin C."
      },
      {
        "family": "Zdancewic",
        "given": "Steve"
      }
    ],
    "title": "From C to Interaction Trees: Specifying, Verifying, and Testing a Networked Server",
    "container-title": "Proceedings of the 8th ACM SIGPLAN International Conference on Certified Programs and Proofs",
    "container-title-short": "From C to Interaction Trees",
    "collection-title": "CPP 2019",
    "title-short": "From C to Interaction Trees",
    "issued": {
      "date-parts": [
        [
          "2019"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "5",
          "26"
        ]
      ]
    },
    "publisher": "ACM",
    "isbn": "978-1-4503-6222-1",
    "abstract": "We present the first formal verification of a networked server implemented in C. Interaction trees, a general structure for representing reactive computations, are used to tie together disparate verification and testing tools (Coq, VST, and QuickChick) and to axiomatize the behavior of the operating system on which the server runs (CertiKOS). The main theorem connects a specification of acceptable server behaviors, written in a straightforward “one client at a time” style, with the CompCert semantics of the C program. The variability introduced by low-level buffering of messages and interleaving of multiple TCP connections is captured using network refinement, a variant of observational refinement.",
    "keywords": "formal verification, interaction trees, network refinement, QuickChick, TCP, testing, VST",
    "URL": "http://doi.acm.org/10.1145/3293880.3294106",
    "DOI": "10.1145/3293880.3294106",
    "publisher-place": "New York, NY, USA",
    "page": "234-248",
    "page-first": "234",
    "note": "event-place: Cascais, Portugal",
    "_line": "FormalReview.bib:3939"
  },
  "mansky_verifying_nodate": {
    "id": "mansky_verifying_nodate",
    "type": "article-journal",
    "author": [
      {
        "family": "Mansky",
        "given": "William"
      }
    ],
    "title": "Verifying Concurrent Programs with VST",
    "page": "15",
    "page-first": "15",
    "language": "en-US",
    "_line": "FormalReview.bib:3959"
  },
  "rand_formally_nodate": {
    "id": "rand_formally_nodate",
    "type": "article-journal",
    "author": [
      {
        "family": "Rand",
        "given": "Robert"
      }
    ],
    "title": "Formally Verified Quantum Programming",
    "page": "222",
    "page-first": "222",
    "language": "en-US",
    "_line": "FormalReview.bib:3967"
  },
  "davenport_computer_2011": {
    "id": "davenport_computer_2011",
    "type": "chapter",
    "author": [
      {
        "family": "Krebbers",
        "given": "Robbert"
      },
      {
        "family": "Spitters",
        "given": "Bas"
      }
    ],
    "editor": [
      {
        "family": "Davenport",
        "given": "James H."
      },
      {
        "family": "Farmer",
        "given": "William M."
      },
      {
        "family": "Urban",
        "given": "Josef"
      },
      {
        "family": "Rabe",
        "given": "Florian"
      }
    ],
    "title": "Computer Certified Efficient Exact Reals in Coq",
    "container-title": "Intelligent Computer Mathematics",
    "issued": {
      "date-parts": [
        [
          "2011"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "5",
          "26"
        ]
      ]
    },
    "publisher": "Springer Berlin Heidelberg",
    "isbn": "978-3-642-22672-4 978-3-642-22673-1",
    "abstract": "Floating point operations are fast, but require continuous effort on the part of the user in order to ensure that the results are correct. This burden can be shifted away from the user by providing a library of exact analysis in which the computer handles the error estimates. We provide an implementation of the exact real numbers in the Coq proof assistant. This improves on the earlier Coq-implementation by O’Connor in two ways: we use dyadic rationals built from the machine integers and we optimize computation of power series by using approximate division. Moreover, we use type classes for clean mathematical interfaces. This appears to be the ﬁrst time that type classes are used in heavy computation. We obtain over a 100 times speed up of the basic operations and indications for improving the Coq system.",
    "URL": "http://link.springer.com/10.1007/978-3-642-22673-1_7",
    "DOI": "10.1007/978-3-642-22673-1_7",
    "publisher-place": "Berlin, Heidelberg",
    "page": "90-106",
    "page-first": "90",
    "volume": "6824",
    "language": "en-US",
    "_line": "FormalReview.bib:3975"
  },
  "hutchison_picard_2013": {
    "id": "hutchison_picard_2013",
    "type": "chapter",
    "author": [
      {
        "family": "Makarov",
        "given": "Evgeny"
      },
      {
        "family": "Spitters",
        "given": "Bas"
      }
    ],
    "editor": [
      {
        "family": "Blazy",
        "given": "Sandrine"
      },
      {
        "family": "Paulin-Mohring",
        "given": "Christine"
      },
      {
        "family": "Pichardie",
        "given": "David"
      }
    ],
    "title": "The Picard Algorithm for Ordinary Differential Equations in Coq",
    "container-title": "Interactive Theorem Proving",
    "issued": {
      "date-parts": [
        [
          "2013"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "5",
          "26"
        ]
      ]
    },
    "publisher": "Springer Berlin Heidelberg",
    "isbn": "978-3-642-39633-5 978-3-642-39634-2",
    "abstract": "Ordinary Diﬀerential Equations (ODEs) are ubiquitous in physical applications of mathematics. The Picard-Lindelo¨f theorem is the ﬁrst fundamental theorem in the theory of ODEs. It allows one to solve diﬀerential equations numerically. We provide a constructive development of the Picard-Lindelo¨f theorem which includes a program together with suﬃcient conditions for its correctness. The proof/program is written in the Coq proof assistant and uses the implementation of eﬃcient real numbers from the CoRN library and the MathClasses library. Our proof makes heavy use of operators and functionals, functions on spaces of functions. This is faithful to the usual mathematical description, but a novel level of abstraction for certiﬁed exact real computation.",
    "URL": "http://link.springer.com/10.1007/978-3-642-39634-2_34",
    "DOI": "10.1007/978-3-642-39634-2_34",
    "publisher-place": "Berlin, Heidelberg",
    "page": "463-468",
    "page-first": "463",
    "volume": "7998",
    "language": "en-US",
    "_line": "FormalReview.bib:3994"
  },
  "nelson_computer_1980": {
    "id": "nelson_computer_1980",
    "type": "book",
    "author": [
      {
        "family": "Nelson",
        "given": "Walter R"
      },
      {
        "family": "Jenkins",
        "given": "T. M"
      }
    ],
    "title": "Computer Techniques in Radiation Transport and Dosimetry",
    "issued": {
      "date-parts": [
        [
          "1980"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "5",
          "27"
        ]
      ]
    },
    "publisher": "Springer US",
    "isbn": "978-1-4684-3608-2",
    "abstract": "In October 1978, a group of 41 scientists from 14 countries met in Erice, Sicily to attend the Second Course of the Interna tional School of Radiation Damage and Protection \"Ettore Majorana\", the proceedings of which are contained in this book. The countries represented at the School were: Brazil, Canada, Federal Republic of Germany, Finland, German Democratic Republic, Hungary, India, Italy, Japan, Spain, Sweden, Switzerland, United States of America, and Yugoslavia. The School was officially sponsored by the Italian Health Physics Association, the Italian Ministry of Public Education, the Italian Ministry of Scientific and Technological Research, and the Sicilian Regional Government. In addition, administrative and tech nical support was received from the Stanford Linear Accelerator Center and from CERN. The past 15 or so years have witnessed a significant develop ment of computer methods in the science of radiation protection. The radiation transport codes associated with hadronic and electro magnetic cascades, reactor shielding, unfolding techniques, and gamma ray spectrum analysis have reached the state-of-the-art level, and the Erice Course aimed at presenting as comprehensive an over view of these programs as was possible within the allotted time span.",
    "URL": "http://public.eblib.com/choice/publicfullrecord.aspx?p=3083212",
    "publisher-place": "Boston, MA",
    "note": "OCLC: 851841483",
    "language": "en-US",
    "_line": "FormalReview.bib:4015"
  },
  "stoddart_forth_2012": {
    "id": "stoddart_forth_2012",
    "type": "paper-conference",
    "author": [
      {
        "family": "Stoddart",
        "given": "Bill"
      },
      {
        "family": "Ritchie",
        "given": "C."
      },
      {
        "family": "Dunne",
        "given": "Steve"
      }
    ],
    "title": "Forth Semantics for Compiler Verification",
    "issued": {
      "date-parts": [
        [
          "2012"
        ]
      ]
    },
    "abstract": "Here we are interested in the semantics of Forth from the point of view of using Forth as a target language for a formally verified compiler for Ruth-R, a reversible sequential programming language we are currently developing. We limit out attention to those Forth operations and constructs which will be targetted by the Ruth-R compiler. To facilitate the comparison of meanings of source and target languages, we represent the semantics of Forth code by translation into a form which can be described using the ”prospective value” semantics we use for Ruth-R.",
    "keywords": "Compiler, Concurrent computing, Formal verification, Foundations, HL7PublishingSubSection &lt;operations&gt;, Programming language, Prospective search, Verification of Theories",
    "_line": "FormalReview.bib:4030"
  },
  "knaggs_practical_1993": {
    "id": "knaggs_practical_1993",
    "type": "paper-conference",
    "author": [
      {
        "family": "Knaggs",
        "given": "Peter J."
      }
    ],
    "title": "Practical and theoretical aspects of FORTH software development",
    "issued": {
      "date-parts": [
        [
          "1993"
        ]
      ]
    },
    "abstract": "This is an investigation into the use of the Forth programming environment. The main areas of enquiry were: interfacing Forth to other languages; interfacing Forth and local area networks; and the use of RISC processors with stack based architecture such as the NC4000 and Harris RTX series. We describe how t o i n terface Forth a n d C. W e also provide a system with a multi-tasking interrupt driven interface to the Ibm NetBios networking software and a simple, generic, method of task activation through message passing. Many aspects of the investigation proved to be dependent on a more thorough theoretical underpinning for the Forth language. The use of a typeless parameter stack means that a programmer must concern himself with the intellectual burden of managing the parameter stack. The mismatching of stack elements can be the cause of subtle logic errors. We therefore investigated the possibility o f d e v eloping a type algebra\" that would allow u s t o d e v elop a typed version of Forth. This thesis includes a theory for a type signature algebra\" for the stack based argument passing method used by Forth. To support the use of multi-tasking we provide a simple, but formal, theory of concurrent tasks based on state machines that synchronise on events. This has a graphical notation for people who are not familiar with formal notations. We also looked at how formalisms might be used to deene a semantic model for the Forth language and how formalisms can help to deene the relationship between Forth's stack based virtual machine and register based target processors.",
    "keywords": "Central processing unit, Computer multitasking, Forth, Graphical user interface, Harris affine region detector, Integrated development environment, Message passing, NetBIOS, Programmer, Software development, Type signature, Virtual machine",
    "_line": "FormalReview.bib:4039"
  },
  "badger_towards_2019": {
    "id": "badger_towards_2019",
    "type": "chapter",
    "author": [
      {
        "family": "Blanchard",
        "given": "Allan"
      },
      {
        "family": "Loulergue",
        "given": "Frédéric"
      },
      {
        "family": "Kosmatov",
        "given": "Nikolai"
      }
    ],
    "editor": [
      {
        "family": "Badger",
        "given": "Julia M."
      },
      {
        "family": "Rozier",
        "given": "Kristin Yvonne"
      }
    ],
    "title": "Towards Full Proof Automation in Frama-C Using Auto-active Verification",
    "container-title": "NASA Formal Methods",
    "issued": {
      "date-parts": [
        [
          "2019"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "6",
          "7"
        ]
      ]
    },
    "publisher": "Springer International Publishing",
    "isbn": "978-3-030-20651-2 978-3-030-20652-9",
    "abstract": "While deductive veriﬁcation is increasingly used on real-life code, making it fully automatic remains difﬁcult. The development of powerful SMT solvers has improved the situation, but some proofs still require interactive theorem provers in order to achieve full formal veriﬁcation. Auto-active veriﬁcation relies on additional guiding annotations (assertions, ghost code, lemma functions, etc.) and provides an important step towards a greater automation of the proof. However, the support of this methodology often remains partial and depends on the veriﬁcation tool. This paper presents an experience report on a complete functional veriﬁcation of several C programs from the literature and real-life code using auto-active veriﬁcation with the C software analysis platform FRAMA-C and its deductive veriﬁcation plugin WP. The goal is to use automatic solvers to verify properties that are classically veriﬁed with interactive provers. Based on our experience, we discuss the beneﬁts of this methodology and the current limitations of the tool, as well as proposals of new features to overcome them.",
    "URL": "http://link.springer.com/10.1007/978-3-030-20652-9_6",
    "DOI": "10.1007/978-3-030-20652-9_6",
    "publisher-place": "Cham",
    "page": "88-105",
    "page-first": "88",
    "volume": "11460",
    "language": "en-US",
    "_line": "FormalReview.bib:4048"
  },
  "badger_extracting_2019": {
    "id": "badger_extracting_2019",
    "type": "chapter",
    "author": [
      {
        "family": "Ioannidis",
        "given": "Eleftherios"
      },
      {
        "family": "Kaashoek",
        "given": "Frans"
      },
      {
        "family": "Zeldovich",
        "given": "Nickolai"
      }
    ],
    "editor": [
      {
        "family": "Badger",
        "given": "Julia M."
      },
      {
        "family": "Rozier",
        "given": "Kristin Yvonne"
      }
    ],
    "title": "Extracting and Optimizing Formally Verified Code for Systems Programming",
    "container-title": "NASA Formal Methods",
    "issued": {
      "date-parts": [
        [
          "2019"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "6",
          "7"
        ]
      ]
    },
    "publisher": "Springer International Publishing",
    "isbn": "978-3-030-20651-2 978-3-030-20652-9",
    "abstract": "MCQC is a compiler for extracting veriﬁed systems programs to low-level assembly, with no runtime or garbage collection requirements and an emphasis on performance. MCQC targets the Gallina functional language used in the Coq proof assistant. MCQC translates pure and recursive functions into C++17, while compiling monadic eﬀectful functions to imperative C++ system calls. With a few memory and performance optimizations, MCQC combines veriﬁability with memory and runtime performance. By handling eﬀectful and pure functions separately MCQC can generate executable veriﬁed code directly from Gallina, reducing the eﬀort of implementing and executing veriﬁed systems.",
    "URL": "http://link.springer.com/10.1007/978-3-030-20652-9_15",
    "DOI": "10.1007/978-3-030-20652-9_15",
    "publisher-place": "Cham",
    "page": "228-236",
    "page-first": "228",
    "volume": "11460",
    "language": "en-US",
    "_line": "FormalReview.bib:4067"
  },
  "fleury_optimizing_2019": {
    "id": "fleury_optimizing_2019",
    "type": "paper-conference",
    "author": [
      {
        "family": "Fleury",
        "given": "Mathias"
      }
    ],
    "editor": [
      {
        "family": "Badger",
        "given": "Julia M."
      },
      {
        "family": "Rozier",
        "given": "Kristin Yvonne"
      }
    ],
    "title": "Optimizing a Verified SAT Solver",
    "container-title": "NASA Formal Methods",
    "collection-title": "Lecture Notes in Computer Science",
    "issued": {
      "date-parts": [
        [
          "2019"
        ]
      ]
    },
    "publisher": "Springer International Publishing",
    "isbn": "978-3-030-20652-9",
    "abstract": "In previous work, I verified a SAT solver with dedicated imperative data structures, including the two-watched-literal scheme. In this paper, I extend this formalization with four additional optimizations. The approach is still based on refining an abstract calculus to a deterministic program. In turn, an imperative version is synthesized from the latter, which is then exported to Standard ML. The first optimization is the extension with blocking literals. Then, the memory management is improved in order to implement the heuristics necessary to implement search restart and forget, which were subsequently implemented. This required changes to the abstract calculus. Finally, the solver uses machine words until they overflow before switching to unbounded integers. Performance has improved and is now closer to MiniSAT without preprocessing.",
    "page": "148-165",
    "page-first": "148",
    "language": "en-US",
    "_line": "FormalReview.bib:4086"
  },
  "salvia_mixed_2019": {
    "id": "salvia_mixed_2019",
    "type": "paper-conference",
    "author": [
      {
        "family": "Salvia",
        "given": "Rocco"
      },
      {
        "family": "Titolo",
        "given": "Laura"
      },
      {
        "family": "Feliú",
        "given": "Marco A."
      },
      {
        "family": "Moscato",
        "given": "Mariano M."
      },
      {
        "family": "Muñoz",
        "given": "César A."
      },
      {
        "family": "Rakamarić",
        "given": "Zvonimir"
      }
    ],
    "editor": [
      {
        "family": "Badger",
        "given": "Julia M."
      },
      {
        "family": "Rozier",
        "given": "Kristin Yvonne"
      }
    ],
    "title": "A Mixed Real and Floating-Point Solver",
    "container-title": "NASA Formal Methods",
    "collection-title": "Lecture Notes in Computer Science",
    "issued": {
      "date-parts": [
        [
          "2019"
        ]
      ]
    },
    "publisher": "Springer International Publishing",
    "isbn": "978-3-030-20652-9",
    "abstract": "Reasoning about mixed real and floating-point constraints is essential for developing accurate analysis tools for floating-point programs. This paper presents FPRoCK, a prototype tool for solving mixed real and floating-point formulas. FPRoCK transforms a mixed formula into an equisatisfiable one over the reals. This formula is then solved using an off-the-shelf SMT solver. FPRoCK is also integrated with the PRECiSA static analyzer, which computes a sound estimation of the round-off error of a floating-point program. It is used to detect infeasible computational paths, thereby improving the accuracy of PRECiSA.",
    "page": "363-370",
    "page-first": "363",
    "language": "en-US",
    "_line": "FormalReview.bib:4115"
  },
  "hoang_spark_2015": {
    "id": "hoang_spark_2015",
    "type": "article-journal",
    "author": [
      {
        "family": "Hoang",
        "given": "Duc"
      },
      {
        "family": "Moy",
        "given": "Yannick"
      },
      {
        "family": "Wallenburg",
        "given": "Angela"
      },
      {
        "family": "Chapman",
        "given": "Roderick"
      }
    ],
    "title": "SPARK 2014 and GNATprove",
    "container-title": "Int J Softw Tools Technol Transfer",
    "issued": {
      "date-parts": [
        [
          "2015",
          "11",
          "1"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "6",
          "11"
        ]
      ]
    },
    "issn": "1433-2787",
    "abstract": "Extensive and expensive testing is the method most widely used for gaining confidence in safety-critical software. With a few exceptions, such as SPARK, formal verification is rarely used in industry due to its high cost and level of skill required. The grand challenge of building a verifying compiler for static formal verification of programs aims at bringing formal verification to non-expert users of powerful programming languages. This challenge has nurtured competition and collaboration among verification tool builders; an example is the VerifyThis competition Huisman et al. (http://digbib.ubka.uni-karlsruhe.de/volltexte/1000034373, 2013). In this paper, we describe our approach to popularising formal verification in the design of the SPARK 2014 language and the associated formal verification tool GNATprove. In particular, we present our solution to combining tests and proofs, which provides a cost-competitive way to develop software to standards such as do-178. At the heart of our technique are executable contracts, and the ability to both test and prove those. We use running examples from the VerifyThis 2012 competition and discuss the results of using our tools on those problems.",
    "keywords": "Program verification, SPARK, Deductive verification, Ada, Static analysis, Verifying compiler",
    "URL": "https://doi.org/10.1007/s10009-014-0322-5",
    "DOI": "10.1007/s10009-014-0322-5",
    "page": "695-707",
    "page-first": "695",
    "volume": "17",
    "issue": "6",
    "language": "en-US",
    "_line": "FormalReview.bib:4129"
  },
  "chapman_fumble_nodate": {
    "id": "chapman_fumble_nodate",
    "type": "webpage",
    "author": [
      {
        "family": "Chapman",
        "given": "Roderick"
      }
    ],
    "title": "The Fumble Programmer",
    "abstract": "This paper reflects on the need for formality, discipline and humility in\nprogramming. Starting with the work of Turing, Dijkstra and Humphrey, this paper\ngoes on to cover our experience with the Personal Software Process, formal pro-\ngramming with SPARK, and the impact of putting the two together.",
    "URL": "https://proteancode.com/wp-content/uploads/2018/02/the_fumble_programmer.pdf",
    "_line": "FormalReview.bib:4147"
  },
  "salvia_mixed_2019-1": {
    "id": "salvia_mixed_2019-1",
    "type": "paper-conference",
    "author": [
      {
        "family": "Salvia",
        "given": "Rocco"
      },
      {
        "family": "Titolo",
        "given": "Laura"
      },
      {
        "family": "Feliú",
        "given": "Marco A."
      },
      {
        "family": "Moscato",
        "given": "Mariano M."
      },
      {
        "family": "Muñoz",
        "given": "César A."
      },
      {
        "family": "Rakamarić",
        "given": "Zvonimir"
      }
    ],
    "editor": [
      {
        "family": "Badger",
        "given": "Julia M."
      },
      {
        "family": "Rozier",
        "given": "Kristin Yvonne"
      }
    ],
    "title": "A Mixed Real and Floating-Point Solver",
    "container-title": "NASA Formal Methods",
    "collection-title": "Lecture Notes in Computer Science",
    "issued": {
      "date-parts": [
        [
          "2019"
        ]
      ]
    },
    "publisher": "Springer International Publishing",
    "isbn": "978-3-030-20652-9",
    "abstract": "Reasoning about mixed real and floating-point constraints is essential for developing accurate analysis tools for floating-point programs. This paper presents FPRoCK, a prototype tool for solving mixed real and floating-point formulas. FPRoCK transforms a mixed formula into an equisatisfiable one over the reals. This formula is then solved using an off-the-shelf SMT solver. FPRoCK is also integrated with the PRECiSA static analyzer, which computes a sound estimation of the round-off error of a floating-point program. It is used to detect infeasible computational paths, thereby improving the accuracy of PRECiSA.",
    "page": "363-370",
    "page-first": "363",
    "language": "en-US",
    "_line": "FormalReview.bib:4157"
  },
  "erosa_taming_1994": {
    "id": "erosa_taming_1994",
    "type": "paper-conference",
    "author": [
      {
        "family": "Erosa",
        "given": "A. M."
      },
      {
        "family": "Hendren",
        "given": "L. J."
      }
    ],
    "title": "Taming control flow: a structured approach to eliminating goto statements",
    "container-title": "Proceedings of 1994 IEEE International Conference on Computer Languages (ICCL'94)",
    "container-title-short": "Taming control flow",
    "title-short": "Taming control flow",
    "event-title": "Proceedings of 1994 IEEE International Conference on Computer Languages (ICCL'94)",
    "issued": {
      "date-parts": [
        [
          "1994",
          "5"
        ]
      ]
    },
    "abstract": "In designing optimizing and parallelizing compilers, it is often simpler and more efficient to deal with programs that have structured control flow. Although most programmers naturally program in a structured fashion, there remain many important programs and benchmarks that include some number of goto statements, thus rendering the entire program unstructured. Such unstructured programs cannot be handled with compilers built with analyses and transformations for structured programs. In this paper we present a straight-forward algorithm to structure C programs by eliminating all goto statements. The method works directly on a high-level abstract syntax tree (AST) representation of the program and could easily be integrated into any compiler that uses an AST-based intermediate representation. The actual algorithm proceeds by eliminating each goto by first applying a sequence of goto-movement transformations followed by the appropriate goto-elimination transformation. We have implemented the method in the McCAT (McGill Compiler Architecture Testbed) optimizing/parallelizing C compiler and we present experimental results that demonstrate that the method is both efficient and effective.&lt;&gt;",
    "keywords": "AST representation, C language, C programs, Computer science, control flow, Design optimization, Flow graphs, goto statements, goto-elimination, goto-movement transformations, high-level abstract syntax tree, Information analysis, intermediate representation, McCAT, McGill Compiler Architecture Testbed, optimizing compilers, Optimizing compilers, parallel programming, parallelizing compilers, program compilers, Program processors, Programming profession, Software engineering, Software testing, Switches",
    "DOI": "10.1109/ICCL.1994.288377",
    "page": "229-240",
    "page-first": "229",
    "_line": "FormalReview.bib:4172"
  },
  "ammarguellat_control-flow_1992": {
    "id": "ammarguellat_control-flow_1992",
    "type": "article-journal",
    "author": [
      {
        "family": "Ammarguellat",
        "given": "Z."
      }
    ],
    "title": "A control-flow normalization algorithm and its complexity",
    "container-title": "IEEE Transactions on Software Engineering",
    "issued": {
      "date-parts": [
        [
          "1992",
          "3"
        ]
      ]
    },
    "issn": "0098-5589",
    "abstract": "A single method for normalizing the control-flow of programs to facilitate program transformations, program analysis, and automatic parallelization is presented. While previous methods result in programs whose control flowgraphs are reducible, programs normalized by this technique satisfy a stronger condition than reducibility and are therefore simpler in their syntax and structure than with previous methods. In particular, all control-flow cycles are normalized into single-entry, single-exit while loops and all GOTOs are eliminated. Furthermore, the method avoids problems of code replication that are characteristic of node-splitting techniques. This restructuring obviates the control dependence graph, since afterwards control dependence relations are manifest in the syntax tree of the program. Transformations that effect this normalization are presented, and the complexity of the method is studied.&lt;&gt;",
    "keywords": "graph theory, Program processors, Algorithm design and analysis, Automatic control, automatic parallelization, complexity, computational complexity, control dependence relations, control flowgraphs, control-flow cycles, control-flow normalization algorithm, Data analysis, GOTOs, node-splitting techniques, parallel algorithms, Pathology, Performance analysis, structured programming, syntax tree, Tree graphs",
    "DOI": "10.1109/32.126773",
    "page": "237-251",
    "page-first": "237",
    "volume": "18",
    "issue": "3",
    "_line": "FormalReview.bib:4186"
  },
  "harrison_can_1997": {
    "id": "harrison_can_1997",
    "type": "paper-conference",
    "author": [
      {
        "family": "Harrison",
        "given": "Luddy"
      }
    ],
    "editor": [
      {
        "family": "Van Hentenryck",
        "given": "Pascal"
      }
    ],
    "title": "Can abstract interpretation become a mainstream compiler technology?",
    "container-title": "Static Analysis",
    "collection-title": "Lecture Notes in Computer Science",
    "issued": {
      "date-parts": [
        [
          "1997"
        ]
      ]
    },
    "publisher": "Springer Berlin Heidelberg",
    "isbn": "978-3-540-69576-9",
    "abstract": "Abstract interpretation has enormous promise and yet remains at the margins of compiler practice. In this talk I will argue that abstract interpretation cannot become a mainstream compiler technlogy until its computational, algorithmic aspects are as well-developed as its mathematical, foundational aspects have been to date. I will put the problem into perspective by comparing abstract interpretation to dataflow analysis, for which a well-developed body of compuational methods exists. This comparison reveals that abstract interpretation is most appropriately seen as a method for specifying problems (that is, equations to be solved), and not as a method for specifying solutions (that is, algorithms for solving equations). In particular, efficient solution methods for the equations that arise from abstract interpretations are seldom obvious from the surface of the equations themselves. In other words, the “algorithms” that are strongly suggested by an abstract interpretation, in which the semantic domains are viewed as “data structures, the semantic functions as procedures”, and a simple fixed point engine used to integrate these parts into a workable whole, is naive and is at best suitable for use in prototyping program analyzers. This point of view calls into question the casual dismissal of abstract interpretation as inefficient, by questioning what can be inferred about the complexity of an abstract interpretation problem by superficial examination of the domains and semantic functions involved.",
    "page": "395-395",
    "page-first": "395",
    "language": "en-US",
    "_line": "FormalReview.bib:4201"
  },
  "brady_idris_2013": {
    "id": "brady_idris_2013",
    "type": "article-journal",
    "author": [
      {
        "family": "Brady",
        "given": "Edwin"
      }
    ],
    "title": "Idris, a general-purpose dependently typed programming language: Design and implementation",
    "container-title": "Journal of Functional Programming",
    "container-title-short": "Idris, a general-purpose dependently typed programming language",
    "title-short": "Idris, a general-purpose dependently typed programming language",
    "issued": {
      "date-parts": [
        [
          "2013",
          "9"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "6",
          "30"
        ]
      ]
    },
    "issn": "0956-7968, 1469-7653",
    "abstract": "Many components of a dependently-typed programming language are by now well understood, for example the underlying type theory, type checking, uniﬁcation and evaluation. How to combine these components into a realistic and usable high-level language is, however, folklore, discovered anew by successive language implementators. In this paper, I describe the implementation of IDRIS, a new dependently-typed functional programming language. IDRIS is intended to be a general purpose programming language and as such provides high-level concepts such as implicit syntax, type classes and do notation. I describe the high-level language and the underlying type theory, and present a tactic-based method for elaborating concrete high-level syntax with implicit arguments and type classes into a fully explicit type theory. Furthermore, I show how this method facilitates the implementation of new high-level language constructs.",
    "URL": "https://www.cambridge.org/core/product/identifier/S095679681300018X/type/journal_article",
    "DOI": "10.1017/S095679681300018X",
    "page": "552-593",
    "page-first": "552",
    "volume": "23",
    "issue": "5",
    "language": "en-US",
    "_line": "FormalReview.bib:4215"
  },
  "fogarty_concoqtion:_2007": {
    "id": "fogarty_concoqtion:_2007",
    "type": "paper-conference",
    "author": [
      {
        "family": "Fogarty",
        "given": "Seth"
      },
      {
        "family": "Pasalic",
        "given": "Emir"
      },
      {
        "family": "Siek",
        "given": "Jeremy"
      },
      {
        "family": "Taha",
        "given": "Walid"
      }
    ],
    "title": "Concoqtion: Indexed Types Now!",
    "container-title": "Proceedings of the 2007 ACM SIGPLAN Symposium on Partial Evaluation and Semantics-based Program Manipulation",
    "container-title-short": "Concoqtion",
    "collection-title": "PEPM '07",
    "title-short": "Concoqtion",
    "issued": {
      "date-parts": [
        [
          "2007"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "7",
          "7"
        ]
      ]
    },
    "publisher": "ACM",
    "isbn": "978-1-59593-620-2",
    "abstract": "Almost twenty years after the pioneering efforts of Cardelli, the programming languages community is vigorously pursuing ways to incorporate Fω-style indexed types into programming languages. This paper advocates Concoqtion, a practical approach to adding such highly expressive types to full-fledged programming languages. The approach is applied to MetaOCaml using the Coq proof checker to conservatively extend Hindley-Milner type inference. The implementation of MetaOCaml Concoqtion requires minimal modifications to the syntax, the type checker, and the compiler; and yields a language comparable in notation to the leading proposals. The resulting language provides unlimited expressiveness in the type system while maintaining decidability. Furthermore, programmers can take advantage of a wide range of libraries not only for the programming language but also for the indexed types. Programming in MetaOCaml Concoqtion is illustrated with small examples and a case study implementing a statically-typed domain-specific language.",
    "URL": "http://doi.acm.org/10.1145/1244381.1244400",
    "DOI": "10.1145/1244381.1244400",
    "publisher-place": "New York, NY, USA",
    "page": "112-121",
    "page-first": "112",
    "note": "event-place: Nice, France",
    "_line": "FormalReview.bib:4233"
  },
  "barras_semantical_nodate": {
    "id": "barras_semantical_nodate",
    "type": "article-journal",
    "author": [
      {
        "family": "Barras",
        "given": "Bruno"
      }
    ],
    "title": "Semantical Investigations in Intuitionistic Set Theory and Type Theories with Inductive Families",
    "page": "170",
    "page-first": "170",
    "language": "en-US",
    "_line": "FormalReview.bib:4252"
  },
  "timany_consistency_2017": {
    "id": "timany_consistency_2017",
    "type": "article-journal",
    "author": [
      {
        "family": "Timany",
        "given": "Amin"
      },
      {
        "family": "Sozeau",
        "given": "Matthieu"
      }
    ],
    "title": "Consistency of the Predicative Calculus of Cumulative Inductive Constructions (pCuIC)",
    "container-title": "arXiv:1710.03912 \\[cs\\]",
    "issued": {
      "date-parts": [
        [
          "2017",
          "10",
          "11"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "7",
          "21"
        ]
      ]
    },
    "abstract": "In order to avoid well-know paradoxes associated with self-referential definitions, higher-order dependent type theories stratify the theory using a countably infinite hierarchy of universes (also known as sorts), Type&dollar;&underscore;0&dollar; : Type&dollar;&underscore;1&dollar; : &dollar;&bslash;cdots&dollar; . Such type systems are called cumulative if for any type &dollar;A&dollar; we have that &dollar;A&dollar; : Type&dollar;&underscore;&lcurly;i&rcurly;&dollar; implies &dollar;A&dollar; : Type&dollar;&underscore;&lcurly;i+1&rcurly;&dollar;. The predicative calculus of inductive constructions (pCIC) which forms the basis of the Coq proof assistant, is one such system. In this paper we present and establish the soundness of the predicative calculus of cumulative inductive constructions (pCuIC) which extends the cumulativity relation to inductive types.",
    "keywords": "Computer Science - Programming Languages",
    "URLtext": "1710.03912",
    "URLpretext": "[arXiv:]{.etype}",
    "eprint-type": "arxiv",
    "eprint": "1710.03912",
    "URL": "http://arxiv.org/abs/1710.03912",
    "_line": "FormalReview.bib:4260"
  },
  "gueneau_procrastination_nodate": {
    "id": "gueneau_procrastination_nodate",
    "type": "article-journal",
    "author": [
      {
        "family": "Guéneau",
        "given": "Armaël"
      }
    ],
    "title": "Procrastination",
    "abstract": "We present a small Coq library for collecting side conditions and deferring their proof.",
    "page": "7",
    "page-first": "7",
    "language": "en-US",
    "_line": "FormalReview.bib:4274"
  },
  "noauthor_mezzo_nodate": {
    "id": "noauthor_mezzo_nodate",
    "type": "webpage",
    "title": "The Mezzo programming language",
    "accessed": {
      "date-parts": [
        [
          "2019",
          "8",
          "5"
        ]
      ]
    },
    "URL": "http://protz.github.io/mezzo/",
    "_line": "FormalReview.bib:4283"
  },
  "hoder_z_2011": {
    "id": "hoder_z_2011",
    "type": "paper-conference",
    "author": [
      {
        "family": "Hoder",
        "given": "Kryštof"
      },
      {
        "family": "Bjørner",
        "given": "Nikolaj"
      },
      {
        "family": "Moura",
        "given": "Leonardo",
        "dropping-particle": "de"
      }
    ],
    "editor": [
      {
        "family": "Gopalakrishnan",
        "given": "Ganesh"
      },
      {
        "family": "Qadeer",
        "given": "Shaz"
      }
    ],
    "title": "μZ– An Efficient Engine for Fixed Points with Constraints",
    "container-title": "Computer Aided Verification",
    "collection-title": "Lecture Notes in Computer Science",
    "issued": {
      "date-parts": [
        [
          "2011"
        ]
      ]
    },
    "publisher": "Springer Berlin Heidelberg",
    "isbn": "978-3-642-22110-1",
    "abstract": "The μZ tool is a scalable, efficient engine for fixed points with constraints. It supports high-level declarative fixed point constraints over a combination of built-in and plugin domains. The built-in domains include formulas presented to the SMT solver Z3 and domains known from abstract interpretation. We present the interface to μZ, a number of the domains, and a set of examples illustrating the use of μZ.",
    "keywords": "Abstract Interpretation, Abstract Machine, Default Representation, Hash Table, Relational Algebra",
    "page": "457-462",
    "page-first": "457",
    "language": "en-US",
    "_line": "FormalReview.bib:4290"
  },
  "selsam_guiding_2019": {
    "id": "selsam_guiding_2019",
    "type": "paper-conference",
    "author": [
      {
        "family": "Selsam",
        "given": "Daniel"
      },
      {
        "family": "Bjørner",
        "given": "Nikolaj"
      }
    ],
    "editor": [
      {
        "family": "Janota",
        "given": "Mikoláš"
      },
      {
        "family": "Lynce",
        "given": "Inês"
      }
    ],
    "title": "Guiding High-Performance SAT Solvers with Unsat-Core Predictions",
    "container-title": "Theory and Applications of Satisfiability Testing – SAT 2019",
    "collection-title": "Lecture Notes in Computer Science",
    "issued": {
      "date-parts": [
        [
          "2019"
        ]
      ]
    },
    "publisher": "Springer International Publishing",
    "isbn": "978-3-030-24258-9",
    "abstract": "The NeuroSAT neural network architecture was introduced in \\[37\\] for predicting properties of propositional formulae. When trained to predict the satisfiability of toy problems, it was shown to find solutions and unsatisfiable cores on its own. However, the authors saw “no obvious path” to using the architecture to improve the state-of-the-art. In this work, we train a simplified NeuroSAT architecture to directly predict the unsatisfiable cores of real problems. We modify several state-of-the-art SAT solvers to periodically replace their variable activity scores with NeuroSAT’s prediction of how likely the variables are to appear in an unsatisfiable core. The modified MiniSat solves 10&perc; more problems on SATCOMP-2018 within the standard 5,000 second timeout than the original does. The modified Glucose solves 11&perc; more problems than the original, while the modified Z3 solves 6&perc; more. The gains are even greater when the training is specialized for a specific distribution of problems; on a benchmark of hard problems from a scheduling domain, the modified Glucose solves 20&perc; more problems than the original does within a one-hour timeout. Our results demonstrate that NeuroSAT can provide effective guidance to high-performance SAT solvers on real problems.",
    "page": "336-353",
    "page-first": "336",
    "language": "en-US",
    "_line": "FormalReview.bib:4306"
  },
  "bardin_bringing_2019": {
    "id": "bardin_bringing_2019",
    "type": "article-journal",
    "author": [
      {
        "family": "Bardin",
        "given": "Sébastien"
      },
      {
        "family": "Bjørner",
        "given": "Nikolaj"
      },
      {
        "family": "Cadar",
        "given": "Cristian"
      }
    ],
    "editor": [
      {
        "family": "Bardin",
        "given": "Sébastien"
      },
      {
        "family": "Bjørner",
        "given": "Nikolaj S."
      },
      {
        "family": "Cadar",
        "given": "Cristian"
      }
    ],
    "title": "Bringing CP, SAT and SMT together: Next Challenges in Constraint Solving (Dagstuhl Seminar 19062)",
    "container-title": "Dagstuhl Reports",
    "container-title-short": "Bringing CP, SAT and SMT together",
    "title-short": "Bringing CP, SAT and SMT together",
    "issued": {
      "date-parts": [
        [
          "2019"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "8",
          "23"
        ]
      ]
    },
    "issn": "2192-5283",
    "keywords": "Automated Decision Procedures, Constraint Programming, SAT, SMT",
    "URL": "http://drops.dagstuhl.de/opus/volltexte/2019/10857",
    "DOI": "10.4230/DagRep.9.2.27",
    "page": "27-47",
    "page-first": "27",
    "volume": "9",
    "issue": "2",
    "_line": "FormalReview.bib:4320"
  },
  "yurichev_sat/smt_nodate": {
    "id": "yurichev_sat/smt_nodate",
    "type": "article-journal",
    "author": [
      {
        "family": "Yurichev",
        "given": "Dennis"
      }
    ],
    "title": "SAT/SMT by Example",
    "page": "555",
    "page-first": "555",
    "language": "en-US",
    "_line": "FormalReview.bib:4338"
  },
  "bjorner_programming_nodate": {
    "id": "bjorner_programming_nodate",
    "type": "no-type",
    "author": [
      {
        "family": "Bjørner",
        "given": "Nikolaj"
      },
      {
        "family": "Moura",
        "given": "Leonardo",
        "dropping-particle": "de"
      },
      {
        "family": "Nachmanson",
        "given": "lev"
      },
      {
        "family": "Wintersteiger",
        "given": "Christoph"
      }
    ],
    "title": "Programming Z3",
    "abstract": "This tutorial provides a programmer's introduction to the Satisfiability Modulo Theories Solver Z3. It describes how to use Z3 through scripts, provided in the Python scripting language, and it describes several of the algorithms underlying the decision procedures within Z3. It aims to broadly cover almost all available features of Z3 and the essence of the underlying algorithms.",
    "URL": "http://theory.stanford.edu/~nikolaj/programmingz3.html",
    "_line": "FormalReview.bib:4346"
  },
  "feldman_inferring_2019": {
    "id": "feldman_inferring_2019",
    "type": "article-journal",
    "author": [
      {
        "family": "Feldman",
        "given": "Yotam M. Y."
      },
      {
        "family": "Wilcox",
        "given": "James R."
      },
      {
        "family": "Shoham",
        "given": "Sharon"
      },
      {
        "family": "Sagiv",
        "given": "Mooly"
      }
    ],
    "title": "Inferring Inductive Invariants from Phase Structures",
    "container-title": "arXiv:1905.07739 \\[cs\\]",
    "issued": {
      "date-parts": [
        [
          "2019",
          "5",
          "19"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "8",
          "26"
        ]
      ]
    },
    "abstract": "Infinite-state systems such as distributed protocols are challenging to verify using interactive theorem provers or automatic verification tools. Of these techniques, deductive verification is highly expressive but requires the user to annotate the system with inductive invariants. To relieve the user from this labor-intensive and challenging task, invariant inference aims to find inductive invariants automatically. Unfortunately, when applied to infinite-state systems such as distributed protocols, existing inference techniques often diverge, which limits their applicability. This paper proposes user-guided invariant inference based on phase invariants, which capture the different logical phases of the protocol. Users conveys their intuition by specifying a phase structure, an automaton with edges labeled by program transitions; the tool automatically infers assertions that hold in the automaton's states, resulting in a full safety proof.The additional structure from phases guides the inference procedure towards finding an invariant. Our results show that user guidance by phase structures facilitates successful inference beyond the state of the art. We find that phase structures are pleasantly well matched to the intuitive reasoning routinely used by domain experts to understand why distributed protocols are correct, so that providing a phase structure reuses this existing intuition.",
    "keywords": "Computer Science - Programming Languages",
    "URLtext": "1905.07739",
    "URLpretext": "[arXiv:]{.etype}",
    "eprint-type": "arxiv",
    "eprint": "1905.07739",
    "URL": "http://arxiv.org/abs/1905.07739",
    "_line": "FormalReview.bib:4353"
  },
  "manna_temporal_1995": {
    "id": "manna_temporal_1995",
    "type": "book",
    "author": [
      {
        "family": "Manna",
        "given": "Zohar"
      },
      {
        "family": "Pnueli",
        "given": "Amir"
      }
    ],
    "title": "Temporal Verification of Reactive Systems: Safety",
    "container-title-short": "Temporal Verification of Reactive Systems",
    "collection-title": "Manna,Z.;Pnueli,A.:Temporal Logic of Reactive Systems",
    "title-short": "Temporal Verification of Reactive Systems",
    "issued": {
      "date-parts": [
        [
          "1995"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "8",
          "29"
        ]
      ]
    },
    "publisher": "Springer-Verlag",
    "isbn": "978-0-387-94459-3",
    "abstract": "This book is about the verification of reactive systems. A reactive system is a system that maintains an ongoing interaction with its environment, as opposed to computing some final value on termination. The family of reactive systems includes many classes of programs whose correct and reliable construction is con­ sidered to be particularly challenging, including concurrent programs, embedded and process control programs, and operating systems. Typical examples of such systems are an air traffic control system, programs controlling mechanical devices such as a train, or perpetually ongoing processes such as a nuclear reactor. With the expanding use of computers in safety-critical areas, where failure is potentially disastrous, correctness is crucial. This has led to the introduction of formal verification techniques, which give both users and designers of software and hardware systems greater confidence that the systems they build meet the desired specifications. Framework The approach promoted in this book is based on the use of temporal logic for specifying properties of reactive systems, and develops an extensive verification methodology for proving that a system meets its temporal specification. Reactive programs must be specified in terms of their ongoing behavior, and temporal logic provides an expressive and natural language for specifying this behavior. Our framework for specifying and verifying temporal properties of reactive systems is based on the following four components: 1. A computational model to describe the behavior of reactive systems. The model adopted in this book is that of a Fair Transition System (FTS).",
    "URL": "https://www.springer.com/gp/book/9780387944593",
    "publisher-place": "New York",
    "language": "en-US",
    "_line": "FormalReview.bib:4367"
  },
  "mullen_oeuf:_2018": {
    "id": "mullen_oeuf:_2018",
    "type": "paper-conference",
    "author": [
      {
        "family": "Mullen",
        "given": "Eric"
      },
      {
        "family": "Pernsteiner",
        "given": "Stuart"
      },
      {
        "family": "Wilcox",
        "given": "James R."
      },
      {
        "family": "Tatlock",
        "given": "Zachary"
      },
      {
        "family": "Grossman",
        "given": "Dan"
      }
    ],
    "title": "ŒUf: Minimizing the Coq Extraction TCB",
    "container-title": "Proceedings of the 7th ACM SIGPLAN International Conference on Certified Programs and Proofs",
    "container-title-short": "ŒUf",
    "collection-title": "CPP 2018",
    "title-short": "ŒUf",
    "issued": {
      "date-parts": [
        [
          "2018"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "8",
          "30"
        ]
      ]
    },
    "publisher": "ACM",
    "isbn": "978-1-4503-5586-5",
    "abstract": "Verifying systems by implementing them in the programming language of a proof assistant (e.g., Gallina for Coq) lets us directly leverage the full power of the proof assistant for verifying the system. But, to execute such an implementation requires extraction, a large complicated process that is in the trusted computing base (TCB).  This paper presents Œuf, a verified compiler from a subset of Gallina to assembly. Œuf’s correctness theorem ensures that compilation preserves the semantics of the source Gallina program. We describe how Œuf’s specification can be used as a foreign function interface to reason about the interaction between compiled Gallina programs and surrounding shim code. Additionally, Œufmaintains a small TCB for its front-end by reflecting Gallina programs to Œufsource and automatically ensuring equivalence using computational denotation. This design enabled us to implement some early compiler passes (e.g., lambda lifting) in the untrusted reflection and ensure their correctness via translation validation. To evaluate Œuf, we compile Appel’s SHA256 specification from Gallina to x86 and write a shim for the generated code, yielding a verified sha256sum implementation with a small TCB.",
    "keywords": "Coq, Compilers, Formal Verification, Verified Systems",
    "URL": "http://doi.acm.org/10.1145/3167089",
    "DOI": "10.1145/3167089",
    "publisher-place": "New York, NY, USA",
    "page": "172-185",
    "page-first": "172",
    "note": "event-place: Los Angeles, CA, USA",
    "_line": "FormalReview.bib:4383"
  },
  "padon_ivy:_2016": {
    "id": "padon_ivy:_2016",
    "type": "paper-conference",
    "author": [
      {
        "family": "Padon",
        "given": "Oded"
      },
      {
        "family": "McMillan",
        "given": "Kenneth L."
      },
      {
        "family": "Panda",
        "given": "Aurojit"
      },
      {
        "family": "Sagiv",
        "given": "Mooly"
      },
      {
        "family": "Shoham",
        "given": "Sharon"
      }
    ],
    "title": "Ivy: Safety Verification by Interactive Generalization",
    "container-title": "Proceedings of the 37th ACM SIGPLAN Conference on Programming Language Design and Implementation",
    "container-title-short": "Ivy",
    "collection-title": "PLDI '16",
    "title-short": "Ivy",
    "issued": {
      "date-parts": [
        [
          "2016"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "8",
          "30"
        ]
      ]
    },
    "publisher": "ACM",
    "isbn": "978-1-4503-4261-2",
    "abstract": "Despite several decades of research, the problem of formal verification of infinite-state systems has resisted effective automation. We describe a system &mdash; Ivy &mdash; for interactively verifying safety of infinite-state systems. Ivy's key principle is that whenever verification fails, Ivy graphically displays a concrete counterexample to induction. The user then interactively guides generalization from this counterexample. This process continues until an inductive invariant is found. Ivy searches for universally quantified invariants, and uses a restricted modeling language. This ensures that all verification conditions can be checked algorithmically. All user interactions are performed using graphical models, easing the user's task. We describe our initial experience with verifying several distributed protocols.",
    "keywords": "counterexamples to induction, distributed systems, invariant inference, safety verification",
    "URL": "http://doi.acm.org/10.1145/2908080.2908118",
    "DOI": "10.1145/2908080.2908118",
    "publisher-place": "New York, NY, USA",
    "page": "614-630",
    "page-first": "614",
    "note": "event-place: Santa Barbara, CA, USA",
    "_line": "FormalReview.bib:4403"
  },
  "noauthor_hazel_nodate": {
    "id": "noauthor_hazel_nodate",
    "type": "webpage",
    "title": "Hazel, a live functional programming environment featuring typed holes.",
    "accessed": {
      "date-parts": [
        [
          "2019",
          "8",
          "30"
        ]
      ]
    },
    "URL": "http://hazel.org/",
    "_line": "FormalReview.bib:4423"
  },
  "noauthor_hazel_2019": {
    "id": "noauthor_hazel_2019",
    "type": "book",
    "title": "Hazel, a live functional programming environment with typed holes: hazelgrove/hazel",
    "container-title-short": "Hazel, a live functional programming environment with typed holes",
    "title-short": "Hazel, a live functional programming environment with typed holes",
    "issued": {
      "date-parts": [
        [
          "2019",
          "8",
          "20"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "8",
          "30"
        ]
      ]
    },
    "publisher": "hazelgrove",
    "URL": "https://github.com/hazelgrove/hazel",
    "note": "original-date: 2017-01-27T02:14:05Z",
    "_line": "FormalReview.bib:4430"
  },
  "ringer_qed_2019": {
    "id": "ringer_qed_2019",
    "type": "article-journal",
    "author": [
      {
        "family": "Ringer",
        "given": "Talia"
      },
      {
        "family": "Palmskog",
        "given": "Karl"
      },
      {
        "family": "Sergey",
        "given": "Ilya"
      },
      {
        "family": "Gligoric",
        "given": "Milos"
      },
      {
        "family": "Tatlock",
        "given": "Zachary"
      }
    ],
    "title": "QED at Large: A Survey of Engineering of Formally Verified Software",
    "container-title": "PGL",
    "container-title-short": "QED at Large",
    "title-short": "QED at Large",
    "issued": {
      "date-parts": [
        [
          "2019",
          "9",
          "3"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "9",
          "10"
        ]
      ]
    },
    "issn": "2325-1107, 2325-1131",
    "abstract": "QED at Large: A Survey of Engineering of Formally Verified Software",
    "URL": "https://www.nowpublishers.com/article/Details/PGL-045",
    "DOI": "10.1561/2500000045",
    "page": "102-281",
    "page-first": "102",
    "volume": "5",
    "issue": "2",
    "_line": "FormalReview.bib:4441"
  },
  "hoare_verifying_2003": {
    "id": "hoare_verifying_2003",
    "type": "article-journal",
    "author": [
      {
        "family": "Hoare",
        "given": "Tony"
      }
    ],
    "title": "The Verifying Compiler: A Grand Challenge for Computing Research",
    "container-title": "J. ACM",
    "container-title-short": "The Verifying Compiler",
    "title-short": "The Verifying Compiler",
    "issued": {
      "date-parts": [
        [
          "2003",
          "1"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "9",
          "17"
        ]
      ]
    },
    "issn": "0004-5411",
    "abstract": "This contribution proposes a set of criteria that distinguish a grand challenge in science or engineering from the many other kinds of short-term or long-term research problems that engage the interest of scientists and engineers. As an example drawn from Computer Science, it revives an old challenge: the construction and application of a verifying compiler that guarantees correctness of a program before running it.",
    "URL": "http://doi.acm.org/10.1145/602382.602403",
    "DOI": "10.1145/602382.602403",
    "page": "63-69",
    "page-first": "63",
    "volume": "50",
    "issue": "1",
    "_line": "FormalReview.bib:4458"
  },
  "cofer_formal_nodate": {
    "id": "cofer_formal_nodate",
    "type": "article-journal",
    "author": [
      {
        "family": "Cofer",
        "given": "Darren"
      },
      {
        "family": "Miller",
        "given": "Steven P"
      },
      {
        "family": "Collins",
        "given": "Rockwell"
      }
    ],
    "title": "Formal Methods Case Studies for DO-333",
    "page": "203",
    "page-first": "203",
    "language": "en-US",
    "_line": "FormalReview.bib:4475"
  },
  "hutchison_formal_2009": {
    "id": "hutchison_formal_2009",
    "type": "chapter",
    "author": [
      {
        "family": "Tschantz",
        "given": "Michael Carl"
      },
      {
        "family": "Wing",
        "given": "Jeannette M."
      }
    ],
    "editor": [
      {
        "family": "Cavalcanti",
        "given": "Ana"
      },
      {
        "family": "Dams",
        "given": "Dennis R."
      }
    ],
    "title": "Formal Methods for Privacy",
    "container-title": "FM 2009: Formal Methods",
    "issued": {
      "date-parts": [
        [
          "2009"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "10",
          "4"
        ]
      ]
    },
    "publisher": "Springer Berlin Heidelberg",
    "isbn": "978-3-642-05088-6 978-3-642-05089-3",
    "URL": "http://link.springer.com/10.1007/978-3-642-05089-3_1",
    "DOI": "10.1007/978-3-642-05089-3_1",
    "publisher-place": "Berlin, Heidelberg",
    "page": "1-15",
    "page-first": "1",
    "volume": "5850",
    "language": "en-US",
    "_line": "FormalReview.bib:4483"
  },
  "collins_secure_nodate": {
    "id": "collins_secure_nodate",
    "type": "article-journal",
    "author": [
      {
        "family": "Collins",
        "given": "Rockwell"
      }
    ],
    "title": "SECURE MATHEMATICALLY- ASSURED COMPOSITION OF CONTROL MODELS",
    "page": "134",
    "page-first": "134",
    "language": "en-US",
    "_line": "FormalReview.bib:4503"
  },
  "ringer_qed_2019-1": {
    "id": "ringer_qed_2019-1",
    "type": "book",
    "author": [
      {
        "family": "Ringer",
        "given": "T."
      },
      {
        "family": "Palmskog",
        "given": "K."
      },
      {
        "family": "Sergey",
        "given": "I."
      },
      {
        "family": "Gligoric",
        "given": "M."
      },
      {
        "family": "Tatlock",
        "given": "Z."
      }
    ],
    "title": "QED at Large: A Survey of Engineering of Formally Verified Software",
    "container-title-short": "QED at Large",
    "title-short": "QED at Large",
    "issued": {
      "date-parts": [
        [
          "2019"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "9",
          "26"
        ]
      ]
    },
    "publisher": "now",
    "abstract": "Development of formal proofs of correctness of programs can increase actual and perceived reliability and facilitate better understanding of program specifications and their underlying assumptions. Tools supporting such development have been available for over 40 years but have only recently seen wide practical use. Projects based on construction of machine-checked formal proofs are now reaching an unprecedented scale, comparable to large software projects, which leads to new challenges in proof development and maintenance. Despite its increasing importance, the field of proof engineering is seldom considered in its own right; related theories, techniques, and tools span many fields and venues. QED at Large covers the timeline and research literature concerning proof development for program verification, including theories, languages, and tools. It emphasizes challenges and breakthroughs at each stage in history and highlights challenges that are currently present due to the increasing scale of proof developments. This monograph is intended for use by researchers and students who are new to the field. It provides the reader with an insightful overview of the work that has led to modern-day techniques for formally verifying software. In times of increasing automation, this underpins many software systems so future trends are also highlighted.",
    "URL": "http://ieeexplore.ieee.org/document/8824174",
    "_line": "FormalReview.bib:4511"
  },
  "tuch_types_2007": {
    "id": "tuch_types_2007",
    "type": "paper-conference",
    "author": [
      {
        "family": "Tuch",
        "given": "Harvey"
      },
      {
        "family": "Klein",
        "given": "Gerwin"
      },
      {
        "family": "Norrish",
        "given": "Michael"
      }
    ],
    "title": "Types, Bytes, and Separation Logic",
    "container-title": "Proceedings of the 34th Annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages",
    "collection-title": "POPL '07",
    "issued": {
      "date-parts": [
        [
          "2007"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "9",
          "26"
        ]
      ]
    },
    "publisher": "ACM",
    "isbn": "978-1-59593-575-5",
    "abstract": "We present a formal model of memory that both captures the low-level features of C's pointers and memory, and that forms the basis for an expressive implementation of separation logic. At the low level, we do not commit common oversimplifications, but correctly deal with C's model of programming language values and the heap. At the level of separation logic, we are still able to reason abstractly and efficiently. We implement this framework in the theorem prover Isabelle/HOL and demonstrate it on two case studies. We show that the divide between detailed and abstract does not impose undue verification overhead, and that simple programs remain easy to verify. We also show that the framework is applicable to real, security- and safety-critical code by formally verifying the memory allocator of the L4 microkernel.",
    "keywords": "separation logic, interactive theorem proving, C",
    "URL": "http://doi.acm.org/10.1145/1190216.1190234",
    "DOI": "10.1145/1190216.1190234",
    "publisher-place": "New York, NY, USA",
    "page": "97-108",
    "page-first": "97",
    "note": "event-place: Nice, France",
    "_line": "FormalReview.bib:4522"
  },
  "ross_exterminators_2005": {
    "id": "ross_exterminators_2005",
    "type": "article-journal",
    "author": [
      {
        "family": "Ross",
        "given": "P.E."
      }
    ],
    "title": "The exterminators \\[software bugs",
    "container-title": "IEEE Spectr.",
    "issued": {
      "date-parts": [
        [
          "2005",
          "9"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "9",
          "24"
        ]
      ]
    },
    "issn": "0018-9235",
    "URL": "http://ieeexplore.ieee.org/document/1502527/",
    "DOI": "10.1109/MSPEC.2005.1502527",
    "page": "36-41",
    "page-first": "36",
    "volume": "42",
    "issue": "9",
    "language": "en-US",
    "_line": "FormalReview.bib:4541"
  },
  "ross_exterminators_2005-1": {
    "id": "ross_exterminators_2005-1",
    "type": "article-journal",
    "author": [
      {
        "family": "Ross",
        "given": "P. E."
      }
    ],
    "title": "The exterminators \\[software bugs\\]",
    "container-title": "IEEE Spectrum",
    "issued": {
      "date-parts": [
        [
          "2005",
          "9"
        ]
      ]
    },
    "abstract": "This paper describes a sound methodology developed at Praxis High Integrity Systems for detecting and exterminating bugs during all stages of a software project. To develop software, the London-based software house uses mathematically based techniques, known as formal methods, which require that programmers begin their work not by writing code but rather by stringing together special symbols that represent the program's logic. Like a mathematical theorem, these symbol strings can be checked to verify that they form logically correct statements. Once the programmer has checked that the program doesn't have logical flaws, it's a relatively simple matter to convert those symbols into programming code. With an average of less than one error in every 10,000 lines of delivered code, Praxis claims a bug rate that is at least 50 times better than the industry standard.",
    "keywords": "formal methods, software engineering, bug-free software, Computer bugs, formal logic, Logic, mathematical logic, Praxis High Integrity Systems, program debugging, software bugs, software development, software engineering methods, software experts, software project",
    "DOI": "10.1109/MSPEC.2005.1502527",
    "page": "36-41",
    "page-first": "36",
    "volume": "42",
    "issue": "9",
    "_line": "FormalReview.bib:4557"
  },
  "furia_autoproof:_2017": {
    "id": "furia_autoproof:_2017",
    "type": "article-journal",
    "author": [
      {
        "family": "Furia",
        "given": "Carlo A."
      },
      {
        "family": "Nordio",
        "given": "Martin"
      },
      {
        "family": "Polikarpova",
        "given": "Nadia"
      },
      {
        "family": "Tschannen",
        "given": "Julian"
      }
    ],
    "title": "AutoProof: auto-active functional verification of object-oriented programs",
    "container-title": "Int J Softw Tools Technol Transfer",
    "container-title-short": "AutoProof",
    "title-short": "AutoProof",
    "issued": {
      "date-parts": [
        [
          "2017",
          "11",
          "1"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "9",
          "23"
        ]
      ]
    },
    "issn": "1433-2787",
    "abstract": "Auto-active verifiers provide a level of automation intermediate between fully automatic and interactive: users supply code with annotations as input while benefiting from a high level of automation in the back-end. This paper presents AutoProof, a state-of-the-art auto-active verifier for object-oriented sequential programs with complex functional specifications. AutoProof fully supports advanced object-oriented features and a powerful methodology for framing and class invariants, which make it applicable in practice to idiomatic object-oriented patterns. The paper focuses on describing AutoProof ’s interface, design, and implementation features, and demonstrates AutoProof ’s performance on a rich collection of benchmark problems. The results attest AutoProof ’s competitiveness among tools in its league on cutting-edge functional verification of object-oriented programs.",
    "keywords": "Auto-active verification, Functional verification, Object-oriented verification, Verification benchmarks",
    "URL": "https://doi.org/10.1007/s10009-016-0419-0",
    "DOI": "10.1007/s10009-016-0419-0",
    "page": "697-716",
    "page-first": "697",
    "volume": "19",
    "issue": "6",
    "language": "en-US",
    "_line": "FormalReview.bib:4570"
  },
  "bjorner_manifest_2017": {
    "id": "bjorner_manifest_2017",
    "type": "article-journal",
    "author": [
      {
        "family": "Bjørner",
        "given": "Dines"
      }
    ],
    "title": "Manifest domains: analysis and description",
    "container-title": "Form Asp Comp",
    "container-title-short": "Manifest domains",
    "title-short": "Manifest domains",
    "issued": {
      "date-parts": [
        [
          "2017",
          "3",
          "1"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "9",
          "23"
        ]
      ]
    },
    "issn": "1433-299X",
    "abstract": "We show that manifest domains, an understanding of which are a prerequisite for software requirements prescriptions, can be precisely described: narrated and formalised. We show that such manifest domains can be understood as a collection of endurant, that is, basically spatial entities: parts, components and materials, and perdurant, that is, basically temporal entities: actions, events and behaviours. We show that parts can be modeled in terms of external qualities whether: atomic or composite parts, having internal qualities: unique identifications, mereologies, which model relations between parts, and attributes. We show that the manifest domain analysis endeavour can be supported by a calculus of manifest domain analysis prompts: is&underscore;entity, is&underscore;endurant, is&underscore;perdurant, is&underscore;part, is&underscore;component, is&underscore;material, is&underscore;atomic, is&underscore;composite, has&underscore;components, has&underscore;materials, has&underscore;concrete&underscore;type, attribute&underscore;names, is&underscore;stationary, etcetera; and show how the manifest domain description endeavour can be supported by a calculus of manifest domain description prompts: observe&underscore;part&underscore;sorts, observe&underscore;part&underscore;type, observe&underscore;components, observe&underscore;materials, observe&underscore;unique&underscore;identifier, observe&underscore;mereology, observe&underscore;attributes. We show how to model attributes, essentially following Michael Jackson (Software requirements &amp; specifications: a lexicon of practice, principles and prejudices. ACM Press, Addison-Wesley, Reading, 1995), but with a twist: The attribute model introduces the attribute analysis prompts is&underscore;static&underscore;attribute, is&underscore;dynamic&underscore;attribute, is&underscore;inert&underscore;attribute, is&underscore;reactive&underscore;attribute, is&underscore;active&underscore;attribute, is&underscore;autonomous&underscore;attribute, is&underscore;biddable&underscore;attribute and is&underscore;programmable&underscore;attribute. The twist suggests ways of modeling “access” to the values of these kinds of attributes: the static attributes by simply “copying” them, once, the reactive and programmable attributes by “carrying” them as function parameters whose values are kept always updated, and the remaining, the external&underscore;attributes, by inquiring, when needed, as to their value, as if they were always offered on CSP-like channels (Hoare, Communicating sequential processes. C.A.R. Hoare series in computer science. Prentice-Hall International, London, 2004). We show how to model essential aspects of perdurants in terms of their signatures based on the concepts of endurants. And we show how one can “compile” descriptions of endurant parts into descriptions of perdurant behaviours. We do not show prompt calculi for perdurants. The above contributions express a method with principles, techniques and tools for constructing domain descriptions. It is important to realise that we do not wish to nor claim that the method can describe all that it is interesting to know about domains.",
    "keywords": "Analysis &amp; description, Domain engineering, Manifest domains, Prompt calculi",
    "URL": "https://doi.org/10.1007/s00165-016-0385-z",
    "DOI": "10.1007/s00165-016-0385-z",
    "page": "175-225",
    "page-first": "175",
    "volume": "29",
    "issue": "2",
    "language": "en-US",
    "_line": "FormalReview.bib:4589"
  },
  "noauthor_dines_nodate": {
    "id": "noauthor_dines_nodate",
    "type": "webpage",
    "title": "Dines Bjorner",
    "accessed": {
      "date-parts": [
        [
          "2019",
          "9",
          "23"
        ]
      ]
    },
    "URL": "http://www.imm.dtu.dk/~dibj/",
    "_line": "FormalReview.bib:4608"
  },
  "hutchison_40_2014": {
    "id": "hutchison_40_2014",
    "type": "chapter",
    "author": [
      {
        "family": "Bjørner",
        "given": "Dines"
      },
      {
        "family": "Havelund",
        "given": "Klaus"
      }
    ],
    "editor": [
      {
        "family": "Jones",
        "given": "Cliff"
      },
      {
        "family": "Pihlajasaari",
        "given": "Pekka"
      },
      {
        "family": "Sun",
        "given": "Jun"
      }
    ],
    "title": "40 Years of Formal Methods: Some Obstacles and Some Possibilities?",
    "container-title": "FM 2014: Formal Methods",
    "container-title-short": "40 Years of Formal Methods",
    "title-short": "40 Years of Formal Methods",
    "issued": {
      "date-parts": [
        [
          "2014"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "9",
          "23"
        ]
      ]
    },
    "publisher": "Springer International Publishing",
    "isbn": "978-3-319-06409-3 978-3-319-06410-9",
    "URL": "http://link.springer.com/10.1007/978-3-319-06410-9_4",
    "DOI": "10.1007/978-3-319-06410-9_4",
    "publisher-place": "Cham",
    "page": "42-61",
    "page-first": "42",
    "volume": "8442",
    "language": "en-US",
    "_line": "FormalReview.bib:4615"
  },
  "mullen_oeuf:_2018-1": {
    "id": "mullen_oeuf:_2018-1",
    "type": "paper-conference",
    "author": [
      {
        "family": "Mullen",
        "given": "Eric"
      },
      {
        "family": "Pernsteiner",
        "given": "Stuart"
      },
      {
        "family": "Wilcox",
        "given": "James R."
      },
      {
        "family": "Tatlock",
        "given": "Zachary"
      },
      {
        "family": "Grossman",
        "given": "Dan"
      }
    ],
    "title": "ŒUf: Minimizing the Coq Extraction TCB",
    "container-title": "Proceedings of the 7th ACM SIGPLAN International Conference on Certified Programs and Proofs",
    "container-title-short": "ŒUf",
    "collection-title": "CPP 2018",
    "title-short": "ŒUf",
    "issued": {
      "date-parts": [
        [
          "2018"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "7",
          "30"
        ]
      ]
    },
    "publisher": "ACM",
    "isbn": "978-1-4503-5586-5",
    "abstract": "Verifying systems by implementing them in the programming language of a proof assistant (e.g., Gallina for Coq) lets us directly leverage the full power of the proof assistant for verifying the system. But, to execute such an implementation requires extraction, a large complicated process that is in the trusted computing base (TCB).  This paper presents Œuf, a verified compiler from a subset of Gallina to assembly. Œuf’s correctness theorem ensures that compilation preserves the semantics of the source Gallina program. We describe how Œuf’s specification can be used as a foreign function interface to reason about the interaction between compiled Gallina programs and surrounding shim code. Additionally, Œufmaintains a small TCB for its front-end by reflecting Gallina programs to Œufsource and automatically ensuring equivalence using computational denotation. This design enabled us to implement some early compiler passes (e.g., lambda lifting) in the untrusted reflection and ensure their correctness via translation validation. To evaluate Œuf, we compile Appel’s SHA256 specification from Gallina to x86 and write a shim for the generated code, yielding a verified sha256sum implementation with a small TCB.",
    "keywords": "Coq, Compilers, Formal Verification, Verified Systems",
    "URL": "http://doi.acm.org/10.1145/3167089",
    "DOI": "10.1145/3167089",
    "publisher-place": "New York, NY, USA",
    "page": "172-185",
    "page-first": "172",
    "note": "event-place: Los Angeles, CA, USA",
    "_line": "FormalReview.bib:4636"
  },
  "farrell_robotics_2018": {
    "id": "farrell_robotics_2018",
    "type": "article-journal",
    "author": [
      {
        "family": "Farrell",
        "given": "Marie"
      },
      {
        "family": "Luckcuck",
        "given": "Matt"
      },
      {
        "family": "Fisher",
        "given": "Michael"
      }
    ],
    "title": "Robotics and Integrated Formal Methods: Necessity meets Opportunity",
    "container-title": "arXiv:1805.11996 \\[cs\\]",
    "container-title-short": "Robotics and Integrated Formal Methods",
    "title-short": "Robotics and Integrated Formal Methods",
    "issued": {
      "date-parts": [
        [
          "2018"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "10",
          "5"
        ]
      ]
    },
    "abstract": "Robotic systems are multi-dimensional entities, combining both hardware and software, that are heavily dependent on, and influenced by, interactions with the real world. They can be variously categorised as embedded, cyberphysical, real-time, hybrid, adaptive and even autonomous systems, with a typical robotic system being likely to contain all of these aspects. The techniques for developing and verifying each of these system varieties are often quite distinct. This, together with the sheer complexity of robotic systems, leads us to argue that diverse formal techniques must be integrated in order to develop, verify, and provide certification evidence for, robotic systems. Furthermore, we propose the fast evolving field of robotics as an ideal catalyst for the advancement of integrated formal methods research, helping to drive the field in new and exciting directions and shedding light on the development of large-scale, dynamic, complex systems.",
    "keywords": "Computer Science - Software Engineering, Computer Science - Robotics",
    "URLtext": "1805.11996",
    "URLpretext": "[arXiv:]{.etype}",
    "eprint-type": "arxiv",
    "eprint": "1805.11996",
    "URL": "http://arxiv.org/abs/1805.11996",
    "DOI": "10.1007/978-3-319-98938-9_10",
    "page": "161-171",
    "page-first": "161",
    "volume": "11023",
    "_line": "FormalReview.bib:4656"
  },
  "gonthier_how_2013": {
    "id": "gonthier_how_2013",
    "type": "article-journal",
    "author": [
      {
        "family": "Gonthier",
        "given": "Georges"
      },
      {
        "family": "Ziliani",
        "given": "Beta"
      },
      {
        "family": "Nanevski",
        "given": "Aleksandar"
      },
      {
        "family": "Dreyer",
        "given": "Derek"
      }
    ],
    "title": "How to make ad hoc proof automation less ad hoc",
    "container-title": "J. Funct. Prog.",
    "issued": {
      "date-parts": [
        [
          "2013",
          "7"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "10",
          "13"
        ]
      ]
    },
    "issn": "0956-7968, 1469-7653",
    "abstract": "Most interactive theorem provers provide support for some form of user-customizable proof automation. In a number of popular systems, such as Coq and Isabelle, this automation is achieved primarily through tactics, which are programmed in a separate language from that of the prover’s base logic. While tactics are clearly useful in practice, they can be difﬁcult to maintain and compose because, unlike lemmas, their behavior cannot be speciﬁed within the expressive type system of the prover itself.",
    "URL": "https://www.cambridge.org/core/product/identifier/S0956796813000051/type/journal_article",
    "DOI": "10.1017/S0956796813000051",
    "page": "357-401",
    "page-first": "357",
    "volume": "23",
    "issue": "4",
    "language": "en-US",
    "_line": "FormalReview.bib:4674"
  },
  "chihani_certication_nodate": {
    "id": "chihani_certication_nodate",
    "type": "article-journal",
    "author": [
      {
        "family": "Chihani",
        "given": "Zakaria"
      }
    ],
    "title": "Certiﬁcation of First-order proofs in classical and intuitionistic logics",
    "page": "167",
    "page-first": "167",
    "language": "en-US",
    "_line": "FormalReview.bib:4691"
  },
  "easterbrook_formal_1997": {
    "id": "easterbrook_formal_1997",
    "type": "paper-conference",
    "author": [
      {
        "family": "Easterbrook",
        "given": "S."
      },
      {
        "family": "Callahan",
        "given": "J."
      }
    ],
    "title": "Formal methods for V &amp; V of partial specifications: an experience report",
    "container-title": "Proceedings of ISRE '97: 3rd IEEE International Symposium on Requirements Engineering",
    "container-title-short": "Formal methods for V amp;V of partial specifications",
    "title-short": "Formal methods for V amp;V of partial specifications",
    "event-title": "Proceedings of ISRE '97: 3rd IEEE International Symposium on Requirements Engineering",
    "issued": {
      "date-parts": [
        [
          "1997",
          "1"
        ]
      ]
    },
    "abstract": "This paper describes our work exploring the suitability of formal specification methods for independent verification and validation (IV&amp;V) of software specifications for large, safety critical systems. An IV&amp;V contractor often has to perform rapid analysis on incomplete specifications, with no control over how those specifications are represented. Lightweight formal methods show significant promise in this context, as they offer a way of uncovering major errors, without the burden of full proofs of correctness. We describe an experiment in the application of the method SCR to testing for consistency properties of a partial model of the requirements for fault detection isolation and recovery on the space station. We conclude that the insights gained from formalizing a specification is valuable, and it is the process of formalization, rather than the end product that is important. It was only necessary to build enough of the formal model to test the properties in which we were interested. Maintenance of fidelity between multiple representations of the same requirements (as they evolve) is still a problem, and deserves further study.",
    "keywords": "program verification, formal methods, formal specification, testing, Performance analysis, aerospace computing, Aerospace safety, artificial satellites, consistency properties, Error correction, errors, fault detection isolation, fault diagnosis, fault recovery, formal specification methods, Formal specifications, incomplete specifications, independent verification, International Space Station, large safety critical systems, NASA, partial specification verification, program testing, safety-critical software, SCR, Software safety, space station, Space stations, Testing, Thyristors",
    "DOI": "10.1109/ISRE.1997.566865",
    "page": "160-168",
    "page-first": "160",
    "_line": "FormalReview.bib:4699"
  },
  "easterbrook_formal_nodate": {
    "id": "easterbrook_formal_nodate",
    "type": "article-journal",
    "author": [
      {
        "family": "Easterbrook",
        "given": "Steve"
      },
      {
        "family": "Callahan",
        "given": "John"
      }
    ],
    "title": "Formal Methods for V&amp;V of partial specifications: An experience report",
    "abstract": "This paper describes our work exploring the suitability of formal specification methods f o r independ e n t verification and validation (IVi3V) of software specifications for large, safety critical systems. An IV&amp;V contractor often has to perform rapid analysis on incomplete specifications, with no control over how those speciJcations are represented. Lightweight formal methods show significant promise in this context, as they offer a way of uncovering major errors, without the burden of full proofs of correctness. We describe an experiment in the application of the method SCR to testing for consistency properties of a partial model of th,e requirements for Fault Detection Isolation and Recovery o n th,e space station. We conclude that the insights gained from formalizing a specification is valuable, and it is the process of formalization, rather than the end product that is important. It was only necessary to build enough of the formal model to test the properties in which we were interested. Maintenance of fidelity between multiple representations of the same requirements (as they evolve) is still a problem,, and deserves further study.",
    "page": "9",
    "page-first": "9",
    "language": "en-US",
    "_line": "FormalReview.bib:4712"
  },
  "ter_beek_gospelproviding_2019": {
    "id": "ter_beek_gospelproviding_2019",
    "type": "chapter",
    "author": [
      {
        "family": "Charguéraud",
        "given": "Arthur"
      },
      {
        "family": "Filliâtre",
        "given": "Jean-Christophe"
      },
      {
        "family": "Lourenço",
        "given": "Cláudio"
      },
      {
        "family": "Pereira",
        "given": "Mário"
      }
    ],
    "editor": [
      {
        "family": "Beek",
        "given": "Maurice H.",
        "dropping-particle": "ter"
      },
      {
        "family": "McIver",
        "given": "Annabelle"
      },
      {
        "family": "Oliveira",
        "given": "José N."
      }
    ],
    "title": "GOSPEL—Providing OCaml with a Formal Specification Language",
    "container-title": "Formal Methods – The Next 30 Years",
    "issued": {
      "date-parts": [
        [
          "2019"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "10",
          "14"
        ]
      ]
    },
    "publisher": "Springer International Publishing",
    "isbn": "978-3-030-30941-1 978-3-030-30942-8",
    "abstract": "This paper introduces GOSPEL, a behavioral speciﬁcation language for OCaml. It is designed to enable modular veriﬁcation of data structures and algorithms. GOSPEL is a contract-based, strongly typed language, with a formal semantics deﬁned by means of translation into Separation Logic. Compared with writing speciﬁcations directly in Separation Logic, GOSPEL provides a high-level syntax that greatly improves conciseness and makes it accessible to programmers with no familiarity with Separation Logic. Although GOSPEL has been developed for specifying OCaml code, we believe that many aspects of its design could apply to other programming languages. This paper presents the design and semantics of GOSPEL, and reports on its application for the development of a formally veriﬁed library of general-purpose OCaml data structures.",
    "URL": "http://link.springer.com/10.1007/978-3-030-30942-8_29",
    "DOI": "10.1007/978-3-030-30942-8_29",
    "publisher-place": "Cham",
    "page": "484-501",
    "page-first": "484",
    "volume": "11800",
    "language": "en-US",
    "_line": "FormalReview.bib:4721"
  },
  "alana_reference_2018": {
    "id": "alana_reference_2018",
    "type": "paper-conference",
    "author": [
      {
        "family": "Alaña",
        "given": "Elena"
      },
      {
        "family": "Herrero",
        "given": "Javier"
      },
      {
        "family": "Urueña",
        "given": "Santiago"
      },
      {
        "family": "Macioszek",
        "given": "Krystyna"
      },
      {
        "family": "Silveira",
        "given": "Daniel"
      }
    ],
    "title": "A reference architecture for space systems",
    "container-title": "Proceedings of the 12th European Conference on Software Architecture Companion Proceedings - ECSA '18",
    "event-title": "the 12th European Conference",
    "issued": {
      "date-parts": [
        [
          "2018"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "10",
          "14"
        ]
      ]
    },
    "publisher": "ACM Press",
    "isbn": "978-1-4503-6483-6",
    "abstract": "The definition of a Reference Architecture for Space Systems is a noteworthy field to improve the development of embedded critical systems. The European Space Agency (ESA) and the European Commission (EU) are actively working on different initiatives to elaborate common and agreed architectures in different fields of the Space Domain. This abstract presents the results of some of these initiatives in which GMV takes part.",
    "URL": "http://dl.acm.org/citation.cfm?doid=3241403.3241416",
    "DOI": "10.1145/3241403.3241416",
    "publisher-place": "Madrid, Spain",
    "page": "1-2",
    "page-first": "1",
    "language": "en-US",
    "_line": "FormalReview.bib:4740"
  },
  "klein_formally_2018": {
    "id": "klein_formally_2018",
    "type": "article-journal",
    "author": [
      {
        "family": "Klein",
        "given": "Gerwin"
      },
      {
        "family": "Andronick",
        "given": "June"
      },
      {
        "family": "Fernandez",
        "given": "Matthew"
      },
      {
        "family": "Kuz",
        "given": "Ihor"
      },
      {
        "family": "Murray",
        "given": "Toby"
      },
      {
        "family": "Heiser",
        "given": "Gernot"
      }
    ],
    "title": "Formally verified software in the real world",
    "container-title": "Commun. ACM",
    "issued": {
      "date-parts": [
        [
          "2018",
          "9",
          "26"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "10",
          "14"
        ]
      ]
    },
    "issn": "00010782",
    "URL": "http://dl.acm.org/citation.cfm?doid=3281635.3230627",
    "DOI": "10.1145/3230627",
    "page": "68-77",
    "page-first": "68",
    "volume": "61",
    "issue": "10",
    "language": "en-US",
    "_line": "FormalReview.bib:4758"
  },
  "moscato_provably_2019": {
    "id": "moscato_provably_2019",
    "type": "paper-conference",
    "author": [
      {
        "family": "Moscato",
        "given": "Mariano M."
      },
      {
        "family": "Titolo",
        "given": "Laura"
      },
      {
        "family": "Feliú",
        "given": "Marco A."
      },
      {
        "family": "Muñoz",
        "given": "César A."
      }
    ],
    "editor": [
      {
        "family": "Beek",
        "given": "Maurice H.",
        "dropping-particle": "ter"
      },
      {
        "family": "McIver",
        "given": "Annabelle"
      },
      {
        "family": "Oliveira",
        "given": "José N."
      }
    ],
    "title": "Provably Correct Floating-Point Implementation of a Point-in-Polygon Algorithm",
    "container-title": "Formal Methods – The Next 30 Years",
    "collection-title": "Lecture Notes in Computer Science",
    "issued": {
      "date-parts": [
        [
          "2019"
        ]
      ]
    },
    "publisher": "Springer International Publishing",
    "isbn": "978-3-030-30942-8",
    "abstract": "The problem of determining whether or not a point lies inside a given polygon occurs in many applications. In air traffic management concepts, a correct solution to the point-in-polygon problem is critical to geofencing systems for Unmanned Aerial Vehicles and in weather avoidance applications. Many mathematical methods can be used to solve the point-in-polygon problem. Unfortunately, a straightforward floating-point implementation of these methods can lead to incorrect results due to round-off errors. In particular, these errors may cause the control flow of the program to diverge with respect to the ideal real-number algorithm. This divergence potentially results in an incorrect point-in-polygon determination even when the point is far from the edges of the polygon. This paper presents a provably correct implementation of a point-in-polygon method that is based on the computation of the winding number. This implementation is mechanically generated from a source-to-source transformation of the ideal real-number specification of the algorithm. The correctness of this implementation is formally verified within the Frama-C analyzer, where the proof obligations are discharged using the Prototype Verification System (PVS).",
    "page": "21-37",
    "page-first": "21",
    "language": "en-US",
    "_line": "FormalReview.bib:4774"
  },
  "noauthor_fm_nodate": {
    "id": "noauthor_fm_nodate",
    "type": "webpage",
    "title": "FM folks - richardlford@gmail.com - Gmail",
    "accessed": {
      "date-parts": [
        [
          "2019",
          "10",
          "14"
        ]
      ]
    },
    "URL": "https://mail.google.com/mail/u/0/#inbox/FMfcgxwDrlVnZmDccTxHFBnzPRMfbmpn?projector=1&messagePartId=0.1",
    "_line": "FormalReview.bib:4788"
  },
  "garillot_packaging_2009": {
    "id": "garillot_packaging_2009",
    "type": "paper-conference",
    "author": [
      {
        "family": "Garillot",
        "given": "François"
      },
      {
        "family": "Gonthier",
        "given": "Georges"
      },
      {
        "family": "Mahboubi",
        "given": "Assia"
      },
      {
        "family": "Rideau",
        "given": "Laurence"
      }
    ],
    "editor": [
      {
        "family": "Berghofer",
        "given": "Stefan"
      },
      {
        "family": "Nipkow",
        "given": "Tobias"
      },
      {
        "family": "Urban",
        "given": "Christian"
      },
      {
        "family": "Wenzel",
        "given": "Makarius"
      }
    ],
    "title": "Packaging Mathematical Structures",
    "container-title": "Theorem Proving in Higher Order Logics",
    "collection-title": "Lecture Notes in Computer Science",
    "issued": {
      "date-parts": [
        [
          "2009"
        ]
      ]
    },
    "publisher": "Springer Berlin Heidelberg",
    "isbn": "978-3-642-03359-9",
    "abstract": "This paper proposes generic design patterns to define and combine algebraic structures, using dependent records, coercions and type inference, inside the Coq system. This alternative to telescopes in particular supports multiple inheritance, maximal sharing of notations and theories, and automated structure inference. Our methodology is robust enough to handle a hierarchy comprising a broad variety of algebraic structures, from types with a choice operator to algebraically closed fields. Interfaces for the structures enjoy the convenience of a classical setting, without requiring any axiom. Finally, we present two applications of our proof techniques: a key lemma for characterising the discrete logarithm, and a matrix decomposition problem.",
    "keywords": "Coq, Coercive subtyping, Formalization of Algebra, SSReflect, Type inference",
    "page": "327-342",
    "page-first": "327",
    "language": "en-US",
    "_line": "FormalReview.bib:4795"
  },
  "hutchison_pragmatic_2013": {
    "id": "hutchison_pragmatic_2013",
    "type": "chapter",
    "author": [
      {
        "family": "Cohen",
        "given": "Cyril"
      }
    ],
    "editor": [
      {
        "family": "Blazy",
        "given": "Sandrine"
      },
      {
        "family": "Paulin-Mohring",
        "given": "Christine"
      },
      {
        "family": "Pichardie",
        "given": "David"
      }
    ],
    "title": "Pragmatic Quotient Types in Coq",
    "container-title": "Interactive Theorem Proving",
    "issued": {
      "date-parts": [
        [
          "2013"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "10",
          "18"
        ]
      ]
    },
    "publisher": "Springer Berlin Heidelberg",
    "isbn": "978-3-642-39633-5 978-3-642-39634-2",
    "abstract": "In intensional type theory, it is not always possible to form the quotient of a type by an equivalence relation. However, quotients are extremely useful when formalizing mathematics, especially in algebra. We provide a Coq library with a pragmatic approach in two complementary components. First, we provide a framework to work with quotient types in an axiomatic manner. Second, we program construction mechanisms for some speciﬁc cases where it is possible to build a quotient type. This library was helpful in implementing the types of rational fractions, multivariate polynomials, ﬁeld extensions and real algebraic numbers.",
    "URL": "http://link.springer.com/10.1007/978-3-642-39634-2_17",
    "DOI": "10.1007/978-3-642-39634-2_17",
    "publisher-place": "Berlin, Heidelberg",
    "page": "213-228",
    "page-first": "213",
    "volume": "7998",
    "language": "en-US",
    "_line": "FormalReview.bib:4811"
  },
  "soare_turing_2016": {
    "id": "soare_turing_2016",
    "type": "book",
    "author": [
      {
        "family": "Soare",
        "given": "Robert I."
      }
    ],
    "title": "Turing Computability",
    "collection-title": "Theory and Applications of Computability",
    "issued": {
      "date-parts": [
        [
          "2016"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "11",
          "15"
        ]
      ]
    },
    "publisher": "Springer Berlin Heidelberg",
    "isbn": "978-3-642-31932-7 978-3-642-31933-4",
    "URL": "http://link.springer.com/10.1007/978-3-642-31933-4",
    "DOI": "10.1007/978-3-642-31933-4",
    "publisher-place": "Berlin, Heidelberg",
    "_line": "FormalReview.bib:4832"
  },
  "longley_higher-order_2015": {
    "id": "longley_higher-order_2015",
    "type": "book",
    "author": [
      {
        "family": "Longley",
        "given": "John"
      },
      {
        "family": "Normann",
        "given": "Dag"
      }
    ],
    "title": "Higher-Order Computability",
    "collection-title": "Theory and Applications of Computability",
    "issued": {
      "date-parts": [
        [
          "2015"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "11",
          "15"
        ]
      ]
    },
    "publisher": "Springer Berlin Heidelberg",
    "isbn": "978-3-662-47991-9 978-3-662-47992-6",
    "URL": "http://link.springer.com/10.1007/978-3-662-47992-6",
    "DOI": "10.1007/978-3-662-47992-6",
    "publisher-place": "Berlin, Heidelberg",
    "_line": "FormalReview.bib:4846"
  },
  "downey_algorithmic_2010": {
    "id": "downey_algorithmic_2010",
    "type": "book",
    "author": [
      {
        "family": "Downey",
        "given": "Rodney G."
      },
      {
        "family": "Hirschfeldt",
        "given": "Denis R."
      }
    ],
    "title": "Algorithmic Randomness and Complexity",
    "collection-title": "Theory and Applications of Computability",
    "issued": {
      "date-parts": [
        [
          "2010"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "11",
          "15"
        ]
      ]
    },
    "publisher": "Springer New York",
    "isbn": "978-0-387-95567-4 978-0-387-68441-3",
    "URL": "http://link.springer.com/10.1007/978-0-387-68441-3",
    "DOI": "10.1007/978-0-387-68441-3",
    "publisher-place": "New York, NY",
    "_line": "FormalReview.bib:4860"
  },
  "bridges_apartness_2011": {
    "id": "bridges_apartness_2011",
    "type": "book",
    "author": [
      {
        "family": "Bridges",
        "given": "Douglas S."
      },
      {
        "family": "Vîţă",
        "given": "Luminiţa Simona"
      }
    ],
    "title": "Apartness and Uniformity",
    "collection-title": "Theory and Applications of Computability",
    "issued": {
      "date-parts": [
        [
          "2011"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "11",
          "15"
        ]
      ]
    },
    "publisher": "Springer Berlin Heidelberg",
    "isbn": "978-3-642-22414-0 978-3-642-22415-7",
    "URL": "http://link.springer.com/10.1007/978-3-642-22415-7",
    "DOI": "10.1007/978-3-642-22415-7",
    "publisher-place": "Berlin, Heidelberg",
    "_line": "FormalReview.bib:4874"
  },
  "oconnor_computer-verified_2010": {
    "id": "oconnor_computer-verified_2010",
    "type": "article-journal",
    "author": [
      {
        "family": "O’Connor",
        "given": "Russell"
      },
      {
        "family": "Spitters",
        "given": "Bas"
      }
    ],
    "title": "A computer-verified monadic functional implementation of the integral",
    "container-title": "Theoretical Computer Science",
    "issued": {
      "date-parts": [
        [
          "2010",
          "8",
          "7"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "11",
          "6"
        ]
      ]
    },
    "issn": "0304-3975",
    "abstract": "We provide a computer-verified exact monadic functional implementation of the Riemann integral in type theory. Together with previous work by O’Connor, this may be seen as the beginning of the realization of Bishop’s vision to use constructive mathematics as a programming language for exact analysis.",
    "keywords": "Type theory, Exact real analysis, Functional programming, Monads",
    "URL": "http://www.sciencedirect.com/science/article/pii/S0304397510003233",
    "DOI": "10.1016/j.tcs.2010.05.031",
    "page": "3386-3402",
    "page-first": "3386",
    "volume": "411",
    "issue": "37",
    "language": "en-US",
    "_line": "FormalReview.bib:4888"
  },
  "noauthor_coquelicot.coquelicot_nodate": {
    "id": "noauthor_coquelicot.coquelicot_nodate",
    "type": "webpage",
    "title": "Coquelicot.Coquelicot",
    "accessed": {
      "date-parts": [
        [
          "2019",
          "11",
          "3"
        ]
      ]
    },
    "URL": "http://coquelicot.saclay.inria.fr/html/Coquelicot.Coquelicot.html",
    "_line": "FormalReview.bib:4906"
  },
  "cooper_incomputable_2017": {
    "id": "cooper_incomputable_2017",
    "type": "book",
    "editor": [
      {
        "family": "Cooper",
        "given": "S. Barry"
      },
      {
        "family": "Soskova",
        "given": "Mariya I."
      }
    ],
    "title": "The Incomputable",
    "collection-title": "Theory and Applications of Computability",
    "issued": {
      "date-parts": [
        [
          "2017"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "11",
          "15"
        ]
      ]
    },
    "publisher": "Springer International Publishing",
    "isbn": "978-3-319-43667-8 978-3-319-43669-2",
    "URL": "http://link.springer.com/10.1007/978-3-319-43669-2",
    "DOI": "10.1007/978-3-319-43669-2",
    "publisher-place": "Cham",
    "_line": "FormalReview.bib:4913"
  },
  "dang_rustbelt_nodate": {
    "id": "dang_rustbelt_nodate",
    "type": "article-journal",
    "author": [
      {
        "family": "Dang",
        "given": "Hoang-Hai"
      },
      {
        "family": "Jourdan",
        "given": "Jacques-Henri"
      },
      {
        "family": "Kaiser",
        "given": "Jan-Oliver"
      },
      {
        "family": "Dreyer",
        "given": "Derek"
      }
    ],
    "title": "RustBelt Meets Relaxed Memory",
    "abstract": "The Rust programming language supports safe systems programming by means of a strong ownership-tracking type system. In their prior work on RustBelt, Jung et al. began the task of setting Rust’s safety claims on a more rigorous formal foundation. Specifically, they used Iris, a Coq-based separation logic framework, to build a machine-checked proof of semantic soundness for a λ-calculus model of Rust, as well as for a number of widely-used Rust libraries that internally employ unsafe language features. However, they also made the significant simplifying assumption that the language is sequentially consistent. In this paper, we adapt RustBelt to account for the relaxed-memory operations that concurrent Rust libraries actually use, in the process uncovering a data race in the Arc library. We focus on the most interesting technical problem: how to reason about resource reclamation under relaxed memory, using a logical construction we call synchronized ghost state. CCS Concepts: • Theory of computation → Separation logic; Operational semantics; Programming logic.",
    "page": "29",
    "page-first": "29",
    "volume": "4",
    "language": "en-US",
    "_line": "FormalReview.bib:4927"
  },
  "jones_function_2013": {
    "id": "jones_function_2013",
    "type": "article-journal",
    "author": [
      {
        "family": "Jones",
        "given": "Capers"
      }
    ],
    "title": "Function Points As a Universal Software Metric",
    "container-title": "SIGSOFT Softw. Eng. Notes",
    "issued": {
      "date-parts": [
        [
          "2013",
          "7"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "11",
          "27"
        ]
      ]
    },
    "issn": "0163-5948",
    "abstract": "Function point metrics are the most accurate and effective metrics yet developed for software sizing and also for studying software productivity, quality, costs, risks, and economic value. Unlike the older \"lines of code\" metric function points can be used to study requirements, design, and in fact all software activities from development through maintenance. In the future function point metrics can easily become a universal metric used for all software applications and for all software contracts in all countries. The government of Brazil already requires function points for all software contracts, and South Korea and Italy may soon follow. However, there are some logistical problems with function point metrics that need to be understood and overcome in order for function point metrics to become the primary metric for software economic analysis. Manual function point counting is too slow and costly to be used on large software projects above 10,000 function points in size. Also, application size is not constant but grows at about 2&perc; per calendar month during development and 8&perc; or more per calendar year for as long as software is in active use. This paper discusses a method of high-speed function point counting that can size any application in less than two minutes, and which can predict application growth during development and for five years after release. This new method is based on pattern matching and is covered by U.S. utility patent application and hence is patent pending.",
    "URL": "http://doi.acm.org/10.1145/2492248.2492268",
    "DOI": "10.1145/2492248.2492268",
    "page": "1-27",
    "page-first": "1",
    "volume": "38",
    "issue": "4",
    "_line": "FormalReview.bib:4937"
  },
  "clark_instructors_2019": {
    "id": "clark_instructors_2019",
    "type": "article-journal",
    "author": [
      {
        "family": "Clark",
        "given": "Pete L."
      }
    ],
    "title": "The Instructor’s Guide to Real Induction",
    "container-title": "Mathematics Magazine",
    "issued": {
      "date-parts": [
        [
          "2019",
          "3",
          "15"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "11",
          "27"
        ]
      ]
    },
    "issn": "0025-570X, 1930-0980",
    "URL": "https://www.tandfonline.com/doi/full/10.1080/0025570X.2019.1549902",
    "DOI": "10.1080/0025570X.2019.1549902",
    "page": "136-150",
    "page-first": "136",
    "volume": "92",
    "issue": "2",
    "language": "en-US",
    "_line": "FormalReview.bib:4953"
  },
  "malecha_towards_2016": {
    "id": "malecha_towards_2016",
    "type": "paper-conference",
    "author": [
      {
        "family": "Malecha",
        "given": "Gregory"
      },
      {
        "family": "Ricketts",
        "given": "Daniel"
      },
      {
        "family": "Alvarez",
        "given": "Mario M."
      },
      {
        "family": "Lerner",
        "given": "Sorin"
      }
    ],
    "title": "Towards foundational verification of cyber-physical systems",
    "container-title": "2016 Science of Security for Cyber-Physical Systems Workshop (SOSCYPS)",
    "event-title": "2016 Science of Security for Cyber-Physical Systems Workshop (SOSCYPS)",
    "issued": {
      "date-parts": [
        [
          "2016",
          "4"
        ]
      ]
    },
    "abstract": "The safety-critical aspects of cyber-physical systems motivate the need for rigorous analysis of these systems. In the literature this work is often done using idealized models of systems where the analysis can be carried out using high-level reasoning techniques such as Lyapunov functions and model checking. In this paper we present VERIDRONE, a foundational framework for reasoning about cyber-physical systems at all levels from high-level models to C code that implements the system. VERIDRONE is a library within the Coq proof assistant enabling us to build on its foundational implementation, its interactive development environments, and its wealth of libraries capturing interesting theories ranging from real numbers and differential equations to verified compilers and floating point numbers. These features make proof assistants in general, and Coq in particular, a powerful platform for unifying foundational results about safety-critical systems and ensuring interesting properties at all levels of the stack.",
    "keywords": "formal verification, Coq proof assistant, program compilers, safety-critical software, Biomedical monitoring, Cognition, cyber-physical systems, Cyber-physical systems, differential equations, floating point numbers, foundational framework, high-level models, idealized models, interactive development environments, Lyapunov functions, model checking, Monitoring, Robustness, safety-critical aspects, Software, Stability analysis, towards foundational verification, verified compilers",
    "DOI": "10.1109/SOSCYPS.2016.7580000",
    "page": "1-5",
    "page-first": "1",
    "note": "ISSN: null",
    "_line": "FormalReview.bib:4969"
  },
  "protzenko_formally_2019": {
    "id": "protzenko_formally_2019",
    "type": "paper-conference",
    "author": [
      {
        "family": "Protzenko",
        "given": "Jonathan"
      },
      {
        "family": "Beurdouche",
        "given": "Benjamin"
      },
      {
        "family": "Merigoux",
        "given": "Denis"
      },
      {
        "family": "Bhargavan",
        "given": "Karthikeyan"
      }
    ],
    "title": "Formally Verified Cryptographic Web Applications in WebAssembly",
    "container-title": "2019 IEEE Symposium on Security and Privacy (SP)",
    "event-title": "2019 IEEE Symposium on Security and Privacy (SP)",
    "issued": {
      "date-parts": [
        [
          "2019",
          "5"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "11",
          "26"
        ]
      ]
    },
    "publisher": "IEEE",
    "isbn": "978-1-5386-6660-9",
    "abstract": "After suffering decades of high-proﬁle attacks, the need for formal veriﬁcation of security-critical software has never been clearer. Veriﬁcation-oriented programming languages like F∗ are now being used to build high-assurance cryptographic libraries and implementations of standard protocols like TLS. In this paper, we seek to apply these veriﬁcation techniques to modern Web applications, like WhatsApp, that embed sophisticated custom cryptographic components. The problem is that these components are often implemented in JavaScript, a language that is both hostile to cryptographic code and hard to reason about. So we instead target WebAssembly, a new instruction set that is supported by all major JavaScript runtimes.",
    "URL": "https://ieeexplore.ieee.org/document/8835291/",
    "DOI": "10.1109/SP.2019.00064",
    "publisher-place": "San Francisco, CA, USA",
    "page": "1256-1274",
    "page-first": "1256",
    "language": "en-US",
    "_line": "FormalReview.bib:4982"
  },
  "giuffrida_safe_2014": {
    "id": "giuffrida_safe_2014",
    "type": "thesis",
    "genre": "phdthesis",
    "author": [
      {
        "family": "Giuffrida",
        "given": "C"
      }
    ],
    "title": "Safe and automatic live update",
    "issued": {
      "date-parts": [
        [
          "2014"
        ]
      ]
    },
    "note": "OCLC: 876276706",
    "language": "en-US",
    "_line": "FormalReview.bib:5000"
  },
  "giuffrida_safe_2013": {
    "id": "giuffrida_safe_2013",
    "type": "article-journal",
    "author": [
      {
        "family": "Giuffrida",
        "given": "Cristiano"
      },
      {
        "family": "Kuijsten",
        "given": "Anton"
      },
      {
        "family": "Tanenbaum",
        "given": "Andrew S."
      },
      {
        "family": "Giuffrida",
        "given": "Cristiano"
      },
      {
        "family": "Kuijsten",
        "given": "Anton"
      },
      {
        "family": "Tanenbaum",
        "given": "Andrew S."
      },
      {
        "family": "Giuffrida",
        "given": "Cristiano"
      },
      {
        "family": "Kuijsten",
        "given": "Anton"
      },
      {
        "family": "Tanenbaum",
        "given": "Andrew S."
      }
    ],
    "title": "Safe and automatic live update for operating systems",
    "container-title": "ACM SIGARCH Computer Architecture News",
    "issued": {
      "date-parts": [
        [
          "2013",
          "3",
          "16"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "12",
          "4"
        ]
      ]
    },
    "issn": "0163-5964, 0362-1340",
    "URL": "http://dl.acm.org/citation.cfm?id=2451116.2451147",
    "DOI": "10.1145/2451116.2451147",
    "page": "279-292",
    "page-first": "279",
    "volume": "41",
    "issue": "1",
    "_line": "FormalReview.bib:5010"
  },
  "bourque_guide_2014": {
    "id": "bourque_guide_2014",
    "type": "book",
    "author": [
      {
        "family": "IEEE Computer Society"
      }
    ],
    "editor": [
      {
        "family": "Bourque",
        "given": "Pierre"
      },
      {
        "family": "Fairley",
        "given": "R. E"
      }
    ],
    "title": "Guide to the software engineering body of knowledge",
    "issued": {
      "date-parts": [
        [
          "2014"
        ]
      ]
    },
    "isbn": "978-0-7695-5166-1",
    "note": "OCLC: 973217192",
    "language": "en-US",
    "_line": "FormalReview.bib:5025"
  },
  "noauthor_rems:_nodate": {
    "id": "noauthor_rems:_nodate",
    "type": "webpage",
    "title": "REMS: Rigorous Engineering of Mainsteam Systems, Papers",
    "accessed": {
      "date-parts": [
        [
          "2019",
          "12",
          "27"
        ]
      ]
    },
    "URL": "https://www.cl.cam.ac.uk/~pes20/rems/rems-all.html",
    "_line": "FormalReview.bib:5036"
  },
  "ford_specification-based_1997": {
    "id": "ford_specification-based_1997",
    "type": "paper-conference",
    "author": [
      {
        "family": "Ford",
        "given": "R.L."
      },
      {
        "family": "Simon",
        "given": "R.T."
      },
      {
        "family": "Bevier",
        "given": "W.R."
      },
      {
        "family": "Smith",
        "given": "L.M."
      }
    ],
    "title": "The specification-based testing of a trusted kernel: MK++",
    "container-title": "First IEEE International Conference on Formal Engineering Methods",
    "container-title-short": "The specification-based testing of a trusted kernel",
    "title-short": "The specification-based testing of a trusted kernel",
    "event-title": "First IEEE International Conference on Formal Engineering Methods",
    "issued": {
      "date-parts": [
        [
          "1997",
          "11"
        ]
      ]
    },
    "abstract": "The MK++ kernel, a descendant of Mach, was designed and implemented at the Open Group Research Institute. Independently, Computational Logic Inc. had developed a formal specification for the Mach kernel interface. We report on the adaptation of this specification to MK++, and its use in the derivation of a testing strategy for the MK++ implementation. The results and utility of the tests are discussed.",
    "keywords": "formal specification, Computer bugs, Logic, Formal specifications, program testing, Atomic layer deposition, Kernel, Law, Legal factors, Mach kernel interface, MK++ implementation, MK++ kernel, operating system kernels, Performance evaluation, software reliability, specification based testing, System testing, testing strategy, trusted kernel, Yarn",
    "DOI": "10.1109/ICFEM.1997.630422",
    "page": "151-160",
    "page-first": "151",
    "note": "ISSN: null",
    "_line": "FormalReview.bib:5043"
  },
  "lamport_pretending_2005": {
    "id": "lamport_pretending_2005",
    "type": "webpage",
    "author": [
      {
        "family": "Lamport",
        "given": "Leslie"
      },
      {
        "family": "Schneider",
        "given": "Fred B"
      }
    ],
    "title": "Pretending Atomicity, Digital Systems Research Center: Report 44",
    "container-title-short": "Pretending Atomicity",
    "title-short": "Pretending Atomicity",
    "issued": {
      "date-parts": [
        [
          "2005",
          "12",
          "27"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "12",
          "30"
        ]
      ]
    },
    "abstract": "We present a theorem for deriving properties of a concurrent program by reasoning about a simpler, coarser-grained version. The theorem generalizes a result that Lipton proved for partial correctness and deadlock-freedom. Our theorem applies to all safety properties.",
    "URL": "https://web.archive.org/web/20051227134748/http://gatekeeper.research.compaq.com/pub/DEC/SRC/research-reports/abstracts/src-rr-044.html",
    "_line": "FormalReview.bib:5058"
  },
  "liu_virtual_2019": {
    "id": "liu_virtual_2019",
    "type": "article-journal",
    "author": [
      {
        "family": "Liu",
        "given": "Mengqi"
      },
      {
        "family": "Rieg",
        "given": "Lionel"
      },
      {
        "family": "Shao",
        "given": "Zhong"
      },
      {
        "family": "Gu",
        "given": "Ronghui"
      },
      {
        "family": "Costanzo",
        "given": "David"
      },
      {
        "family": "Kim",
        "given": "Jung-Eun"
      },
      {
        "family": "Yoon",
        "given": "Man-Ki"
      }
    ],
    "title": "Virtual timeline: a formal abstraction for verifying preemptive schedulers with temporal isolation",
    "container-title": "Proceedings of the ACM on Programming Languages",
    "container-title-short": "Virtual timeline",
    "title-short": "Virtual timeline",
    "issued": {
      "date-parts": [
        [
          "2019",
          "12",
          "20"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "12",
          "31"
        ]
      ]
    },
    "issn": "24751421",
    "URL": "http://dl.acm.org/citation.cfm?doid=3377388.3371088",
    "DOI": "10.1145/3371088",
    "page": "1-31",
    "page-first": "1",
    "volume": "4",
    "language": "en-US",
    "_line": "FormalReview.bib:5069"
  },
  "shin_wormspace:_2019": {
    "id": "shin_wormspace:_2019",
    "type": "paper-conference",
    "author": [
      {
        "family": "Shin",
        "given": "Ji-Yong"
      },
      {
        "family": "Kim",
        "given": "Jieung"
      },
      {
        "family": "Honoré",
        "given": "Wolf"
      },
      {
        "family": "Vanzetto",
        "given": "Hernán"
      },
      {
        "family": "Radhakrishnan",
        "given": "Srihari"
      },
      {
        "family": "Balakrishnan",
        "given": "Mahesh"
      },
      {
        "family": "Shao",
        "given": "Zhong"
      }
    ],
    "title": "WormSpace: A Modular Foundation for Simple, Verifiable Distributed Systems",
    "container-title": "Proceedings of the ACM Symposium on Cloud Computing  - SoCC '19",
    "container-title-short": "WormSpace",
    "title-short": "WormSpace",
    "event-title": "the ACM Symposium",
    "issued": {
      "date-parts": [
        [
          "2019"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2019",
          "12",
          "31"
        ]
      ]
    },
    "publisher": "ACM Press",
    "isbn": "978-1-4503-6973-2",
    "abstract": "We propose the Write-Once Register (WOR) as an abstraction for building and verifying distributed systems. A WOR exposes a simple, data-centric API: clients can capture, write, and read it. Applications can use a sequence or a set of WORs to obtain properties such as durability, concurrency control, and failure atomicity. By hiding the logic for distributed coordination underneath a data-centric API, the WOR abstraction enables easy, incremental, and extensible implementation and verification of applications built above it. We present the design, implementation, and verification of a system called WormSpace that provides developers with an address space of WORs, implementing each WOR via a Paxos instance. We describe three applications built over WormSpace: a flexible, efficient Multi-Paxos implementation; a shared log implementation with lower append latency than the state-of-the-art; and a faulttolerant transaction coordinator that uses an optimal number of round-trips. We show that these applications are simple, easy to verify, and match the performance of unverified monolithic implementations. We use a modular layered verification approach to link the proofs for WormSpace, its applications, and a verified operating system to produce the first verified distributed system stack from the application to the operating system.",
    "URL": "http://dl.acm.org/citation.cfm?doid=3357223.3362739",
    "DOI": "10.1145/3357223.3362739",
    "publisher-place": "Santa Cruz, CA, USA",
    "page": "299-311",
    "page-first": "299",
    "language": "en-US",
    "_line": "FormalReview.bib:5086"
  },
  "kennedy_types_2010": {
    "id": "kennedy_types_2010",
    "type": "chapter",
    "author": [
      {
        "family": "Kennedy",
        "given": "Andrew"
      }
    ],
    "editor": [
      {
        "family": "Horváth",
        "given": "Zoltán"
      },
      {
        "family": "Plasmeijer",
        "given": "Rinus"
      },
      {
        "family": "Zsók",
        "given": "Viktória"
      }
    ],
    "title": "Types for Units-of-Measure: Theory and Practice",
    "container-title": "Central European Functional Programming School: Third Summer School, CEFP 2009, Budapest, Hungary, May 21-23, 2009 and Komárno, Slovakia, May 25-30, 2009, Revised Selected Lectures",
    "container-title-short": "Types for Units-of-Measure",
    "collection-title": "Lecture Notes in Computer Science",
    "title-short": "Types for Units-of-Measure",
    "issued": {
      "date-parts": [
        [
          "2010"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2020",
          "1",
          "1"
        ]
      ]
    },
    "publisher": "Springer",
    "isbn": "978-3-642-17685-2",
    "abstract": "Units-of-measure are to science what types are to programming. In science and engineering, dimensional and unit consistency provides a first check on the correctness of an equation or formula, just as in programming the validation of a program by the type-checker eliminates one possible reason for failure.",
    "keywords": "Equational Theory, Inference Algorithm, Type Inference, Type Scheme, Type System",
    "URL": "https://doi.org/10.1007/978-3-642-17685-2_8",
    "DOI": "10.1007/978-3-642-17685-2_8",
    "publisher-place": "Berlin, Heidelberg",
    "page": "268-305",
    "page-first": "268",
    "language": "en-US",
    "_line": "FormalReview.bib:5105"
  },
  "noauthor_acsl_nodate": {
    "id": "noauthor_acsl_nodate",
    "type": "webpage",
    "title": "ACSL by Example.GitHub",
    "accessed": {
      "date-parts": [
        [
          "2020",
          "1",
          "10"
        ]
      ]
    },
    "abstract": "Public snapshots of \"ACSL by Example\". Contribute to fraunhoferfokus/acsl-by-example development by creating an account on GitHub.",
    "URL": "https://github.com/fraunhoferfokus/acsl-by-example",
    "language": "en-US",
    "_line": "FormalReview.bib:5126"
  },
  "noauthor_iris_nodate": {
    "id": "noauthor_iris_nodate",
    "type": "webpage",
    "title": "Iris / stdpp.GitLab",
    "accessed": {
      "date-parts": [
        [
          "2020",
          "1",
          "10"
        ]
      ]
    },
    "abstract": "An extended \"Standard Library\" for Coq. \\[\\[coqdoc\\]\\](https://plv.mpi-sws.org/coqdoc/stdpp/)",
    "URL": "https://gitlab.mpi-sws.org/iris/stdpp",
    "language": "en-US",
    "_line": "FormalReview.bib:5136"
  },
  "noauthor_coqeal_2020": {
    "id": "noauthor_coqeal_2020",
    "type": "book",
    "title": "CoqEAL",
    "issued": {
      "date-parts": [
        [
          "2020",
          "1",
          "8"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2020",
          "1",
          "10"
        ]
      ]
    },
    "publisher": "CoqEAL",
    "abstract": "CoqEAL &ndash; The Coq Effective Algebra Library. Contribute to CoqEAL/CoqEAL development by creating an account on GitHub.",
    "URL": "https://github.com/CoqEAL/CoqEAL",
    "note": "original-date: 2014-02-10T12:35:29Z",
    "_line": "FormalReview.bib:5146"
  },
  "noauthor_event-b_nodate": {
    "id": "noauthor_event-b_nodate",
    "type": "webpage",
    "title": "Event-B and the Rodin Platform",
    "accessed": {
      "date-parts": [
        [
          "2020",
          "1",
          "10"
        ]
      ]
    },
    "URL": "http://www.event-b.org/",
    "_line": "FormalReview.bib:5156"
  },
  "noauthor_theorem_nodate": {
    "id": "noauthor_theorem_nodate",
    "type": "webpage",
    "title": "Theorem Proving in Lean — Theorem Proving in Lean 3.4.0 documentation",
    "accessed": {
      "date-parts": [
        [
          "2020",
          "1",
          "10"
        ]
      ]
    },
    "URL": "https://leanprover.github.io/theorem_proving_in_lean/index.html",
    "_line": "FormalReview.bib:5163"
  },
  "shafiq_integrating_2014": {
    "id": "shafiq_integrating_2014",
    "type": "article-journal",
    "author": [
      {
        "family": "Shafiq",
        "given": "Shagufta"
      },
      {
        "family": "Minhas",
        "given": "Nasir Mehmood"
      }
    ],
    "title": "Integrating Formal Methods in XP—A Conceptual Solution",
    "container-title": "Journal of Software Engineering and Applications",
    "issued": {
      "date-parts": [
        [
          "2014"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2020",
          "1",
          "10"
        ]
      ]
    },
    "issn": "1945-3116, 1945-3124",
    "URL": "http://www.scirp.org/journal/doi.aspx?DOI=10.4236/jsea.2014.74029",
    "DOI": "10.4236/jsea.2014.74029",
    "page": "299-310",
    "page-first": "299",
    "volume": "07",
    "issue": "4",
    "_line": "FormalReview.bib:5170"
  },
  "ullrich_counting_2019": {
    "id": "ullrich_counting_2019",
    "type": "article-journal",
    "author": [
      {
        "family": "Ullrich",
        "given": "Sebastian"
      },
      {
        "family": "Moura",
        "given": "Leonardo",
        "dropping-particle": "de"
      }
    ],
    "title": "Counting Immutable Beans: Reference Counting Optimized for Purely Functional Programming",
    "container-title": "arXiv:1908.05647 \\[cs\\]",
    "container-title-short": "Counting Immutable Beans",
    "title-short": "Counting Immutable Beans",
    "issued": {
      "date-parts": [
        [
          "2019",
          "9",
          "3"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2020",
          "1",
          "10"
        ]
      ]
    },
    "abstract": "Most functional languages rely on some garbage collection for automatic memory management. They usually eschew reference counting in favor of a tracing garbage collector, which has less bookkeeping overhead at runtime. On the other hand, having an exact reference count of each value can enable optimizations, such as destructive updates. We explore these optimization opportunities in the context of an eager, purely functional programming language. We propose a new mechanism for efficiently reclaiming memory used by nonshared values, reducing stress on the global memory allocator. We describe an approach for minimizing the number of reference counts updates using borrowed references and a heuristic for automatically inferring borrow annotations. We implemented all these techniques in a new compiler for an eager and purely functional programming language with support for multi-threading. Our preliminary experimental results demonstrate our approach is competitive and often outperforms state-of-the-art compilers.",
    "keywords": "Computer Science - Programming Languages",
    "URLtext": "1908.05647",
    "URLpretext": "[arXiv:]{.etype}",
    "eprint-type": "arxiv",
    "eprint": "1908.05647",
    "URL": "http://arxiv.org/abs/1908.05647",
    "_line": "FormalReview.bib:5185"
  },
  "carneiro_metamath_2020": {
    "id": "carneiro_metamath_2020",
    "type": "book",
    "author": [
      {
        "family": "Carneiro",
        "given": "Mario"
      }
    ],
    "title": "Metamath Zero",
    "issued": {
      "date-parts": [
        [
          "2020",
          "1",
          "10"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2020",
          "1",
          "10"
        ]
      ]
    },
    "abstract": "Metamath Zero specification language. Contribute to digama0/mm0 development by creating an account on GitHub.",
    "URL": "https://github.com/digama0/mm0",
    "note": "original-date: 2019-02-25T07:34:19Z",
    "_line": "FormalReview.bib:5200"
  },
  "carneiro_type_2019": {
    "id": "carneiro_type_2019",
    "type": "article-journal",
    "author": [
      {
        "family": "Carneiro",
        "given": "Mario"
      }
    ],
    "title": "The Type Theory of Lean",
    "issued": {
      "date-parts": [
        [
          "2019",
          "4",
          "16"
        ]
      ]
    },
    "URL": "https://github.com/digama0/lean-type-theory/releases/download/v1.0/main.pdf",
    "_line": "FormalReview.bib:5211"
  },
  "carneiro_specifying_2019": {
    "id": "carneiro_specifying_2019",
    "type": "article-journal",
    "author": [
      {
        "family": "Carneiro",
        "given": "Mario"
      }
    ],
    "title": "Specifying verified x86 software from scratch",
    "container-title": "arXiv:1907.01283 \\[cs\\]",
    "issued": {
      "date-parts": [
        [
          "2019",
          "7",
          "2"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2020",
          "1",
          "10"
        ]
      ]
    },
    "abstract": "We present a simple framework for specifying and proving facts about the input/output behavior of ELF binary files on the x86-64 architecture. A strong emphasis has been placed on simplicity at all levels: the specification says only what it needs to about the target executable, the specification is performed inside a simple logic (equivalent to first-order Peano Arithmetic), and the verification language and proof checker are custom-designed to have only what is necessary to perform efficient general purpose verification. This forms a part of the Metamath Zero project, to build a minimal verifier that is capable of verifying its own binary. In this paper, we will present the specification of the dynamic semantics of x86 machine code, together with enough information about Linux system calls to perform simple IO.",
    "keywords": "Computer Science - Logic in Computer Science, 68Q60 (Primary) 68N30 (Secondary)",
    "URLtext": "1907.01283",
    "URLpretext": "[arXiv:]{.etype}",
    "eprint-type": "arxiv",
    "eprint": "1907.01283",
    "URL": "http://arxiv.org/abs/1907.01283",
    "_line": "FormalReview.bib:5219"
  },
  "avigad_data_2019": {
    "id": "avigad_data_2019",
    "type": "article-journal",
    "author": [
      {
        "family": "Avigad",
        "given": "Jeremy"
      },
      {
        "family": "Carneiro",
        "given": "Mario"
      },
      {
        "family": "Hudon",
        "given": "Simon"
      }
    ],
    "title": "Data Types as Quotients of Polynomial Functors",
    "container-title": "Schloss Dagstuhl - Leibniz-Zentrum fuer Informatik GmbH, Wadern/Saarbruecken, Germany",
    "issued": {
      "date-parts": [
        [
          "2019"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2020",
          "1",
          "10"
        ]
      ]
    },
    "abstract": "A broad class of data types, including arbitrary nestings of inductive types, coinductive types, and quotients, can be represented as quotients of polynomial functors. This provides perspicuous ways of constructing them and reasoning about them in an interactive theorem prover.",
    "URL": "http://drops.dagstuhl.de/opus/volltexte/2019/11061/",
    "DOI": "10.4230/lipics.itp.2019.6",
    "language": "en-US",
    "_line": "FormalReview.bib:5233"
  },
  "bolignano_proven_2016": {
    "id": "bolignano_proven_2016",
    "type": "article-journal",
    "author": [
      {
        "family": "Bolignano",
        "given": "Dominique"
      }
    ],
    "title": "Proven Security for the Internet of Things",
    "issued": {
      "date-parts": [
        [
          "2016"
        ]
      ]
    },
    "abstract": "The large-scale deployment of the Internet of Things will not be possible without resolving current security issues and challenges. We believe this can be addressed using a few key security software components and will illustrate this using representative examples drawn mainly from the connected car use case.",
    "page": "11",
    "page-first": "11",
    "language": "en-US",
    "_line": "FormalReview.bib:5246"
  },
  "noauthor_xetex_nodate": {
    "id": "noauthor_xetex_nodate",
    "type": "webpage",
    "title": "XeTeX - TeX Users Group",
    "accessed": {
      "date-parts": [
        [
          "2020",
          "1",
          "10"
        ]
      ]
    },
    "URL": "https://tug.org/xetex/",
    "_line": "FormalReview.bib:5256"
  },
  "kennedy_types_2010-1": {
    "id": "kennedy_types_2010-1",
    "type": "chapter",
    "author": [
      {
        "family": "Kennedy",
        "given": "Andrew"
      }
    ],
    "editor": [
      {
        "family": "Horváth",
        "given": "Zoltán"
      },
      {
        "family": "Plasmeijer",
        "given": "Rinus"
      },
      {
        "family": "Zsók",
        "given": "Viktória"
      }
    ],
    "title": "Types for Units-of-Measure: Theory and Practice",
    "container-title": "Central European Functional Programming School: Third Summer School, CEFP 2009, Budapest, Hungary, May 21-23, 2009 and Komárno, Slovakia, May 25-30, 2009, Revised Selected Lectures",
    "container-title-short": "Types for Units-of-Measure",
    "collection-title": "Lecture Notes in Computer Science",
    "title-short": "Types for Units-of-Measure",
    "issued": {
      "date-parts": [
        [
          "2010"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2020",
          "1",
          "10"
        ]
      ]
    },
    "publisher": "Springer",
    "isbn": "978-3-642-17685-2",
    "abstract": "Units-of-measure are to science what types are to programming. In science and engineering, dimensional and unit consistency provides a first check on the correctness of an equation or formula, just as in programming the validation of a program by the type-checker eliminates one possible reason for failure.",
    "keywords": "Equational Theory, Inference Algorithm, Type Inference, Type Scheme, Type System",
    "URL": "https://doi.org/10.1007/978-3-642-17685-2_8",
    "DOI": "10.1007/978-3-642-17685-2_8",
    "publisher-place": "Berlin, Heidelberg",
    "page": "268-305",
    "page-first": "268",
    "language": "en-US",
    "_line": "FormalReview.bib:5263"
  },
  "goossens_xetex_nodate": {
    "id": "goossens_xetex_nodate",
    "type": "article-journal",
    "author": [
      {
        "family": "Goossens",
        "given": "Michel"
      }
    ],
    "title": "The XeTeX Companion: TeX meets OpenType and Unicode",
    "page": "112",
    "page-first": "112",
    "language": "en-US",
    "_line": "FormalReview.bib:5283"
  },
  "noauthor_texmaker_nodate": {
    "id": "noauthor_texmaker_nodate",
    "type": "webpage",
    "title": "Texmaker (free cross-platform latex editor)",
    "accessed": {
      "date-parts": [
        [
          "2020",
          "1",
          "10"
        ]
      ]
    },
    "URL": "https://www.xm1math.net/texmaker/doc.html",
    "_line": "FormalReview.bib:5291"
  },
  "noauthor_galois_nodate": {
    "id": "noauthor_galois_nodate",
    "type": "motion-picture",
    "title": "Galois, Inc. Tech Talk: JaVerT: a JavaScript Verification Toolchain (Dr. Philippa Gardner)",
    "container-title-short": "Galois, Inc. Tech Talk",
    "title-short": "Galois, Inc. Tech Talk",
    "accessed": {
      "date-parts": [
        [
          "2020",
          "1",
          "10"
        ]
      ]
    },
    "abstract": "Abstract:\n\nThe dynamic nature of JavaScript and its complex semantics make it a difficult target for logic-based verification. In this talk, I will describe JaVerT, a semi-automatic JavaScript Verification Toolchain\nbased on separation logic. JaVerT is aimed at the specialist developer wanting rich, mechanically verified specifications of critical JavaScript code. The specification challenge is to design specifications that are readable by developers. The verification challenge is to handle the complex, dynamic nature of JavaScript\nwithout simplification. The validation challenge is to understand what it means for the verification to be trusted.\n\nBio:\n\nPhilippa Gardner is a professor in the Department of Computing at Imperial College London and leader of the research group working on Verified Trustworthy Software Specification. Her current research focusses on reasoning about web programs (JavaScript and DOM); and reasoning about concurrent programs. \nShe completed her PhD thesis, supervised by Professor Gordon Plotkin FRS at Edinburgh in 1992. She moved to Cambridge in 1998 on an EPSRC Advanced Fellowship, hosted by Professor Robin Milner FRS. She obtained a lectureship at Imperial in 2001, and became professor in 2009. She held a Microsoft Research Cambridge/Royal Academy of Engineering Senior Fellowship from 2005 to 2010 at Imperial.\n\nPhilippa directs the Research Institute on Verified Trustworthy Software Systems (VeTSS), funded by EPSRC, from 2017 to 2022. She also chairs the BCS awards committee, which decides the Lovelace medal (senior) and Roger Needham award (mid-career) for computer science and engineering.",
    "URL": "https://www.youtube.com/watch?v=uNVAmCYL1Jo",
    "_line": "FormalReview.bib:5298"
  },
  "devai_embedding_2009": {
    "id": "devai_embedding_2009",
    "type": "paper-conference",
    "author": [
      {
        "family": "Dévai",
        "given": "Gergely"
      }
    ],
    "title": "Embedding a Proof System in Haskell",
    "container-title": "Central European Functional Programming School",
    "event-title": "Central European Functional Programming School",
    "issued": {
      "date-parts": [
        [
          "2009",
          "5",
          "21"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2020",
          "1",
          "10"
        ]
      ]
    },
    "publisher": "Springer, Berlin, Heidelberg",
    "abstract": "This article reports about a work-in-progress project that aims at embedding a proof system \\[4\\] in the Haskellprogramming language. The goal of the system is to create formally verified software...",
    "URL": "http://link.springer.com/chapter/10.1007/978-3-642-17685-2_10",
    "DOI": "10.1007/978-3-642-17685-2_10",
    "page": "354-371",
    "page-first": "354",
    "language": "en-US",
    "_line": "FormalReview.bib:5317"
  },
  "noauthor_etaps_nodate": {
    "id": "noauthor_etaps_nodate",
    "type": "webpage",
    "title": "ETAPS 2020",
    "accessed": {
      "date-parts": [
        [
          "2020",
          "1",
          "10"
        ]
      ]
    },
    "URL": "https://www.etaps.org/",
    "_line": "FormalReview.bib:5333"
  },
  "lombardi_commutative_2015": {
    "id": "lombardi_commutative_2015",
    "type": "article-journal",
    "author": [
      {
        "family": "Lombardi",
        "given": "Henri"
      },
      {
        "family": "Quitté",
        "given": "Claude"
      }
    ],
    "title": "Commutative algebra: Constructive methods. Finite projective modules",
    "container-title": "arXiv:1605.04832 \\[math\\]",
    "container-title-short": "Commutative algebra",
    "title-short": "Commutative algebra",
    "issued": {
      "date-parts": [
        [
          "2015"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2020",
          "1",
          "10"
        ]
      ]
    },
    "abstract": "This book is an introductory course to basic commutative algebra with a particular emphasis on finitely generated projective modules. We adopt the constructive point of view, with which all existence theorems have an explicit algorithmic content content. In particular, when a theorem affirms the existence of an object &ndash; the solution of a problem &ndash; a construction algorithm of the object can always be extracted from the given proof. We revisit with a new and often simplifying eye several abstract classical theories. In particular, we review theories which did not have any algorithmic content in their general natural framework, such as Galois theory, the Dedekind domains, the finitely generated projective modules or the Krull dimension.",
    "keywords": "13-02 (13C10), Mathematics - Commutative Algebra",
    "URLtext": "1605.04832",
    "URLpretext": "[arXiv:]{.etype}",
    "eprint-type": "arxiv",
    "eprint": "1605.04832",
    "URL": "http://arxiv.org/abs/1605.04832",
    "DOI": "10.1007/978-94-017-9944-7",
    "volume": "20",
    "_line": "FormalReview.bib:5340"
  },
  "noauthor_eacsl_nodate": {
    "id": "noauthor_eacsl_nodate",
    "type": "webpage",
    "title": "EACSL – European Association for Computer Science Logic",
    "accessed": {
      "date-parts": [
        [
          "2020",
          "1",
          "10"
        ]
      ]
    },
    "URL": "https://www.eacsl.org/",
    "language": "en-US",
    "_line": "FormalReview.bib:5357"
  },
  "leslie-hurd_joe_nodate": {
    "id": "leslie-hurd_joe_nodate",
    "type": "webpage",
    "author": [
      {
        "family": "Leslie-Hurd",
        "given": "Joe"
      }
    ],
    "title": "Joe Leslie-Hurd - Gilith",
    "accessed": {
      "date-parts": [
        [
          "2020",
          "1",
          "10"
        ]
      ]
    },
    "abstract": "Has Opentheory, Metis, and Chess as well as other links.",
    "URL": "http://www.gilith.com/",
    "_line": "FormalReview.bib:5365"
  },
  "noauthor_opentheory_nodate": {
    "id": "noauthor_opentheory_nodate",
    "type": "webpage",
    "title": "OpenTheory Project - Gilith",
    "accessed": {
      "date-parts": [
        [
          "2020",
          "1",
          "10"
        ]
      ]
    },
    "URL": "http://www.gilith.com/opentheory/",
    "_line": "FormalReview.bib:5374"
  },
  "noauthor_metis_nodate": {
    "id": "noauthor_metis_nodate",
    "type": "webpage",
    "title": "Metis Theorem Prover - Gilith",
    "accessed": {
      "date-parts": [
        [
          "2020",
          "1",
          "10"
        ]
      ]
    },
    "URL": "http://www.gilith.com/metis/",
    "_line": "FormalReview.bib:5381"
  },
  "bobaru_opentheory_2011": {
    "id": "bobaru_opentheory_2011",
    "type": "chapter",
    "author": [
      {
        "family": "Hurd",
        "given": "Joe"
      }
    ],
    "editor": [
      {
        "family": "Bobaru",
        "given": "Mihaela"
      },
      {
        "family": "Havelund",
        "given": "Klaus"
      },
      {
        "family": "Holzmann",
        "given": "Gerard J."
      },
      {
        "family": "Joshi",
        "given": "Rajeev"
      }
    ],
    "title": "The OpenTheory Standard Theory Library",
    "container-title": "NASA Formal Methods",
    "issued": {
      "date-parts": [
        [
          "2011"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2020",
          "1",
          "10"
        ]
      ]
    },
    "publisher": "Springer Berlin Heidelberg",
    "isbn": "978-3-642-20397-8 978-3-642-20398-5",
    "abstract": "Interactive theorem proving is tackling ever larger formalization and veriﬁcation projects, and there is a critical need for theory engineering techniques to support these eﬀorts. One such technique is cross-prover package management, which has the potential to simplify the development of logical theories and eﬀectively share theories between diﬀerent theorem prover implementations. The OpenTheory project has developed standards for packaging theories of the higher order logic implemented by the HOL family of theorem provers. What is currently missing is a standard theory library that can serve as a published contract of interoperability and contain proofs of basic properties that would otherwise appear in many theory packages. The core contribution of this paper is the presentation of a standard theory library for higher order logic represented as an OpenTheory package. We identify the core theory set of the HOL family of theorem provers, and describe the process of instrumenting the HOL Light theorem prover to extract a standardized version of its core theory development. We proﬁle the axioms and theorems of our standard theory library and investigate the performance cost of separating the standard theory library into coherent hierarchical theory packages.",
    "URL": "http://link.springer.com/10.1007/978-3-642-20398-5_14",
    "DOI": "10.1007/978-3-642-20398-5_14",
    "publisher-place": "Berlin, Heidelberg",
    "page": "177-191",
    "page-first": "177",
    "volume": "6617",
    "language": "en-US",
    "_line": "FormalReview.bib:5388"
  },
  "noauthor_proofpower_nodate": {
    "id": "noauthor_proofpower_nodate",
    "type": "webpage",
    "title": "The ProofPower Web Pages",
    "accessed": {
      "date-parts": [
        [
          "2020",
          "1",
          "10"
        ]
      ]
    },
    "URL": "http://www.lemma-one.com/ProofPower/index/",
    "_line": "FormalReview.bib:5407"
  },
  "joe_leslie-hurd_slowest_2015": {
    "id": "joe_leslie-hurd_slowest_2015",
    "type": "webpage",
    "author": [
      {
        "family": "Joe Leslie-Hurd"
      }
    ],
    "title": "The Slowest Software Development Methodology in the World.The Robot Mathematician",
    "issued": {
      "date-parts": [
        [
          "2015",
          "7",
          "19"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2020",
          "1",
          "10"
        ]
      ]
    },
    "abstract": "For some time now I’ve been practicing what can only be described as the slowest software development methodology in the world: a three step waltz of Prototyping, Verification and Export. Pro…",
    "URL": "https://gilith.wordpress.com/2015/07/19/the-slowest-software-development-methodology-in-the-world/",
    "language": "en-US",
    "_line": "FormalReview.bib:5414"
  },
  "noauthor_ats_nodate": {
    "id": "noauthor_ats_nodate",
    "type": "webpage",
    "title": "The ATS Programming Language",
    "accessed": {
      "date-parts": [
        [
          "2020",
          "1",
          "10"
        ]
      ]
    },
    "URL": "http://www.ats-lang.org/",
    "_line": "FormalReview.bib:5426"
  },
  "xi_applied_2017": {
    "id": "xi_applied_2017",
    "type": "article-journal",
    "author": [
      {
        "family": "Xi",
        "given": "Hongwei"
      }
    ],
    "title": "Applied Type System: An Approach to Practical Programming with Theorem-Proving",
    "container-title": "arXiv:1703.08683 \\[cs\\]",
    "container-title-short": "Applied Type System",
    "title-short": "Applied Type System",
    "issued": {
      "date-parts": [
        [
          "2017",
          "3",
          "25"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2020",
          "1",
          "10"
        ]
      ]
    },
    "abstract": "The framework Pure Type System (PTS) offers a simple and general approach to designing and formalizing type systems. However, in the presence of dependent types, there often exist certain acute problems that make it difficult for PTS to directly accommodate many common realistic programming features such as general recursion, recursive types, effects (e.g., exceptions, references, input/output), etc. In this paper, Applied Type System (ATS) is presented as a framework for designing and formalizing type systems in support of practical programming with advanced types (including dependent types). In particular, it is demonstrated that ATS can readily accommodate a paradigm referred to as programming with theorem-proving (PwTP) in which programs and proofs are constructed in a syntactically intertwined manner, yielding a practical approach to internalizing constraint-solving needed during type-checking. The key salient feature of ATS lies in a complete separation between statics, where types are formed and reasoned about, and dynamics, where programs are constructed and evaluated. With this separation, it is no longer possible for a program to occur in a type as is otherwise allowed in PTS. The paper contains not only a formal development of ATS but also some examples taken from ats-lang.org, a programming language with a type system rooted in ATS, in support of employing ATS as a framework to formulate advanced type systems for practical programming.",
    "keywords": "Computer Science - Logic in Computer Science, Computer Science - Programming Languages",
    "URLtext": "1703.08683",
    "URLpretext": "[arXiv:]{.etype}",
    "eprint-type": "arxiv",
    "eprint": "1703.08683",
    "URL": "http://arxiv.org/abs/1703.08683",
    "_line": "FormalReview.bib:5433"
  },
  "xi_introduction_nodate": {
    "id": "xi_introduction_nodate",
    "type": "article-journal",
    "author": [
      {
        "family": "Xi",
        "given": "Hongwei"
      }
    ],
    "title": "Introduction to Programming in ATS",
    "page": "252",
    "page-first": "252",
    "language": "en-US",
    "_line": "FormalReview.bib:5448"
  },
  "noauthor_hongwei_nodate": {
    "id": "noauthor_hongwei_nodate",
    "type": "webpage",
    "title": "Hongwei Xi",
    "accessed": {
      "date-parts": [
        [
          "2020",
          "1",
          "10"
        ]
      ]
    },
    "abstract": "Author of ATS",
    "URL": "http://www.cs.bu.edu/~hwxi/",
    "_line": "FormalReview.bib:5456"
  },
  "noauthor_deducteamholide_2019": {
    "id": "noauthor_deducteamholide_2019",
    "type": "book",
    "title": "Deducteam/Holide",
    "issued": {
      "date-parts": [
        [
          "2019",
          "11",
          "5"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2020",
          "1",
          "10"
        ]
      ]
    },
    "publisher": "Deducteam",
    "abstract": "A translator from OpenTheory to Dedukti. Contribute to Deducteam/Holide development by creating an account on GitHub.",
    "URL": "https://github.com/Deducteam/Holide",
    "note": "original-date: 2018-02-08T13:18:34Z",
    "_line": "FormalReview.bib:5464"
  },
  "noauthor_deducteamdedukti_2019": {
    "id": "noauthor_deducteamdedukti_2019",
    "type": "book",
    "title": "Deducteam/Dedukti",
    "issued": {
      "date-parts": [
        [
          "2019",
          "12",
          "22"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2020",
          "1",
          "10"
        ]
      ]
    },
    "publisher": "Deducteam",
    "abstract": "Implementation of the λΠ-calculus modulo rewriting",
    "URL": "https://github.com/Deducteam/Dedukti",
    "note": "original-date: 2017-11-16T15:34:07Z",
    "_line": "FormalReview.bib:5474"
  },
  "noauthor_dedukti_nodate": {
    "id": "noauthor_dedukti_nodate",
    "type": "webpage",
    "title": "Dedukti - a Logical Framework",
    "accessed": {
      "date-parts": [
        [
          "2020",
          "1",
          "10"
        ]
      ]
    },
    "URL": "https://deducteam.github.io/",
    "_line": "FormalReview.bib:5484"
  },
  "assaf_dedukti_nodate": {
    "id": "assaf_dedukti_nodate",
    "type": "article-journal",
    "author": [
      {
        "family": "Assaf",
        "given": "Ali"
      },
      {
        "family": "Burel",
        "given": "Guillaume"
      },
      {
        "family": "Cauderlier",
        "given": "Raphaël"
      },
      {
        "family": "Dowek",
        "given": "Gilles"
      },
      {
        "family": "Dubois",
        "given": "Catherine"
      },
      {
        "family": "Gilbert",
        "given": "Frédéric"
      },
      {
        "family": "Halmagrand",
        "given": "Pierre"
      },
      {
        "family": "Hermant",
        "given": "Olivier"
      },
      {
        "family": "Saillard",
        "given": "Ronan"
      }
    ],
    "title": "Dedukti: a Logical Framework based on the λΠ-Calculus Modulo Theory",
    "abstract": "Dedukti is a Logical Framework based on the λΠ-Calculus Modulo Theory. We show that many theories can be expressed in Dedukti: constructive and classical predicate logic, Simple type theory, programming languages, Pure type systems, the Calculus of inductive constructions with universes, etc. and that permits to used it to check large libraries of proofs developed in other proof systems: Zenon, iProver, FoCaLiZe, HOL Light, and Matita.",
    "page": "36",
    "page-first": "36",
    "language": "en-US",
    "_line": "FormalReview.bib:5491"
  },
  "noauthor_qemu_nodate": {
    "id": "noauthor_qemu_nodate",
    "type": "webpage",
    "title": "QEMU",
    "accessed": {
      "date-parts": [
        [
          "2020",
          "1",
          "10"
        ]
      ]
    },
    "URL": "https://wiki.qemu.org/Main_Page",
    "_line": "FormalReview.bib:5500"
  },
  "noauthor_qemu_nodate-1": {
    "id": "noauthor_qemu_nodate-1",
    "type": "webpage",
    "title": "QEMU version 4.1.0 User Documentation",
    "accessed": {
      "date-parts": [
        [
          "2020",
          "1",
          "10"
        ]
      ]
    },
    "URL": "https://qemu.weilnetz.de/doc/qemu-doc.html",
    "_line": "FormalReview.bib:5507"
  },
  "scott_continuous_nodate": {
    "id": "scott_continuous_nodate",
    "type": "webpage",
    "author": [
      {
        "family": "Scott",
        "given": "Dana"
      }
    ],
    "title": "Continuous lattices.ResearchGate",
    "accessed": {
      "date-parts": [
        [
          "2020",
          "1",
          "12"
        ]
      ]
    },
    "abstract": "Starting from the topological point of view a certain wide class of To-spaces is introduced having a very strong extension property for continuous functions with values in these spaces. It is then shown that all such spaces are complete lattices whose lattice structure determines the topology — these are the continuous lattices — and every such lattice has the extension property. With this foundation the lattices are studied in detail with respect to projections, subspaces, embeddings, and constructions such as products, sums, function spaces, and inverse limits. The main result of the paper is a proof that every topological space can be embedded in a continuous lattice which is homeomorphic (and isomorphic) to its own function space. The function algebra of such spaces provides mathematical models for the Church-Curry λ-calculus.",
    "URL": "https://www.researchgate.net/publication/251394986_Continuous_lattices",
    "language": "en-US",
    "_line": "FormalReview.bib:5514"
  },
  "weisstein_mathworld_nodate": {
    "id": "weisstein_mathworld_nodate",
    "type": "webpage",
    "genre": "Text",
    "author": [
      {
        "family": "Weisstein",
        "given": "Eric W."
      }
    ],
    "title": "Mathworld Classroom",
    "accessed": {
      "date-parts": [
        [
          "2020",
          "1",
          "12"
        ]
      ]
    },
    "abstract": "Course List",
    "URL": "http://mathworld.wolfram.com/classroom/",
    "language": "en-US",
    "_line": "FormalReview.bib:5525"
  },
  "aydemir_engineering_nodate": {
    "id": "aydemir_engineering_nodate",
    "type": "article-journal",
    "author": [
      {
        "family": "Aydemir",
        "given": "Brian"
      },
      {
        "family": "Chargueraud",
        "given": "Arthur"
      },
      {
        "family": "Pierce",
        "given": "Benjamin C"
      },
      {
        "family": "Pollack",
        "given": "Randy"
      },
      {
        "family": "Weirich",
        "given": "Stephanie"
      }
    ],
    "title": "Engineering Formal Metatheory",
    "abstract": "Machine-checked proofs of properties of programming languages have become a critical need, both for increased conﬁdence in large and complex designs and as a foundation for technologies such as proof-carrying code. However, constructing these proofs remains a black art, involving many choices in the formulation of deﬁnitions and theorems that make a huge cumulative difference in the difﬁculty of carrying out large formal developments. The representation and manipulation of terms with variable binding is a key issue.",
    "page": "13",
    "page-first": "13",
    "language": "en-US",
    "_line": "FormalReview.bib:5537"
  },
  "gross_experience_2014": {
    "id": "gross_experience_2014",
    "type": "article-journal",
    "author": [
      {
        "family": "Gross",
        "given": "Jason"
      },
      {
        "family": "Chlipala",
        "given": "Adam"
      },
      {
        "family": "Spivak",
        "given": "David I."
      }
    ],
    "title": "Experience Implementing a Performant Category-Theory Library in Coq",
    "container-title": "arXiv:1401.7694 \\[cs, math\\]",
    "issued": {
      "date-parts": [
        [
          "2014",
          "4",
          "17"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2020",
          "1",
          "13"
        ]
      ]
    },
    "abstract": "We describe our experience implementing a broad categorytheory library in Coq. Category theory and computational performance are not usually mentioned in the same breath, but we have needed substantial engineering effort to teach Coq to cope with large categorical constructions without slowing proof script processing unacceptably. In this paper, we share the lessons we have learned about how to represent very abstract mathematical objects and arguments in Coq and how future proof assistants might be designed to better support such reasoning. One particular encoding trick to which we draw attention allows category-theoretic arguments involving duality to be internalized in Coq’s logic with definitional equality. Ours may be the largest Coq development to date that uses the relatively new Coq version developed by homotopy type theorists, and we reflect on which new features were especially helpful.",
    "keywords": "Computer Science - Logic in Computer Science, Mathematics - Category Theory",
    "URLtext": "1401.7694",
    "URLpretext": "[arXiv:]{.etype}",
    "eprint-type": "arxiv",
    "eprint": "1401.7694",
    "URL": "http://arxiv.org/abs/1401.7694",
    "language": "en-US",
    "_line": "FormalReview.bib:5546"
  },
  "noauthor_welcome_nodate": {
    "id": "noauthor_welcome_nodate",
    "type": "webpage",
    "title": "Welcome to dune’s documentation! — dune documentation",
    "accessed": {
      "date-parts": [
        [
          "2020",
          "1",
          "13"
        ]
      ]
    },
    "URL": "https://dune.readthedocs.io/en/stable/",
    "_line": "FormalReview.bib:5561"
  },
  "birkedal_taste_nodate": {
    "id": "birkedal_taste_nodate",
    "type": "article-journal",
    "author": [
      {
        "family": "Birkedal",
        "given": "Lars"
      }
    ],
    "title": "A Taste of Categorical Logic — Tutorial Notes",
    "page": "41",
    "page-first": "41",
    "language": "en-US",
    "_line": "FormalReview.bib:5568"
  },
  "noauthor_lambdapi_2020": {
    "id": "noauthor_lambdapi_2020",
    "type": "book",
    "title": "Lambdapi, a proof assistant based on the λΠ-calculus modulo rewriting",
    "issued": {
      "date-parts": [
        [
          "2020",
          "1",
          "10"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2020",
          "1",
          "13"
        ]
      ]
    },
    "publisher": "Deducteam",
    "abstract": "Proof assistant based on the λΠ-calculus modulo rewriting",
    "keywords": "dependent-types, logical-framework, proof-assistant, proof-checker, rewriting",
    "URL": "https://github.com/Deducteam/lambdapi",
    "note": "original-date: 2017-09-10T20:32:16Z",
    "_line": "FormalReview.bib:5576"
  },
  "noauthor_matita_nodate": {
    "id": "noauthor_matita_nodate",
    "type": "webpage",
    "title": "Matita - Interactive Theorem Prover",
    "accessed": {
      "date-parts": [
        [
          "2020",
          "1",
          "13"
        ]
      ]
    },
    "abstract": "Matita (that means pencil in italian) is an experimental, interactive theorem prover under development at the Computer Science Department of the University of Bologna.",
    "URL": "http://matita.cs.unibo.it/",
    "_line": "FormalReview.bib:5587"
  },
  "noauthor_cerco_nodate": {
    "id": "noauthor_cerco_nodate",
    "type": "webpage",
    "title": "CerCo - Certified Complexity",
    "accessed": {
      "date-parts": [
        [
          "2020",
          "1",
          "13"
        ]
      ]
    },
    "abstract": "CerCo (Certified Complexity) is a European research project in the ​7th Research Framework Programme (FP7) of the ​European Commission (project number 243381). The project is situated in the FP7 theme ​Information &amp; Communication Technologies (ICT) in the topic Future and Emerging Technologies (FET Open). The project has started February 1st, 2010, and will have a duration of 3 years.\n\nThe project aims to the construction of a formally verified complexity preserving compiler from a large subset of C to some typical microcontroller assembly, of the kind traditionally used in embedded systems. The work comprise the definition of cost models for the input and target languages, and the machine-checked proof of preservation of complexity (concrete, not asymptotic) along compilation. The compiler will also return tight and certified cost annotations for the source program, providing a reliable infrastructure to draw temporal assertions on the executable code while reasoning on the source. The compiler will be open source, and all proofs will be public domain.",
    "URL": "http://cerco.cs.unibo.it/",
    "_line": "FormalReview.bib:5595"
  },
  "saillard_typechecking_2015": {
    "id": "saillard_typechecking_2015",
    "type": "thesis",
    "genre": "phdthesis",
    "author": [
      {
        "family": "Saillard",
        "given": "Ronan"
      }
    ],
    "title": "Typechecking in the lambda-Pi-Calculus Modulo : Theory and Practice",
    "container-title-short": "Typechecking in the lambda-Pi-Calculus Modulo",
    "title-short": "Typechecking in the lambda-Pi-Calculus Modulo",
    "issued": {
      "date-parts": [
        [
          "2015",
          "9",
          "25"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2020",
          "1",
          "13"
        ]
      ]
    },
    "publisher": "Ecole Nationale Supérieure des Mines de Paris",
    "abstract": "Automatic proof checking is about using a computer to check the validity of proofs of mathematical statements. Since this verification is purely computational, it offers a high degree of confidence. Therefore, it is particularly useful for checking that a critical software, i.e., a software that when malfunctioning may result in death or serious injury to people, loss or severe damage to equipment or environmental harm, corresponds to its specification. DEDUKTI is such a proof checker. It implements a type system, the lambda-Pi-Calculus Modulo, that is an extension of the dependently-typed lambda-calculus with first-order rewrite rules. Through the Curry-Howard correspondence, DEDUKTI implements both a powerful programming language and an expressive logical system. Furthermore, this language is particularly well suited for encoding other proof systems. For instance, we can import in DEDUKTI theorems proved using other tools such as COQ, HOL or ZENON, a first step towards creating interoperability between these systems.The lambda-Pi-Calculus Modulo is a very expressive language. On the other hand, some fundamental properties such as subject reduction (i.e., the stability of typing by reduction) and uniqueness of types are not guaranteed in general and depend on the rewrite rules considered. Yet, these properties are necessary for guaranteeing the coherence of the proof system, but also for provingthe soundness and completeness of the type-checking algorithms implemented in DEDUKTI. Unfortunately, these properties are undecidable. In this thesis, we design new criteria for subject reduction and uniqueness of types that are decidable in order to be implemented in DEDUKTI.For this purpose, we give a new definition of the lambda-Pi-Calculus Modulo that takes into account the iterative aspect of the addition of rewrite rules in the typing context. A detailed study of this new system shows that the problems of subject reduction and uniqueness of types can be reduced to two simpler properties that we call product compatibility and well-typedness of rewrite rules.Hence, we study these two properties separately and give effective sufficient conditions for them to hold.These ideas have been implemented in DEDUKTI, increasing its generality and reliability.",
    "URL": "https://pastel.archives-ouvertes.fr/tel-01299180",
    "language": "en-US",
    "_line": "FormalReview.bib:5605"
  },
  "krebbers_mosel_2018": {
    "id": "krebbers_mosel_2018",
    "type": "article-journal",
    "author": [
      {
        "family": "Krebbers",
        "given": "Robbert"
      },
      {
        "family": "Jourdan",
        "given": "Jacques-Henri"
      },
      {
        "family": "Jung",
        "given": "Ralf"
      },
      {
        "family": "Tassarotti",
        "given": "Joseph"
      },
      {
        "family": "Kaiser",
        "given": "Jan-Oliver"
      },
      {
        "family": "Timany",
        "given": "Amin"
      },
      {
        "family": "Charguéraud",
        "given": "Arthur"
      },
      {
        "family": "Dreyer",
        "given": "Derek"
      }
    ],
    "title": "MoSeL: a general, extensible modal framework for interactive proofs in separation logic",
    "container-title": "Proceedings of the ACM on Programming Languages",
    "container-title-short": "MoSeL",
    "title-short": "MoSeL",
    "issued": {
      "date-parts": [
        [
          "2018",
          "7",
          "30"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2020",
          "1",
          "13"
        ]
      ]
    },
    "issn": "24751421",
    "URL": "http://dl.acm.org/citation.cfm?doid=3243631.3236772",
    "DOI": "10.1145/3236772",
    "page": "1-30",
    "page-first": "1",
    "volume": "2",
    "language": "en-US",
    "_line": "FormalReview.bib:5619"
  },
  "hutchison_embedding_2007": {
    "id": "hutchison_embedding_2007",
    "type": "chapter",
    "author": [
      {
        "family": "Cousineau",
        "given": "Denis"
      },
      {
        "family": "Dowek",
        "given": "Gilles"
      }
    ],
    "editor": [
      {
        "family": "Della Rocca",
        "given": "Simona Ronchi"
      }
    ],
    "title": "Embedding Pure Type Systems in the Lambda-Pi-Calculus Modulo",
    "container-title": "Typed Lambda Calculi and Applications",
    "issued": {
      "date-parts": [
        [
          "2007"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2020",
          "1",
          "13"
        ]
      ]
    },
    "publisher": "Springer Berlin Heidelberg",
    "isbn": "978-3-540-73227-3 978-3-540-73228-0",
    "abstract": "The lambda-Pi-calculus allows to express proofs of minimal predicate logic. It can be extended, in a very simple way, by adding computation rules. This leads to the lambda-Pi-calculus modulo. We show in this paper that this simple extension is surprisingly expressive and, in particular, that all functional Pure Type Systems, such as the system F, or the Calculus of Constructions, can be embedded in it. And, moreover, that this embedding is conservative under termination hypothesis.",
    "URL": "http://link.springer.com/10.1007/978-3-540-73228-0_9",
    "DOI": "10.1007/978-3-540-73228-0_9",
    "publisher-place": "Berlin, Heidelberg",
    "page": "102-117",
    "page-first": "102",
    "volume": "4583",
    "language": "en-US",
    "_line": "FormalReview.bib:5636"
  },
  "noauthor_introduction_nodate": {
    "id": "noauthor_introduction_nodate",
    "type": "webpage",
    "title": "Introduction to Domain Theory",
    "accessed": {
      "date-parts": [
        [
          "2020",
          "1",
          "13"
        ]
      ]
    },
    "URL": "http://www.cs.nott.ac.uk/~pszgmh/domains.html",
    "_line": "FormalReview.bib:5657"
  },
  "di_cosmo_linear_2019": {
    "id": "di_cosmo_linear_2019",
    "type": "chapter",
    "author": [
      {
        "family": "Di Cosmo",
        "given": "Roberto"
      },
      {
        "family": "Miller",
        "given": "Dale"
      }
    ],
    "editor": [
      {
        "family": "Zalta",
        "given": "Edward N."
      }
    ],
    "title": "Linear Logic",
    "container-title": "The Stanford Encyclopedia of Philosophy",
    "issued": {
      "date-parts": [
        [
          "2019"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2020",
          "1",
          "13"
        ]
      ]
    },
    "publisher": "Metaphysics Research Lab, Stanford University",
    "edition": "Summer 2019",
    "abstract": "Linear logic is a refinement of classical and intuitionistic logic.Instead of emphasizing truth, as in classical logic, orproof, as in intuitionistic logic, linear logic emphasizes therole of formulas as resources. To achieve this focus, linearlogic does not allow the usual structural rules of contraction andweakening to apply to all formulas but only those formulas marked withcertain modals. Linear logic contains a fully involutive negation whilemaintaining a strong constructive interpretation. Linear logic alsoprovides new insights into the nature of proofs in both classical andintuitionistic logic. Given its focus on resources, linear logic hasfound many applications in Computer Science.",
    "keywords": "logic: and games, logic: classical, logic: dialogical, logic: intuitionistic, logic: substructural, proof theory",
    "URL": "https://plato.stanford.edu/archives/sum2019/entries/logic-linear/",
    "_line": "FormalReview.bib:5664"
  },
  "girard_linear_1995": {
    "id": "girard_linear_1995",
    "type": "chapter",
    "author": [
      {
        "family": "Girard",
        "given": "J.-Y."
      }
    ],
    "editor": [
      {
        "family": "Girard",
        "given": "Jean-Yves"
      },
      {
        "family": "Lafont",
        "given": "Yves"
      },
      {
        "family": "Regnier",
        "given": "Laurent"
      }
    ],
    "title": "Linear Logic: its syntax and semantics",
    "container-title": "Advances in Linear Logic",
    "container-title-short": "Linear Logic",
    "title-short": "Linear Logic",
    "issued": {
      "date-parts": [
        [
          "1995"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2020",
          "1",
          "13"
        ]
      ]
    },
    "publisher": "Cambridge University Press",
    "isbn": "978-0-511-62915-0",
    "URL": "https://www.cambridge.org/core/product/identifier/CBO9780511629150A008/type/book_part",
    "DOI": "10.1017/CBO9780511629150.002",
    "publisher-place": "Cambridge",
    "page": "1-42",
    "page-first": "1",
    "language": "en-US",
    "_line": "FormalReview.bib:5679"
  },
  "noauthor_formal_nodate": {
    "id": "noauthor_formal_nodate",
    "type": "webpage",
    "title": "Formal Versus Agile: Survival of the Fittest.ResearchGate",
    "container-title-short": "(17) (PDF) Formal Versus Agile",
    "title-short": "(17) (PDF) Formal Versus Agile",
    "accessed": {
      "date-parts": [
        [
          "2020",
          "1",
          "14"
        ]
      ]
    },
    "abstract": "ResearchGate is a network dedicated to science and research. Connect, collaborate and discover scientific publications, jobs and conferences. All for free.",
    "URL": "https://www.researchgate.net/publication/224587383_Formal_Versus_Agile_Survival_of_the_Fittest",
    "language": "en-US",
    "_line": "FormalReview.bib:5697"
  },
  "birkedal_lecture_nodate": {
    "id": "birkedal_lecture_nodate",
    "type": "article-journal",
    "author": [
      {
        "family": "Birkedal",
        "given": "Lars"
      },
      {
        "family": "Bizjak",
        "given": "Aleš"
      }
    ],
    "title": "Lecture Notes on Iris: Higher-Order Concurrent Separation Logic",
    "page": "138",
    "page-first": "138",
    "language": "en-US",
    "_line": "FormalReview.bib:5708"
  },
  "bizjak_iron_2019": {
    "id": "bizjak_iron_2019",
    "type": "article-journal",
    "author": [
      {
        "family": "Bizjak",
        "given": "Aleš"
      },
      {
        "family": "Gratzer",
        "given": "Daniel"
      },
      {
        "family": "Krebbers",
        "given": "Robbert"
      },
      {
        "family": "Birkedal",
        "given": "Lars"
      }
    ],
    "title": "Iron: managing obligations in higher-order concurrent separation logic",
    "container-title": "Proceedings of the ACM on Programming Languages",
    "container-title-short": "Iron",
    "title-short": "Iron",
    "issued": {
      "date-parts": [
        [
          "2019",
          "1",
          "2"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2020",
          "1",
          "14"
        ]
      ]
    },
    "issn": "24751421",
    "URL": "http://dl.acm.org/citation.cfm?doid=3302515.3290378",
    "DOI": "10.1145/3290378",
    "page": "1-30",
    "page-first": "1",
    "volume": "3",
    "language": "en-US",
    "_line": "FormalReview.bib:5716"
  },
  "noauthor_iron_nodate": {
    "id": "noauthor_iron_nodate",
    "type": "webpage",
    "title": "Iron: Managing Obligations in Higher-Order Concurrent Separation Logic (POPL 2019)",
    "accessed": {
      "date-parts": [
        [
          "2020",
          "1",
          "14"
        ]
      ]
    },
    "URL": "https://iris-project.org/iron/",
    "_line": "FormalReview.bib:5733"
  },
  "noauthor_alloy_nodate": {
    "id": "noauthor_alloy_nodate",
    "type": "webpage",
    "title": "Alloy - software modeling",
    "accessed": {
      "date-parts": [
        [
          "2020",
          "1",
          "15"
        ]
      ]
    },
    "abstract": "Alloy is an open source language and analyzer for software modeling. It has been used in a wide range of applications, from finding holes in security mechanisms to designing telephone switching networks. This site provides language documentation, tool downloads, and a repository of links to case studies and applications. As the open source community grows, this site will also provide access to extensions of the Alloy Analyzer, and tools built on top of it and on top of Kodkod, its model finding engine.",
    "URL": "http://alloytools.org/",
    "_line": "FormalReview.bib:5740"
  },
  "adamek_abstract_2004": {
    "id": "adamek_abstract_2004",
    "type": "article-journal",
    "author": [
      {
        "family": "Adamek",
        "given": "Jiri"
      },
      {
        "family": "Herrlich",
        "given": "Horst"
      },
      {
        "family": "Strecker",
        "given": "George E"
      },
      {
        "family": "Schubert",
        "given": "Christoph"
      }
    ],
    "title": "Abstract and Concrete Categories - The Joy of Cats",
    "issued": {
      "date-parts": [
        [
          "2004",
          "1",
          "12"
        ]
      ]
    },
    "abstract": "Abstract and Concrete Categories was published by John Wiley and Sons, Inc, in 1990, and after several reprints, the book has been sold out and unavailable for several years. We now present an improved and corrected version as an open access file. This was made possible due to the return of copyright to the authors, and due to many hours of hard work and the exceptional skill of Christoph Schubert, to whom we wish to express our profound gratitude. The illustrations of Edward Gorey are unfortunately missing in the current version (for copyright reasons), but fortunately additional original illustrations by Marcel Erné, to whom additional special thanks of the authors belong, counterbalance the loss.\nOpen access includes the right of any reader to copy, store or distribute the book or parts of it freely. (See the GNU Free Documentation License at the end of the text.) Besides the acknowledgements appearing at the end of the original preface (below), we wish to thank all those who have helped to eliminate mistakes that survived the first printing of the text, particularly H. Bargenda, J. Jürjens W. Meyer, L. Schröder A. M. Torkabud, and O. Wyler.\nJanuary 12, 2004",
    "URL": "http://katmat.math.uni-bremen.de/acc/acc.pdf",
    "page": "524",
    "page-first": "524",
    "language": "en-US",
    "_line": "FormalReview.bib:5748"
  },
  "riehl_category_2017": {
    "id": "riehl_category_2017",
    "type": "book",
    "author": [
      {
        "family": "Riehl",
        "given": "Emily"
      }
    ],
    "title": "Category Theory in Context",
    "issued": {
      "date-parts": [
        [
          "2017",
          "3",
          "9"
        ]
      ]
    },
    "publisher": "Dover Publications",
    "number-of-pages": "272",
    "abstract": "Category theory has provided the foundations for many of the twentieth century's greatest advances in pure mathematics. This concise, original text for a one-semester course on the subject is derived from courses that author Emily Riehl taught at Harvard and Johns Hopkins Universities. The treatment introduces the essential concepts of category theory: categories, functors, natural transformations, the Yoneda lemma, limits and colimits, adjunctions, monads, and other topics. Suitable for advanced undergraduates and graduate students in mathematics, the text provides tools for understanding and attacking difficult problems in algebra, number theory, algebraic geometry, and algebraic topology. Drawing upon a broad range of mathematical examples from the categorical perspective, the author illustrates how the concepts and constructions of category theory arise from and illuminate more basic mathematical ideas. Prerequisites are limited to familiarity with some basic set theory and logic.",
    "_line": "FormalReview.bib:5761"
  },
  "appel_program_2014": {
    "id": "appel_program_2014",
    "type": "book",
    "author": [
      {
        "family": "Appel",
        "given": "Andrew W."
      },
      {
        "family": "Dockins",
        "given": "Robert"
      },
      {
        "family": "Hobor",
        "given": "Aquinas"
      },
      {
        "family": "Beringer",
        "given": "Lennart"
      },
      {
        "family": "Dodds",
        "given": "Josiah"
      },
      {
        "family": "Stewart",
        "given": "Gordon"
      },
      {
        "family": "Blazy",
        "given": "Sandrine"
      },
      {
        "family": "Leroy",
        "given": "Xavier"
      }
    ],
    "title": "Program Logics for Certified Compilers",
    "issued": {
      "date-parts": [
        [
          "2014",
          "4",
          "21"
        ]
      ]
    },
    "publisher": "Cambridge University Press",
    "number-of-pages": "472",
    "edition": "1 edition",
    "abstract": "Separation logic is the twenty-first-century variant of Hoare logic that permits verification of pointer-manipulating programs. This book covers practical and theoretical aspects of separation logic at a level accessible to beginning graduate students interested in software verification. On the practical side it offers an introduction to verification in Hoare and separation logics, simple case studies for toy languages, and the Verifiable C program logic for the C programming language. On the theoretical side it presents separation algebras as models of separation logics; step-indexed models of higher-order logical features for higher-order programs; indirection theory for constructing step-indexed separation algebras; tree-shares as models for shared ownership; and the semantic construction (and soundness proof) of Verifiable C. In addition, the book covers several aspects of the CompCert verified C compiler, and its connection to foundationally verified software analysis tools. All constructions and proofs are made rigorous and accessible in the Coq developments of the open-source Verified Software Toolchain.",
    "_line": "FormalReview.bib:5770"
  },
  "leinster_higher_2003": {
    "id": "leinster_higher_2003",
    "type": "article-journal",
    "author": [
      {
        "family": "Leinster",
        "given": "Tom"
      }
    ],
    "title": "Higher Operads, Higher Categories",
    "container-title": "arXiv:math/0305049",
    "issued": {
      "date-parts": [
        [
          "2003",
          "5",
          "2"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2020",
          "1",
          "15"
        ]
      ]
    },
    "abstract": "Higher-dimensional category theory is the study of n-categories, operads, braided monoidal categories, and other such exotic structures. It draws its inspiration from areas as diverse as topology, quantum algebra, mathematical physics, logic, and theoretical computer science. This is the first book on the subject and lays its foundations. Many examples are given throughout. There is also an introductory chapter motivating the subject for topologists.",
    "keywords": "Mathematics - Category Theory, Mathematics - Algebraic Geometry, Mathematics - Algebraic Topology, Mathematics - Quantum Algebra",
    "URLtext": "math/0305049",
    "URLpretext": "[arXiv:]{.etype}",
    "eprint-type": "arxiv",
    "eprint": "math/0305049",
    "URL": "http://arxiv.org/abs/math/0305049",
    "_line": "FormalReview.bib:5780"
  },
  "friedman_elementary_2016": {
    "id": "friedman_elementary_2016",
    "type": "article-journal",
    "author": [
      {
        "family": "Friedman",
        "given": "Greg"
      }
    ],
    "title": "An elementary illustrated introduction to simplicial sets",
    "container-title": "arXiv:0809.4221 \\[math\\]",
    "issued": {
      "date-parts": [
        [
          "2016",
          "10",
          "3"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2020",
          "1",
          "15"
        ]
      ]
    },
    "abstract": "This is an expository introduction to simplicial sets and simplicial homotopy theory with particular focus on relating the combinatorial aspects of the theory to their geometric/topological origins. It is intended to be accessible to students familiar with just the fundamentals of algebraic topology.",
    "keywords": "Mathematics - Category Theory, Mathematics - Algebraic Topology, 18G30, 55U10, Mathematics - Geometric Topology",
    "URLtext": "0809.4221",
    "URLpretext": "[arXiv:]{.etype}",
    "eprint-type": "arxiv",
    "eprint": "0809.4221",
    "URL": "http://arxiv.org/abs/0809.4221",
    "_line": "FormalReview.bib:5794"
  },
  "hutchison_impredicative_2014": {
    "id": "hutchison_impredicative_2014",
    "type": "chapter",
    "author": [
      {
        "family": "Svendsen",
        "given": "Kasper"
      },
      {
        "family": "Birkedal",
        "given": "Lars"
      }
    ],
    "editor": [
      {
        "family": "Shao",
        "given": "Zhong"
      }
    ],
    "title": "Impredicative Concurrent Abstract Predicates",
    "container-title": "Programming Languages and Systems",
    "issued": {
      "date-parts": [
        [
          "2014"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2020",
          "1",
          "15"
        ]
      ]
    },
    "publisher": "Springer Berlin Heidelberg",
    "isbn": "978-3-642-54832-1 978-3-642-54833-8",
    "abstract": "We present impredicative concurrent abstract predicates –iCAP – a program logic for modular reasoning about concurrent, higherorder, reentrant, imperative code. Building on earlier work, iCAP uses protocols to reason about shared mutable state. A key novel feature of iCAP is the ability to deﬁne impredicative protocols; protocols that are parameterized on arbitrary predicates, including predicates that themselves refer to protocols. We demonstrate the utility of impredicative protocols through a series of examples, including the speciﬁcation and veriﬁcation, in the logic, of a spin-lock, a reentrant event loop, and a concurrent bag implemented using cooperation, against modular speciﬁcations.",
    "URL": "http://link.springer.com/10.1007/978-3-642-54833-8_9",
    "DOI": "10.1007/978-3-642-54833-8_9",
    "publisher-place": "Berlin, Heidelberg",
    "page": "149-168",
    "page-first": "149",
    "volume": "8410",
    "language": "en-US",
    "_line": "FormalReview.bib:5808"
  },
  "hutchison_modular_2013": {
    "id": "hutchison_modular_2013",
    "type": "chapter",
    "author": [
      {
        "family": "Svendsen",
        "given": "Kasper"
      },
      {
        "family": "Birkedal",
        "given": "Lars"
      },
      {
        "family": "Parkinson",
        "given": "Matthew"
      }
    ],
    "editor": [
      {
        "family": "Felleisen",
        "given": "Matthias"
      },
      {
        "family": "Gardner",
        "given": "Philippa"
      }
    ],
    "title": "Modular Reasoning about Separation of Concurrent Data Structures",
    "container-title": "Programming Languages and Systems",
    "issued": {
      "date-parts": [
        [
          "2013"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2020",
          "1",
          "15"
        ]
      ]
    },
    "publisher": "Springer Berlin Heidelberg",
    "isbn": "978-3-642-37035-9 978-3-642-37036-6",
    "abstract": "In a concurrent setting, the usage protocol of standard separation logic speciﬁcations are not reﬁnable by clients, because standard speciﬁcations abstract all information about potential interleavings. This breaks modularity, as libraries cannot be veriﬁed in isolation, since the appropriate speciﬁcation depends on how clients intend to use the library. In this paper we propose a new logic and a new style of speciﬁcation for thread-safe concurrent data structures. Our speciﬁcations allow clients to reﬁne usage protocols and associate ownership of additional resources with instances of these data structures.",
    "URL": "http://link.springer.com/10.1007/978-3-642-37036-6_11",
    "DOI": "10.1007/978-3-642-37036-6_11",
    "publisher-place": "Berlin, Heidelberg",
    "page": "169-188",
    "page-first": "169",
    "volume": "7792",
    "language": "en-US",
    "_line": "FormalReview.bib:5829"
  },
  "epstein_computability_1989": {
    "id": "epstein_computability_1989",
    "type": "book",
    "author": [
      {
        "family": "Epstein",
        "given": "Richard L."
      },
      {
        "family": "Carnielli",
        "given": "Walter Alexandr"
      }
    ],
    "title": "Computability: Computable Functions Logic and the Foundations of Math",
    "container-title-short": "Computability",
    "title-short": "Computability",
    "issued": {
      "date-parts": [
        [
          "1989",
          "11",
          "9"
        ]
      ]
    },
    "publisher": "Chapman and Hall/CRC",
    "number-of-pages": "320",
    "edition": "1 edition",
    "isbn": "978-0-534-10356-9",
    "abstract": "This book should be of interest to intermediate mathematics undergraduates; postgraduates in theoretical computer science/philosophy of mathematics.",
    "publisher-place": "Pacific Grove, Calif",
    "_line": "FormalReview.bib:5850"
  },
  "celik_mutation_2019": {
    "id": "celik_mutation_2019",
    "type": "paper-conference",
    "author": [
      {
        "family": "Celik",
        "given": "Ahmet"
      },
      {
        "family": "Palmskog",
        "given": "Karl"
      },
      {
        "family": "Parovic",
        "given": "Marinela"
      },
      {
        "family": "Jesus Gallego Arias",
        "given": "Emilio"
      },
      {
        "family": "Gligoric",
        "given": "Milos"
      }
    ],
    "title": "Mutation Analysis for Coq",
    "container-title": "2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)",
    "event-title": "2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)",
    "issued": {
      "date-parts": [
        [
          "2019",
          "11"
        ]
      ]
    },
    "accessed": {
      "date-parts": [
        [
          "2020",
          "1",
          "20"
        ]
      ]
    },
    "publisher": "IEEE",
    "isbn": "978-1-72812-508-4",
    "abstract": "Mutation analysis, which introduces artiﬁcial defects into software systems, is the basis of mutation testing, a technique widely applied to evaluate and enhance the quality of test suites. However, despite the deep analogy between tests and formal proofs, mutation analysis has seldom been considered in the context of deductive veriﬁcation. We propose mutation proving, a technique for analyzing veriﬁcation projects that use proof assistants. We implemented our technique for the Coq proof assistant in a tool dubbed MCOQ. MCOQ applies a set of mutation operators to Coq deﬁnitions of functions and datatypes, inspired by operators previously proposed for functional programming languages. MCOQ then checks proofs of lemmas affected by operator application. To make our technique feasible in practice, we implemented several optimizations in MCOQ such as parallel proof checking. We applied MCOQ to several medium and large scale Coq projects, and recorded whether proofs passed or failed when applying different mutation operators. We then qualitatively analyzed the mutants, ﬁnding many instances of incomplete speciﬁcations. For our evaluation, we made several improvements to serialization of Coq ﬁles and even discovered a notable bug in Coq itself, all acknowledged by developers. We believe MCOQ can be useful both to proof engineers for improving the quality of their veriﬁcation projects and to researchers for evaluating proof engineering techniques.",
    "URL": "https://ieeexplore.ieee.org/document/8952421/",
    "DOI": "10.1109/ASE.2019.00057",
    "publisher-place": "San Diego, CA, USA",
    "page": "539-551",
    "page-first": "539",
    "language": "en-US",
    "_line": "FormalReview.bib:5863"
  }
}