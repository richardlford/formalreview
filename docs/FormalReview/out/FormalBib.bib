
@thesis{spector-zabusky_dont_2021,
	title = {{DON}’T {MIND} {THE} {FORMALIZATION} {GAP}: {THE} {DESIGN} {AND} {USAGE} {OF} {HS}-{TO}-{COQ}},
	url = {https://www.cis.upenn.edu/~sweirich/papers/spector-zabusky-thesis.pdf},
	abstract = {Using proof assistants to perform formal, mechanical software verification is a
powerful technique for producing correct software. However, the verification is timeconsuming and limited to software written in the language of the proof assistant. As
an approach to mitigating this tradeoff, this dissertation presents hs-to-coq, a tool
for translating programs written in the Haskell programming language into the Coq
proof assistant, along with its applications and a general methodology for using it to
verify programs. By introducing edit files containing programmatic descriptions of
code transformations, we provide the ability to flexibly adapt our verification goals to
exist anywhere on the spectrum between “increased confidence” and “full functional
correctness”.},
	pagetotal = {240},
	institution = {University of Pennsylvania},
	type = {phdthesis},
	author = {Spector-Zabusky, Antal},
	date = {2021},
	langid = {english},
	file = {Spector-Zabusky - DON’T MIND THE FORMALIZATION GAP THE DESIGN AND U.pdf:/home/fordrl/Zotero/storage/YFYZE4CD/Spector-Zabusky - DON’T MIND THE FORMALIZATION GAP THE DESIGN AND U.pdf:application/pdf},
}

@article{abate_extended_2021,
	title = {An Extended Account of Trace-Relating Compiler Correctness and Secure Compilation},
	volume = {To Appear},
	url = {https://people.mpi-sws.org/~dg/papers/toplas21-diff.pdf},
	pages = {48},
	journaltitle = {{TOPLAS}},
	shortjournal = {{TOPLAS}},
	author = {Abate, Carmine and Blanco, Roberto and Ciobâcă, Tefan and Durier, Adrien and Garg, Deepak and Hrit, Cătălin and Patrignani, Marco and Tanter, Éric and Thibault, Jérémy},
	date = {2021},
	langid = {english},
	file = {Abate et al. - An Extended Account of Trace-Relating Compiler Cor.pdf:/home/fordrl/Zotero/storage/IDHXJP29/Abate et al. - An Extended Account of Trace-Relating Compiler Cor.pdf:application/pdf},
}

@article{ye_type-directed_2016,
	title = {Type-Directed Operational Semantics for Gradual Typing},
	abstract = {The semantics of gradually typed languages is typically given indirectly via an elaboration into a cast calculus. This contrasts with more conventional formulations of programming language semantics, where the semantics of a language is given directly using, for instance, an operational semantics. This paper presents a new approach to give the semantics of gradually typed languages directly. We use a recently proposed variant of small-step operational semantics called type-directed operational semantics ({TDOS}). In {TDOS} type annotations become operationally relevant and can affect the result of a program. In the context of a gradually typed language, such type annotations are used to trigger type-based conversions on values. We illustrate how to employ {TDOS} on gradually typed languages using two calculi. The first calculus, called λBg, is inspired by the semantics of the blame calculus, but it has implicit type conversions, enabling it to be used as a gradually typed language. The second calculus, called λBr, explores a different design space in the semantics of gradually typed languages. It uses a so-called blame recovery semantics, which enables eliminating some false positives where blame is raised but normal computation could succeed. For both calculi, type safety is proved. Furthermore we show that the semantics of λBg is sound with respect to the semantics of the blame calculus, and that λBr comes with a gradual guarantee. All the results have been mechanically formalized in the Coq theorem prover.},
	pages = {29},
	author = {Ye, Wenjia},
	date = {2016},
	langid = {english},
	file = {Ye - 2016 - Type-Directed Operational Semantics for Gradual Ty.pdf:/home/fordrl/Zotero/storage/MNET5R9M/Ye - 2016 - Type-Directed Operational Semantics for Gradual Ty.pdf:application/pdf},
}

@article{sinkarovs_choosing_2021,
	title = {Choosing is Losing: How to combine the benefits of shallow and deep embeddings through reflection},
	url = {http://arxiv.org/abs/2105.10819},
	shorttitle = {Choosing is Losing},
	abstract = {Dependently-typed host languages empower users to verify a wide range of properties of embedded languages and programs written in them. Designers of such embedded languages are faced with a difficult choice between using a shallow or a deep embedding. The former is easier to use because the entire infrastructure of the host langauge is immediately available. Meanwhile, the latter gives full access to the structure of embedded programs, but is difficult to use in practice, especially when the embedded language is itself dependently typed. The main insight presented in this paper is that the choice between shallow and deep embedding can be eliminated by working in a host language with reflection capabilities: we start from a shallow embedding that can use all libraries and tools of the host language, and later use reflection to expose the deep structure of the embedded programs. Concretely, we apply this technique to embed three programming languages -- Kaleidoscope, {SaC}, and (a subset of) {APL} -- into the dependently typed theorem prover Agda, using dependent types to statically enforce several properties of interest. We then use Agda's reflection capabilities to extract the embedded programs back into the original language, so that the existing toolchain can be leveraged. In this process, statically verified properties of the host language are mapped onto runtime checks in the target language, allowing extracted programs to interact safely with existing code. Finally, we demonstrate the feasibility of our approach with the implementation and extraction of a convolutional neural network in our embedding of {APL}.{\textbackslash}@},
	journaltitle = {{arXiv}:2105.10819 [cs]},
	author = {Šinkarovs, Artjoms and Cockx, Jesper},
	urldate = {2021-05-31},
	date = {2021-05-22},
	eprinttype = {arxiv},
	eprint = {2105.10819},
	keywords = {Computer Science - Programming Languages},
	file = {arXiv.org Snapshot:/home/fordrl/Zotero/storage/BEISISEP/2105.html:text/html;arXiv Fulltext PDF:/home/fordrl/Zotero/storage/E99MHQEZ/Šinkarovs and Cockx - 2021 - Choosing is Losing How to combine the benefits of.pdf:application/pdf},
}

@article{pimpalkhare_medleysolver_nodate,
	title = {{MedleySolver}: Online {SMT} Algorithm Selection},
	abstract = {Satisﬁability modulo theories ({SMT}) solvers implement a wide range of optimizations that are often tailored to a particular class of problems, and that diﬀer signiﬁcantly between solvers. As a result, one solver may solve a query quickly while another might be ﬂummoxed completely. Predicting the performance of a given solver is diﬃcult for users of {SMT}-driven applications, particularly when the problems they have to solve do not fall neatly into a well-understood category. In this paper, we propose an online algorithm selection framework for {SMT} called {MedleySolver} that predicts the relative performances of a set of {SMT} solvers on a given query, distributes time amongst the solvers, and deploys the solvers in sequence until a solution is obtained. We evaluate {MedleySolver} against the best available alternative, an oﬄine learning technique, in terms of pure performance and practical usability for a typical {SMT} user. We ﬁnd that with no prior training, {MedleySolver} solves 93.9\% of the queries solved by the virtual best solver selector achieving 59.8\% of the par-2 score of the most successful individual solver, which solves 87.3\%. For comparison, the best available alternative takes longer to train than {MedleySolver} takes to solve our entire set of 2000 queries.},
	pages = {18},
	author = {Pimpalkhare, Nikhil and Mora, Federico and Polgreen, Elizabeth and Seshia, Sanjit A},
	langid = {english},
	file = {Pimpalkhare et al. - MedleySolver Online SMT Algorithm Selection.pdf:/home/fordrl/Zotero/storage/K2MK7DPQ/Pimpalkhare et al. - MedleySolver Online SMT Algorithm Selection.pdf:application/pdf},
}

@report{milner_models_1973,
	location = {Stanford University},
	title = {Models of {LCF}},
	url = {http://i.stanford.edu/pub/cstr/reports/cs/tr/73/332/CS-TR-73-332.pdf},
	pages = {19},
	number = {{STAN}-{CS}-73-332, Memo {AIM}-186},
	institution = {Stanford University},
	author = {Milner, Robin},
	date = {1973-01},
	file = {Milner - 1973 - Models of LCF.pdf:/home/fordrl/Zotero/storage/7JKYQCYK/Milner - 1973 - Models of LCF.pdf:application/pdf},
}

@article{iosif_encoding_nodate,
	title = {Encoding Separation Logic in {SMT}-{LIB} v2.5},
	abstract = {We propose an encoding of Separation Logic using {SMT}-{LIB} v2.5. This format is currently supported by {SMT} solvers ({CVC}4) and inductive prooftheoretic solvers ({SLIDE} and {SPEN}). Moreover, we provide a library of benchmarks written using this format, which stems from the set of benchmarks used in {SL}-{COMP}’14 [7].},
	pages = {8},
	author = {Iosif, Radu and Serban, Cristina and Reynolds, Andrew and Sighireanu, Mihaela},
	langid = {english},
	file = {Iosif et al. - Encoding Separation Logic in SMT-LIB v2.5.pdf:/home/fordrl/Zotero/storage/LN7PYXNK/Iosif et al. - Encoding Separation Logic in SMT-LIB v2.5.pdf:application/pdf},
}

@article{li_memory_2021,
	title = {Memory State Verification Based on Inductive and Deductive Reasoning},
	issn = {1558-1721},
	doi = {10.1109/TR.2021.3074709},
	abstract = {Memory allocation and deallocation are the fundamental operations of embedded operating systems, which have been extensively used in many safety critical systems. The correctness of the operations is of paramount importance because their failure could incur severe consequences. While the system is running, the memory state can easily grow to a gigantic amount, which means that it is impossible to verify the huge memory states one by one. Therefore, it is a challenge how to verify the correctness of running memory state of the system. In this article, we propose a novel memory state verification method based on inductive and deductive reasoning. First, we abstract the memory state as a list of memory blocks, which will transform in memory operations. Second, we construct the generic model based on the transition function of the memory management and summarize the invariant properties of the memory state. Third, we use the inductive method to calculate the changes between the memory states, and verify that the memory state of the system always satisfy the global properties. All the proofs are implemented in the interactive theorem prover Coq. On the basis of our proposed model, we verify the correctness of a two-level segregated fit ({TLSF}) algorithm through some extensions, and we also apply this method to verify the correctness of the memory state of the embedded system at runtime.},
	pages = {1--14},
	journaltitle = {{IEEE} Transactions on Reliability},
	author = {Li, Shaofeng and Qiao, Lei and Yang, Mengfei},
	date = {2021},
	note = {Conference Name: {IEEE} Transactions on Reliability},
	keywords = {Safety, Deductive, Embedded systems, formal verification, Indexes, inductive, Kernel, memory management, Memory management, {OS} kernels, Resource management, Runtime},
	file = {IEEE Xplore Abstract Record:/home/fordrl/Zotero/storage/XVN46N62/9435092.html:text/html},
}

@article{nipkow_functional_nodate,
	title = {Functional Algorithms, Veriﬁed!},
	pages = {276},
	author = {Nipkow, Tobias and Blanchette, Jasmin and Eberl, Manuel and Gómez-Londoño, Alejandro and Lammich, Peter and Sternagel, Christian and Wimmer, Simon and Zhan, Bohua},
	langid = {english},
	file = {Nipkow et al. - Functional Algorithms, Veriﬁed!.pdf:/home/fordrl/Zotero/storage/68LMWS45/Nipkow et al. - Functional Algorithms, Veriﬁed!.pdf:application/pdf},
}

@article{mitsch_implicit_nodate,
	title = {Implicit and Explicit Proof Management in {KeYmaera} X},
	pages = {15},
	author = {Mitsch, Stefan},
	langid = {english},
	file = {Mitsch - Implicit and Explicit Proof Management in KeYmaera.pdf:/home/fordrl/Zotero/storage/27ZI9II8/Mitsch - Implicit and Explicit Proof Management in KeYmaera.pdf:application/pdf},
}

@article{morshtein_verifying_nodate,
	title = {Verifying Time Complexity of Binary Search using Dafny},
	abstract = {Formal software veriﬁcation techniques are widely used to specify and prove the functional correctness of programs. However, nonfunctional properties such as time complexity are usually carried out with pen and paper. Ineﬃcient code in terms of time complexity may cause massive performance problems in large-scale complex systems. We present a proof of concept for using the Dafny veriﬁcation tool to specify and verify the worst-case time complexity of binary search. This approach can also be used for academic purposes as a new way to teach algorithms and complexity.},
	pages = {16},
	author = {Morshtein, Shiri and Ettinger, Ran},
	langid = {english},
	file = {Morshtein and Ettinger - Verifying Time Complexity of Binary Search using D.pdf:/home/fordrl/Zotero/storage/MIPC43JJ/Morshtein and Ettinger - Verifying Time Complexity of Binary Search using D.pdf:application/pdf},
}

@inproceedings{rakotomalala_verifying_2021,
	location = {virtual, United States},
	title = {Verifying min-plus Computations with Coq (extended version with appendix)},
	url = {https://hal.archives-ouvertes.fr/hal-03176024},
	abstract = {Network-calculus is a theory that bounds delays in embedded networks such as {AFDX} networks used in modern airplanes. Effective computations rely on operators from the min-plus algebra on real functions. Algorithms on specific subsets can be found in the literature. Such algorithms and related implementations are however complicated. Instead of redeveloping a provably correct implementation, we take an existing implementation as an oracle and propose a Coq based verifier.},
	booktitle = {13th {NASA} Formal Methods Symposium ({NFM} 2021)},
	author = {Rakotomalala, Lucien and Roux, Pierre and Boyer, Marc},
	urldate = {2021-05-26},
	date = {2021-05},
	keywords = {Coq, functions on real numbers, min-plus computations, network-calculus},
	file = {HAL PDF Full Text:/home/fordrl/Zotero/storage/RGBGDL8S/Rakotomalala et al. - 2021 - Verifying min-plus Computations with Coq (extended.pdf:application/pdf},
}

@article{chen_initial_2020,
	title = {Initial Algebra Semantics in Matching Logic},
	url = {https://www.ideals.illinois.edu/handle/2142/107781},
	abstract = {Matching logic is a unifying foundational logic for defining formal programming language semantics, which adopts a minimalist design with few primitive constructs that are enough to express all properties within a variety of logical systems, including {FOL}, separation logic, (dependent) type systems, modal mu-logic, and more. In this paper, we consider initial algebra semantics and show how to capture it by matching logic specifications. Formally, given an algebraic specification E that defines a set of sorts (of data) and a set of operations whose behaviors are defined by a set of equational axioms, we define a corresponding matching logic specification, denoted {INITIALALGEBRA}(E), whose models are exactly the initial algebras of E. Thus, we reduce initial E-algebra semantics to the matching logic specifications {INITIALALGEBRA}(E), and reduce extrinsic initial E-algebra reasoning, which includes inductive reasoning, to generic, intrinsic matching logic reasoning.},
	author = {Chen, Xiaohong and Lucanu, Dorel and Roşu, Grigore},
	urldate = {2021-05-25},
	date = {2020-07},
	langid = {english},
	note = {Accepted: 2020-07-19T19:02:15Z},
	file = {Snapshot:/home/fordrl/Zotero/storage/AWL7X9Z2/107781.html:text/html;Full Text PDF:/home/fordrl/Zotero/storage/JE35ZGX2/Chen et al. - 2020 - Initial Algebra Semantics in Matching Logic.pdf:application/pdf},
}

@article{chen_general_2020,
	title = {A general approach to define binders using matching logic},
	volume = {4},
	issn = {2475-1421},
	url = {https://dl.acm.org/doi/10.1145/3408970},
	doi = {10.1145/3408970},
	abstract = {We propose a novel definition of binders using matching logic, where the binding behavior of object-level binders is directly inherited from the built-in exists binder of matching logic. We show that the behavior of binders in various logical systems such as lambda-calculus, System F, pi-calculus, pure type systems, can be axiomatically defined in matching logic as notations and logical theories. We show the correctness of our definitions by proving conservative extension theorems, which state that a sequent/judgment is provable in the original system if and only if it is provable in matching logic, in the corresponding theory. Our matching logic definition of binders also yields models to all binders, which are deductively complete with respect to formal reasoning in the original systems. For lambda-calculus, we further show that the yielded models are representationally complete, a desired property that is not enjoyed by many existing lambda-calculus semantics. This work is part of a larger effort to develop a logical foundation for the programming language semantics framework K (http://kframework.org).},
	pages = {1--32},
	issue = {{ICFP}},
	journaltitle = {Proceedings of the {ACM} on Programming Languages},
	shortjournal = {Proc. {ACM} Program. Lang.},
	author = {Chen, Xiaohong and Roşu, Grigore},
	urldate = {2021-05-25},
	date = {2020-08-02},
	langid = {english},
	file = {Chen and Roşu - 2020 - A general approach to define binders using matchin.pdf:/home/fordrl/Zotero/storage/PQVCHPR5/Chen and Roşu - 2020 - A general approach to define binders using matchin.pdf:application/pdf},
}

@online{rosu_matching_2017,
	title = {Matching logic · Formal Systems Laboratory},
	url = {https://fsl.cs.illinois.edu/publications/rosu-2017-lmcs.html},
	abstract = {This paper presents matching logic , a first-order logic ({FOL}) variant for spec-
ifying and reasoning about structure by means of patterns and pattern matching. Its
sentences, the patterns , are constructed using variables , symbols , connectives and quan-
tifiers , but no difference is made between function and predicate symbols. In models, a
pattern evaluates into a power-set domain (the set of values that match it), in contrast to
{FOL} where functions and predicates map into a regular domain. Matching logic uniformly
generalizes several logical frameworks important for program analysis, such as: proposi-
tional logic, algebraic specification, {FOL} with equality, modal logic, and separation logic.
Patterns can specify separation requirements at any level in any program configuration,
not only in the heaps or stores, without any special logical constructs for that: the very
nature of pattern matching is that if two structures are matched as part of a pattern, then
they can only be spatially separated. Like {FOL}, matching logic can also be translated
into pure predicate logic with equality, at the same time admitting its own sound and
complete proof system. A practical aspect of matching logic is that {FOL} reasoning with
equality remains sound, so off-the-shelf provers and {SMT} solvers can be used for matching
logic reasoning. Matching logic is particularly well-suited for reasoning about programs in
programming languages that have an operational semantics, but it is not limited to this.},
	author = {Rosu, Grigore},
	urldate = {2021-05-24},
	date = {2017-12},
	file = {rosu-2017-lmcs.pdf:/home/fordrl/Zotero/storage/EVJCZRUA/rosu-2017-lmcs.pdf:application/pdf;Matching logic · Formal Systems Laboratory:/home/fordrl/Zotero/storage/7ZSVI9ZI/rosu-2017-lmcs.html:text/html},
}

@article{tusil_executable_2017,
	title = {An Executable Formal Semantics of C++},
	pages = {87},
	author = {Tušil, Jan},
	date = {2017},
	langid = {english},
	file = {Tušil - 2017 - An Executable Formal Semantics of C++.pdf:/home/fordrl/Zotero/storage/2LQDPVUE/Tušil - 2017 - An Executable Formal Semantics of C++.pdf:application/pdf},
}

@article{thakur_posthat_2013,
	title = {{PostHat} and All That: Automating Abstract Interpretation},
	abstract = {Abstract interpretation provides an elegant formalism for performing program analysis. Unfortunately, designing and implementing a sound, precise, scalable, and extensible abstract interpreter is diﬃcult. In this paper, we describe an approach to creating correct-by-construction abstract interpreters that also attain the fundamental limits on precision that abstract-interpretation theory establishes. Our approach requires the analysis designer to implement only a small number of operations. In particular, we describe a systematic method for implementing an abstract interpreter that solves the following problem: Given program P , and an abstract domain A, ﬁnd the most-precise inductive A-invariant for P .},
	pages = {20},
	journaltitle = {Electronic Notes in Theoretical Computer Science},
	author = {Thakur, A and Lal, A and Lim, J and Reps, T},
	date = {2013},
	langid = {english},
	file = {Thakur et al. - PostHat and All That Automating Abstract Interpre.pdf:/home/fordrl/Zotero/storage/C85ZSEF5/Thakur et al. - PostHat and All That Automating Abstract Interpre.pdf:application/pdf},
}

@article{bugariu_identifying_2021,
	title = {Identifying Overly Restrictive Matching Patterns in {SMT}-based Program Verifiers},
	url = {http://arxiv.org/abs/2105.04385},
	abstract = {Universal quantifiers occur frequently in proof obligations produced by program verifiers, for instance, to axiomatize uninterpreted functions and to express properties of arrays. {SMT}-based verifiers typically reason about them via E-matching, an {SMT} algorithm that requires syntactic matching patterns to guide the quantifier instantiations. Devising good matching patterns is challenging. In particular, overly restrictive patterns may lead to spurious verification errors if the quantifiers needed for a proof are not instantiated; they may also conceal unsoundness caused by inconsistent axiomatizations. In this paper, we present the first technique that identifies and helps the users remedy the effects of overly restrictive matching patterns. We designed a novel algorithm to synthesize missing triggering terms required to complete a proof. Tool developers can use this information to refine their matching patterns and prevent similar verification errors, or to fix a detected unsoundness.},
	journaltitle = {{arXiv}:2105.04385 [cs]},
	author = {Bugariu, Alexandra and Ter-Gabrielyan, Arshavir and Müller, Peter},
	urldate = {2021-05-19},
	date = {2021-05-10},
	eprinttype = {arxiv},
	eprint = {2105.04385},
	keywords = {Computer Science - Programming Languages},
	file = {arXiv.org Snapshot:/home/fordrl/Zotero/storage/BAA8K78B/2105.html:text/html;arXiv Fulltext PDF:/home/fordrl/Zotero/storage/B4LZX6IM/Bugariu et al. - 2021 - Identifying Overly Restrictive Matching Patterns i.pdf:application/pdf},
}

@article{foster_formally_2021,
	title = {Formally Verified Simulations of State-Rich Processes using Interaction Trees in Isabelle/{HOL}},
	url = {http://arxiv.org/abs/2105.05133},
	abstract = {Simulation and formal verification are important complementary techniques necessary in high assurance model-based systems development. In order to support coherent results, it is necessary to provide unifying semantics and automation for both activities. In this paper we apply Interaction Trees in Isabelle/{HOL} to produce a verification and simulation framework for state-rich process languages. We develop the core theory and verification techniques for Interaction Trees, use them to give a semantics to the {CSP} and Circus languages, and formally link our new semantics with the failures-divergences semantic model. We also show how the Isabelle code generator can be used to generate verified executable simulations for reactive and concurrent programs.},
	journaltitle = {{arXiv}:2105.05133 [cs]},
	author = {Foster, Simon and Hur, Chung-Kil and Woodcock, Jim},
	urldate = {2021-05-19},
	date = {2021-05-11},
	eprinttype = {arxiv},
	eprint = {2105.05133},
	keywords = {Computer Science - Logic in Computer Science},
	file = {arXiv.org Snapshot:/home/fordrl/Zotero/storage/YDDY7DDN/2105.html:text/html;arXiv Fulltext PDF:/home/fordrl/Zotero/storage/GYN9PRXC/Foster et al. - 2021 - Formally Verified Simulations of State-Rich Proces.pdf:application/pdf},
}

@article{steinberg_computable_nodate,
	title = {Computable analysis and notions of continuity in Coq},
	volume = {17},
	abstract = {We give a number of formal proofs of theorems from computable analysis. Many of our results specify executable algorithms that work on inﬁnite inputs by means of operating on ﬁnite approximations. The proofs that these algorithms are correct in the sense of computable analysis are veriﬁed in the proof assistant Coq heavily relying on the Incone library for information theoretic continuity. This library is developed by one of the authors and the paper can be used as an introduction to it. Incone formulates the continuity-theoretic aspects of computable analysis. It is designed in such a way that it can be combined with Coq’s Type/Prop distinction to provide a general purpose interface for algorithmic reasoning on continuous structures and many of our results provide complete computational content.},
	pages = {43},
	author = {Steinberg, Florian and Théry, Laurent and Thies, Holger},
	langid = {english},
	file = {Steinberg et al. - Computable analysis and notions of continuity in C.pdf:/home/fordrl/Zotero/storage/992D5GTN/Steinberg et al. - Computable analysis and notions of continuity in C.pdf:application/pdf},
}

@article{ferrando_toward_2021,
	title = {Toward a Holistic Approach to Verification and Validation of Autonomous Cognitive Systems},
	volume = {30},
	issn = {1049-331X},
	url = {https://doi.org/10.1145/3447246},
	doi = {10.1145/3447246},
	abstract = {When applying formal verification to a system that interacts with the real world, we must use a model of the environment. This model represents an abstraction of the actual environment, so it is necessarily incomplete and hence presents an issue for system verification. If the actual environment matches the model, then the verification is correct; however, if the environment falls outside the abstraction captured by the model, then we cannot guarantee that the system is well behaved. A solution to this problem consists in exploiting the model of the environment used for statically verifying the system’s behaviour and, if the verification succeeds, using it also for validating the model against the real environment via runtime verification. The article discusses this approach and demonstrates its feasibility by presenting its implementation on top of a framework integrating the Agent Java {PathFinder} model checker. A high-level Domain Specific Language is used to model the environment in a user-friendly way; the latter is then compiled to trace expressions for both static formal verification and runtime verification. To evaluate our approach, we apply it to two different case studies: an autonomous cruise control system and a simulation of the Mars Curiosity rover.},
	pages = {43:1--43:43},
	number = {4},
	journaltitle = {{ACM} Transactions on Software Engineering and Methodology},
	shortjournal = {{ACM} Trans. Softw. Eng. Methodol.},
	author = {Ferrando, Angelo and Dennis, Louise A. and Cardoso, Rafael C. and Fisher, Michael and Ancona, Davide and Mascardi, Viviana},
	urldate = {2021-05-17},
	date = {2021-05-10},
	keywords = {autonomous systems, {MCAPL}, model checking, Runtime verification, trace expressions},
	file = {Full Text PDF:/home/fordrl/Zotero/storage/XEGULAGQ/Ferrando et al. - 2021 - Toward a Holistic Approach to Verification and Val.pdf:application/pdf},
}

@article{kimura_decidability_2021,
	title = {Decidability for Entailments of Symbolic Heaps with Arrays},
	volume = {17},
	doi = {DOI:10.23638/LMCS-17(2:15)2021},
	abstract = {This paper presents two decidability results on the validity checking problem for entailments of symbolic heaps in separation logic with Presburger arithmetic and arrays. The ﬁrst result is for a system with arrays and existential quantiﬁers. The correctness of the decision procedure is proved under the condition that sizes of arrays in the succedent are not existentially quantiﬁed. This condition is diﬀerent from that proposed by Brotherston et al. in 2017 and one of them does not imply the other. The main idea is a novel translation from an entailment of symbolic heaps into a formula in Presburger arithmetic. The second result is the decidability for a system with both arrays and lists. The key idea is to extend the unroll collapse technique proposed by Berdine et al. in 2005 to arrays and arithmetic as well as double-linked lists.},
	pages = {33},
	number = {2},
	journaltitle = {Logical Methods in Computer Science},
	author = {Kimura, Daisuke and Tatsuta, Makoto},
	date = {2021-05-11},
	langid = {english},
	file = {Kimura and Tatsuta - Decidability for Entailments of Symbolic Heaps wit.pdf:/home/fordrl/Zotero/storage/ZK6AKAQZ/Kimura and Tatsuta - Decidability for Entailments of Symbolic Heaps wit.pdf:application/pdf},
}

@article{robles_methodology_nodate,
	title = {Methodology for Speciﬁcation and Veriﬁcation of High-Level Requirements with {MetAcsl}},
	abstract = {Speciﬁcation and formal veriﬁcation of high-level properties (such as security properties, like data integrity or conﬁdentiality) over a large software product remains an important challenge for the industrial practice. Recent work introduced {METACSL}, a plugin of the {FRAMA}-C veriﬁcation platform, that allows the user to specify high-level properties, called {HIghLevel} {ACSL} {REquirements} or {HILARE}, for C programs and transform them into assertions that can then be veriﬁed by classic deductive veriﬁcation. This paper presents a methodology of speciﬁcation and veriﬁcation of a wide range of high-level properties with {METACSL} and illustrates it on several examples. The goal is to provide veriﬁcation practitioners with detailed methodological guidelines for common patterns of properties in order to facilitate their everyday work and to avoid some frequent pitfalls. The illustrating examples are inspired by very usual kinds of properties and illustrated on two use cases. One of them—on the real-life code of the bootloader module of the secure storage device Wookey—was fully veriﬁed using the described approach, demonstrating its capacity to scale to real-life code. The other one—on a microkernel of an {OS}—was added to illustrate other common properties, where the description of the system was intentionally left very generic.},
	pages = {14},
	author = {Robles, Virgile and Kosmatov, Nikolai and Prevosto, Virgile and Rilling, Louis and Paris-Saclay, Université},
	langid = {english},
	file = {Robles et al. - Methodology for Speciﬁcation and Veriﬁcation of Hi.pdf:/home/fordrl/Zotero/storage/RIUMIK2W/Robles et al. - Methodology for Speciﬁcation and Veriﬁcation of Hi.pdf:application/pdf},
}

@article{zhang_compositional_nodate,
	title = {Compositional Programming},
	volume = {1},
	abstract = {Modularity is a key concern in programming. However, programming languages remain limited in terms of modularity and extensibility. Small canonical problems, such as the Expression Problem ({EP}), illustrate some of the basic issues: the dilemma between choosing one kind of extensibility over another one in most programming languages. Other problems, such as how to express dependencies in a modular way, add up to the basic issues and remain a significant challenge. This paper presents a new statically typed modular programming style called Compositional Programming. In Compositional Programming, there is no {EP}: it is easy to get extensibility in multiple dimensions (i.e. it is easy to add new variants as well as new operations). Compositional Programming offers an alternative way to model data structures that differs from both algebraic datatypes in functional programming and conventional {OOP} class hierarchies. We introduce four key concepts for Compositional Programming: compositional interfaces, compositional traits, method patterns, and nested trait composition. Altogether these concepts allow us to naturally solve challenges such as the Expression Problem, model attribute-grammar-like programs, and generally deal with modular programs with complex dependencies. We present a language design, called {CP}, which is proved to be type-safe, together with several examples and three case studies. {CCS} Concepts: • Software and its engineering → Object oriented languages.},
	pages = {60},
	number = {1},
	author = {Zhang, Weixin and Sun, Yaozhu},
	langid = {english},
	file = {Zhang and Sun - Compositional Programming.pdf:/home/fordrl/Zotero/storage/CLG55ZC2/Zhang and Sun - Compositional Programming.pdf:application/pdf},
}

@unpublished{monniaux_simple_2021,
	title = {Simple, Light, Yet Formally Verified, Global Common Subexpression Elimination and Loop-Invariant Code Motion},
	url = {https://hal.archives-ouvertes.fr/hal-03212087},
	abstract = {We present an approach for implementing a formally certified loop-invariant code motion optimization by composing an unrolling pass and a formally certified yet efficient global subexpression elimination.
This approach is lightweight: each pass comes with a simple and independent proof of correctness.
Experiments show the approach significantly narrows the performance gap between the {CompCert} certified compiler and state-of-the-art optimizing compilers.
Our static analysis employs an efficient yet verified hashed set structure, resulting in fast compilation.},
	author = {Monniaux, David and Six, Cyril},
	urldate = {2021-05-12},
	date = {2021-05},
	keywords = {Coq, common subexpression elimination, invariants, optimization, verified compilers, verified hashed sets},
	file = {HAL PDF Full Text:/home/fordrl/Zotero/storage/V4MFXNJA/Monniaux and Six - 2021 - Simple, Light, Yet Formally Verified, Global Commo.pdf:application/pdf},
}

@article{stanford_symbolic_2021,
	title = {Symbolic Boolean Derivatives for Efficiently Solving Extended Regular Expression Constraints},
	abstract = {The manipulation of raw string data is ubiquitous in securitycritical software, and verification of such software relies on efficiently solving string and regular expression constraints via {SMT}. However, the typical case of Boolean combinations of regular expression constraints exposes blowup in existing techniques. To address solvability of such constraints, we propose a new theory of derivatives of symbolic extended regular expressions (extended meaning that complement and intersection are incorporated), and show how to apply this theory to obtain more efficient decision procedures. Our implementation of these ideas, built on top of Z3, matches or outperforms state-of-the-art solvers on standard and handwritten benchmarks, showing particular benefits on examples with Boolean combinations.},
	pages = {16},
	author = {Stanford, Caleb and Veanes, Margus and Bj, Nikolaj},
	date = {2021},
	langid = {english},
	file = {Stanford et al. - 2021 - Symbolic Boolean Derivatives for Efficiently Solvi.pdf:/home/fordrl/Zotero/storage/2YRI7KJX/Stanford et al. - 2021 - Symbolic Boolean Derivatives for Efficiently Solvi.pdf:application/pdf},
}

@article{sanan_csim2_2021,
	title = {{CSim}{\textasciicircum}2: Compositional Top-down Verification of Concurrent Systems using Rely-Guarantee},
	volume = {43},
	issn = {0164-0925},
	url = {https://doi.org/10.1145/3436808},
	doi = {10.1145/3436808},
	shorttitle = {\textbf{{CSim}}$^{\textrm{\textit{2}}}$},
	abstract = {To make feasible and scalable the verification of large and complex concurrent systems, it is necessary the use of compositional techniques even at the highest abstraction layers. When focusing on the lowest software abstraction layers, such as the implementation or the machine code, the high level of detail of those layers makes the direct verification of properties very difficult and expensive. It is therefore essential to use techniques allowing to simplify the verification on these layers. One technique to tackle this challenge is top-down verification where by means of simulation properties verified on top layers (representing abstract specifications of a system) are propagated down to the lowest layers (that are an implementation of the top layers). There is no need to say that simulation of concurrent systems implies a greater level of complexity, and having compositional techniques to check simulation between layers is also desirable when seeking for both feasibility and scalability of the refinement verification. In this article, we present {CSim}2 a (compositional) rely-guarantee-based framework for the top-down verification of complex concurrent systems in the Isabelle/{HOL} theorem prover. {CSim}2 uses {CSimpl}, a language with a high degree of expressiveness designed for the specification of concurrent programs. Thanks to its expressibility, {CSimpl} is able to model many of the features found in real world programming languages like exceptions, assertions, and procedures. {CSim}2 provides a framework for the verification of rely-guarantee properties to compositionally reason on {CSimpl} specifications. Focusing on top-down verification, {CSim}2 provides a simulation-based framework for the preservation of {CSimpl} rely-guarantee properties from specifications to implementations. By using the simulation framework, properties proven on the top layers (abstract specifications) are compositionally propagated down to the lowest layers (source or machine code) in each concurrent component of the system. Finally, we show the usability of {CSim}2 by running a case study over two {CSimpl} specifications of an Arinc-653 communication service. In this case study, we prove a complex property on a specification, and we use {CSim}2 to preserve the property on lower abstraction layers.},
	pages = {2:1--2:46},
	number = {1},
	journaltitle = {{ACM} Transactions on Programming Languages and Systems},
	shortjournal = {{ACM} Trans. Program. Lang. Syst.},
	author = {Sanan, David and Zhao, Yongwang and Lin, Shang-Wei and Yang, Liu},
	urldate = {2021-02-17},
	date = {2021-02-09},
	keywords = {compositional verification, concurrency verification, isabelle/{HOL}, operating systems verification, Rely-guarantee, simulation and refinement},
	file = {Full Text PDF:/home/fordrl/Zotero/storage/5XKJ5BHW/Sanan et al. - 2021 - CSim2 Compositional Top-.pdf:application/pdf},
}

@article{khayam_jskel_2021,
	title = {{JSkel}: Towards a Formalization of {JavaScript}’s Semantics},
	abstract = {We present {JSkel}, a formalization of the semantics of {JavaScript} in Skel, the concrete language used to write skeletal semantics. We describe the improvements to Skel we designed and implemented to signiﬁcantly simplify the formalization. We show the formalization is both close to the speciﬁcation and executable.},
	pages = {22},
	author = {Khayam, Adam and Noizet, Louis and Schmitt, Alan},
	date = {2021},
	langid = {english},
	file = {Khayam et al. - JSkel Towards a Formalization of JavaScript’s Sem.pdf:/home/fordrl/Zotero/storage/TW27DYLI/Khayam et al. - JSkel Towards a Formalization of JavaScript’s Sem.pdf:application/pdf},
}

@article{wing_specifiers_1990,
	title = {A Specifier's Introduction to Formal Methods},
	journaltitle = {{IEEE} Computer},
	author = {Wing, Jeannette M.},
	date = {1990},
	file = {Wing90a.pdf:/home/fordrl/Zotero/storage/K84R5YG4/Wing90a.pdf:application/pdf},
}

@book{guttag_larch_1993,
	location = {New York, {NY}},
	title = {Larch: Languages and Tools for Formal Specification},
	isbn = {978-1-4612-7636-4 978-1-4612-2704-5},
	url = {http://link.springer.com/10.1007/978-1-4612-2704-5},
	shorttitle = {Larch},
	publisher = {Springer New York},
	author = {Guttag, John V. and Horning, James J. and Garland, S. J. and Jones, K. D. and Modet, A. and Wing, J. M.},
	urldate = {2021-02-03},
	date = {1993},
	langid = {english},
	doi = {10.1007/978-1-4612-2704-5},
	file = {Guttag et al. - 1993 - Larch Languages and Tools for Formal Specificatio.pdf:/home/fordrl/Zotero/storage/V9N9QJJB/Guttag et al. - 1993 - Larch Languages and Tools for Formal Specificatio.pdf:application/pdf},
}

@inproceedings{zaliva_helix_2018,
	location = {New York, {NY}, {USA}},
	title = {{HELIX}: a case study of a formal verification of high performance program generation},
	isbn = {978-1-4503-5813-2},
	url = {https://doi.org/10.1145/3264738.3264739},
	doi = {10.1145/3264738.3264739},
	series = {{FHPC} 2018},
	shorttitle = {{HELIX}},
	abstract = {In this paper, we present {HELIX}, a formally verified operator language and rewriting engine for generation of high-performance implementation for a variety of linear algebra algorithms. Based on the existing {SPIRAL} system, {HELIX} adds the rigor of formal verification of its correctness using Coq proof assistant. It formally defines two domain-specific languages: {HCOL}, which represents a computation data flow and Σ-{HCOL}, which extends {HCOL} with iterative computations. A framework for automatically proving semantic preservation of expression rewriting for both languages is presented. The structural properties of the dataflow graph which allow efficient compilation are formalized, and a monadic approach to tracking them and to reasoning about structural correctness of Σ-{HCOL} expressions is presented.},
	pages = {1--9},
	booktitle = {Proceedings of the 7th {ACM} {SIGPLAN} International Workshop on Functional High-Performance Computing},
	publisher = {Association for Computing Machinery},
	author = {Zaliva, Vadim and Franchetti, Franz},
	urldate = {2021-02-01},
	date = {2018-09-17},
	keywords = {formal verification, Coq, operator language, rule rewriting},
}

@thesis{zaliva_helix_2021,
	title = {{HELIX}: From Math to Verified Code},
	url = {/articles/thesis/HELIX_From_Math_to_Verified_Code/13636808/1},
	shorttitle = {{HELIX}},
	abstract = {This thesis presents {HELIX}, a code generation and formal verification system with a focus on the intersection of high-performance and high-assurance numerical computing.This allowed us to build a system that could be ?ne-tuned to generate efficient code for a broad set of computer architectures while providing formal guarantees ofsuch generated code's correctness. The method we used for high-performance code synthesis is the algebraictransformation of vector and matrix computations into a dataow optimized for parallel or vectorized processing on target hardware. The abstraction used to formalize and verify this technique is an operator language used with semantics-preserving term-rewriting. We use sparse vector abstraction to represent partial computations, enabling us to use algebraic reasoning to prove parallel decomposition properties. {HELIX} provides a formal verification foundation for rewriting-based algebraic code synthesis optimizations, driven by an external oracle. Presently {HELIX} uses {SPIRAL} as an oracle deriving the rule application order. The {SPIRAL} system was developed over the years and successfully applied to generate code for various numeric algorithms. Building on its sound algebraic foundation, we generalize and extend it in the direction of non-linear operators, towards a new theory of partial computations, applying formal language theory and formal verification techniques.{HELIX} is developed and proven in Coq proof assistant and demonstrated on a real-life example of verified high-performance code generation of the dynamic window safety monitor for a cyber-physical robot system.},
	institution = {Carnegie Mellon University},
	type = {thesis},
	author = {Zaliva, Vadim},
	urldate = {2021-02-01},
	date = {2021-01-25},
	langid = {english},
	doi = {10.1184/R1/13636808.v1},
	file = {Snapshot:/home/fordrl/Zotero/storage/RTTAQNND/13636808.html:text/html;Full Text PDF:/home/fordrl/Zotero/storage/BX8PPL9R/Zaliva - 2021 - HELIX From Math to Verified Code.pdf:application/pdf},
}

@online{noauthor_carnegie_nodate,
	title = {Carnegie Mellon University research repository - Browse},
	url = {https://kilthub.cmu.edu/etd},
	urldate = {2021-02-01},
	file = {Carnegie Mellon University research repository - Browse:/home/fordrl/Zotero/storage/ZASGJ9UK/etd.html:text/html},
}

@article{bao_haccle_2020,
	title = {{HACCLE}: An Ecosystem for Building Secure Multi-Party Computations},
	url = {http://arxiv.org/abs/2009.01489},
	shorttitle = {{HACCLE}},
	abstract = {Cryptographic techniques have the potential to enable distrusting parties to collaborate in fundamentally new ways, but their practical implementation poses numerous challenges. An important class of such cryptographic techniques is known as secure multi-party computation ({MPC}). In an effort to provide an ecosystem for building secure {MPC} applications using higher degrees of automation, we present the {HACCLE} (High Assurance Compositional Cryptography: Languages and Environments) toolchain. The {HACCLE} toolchain contains an embedded domain-specific language (Harpoon) for software developers without cryptographic expertise to write {MPC}-based programs. Harpoon programs are compiled into acyclic circuits represented in {HACCLE}'s Intermediate Representation ({HIR}) that serves as an abstraction for implementing a computation using different cryptographic protocols such as secret sharing, homomorphic encryption, or garbled circuits. Implementations of different cryptographic protocols serve as different backends of our toolchain. The extensible design of {HIR} allows cryptographic experts to plug in new primitives and protocols to realize computations.We have implemented {HACCLE}, and used it to program interesting algorithms and applications (e.g., secure auction, matrix-vector multiplication, and merge sort). We show that the performance is improved by using our optimization strategies and heuristics.},
	journaltitle = {{arXiv}:2009.01489 [cs]},
	author = {Bao, Yuyan and Sundararajah, Kirshanthan and Malik, Raghav and Ye, Qianchuan and Wagner, Christopher and Wang, Fei and Ameri, Mohammad Hassan and Lu, Donghang and Seto, Alexander and Delaware, Benjamin and Samanta, Roopsha and Kate, Aniket and Garman, Christina and Blocki, Jeremiah and Letourneau, Pierre-David and Meister, Benoit and Springer, Jonathan and Rompf, Tiark and Kulkarni, Milind},
	urldate = {2021-02-01},
	date = {2020-09-03},
	eprinttype = {arxiv},
	eprint = {2009.01489},
	keywords = {Computer Science - Programming Languages},
	file = {arXiv.org Snapshot:/home/fordrl/Zotero/storage/XKCIHGJ9/2009.html:text/html;arXiv Fulltext PDF:/home/fordrl/Zotero/storage/MVPA4WDZ/Bao et al. - 2020 - HACCLE An Ecosystem for Building Secure Multi-Par.pdf:application/pdf},
}

@article{dickerson_rhle_2020,
	title = {{RHLE}: Modular Deductive Verification of Relational \${\textbackslash}forall{\textbackslash}exists\$ Properties},
	url = {http://arxiv.org/abs/2002.02904},
	shorttitle = {{RHLE}},
	abstract = {Relational program logics are used to prove that a desired relationship holds between the execution of multiple programs. Existing relational program logics have focused on verifying that all runs of a collection of programs do not fall outside a desired set of behaviors. Several important relational properties, including refinement and noninterference, do not fit into this category, as they require the existence of specific desirable executions. This paper presents {RHLE}, a logic for verifying a class of relational properties which we term \${\textbackslash}forall{\textbackslash}exists\$ properties. \${\textbackslash}forall{\textbackslash}exists\$ properties assert that for all executions of a collection of programs, there exist executions of another set of programs exhibiting some intended behavior. Importantly, {RHLE} can reason modularly about programs which make library calls, ensuring that \${\textbackslash}forall{\textbackslash}exists\$ properties are preserved when the programs are linked with any valid implementation of the library. To achieve this, we develop a novel form of function specification that requires the existence of certain behaviors in valid implementations. We have built a tool based on {RHLE} which we use to verify a diverse set of relational properties drawn from the literature, including refinement and generalized noninterference.},
	journaltitle = {{arXiv}:2002.02904 [cs]},
	author = {Dickerson, Robert and Ye, Qianchuan and Delaware, Benjamin},
	urldate = {2021-02-01},
	date = {2020-11-30},
	eprinttype = {arxiv},
	eprint = {2002.02904},
	keywords = {Computer Science - Programming Languages, Computer Science - Logic in Computer Science, D.2.4, F.3.1},
	file = {arXiv.org Snapshot:/home/fordrl/Zotero/storage/KL72MUHH/2002.html:text/html;arXiv Fulltext PDF:/home/fordrl/Zotero/storage/9NXWEHZG/Dickerson et al. - 2020 - RHLE Modular Deductive Verification of Relational.pdf:application/pdf},
}

@article{sokar_self-attention_2021,
	title = {Self-Attention Meta-Learner for Continual Learning},
	url = {http://arxiv.org/abs/2101.12136},
	abstract = {Continual learning aims to provide intelligent agents capable of learning multiple tasks sequentially with neural networks. One of its main challenging, catastrophic forgetting, is caused by the neural networks non-optimal ability to learn in non-stationary distributions. In most settings of the current approaches, the agent starts from randomly initialized parameters and is optimized to master the current task regardless of the usefulness of the learned representation for future tasks. Moreover, each of the future tasks uses all the previously learned knowledge although parts of this knowledge might not be helpful for its learning. These cause interference among tasks, especially when the data of previous tasks is not accessible. In this paper, we propose a new method, named Self-Attention Meta-Learner ({SAM}), which learns a prior knowledge for continual learning that permits learning a sequence of tasks, while avoiding catastrophic forgetting. {SAM} incorporates an attention mechanism that learns to select the particular relevant representation for each future task. Each task builds a specific representation branch on top of the selected knowledge, avoiding the interference between tasks. We evaluate the proposed method on the Split {CIFAR}-10/100 and Split {MNIST} benchmarks in the task agnostic inference. We empirically show that we can achieve a better performance than several state-of-the-art methods for continual learning by building on the top of selected representation learned by {SAM}. We also show the role of the meta-attention mechanism in boosting informative features corresponding to the input data and identifying the correct target in the task agnostic inference. Finally, we demonstrate that popular existing continual learning methods gain a performance boost when they adopt {SAM} as a starting point.},
	journaltitle = {{arXiv}:2101.12136 [cs]},
	author = {Sokar, Ghada and Mocanu, Decebal Constantin and Pechenizkiy, Mykola},
	urldate = {2021-02-01},
	date = {2021-01-28},
	eprinttype = {arxiv},
	eprint = {2101.12136},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition},
	file = {arXiv.org Snapshot:/home/fordrl/Zotero/storage/5E6DRWBL/2101.html:text/html;arXiv Fulltext PDF:/home/fordrl/Zotero/storage/BTYBAVKF/Sokar et al. - 2021 - Self-Attention Meta-Learner for Continual Learning.pdf:application/pdf},
}

@article{hofmann_type-based_2021,
	title = {Type-Based Analysis of Logarithmic Amortised Complexity},
	url = {http://arxiv.org/abs/2101.12029},
	abstract = {We introduce a novel amortised resource analysis couched in a type-and-effect system. Our analysis is formulated in terms of the physicist's method of amortised analysis, and is potential-based. The type system makes use of logarithmic potential functions and is the first such system to exhibit *logarithmic amortised complexity*. With our approach we target the automated analysis of self-adjusting data structures, like splay trees, which so far have only manually been analysed in the literature. In particular, we have implemented a semi-automated prototype, which successfully analyses the zig-zig case of *splaying*, once the type annotations are fixed.},
	journaltitle = {{arXiv}:2101.12029 [cs]},
	author = {Hofmann, Martin and Leutgeb, Lorenz and Moser, Georg and Obwaller, David and Zuleger, Florian},
	urldate = {2021-02-01},
	date = {2021-01-28},
	eprinttype = {arxiv},
	eprint = {2101.12029},
	keywords = {Computer Science - Programming Languages, Computer Science - Logic in Computer Science, F.3.2},
	file = {arXiv.org Snapshot:/home/fordrl/Zotero/storage/8XN4ILYZ/2101.html:text/html;arXiv Fulltext PDF:/home/fordrl/Zotero/storage/H6YL2SV3/Hofmann et al. - 2021 - Type-Based Analysis of Logarithmic Amortised Compl.pdf:application/pdf},
}

@article{xu_-ide_2021,
	title = {In-{IDE} Code Generation from Natural Language: Promise and Challenges},
	url = {http://arxiv.org/abs/2101.11149},
	shorttitle = {In-{IDE} Code Generation from Natural Language},
	abstract = {A great part of software development involves conceptualizing or communicating the underlying procedures and logic that needs to be expressed in programs. One major difficulty of programming is turning concept into code, especially when dealing with the {APIs} of unfamiliar libraries. Recently, there has been a proliferation of machine learning methods for code generation and retrieval from natural language queries, but these have primarily been evaluated purely based on retrieval accuracy or overlap of generated code with developer-written code, and the actual effect of these methods on the developer workflow is surprisingly unattested. We perform the first comprehensive investigation of the promise and challenges of using such technology inside the {IDE}, asking "at the current state of technology does it improve developer productivity or accuracy, how does it affect the developer experience, and what are the remaining gaps and challenges?" We first develop a plugin for the {IDE} that implements a hybrid of code generation and code retrieval functionality, and orchestrate virtual environments to enable collection of many user events. We ask developers with various backgrounds to complete 14 Python programming tasks ranging from basic file manipulation to machine learning or data visualization, with or without the help of the plugin. While qualitative surveys of developer experience are largely positive, quantitative results with regards to increased productivity, code quality, or program correctness are inconclusive. Analysis identifies several pain points that could improve the effectiveness of future machine learning based code generation/retrieval developer assistants, and demonstrates when developers prefer code generation over code retrieval and vice versa. We release all data and software to pave the road for future empirical studies and development of better models.},
	journaltitle = {{arXiv}:2101.11149 [cs]},
	author = {Xu, Frank F. and Vasilescu, Bogdan and Neubig, Graham},
	urldate = {2021-02-01},
	date = {2021-01-28},
	eprinttype = {arxiv},
	eprint = {2101.11149},
	keywords = {Computer Science - Software Engineering},
	file = {arXiv.org Snapshot:/home/fordrl/Zotero/storage/ML8BNSC6/2101.html:text/html;arXiv Fulltext PDF:/home/fordrl/Zotero/storage/477Y4DAD/Xu et al. - 2021 - In-IDE Code Generation from Natural Language Prom.pdf:application/pdf},
}

@article{malecha_towards_2020,
	title = {Towards an Axiomatic Basis for C++},
	pages = {3},
	journaltitle = {The Coq Workshop 2020},
	author = {Malecha, Gregory and Anand, Abhishek and Stewart, Gordon},
	date = {2020-07-06},
	langid = {english},
	file = {Malecha et al. - Towards an Axiomatic Basis for C++.pdf:/home/fordrl/Zotero/storage/IJV8YHKS/Malecha et al. - Towards an Axiomatic Basis for C++.pdf:application/pdf},
}

@article{mitsch_modelplex_2016,
	title = {{ModelPlex}: verified runtime validation of verified cyber-physical system models},
	volume = {49},
	issn = {1572-8102},
	url = {https://doi.org/10.1007/s10703-016-0241-z},
	doi = {10.1007/s10703-016-0241-z},
	shorttitle = {{ModelPlex}},
	abstract = {Formal verification and validation play a crucial role in making cyber-physical systems ({CPS}) safe. Formal methods make strong guarantees about the system behavior if accurate models of the system can be obtained, including models of the controller and of the physical dynamics. In {CPS}, models are essential; but any model we could possibly build necessarily deviates from the real world. If the real system fits to the model, its behavior is guaranteed to satisfy the correctness properties verified with respect to the model. Otherwise, all bets are off. This article introduces {ModelPlex}, a method ensuring that verification results about models apply to {CPS} implementations. {ModelPlex} provides correctness guarantees for {CPS} executions at runtime: it combines offline verification of {CPS} models with runtime validation of system executions for compliance with the model. {ModelPlex} ensures in a provably correct way that the verification results obtained for the model apply to the actual system runs by monitoring the behavior of the world for compliance with the model. If, at some point, the observed behavior no longer complies with the model so that offline verification results no longer apply, {ModelPlex} initiates provably safe fallback actions, assuming the system dynamics deviation is bounded. This article, furthermore, develops a systematic technique to synthesize provably correct monitors automatically from {CPS} proofs in differential dynamic logic by a correct-by-construction approach, leading to verifiably correct runtime model validation. Overall, {ModelPlex} generates provably correct monitor conditions that, if checked to hold at runtime, are provably guaranteed to imply that the offline safety verification results about the {CPS} model apply to the present run of the actual {CPS} implementation.},
	pages = {33--74},
	number = {1},
	journaltitle = {Formal Methods in System Design},
	shortjournal = {Form Methods Syst Des},
	author = {Mitsch, Stefan and Platzer, André},
	urldate = {2021-01-27},
	date = {2016-10-01},
	langid = {english},
	file = {Springer Full Text PDF:/home/fordrl/Zotero/storage/97DKW37G/Mitsch and Platzer - 2016 - ModelPlex verified runtime validation of verified.pdf:application/pdf},
}

@book{beg_working_2020,
	title = {Working Document for state of the art - formality meets autonomy/robotics},
	abstract = {This document summarises the state-of-the-art of our ultimate goal of formal verification of the {ROS} based robotic systems.},
	author = {Beg, Arshad and Butterfield, Andrew},
	date = {2020-08-01},
	doi = {10.13140/RG.2.2.30437.22249},
}

@article{chong_code-level_2021,
	title = {Code-level model checking in the software development workflow at Amazon Web Services},
	volume = {n/a},
	issn = {1097-024X},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/spe.2949},
	doi = {https://doi.org/10.1002/spe.2949},
	abstract = {This article describes a style of applying symbolic model checking developed over the course of four years at Amazon Web Services ({AWS}). Lessons learned are drawn from proving properties of numerous C-based systems, for example, custom hypervisors, encryption code, boot loaders, and an {IoT} operating system. Using our methodology, we find that we can prove the correctness of industrial low-level C-based systems with reasonable effort and predictability. Furthermore, {AWS} developers are increasingly writing their own formal specifications. As part of this effort, we have developed a {CI} system that allows integration of the proofs into standard development workflows and extended the proof tools to provide better feedback to users. All proofs discussed in this article are publicly available on {GitHub}.},
	issue = {n/a},
	journaltitle = {Software: Practice and Experience},
	author = {Chong, Nathan and Cook, Byron and Eidelman, Jonathan and Kallas, Konstantinos and Khazem, Kareem and Monteiro, Felipe R. and Schwartz‐Narbonne, Daniel and Tasiran, Serdar and Tautschnig, Michael and Tuttle, Mark R.},
	urldate = {2021-01-26},
	date = {2021},
	langid = {english},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/spe.2949},
	keywords = {model checking, continuous integration, memory safety},
	file = {Full Text PDF:/home/fordrl/Zotero/storage/Q48F8JN7/Chong et al. - Code-level model checking in the software developm.pdf:application/pdf;Snapshot:/home/fordrl/Zotero/storage/NNUW6UGX/spe.html:text/html},
}

@article{vu_secure_2021,
	title = {Secure Optimization Through Opaque Observations},
	pages = {43},
	journaltitle = {Preprint {PriSC} workshop (with {POPL} 2021)},
	author = {Vu, Son Tuan and Cohen, Albert and Heydemann, Karine},
	date = {2021-01-17},
	langid = {english},
	file = {Vu et al. - Secure Optimization Through Opaque Observations.pdf:/home/fordrl/Zotero/storage/ETFIPJT8/Vu et al. - Secure Optimization Through Opaque Observations.pdf:application/pdf},
}

@inproceedings{hu_formalizing_2021,
	location = {New York, {NY}, {USA}},
	title = {Formalizing category theory in Agda},
	isbn = {978-1-4503-8299-1},
	url = {https://doi.org/10.1145/3437992.3439922},
	doi = {10.1145/3437992.3439922},
	series = {{CPP} 2021},
	abstract = {The generality and pervasiveness of category theory in modern mathematics makes it a frequent and useful target of formalization. It is however quite challenging to formalize, for a variety of reasons. Agda currently (i.e. in 2020) does not have a standard, working formalization of category theory. We document our work on solving this dilemma. The formalization revealed a number of potential design choices, and we present, motivate and explain the ones we picked. In particular, we find that alternative definitions or alternative proofs from those found in standard textbooks can be advantageous, as well as "fit" Agda's type theory more smoothly. Some definitions regarded as equivalent in standard textbooks turn out to make different "universe level" assumptions, with some being more polymorphic than others. We also pay close attention to engineering issues so that the library integrates well with Agda's own standard library, as well as being compatible with as many of supported type theories in Agda as possible.},
	pages = {327--342},
	booktitle = {Proceedings of the 10th {ACM} {SIGPLAN} International Conference on Certified Programs and Proofs},
	publisher = {Association for Computing Machinery},
	author = {Hu, Jason Z. S. and Carette, Jacques},
	urldate = {2021-01-26},
	date = {2021-01-17},
	keywords = {Agda, category theory, formal mathematics},
	file = {Full Text PDF:/home/fordrl/Zotero/storage/WSAHP5LE/Hu and Carette - 2021 - Formalizing category theory in Agda.pdf:application/pdf},
}

@incollection{artho_decision_2016,
	location = {Cham},
	title = {A Decision Procedure for Separation Logic in {SMT}},
	volume = {9938},
	isbn = {978-3-319-46519-7 978-3-319-46520-3},
	url = {http://link.springer.com/10.1007/978-3-319-46520-3_16},
	abstract = {This paper presents a complete decision procedure for the entire quantiﬁerfree fragment of Separation Logic ({SL}) interpreted over heaplets with data elements ranging over a parametric multi-sorted (possibly inﬁnite) domain. The algorithm uses a combination of theories and is used as a specialized solver inside a {DPLL}(T ) architecture. A prototype was implemented within the {CVC}4 {SMT} solver. Preliminary evaluation suggests the possibility of using this procedure as a building block of a more elaborate theorem prover for {SL} with inductive predicates, or as back-end of a bounded model checker for programs with low-level pointer and data manipulations.},
	pages = {244--261},
	booktitle = {Automated Technology for Verification and Analysis},
	publisher = {Springer International Publishing},
	author = {Reynolds, Andrew and Iosif, Radu and Serban, Cristina and King, Tim},
	editor = {Artho, Cyrille and Legay, Axel and Peled, Doron},
	urldate = {2021-01-25},
	date = {2016},
	langid = {english},
	doi = {10.1007/978-3-319-46520-3_16},
	note = {Series Title: Lecture Notes in Computer Science},
	file = {Reynolds et al. - 2016 - A Decision Procedure for Separation Logic in SMT.pdf:/home/fordrl/Zotero/storage/2WR4XNW3/Reynolds et al. - 2016 - A Decision Procedure for Separation Logic in SMT.pdf:application/pdf},
}

@article{xie_effect_2020,
	title = {Effect handlers, evidently},
	volume = {4},
	url = {https://doi.org/10.1145/3408981},
	doi = {10.1145/3408981},
	abstract = {Algebraic effect handlers are a powerful way to incorporate effects in a programming language. Sometimes perhaps even \_too\_ powerful. In this article we define a restriction of general effect handlers with \_scoped resumptions\_. We argue one can still express all important effects, while improving reasoning about effect handlers. Using the newly gained guarantees, we define a sound and coherent evidence translation for effect handlers, which directly passes the handlers as evidence to each operation. We prove full soundness and coherence of the translation into plain lambda calculus. The evidence in turn enables efficient implementations of effect operations; in particular, we show we can execute tail-resumptive operations \_in place\_ (without needing to capture the evaluation context), and how we can replace the runtime search for a handler by indexing with a constant offset.},
	pages = {99:1--99:29},
	issue = {{ICFP}},
	journaltitle = {Proceedings of the {ACM} on Programming Languages},
	shortjournal = {Proc. {ACM} Program. Lang.},
	author = {Xie, Ningning and Brachthäuser, Jonathan Immanuel and Hillerström, Daniel and Schuster, Philipp and Leijen, Daan},
	urldate = {2021-01-25},
	date = {2020-08-02},
	keywords = {Algebraic Effects, Evidence Passing Translation, Handlers},
	file = {Full Text PDF:/home/fordrl/Zotero/storage/S5X2TDSS/Xie et al. - 2020 - Effect handlers, evidently.pdf:application/pdf},
}

@inproceedings{xie_effect_2020-1,
	location = {New York, {NY}, {USA}},
	title = {Effect handlers in Haskell, evidently},
	isbn = {978-1-4503-8050-8},
	url = {https://doi.org/10.1145/3406088.3409022},
	doi = {10.1145/3406088.3409022},
	series = {Haskell 2020},
	abstract = {Algebraic effect handlers offer an alternative to monads to incorporate effects in Haskell. In recent work Xie \_et al.\_ show how to give semantics to effect handlers in terms of plain polymorphic lambda calculus through \_evidence translation\_. Besides giving precise semantics, this translation also allows for potentially more efficient implementations. Here we present the first implementation of this technique as a library for effect handlers in Haskell. We show how the design naturally leads to a concise effect interface and how evidence translation enables evaluating \_tail resumptive\_ operations \_in-place\_. We give detailed benchmark results where our library performs well with respect to other approaches.},
	pages = {95--108},
	booktitle = {Proceedings of the 13th {ACM} {SIGPLAN} International Symposium on Haskell},
	publisher = {Association for Computing Machinery},
	author = {Xie, Ningning and Leijen, Daan},
	urldate = {2021-01-25},
	date = {2020-08-27},
	keywords = {Algebraic Effects, Evidence Passing Translation, Handlers},
}

@software{mit_programming_languages_and_verification_group_fiat-crypto_2021,
	title = {Fiat-Crypto},
	rights = {View license         ,                 View license},
	url = {https://github.com/mit-plv/fiat-crypto},
	abstract = {Cryptographic Primitive Code Generation by Fiat.},
	publisher = {Programming Languages and Verification Group at {MIT} {CSAIL}},
	author = {{MIT} Programming Languages \{and\} Verification Group},
	urldate = {2021-01-25},
	date = {2021-01-25},
	note = {original-date: 2015-09-10T20:29:16Z},
}

@article{tabareau_marriage_2021,
	title = {The Marriage of Univalence and Parametricity},
	volume = {68},
	issn = {0004-5411},
	url = {https://doi.org/10.1145/3429979},
	doi = {10.1145/3429979},
	abstract = {Reasoning modulo equivalences is natural for everyone, including mathematicians. Unfortunately, in proof assistants based on type theory, which are frequently used to mechanize mathematical results and carry out program verification efforts, equality is appallingly syntactic, and as a result, exploiting equivalences is cumbersome at best. Parametricity and univalence are two major concepts that have been explored in the literature to transport programs and proofs across type equivalences, but they fall short of achieving seamless, automatic transport. This work first clarifies the limitations of these two concepts when considered in isolation and then devises a fruitful marriage between both. The resulting concept, called univalent parametricity, is an extension of parametricity strengthened with univalence that fully realizes programming and proving modulo equivalences. Our approach handles both type and term dependency, as well as type-level computation. In addition to the theory of univalent parametricity, we present a lightweight framework implemented in the Coq proof assistant that allows the user to transparently transfer definitions and theorems for a type to an equivalent one, as if they were equal. For instance, this makes it possible to conveniently switch between an easy-to-reason-about representation and a computationally efficient representation as soon as they are proven equivalent. The combination of parametricity and univalence supports transport à la carte: basic univalent transport, which stems from a type equivalence, can be complemented with additional proofs of equivalences between functions over these types, in order to be able to transport more programs and proofs, as well as to yield more efficient terms. We illustrate the use of univalent parametricity on several examples, including a recent integration of native integers in Coq. This work paves the way to easier-to-use proof assistants by supporting seamless programming and proving modulo equivalences.},
	pages = {5:1--5:44},
	number = {1},
	journaltitle = {Journal of the {ACM}},
	shortjournal = {J. {ACM}},
	author = {Tabareau, Nicolas and Tanter, Éric and Sozeau, Matthieu},
	urldate = {2021-01-25},
	date = {2021-01-15},
	keywords = {Coq, parametricity, proof assistants, Type equivalence, univalence},
	file = {Full Text PDF:/home/fordrl/Zotero/storage/2AIW4BVY/Tabareau et al. - 2021 - The Marriage of Univalence and Parametricity.pdf:application/pdf},
}

@inproceedings{annenkov_extracting_2021,
	location = {New York, {NY}, {USA}},
	title = {Extracting smart contracts tested and verified in Coq},
	isbn = {978-1-4503-8299-1},
	url = {https://doi.org/10.1145/3437992.3439934},
	doi = {10.1145/3437992.3439934},
	series = {{CPP} 2021},
	abstract = {We implement extraction of Coq programs to functional languages based on {MetaCoq}'s certified erasure. As part of this, we implement an optimisation pass removing unused arguments. We prove the pass correct wrt. a conventional call-by-value operational semantics of functional languages. We apply this to two functional smart contract languages, Liquidity and Midlang, and to the functional language Elm. Our development is done in the context of the {ConCert} framework that enables smart contract verification. We contribute a verified boardroom voting smart contract featuring maximum voter privacy such that each vote is kept private except under collusion of all other parties. We also integrate property-based testing into {ConCert} using {QuickChick} and our development is the first to support testing properties of interacting smart contracts. We test several complex contracts such as a {DAO}-like contract, an escrow contract, an implementation of a Decentralized Finance ({DeFi}) contract which includes a custom token standard (Tezos {FA}2), and more. In total, this gives us a way to write dependent programs in Coq, test them semi-automatically, verify, and then extract to functional smart contract languages, while retaining a small trusted computing base of only {MetaCoq} and the pretty-printers into these languages.},
	pages = {105--121},
	booktitle = {Proceedings of the 10th {ACM} {SIGPLAN} International Conference on Certified Programs and Proofs},
	publisher = {Association for Computing Machinery},
	author = {Annenkov, Danil and Milo, Mikkel and Nielsen, Jakob Botsch and Spitters, Bas},
	urldate = {2021-01-25},
	date = {2021-01-17},
	keywords = {formal verification, Coq, proof assistants, blockchain, certified programming, code extraction, property-based testing, smart contracts, software correctness},
	file = {Full Text PDF:/home/fordrl/Zotero/storage/R73DFS73/Annenkov et al. - 2021 - Extracting smart contracts tested and verified in .pdf:application/pdf},
}

@online{merigoux_steel_2020,
	title = {Steel: scaling up memory reasoning for F* ({ADSL} 2020) - {POPL} 2020},
	url = {https://popl20.sigplan.org/details/adsl-2020-papers/8/Steel-scaling-up-memory-reasoning-for-F-},
	shorttitle = {Steel},
	abstract = {We present Steel, a semi-automated separation logic framework for the F* proof assistant. Steel is built as a set of verified libraries on top of an existing C-like subset language and memory model, Low*. It relies on the careful mixing of separation logic terms describing the heap together with functional specifications to offer an improved proof development experience compared to current Low*, already used for large-scale projects going over several thousands lines of code. While manipulation of separation logic terms is ensured by F* tactics, the rest of the functional verification conditions is still discharged to the Z3 theorem prover. Bundling fractional permissions and a basic fork-join concurrency model, Steel is designed to automate by tactics the most common patterns of separation logic proofs such as the application of the frame rule in a populated context. While lacking proper evaluation and currently suffering from F* tactics performance issue, we hope to demonstrate its usefulness in the coming year.},
	author = {Merigoux, Denis and Fromherz, Aymeric},
	urldate = {2021-01-22},
	date = {2020-01},
	file = {Snapshot:/home/fordrl/Zotero/storage/AUQG37HA/Steel-scaling-up-memory-reasoning-for-F-.html:text/html},
}

@online{zuleger_strong-separation_nodate,
	title = {Strong-Separation Logic ({ADSL} 2020) - {POPL} 2020},
	url = {https://popl20.sigplan.org/details/adsl-2020-papers/9/Strong-Separation-Logic},
	abstract = {Most automated verifiers for separation logic target the symbolic-heap fragment, disallowing both the magic-wand operator and the application of classical Boolean operators to spatial formulas. This is not surprising, as support for the magic wand quickly leads to undecidability, especially when combined with inductive predicates for reasoning about data structures.

To circumvent these undecidability results, we propose to assign a more restrictive semantics to the separating conjunction. We argue that the resulting logic, strong-separation logic, can be used for compositional program verification and bi-abductive static analysis just like ``standard'' separation logic, while remaining decidable even in the presence of both the magic wand and the list-segment predicate—a combination of features that leads to undecidability assuming the standard semantics.},
	author = {Zuleger, Florian and Katelaan, Jens},
	urldate = {2021-01-22},
	file = {Snapshot:/home/fordrl/Zotero/storage/ZTJRZIBM/Strong-Separation-Logic.html:text/html},
}

@online{noauthor_sledge_nodate,
	title = {{SLEdge}: Bounded Model Checking in Separation Logic ({ADSL} 2020) - {POPL} 2020},
	url = {https://popl20.sigplan.org/details/adsl-2020-papers/1/SLEdge-Bounded-Model-Checking-in-Separation-Logic},
	shorttitle = {{SLEdge}},
	abstract = {In recent times, the verification of heap-manipulating programs, and static analyses in particular, has seen substantial success, largely due to the development of ‘Separation Logics’ ({SLs}). {SLs} provide embedded support for ‘local reasoning’: reasoning about the resource(s) being modified, instead of the state of the entire system. This form of reasoning is enabled by new syntax (dedicated atomic proposition and separating connectives) and corresponding semantics. Such expressivity comes with the inherent difficulty of automating these logics. Combining this power with induction/recursion  ...},
	urldate = {2021-01-22},
	file = {Snapshot:/home/fordrl/Zotero/storage/BFB2MYEU/SLEdge-Bounded-Model-Checking-in-Separation-Logic.html:text/html},
}

@article{rastogi_layered_nodate,
	title = {Layered Indexed Effects},
	volume = {1},
	pages = {28},
	journaltitle = {Unpublished},
	author = {Rastogi, Aseem and Martínez, Guido and Fromherz, Aymeric and Ramananandro, Tahina and Swamy, Nikhil},
	langid = {english},
	file = {Rastogi et al. - Layered Indexed Effects.pdf:/home/fordrl/Zotero/storage/FA2ZGL3R/Rastogi et al. - Layered Indexed Effects.pdf:application/pdf},
}

@online{everestteam_project_2021,
	title = {Project Everest},
	url = {https://project-everest.github.io/},
	author = {{EverestTeam}},
	urldate = {2021-01-21},
	date = {2021},
	file = {Project Everest:/home/fordrl/Zotero/storage/A73T8G84/project-everest.github.io.html:text/html},
}

@software{leino_dafny_2021,
	title = {Dafny},
	rights = {View license         ,                 View license},
	url = {https://github.com/dafny-lang/dafny},
	abstract = {Dafny is a verification-aware programming language},
	publisher = {Dafny},
	author = {Leino, Rustan},
	urldate = {2021-01-21},
	date = {2021-01-21},
	note = {original-date: 2016-04-16T20:05:38Z},
}

@online{p4_consortium_p4_16_2020,
	title = {P4\_16 Language Specification},
	url = {https://p4.org/p4-spec/docs/P4-16-working-spec.html},
	author = {P4 Consortium},
	urldate = {2021-01-05},
	date = {2020-06-11},
	file = {P4-16-v1.2.1.pdf:/home/fordrl/Zotero/storage/3DANSIZN/P4-16-v1.2.1.pdf:application/pdf;P4~16~ Language Specification:/home/fordrl/Zotero/storage/G5HT74DB/P4-16-working-spec.html:text/html},
}

@online{peterson_5g_2020,
	title = {5G Mobile Networks: A Systems Approach},
	url = {https://5g.systemsapproach.org/},
	author = {Peterson, Larry and Sunay, Oguz},
	urldate = {2020-12-31},
	date = {2020},
	file = {5G Mobile Networks\: A Systems Approach:/home/fordrl/Zotero/storage/W3PWFHSC/5G Mobile Networks A Systems Approach.html:text/html},
}

@online{peterson_software-defined_2020,
	title = {Software-Defined Networks: A Systems Approach},
	url = {https://sdn.systemsapproach.org/},
	author = {Peterson, Larry and Davie, Bruce and Cascone, Carmelo and O'Connor, Brian and Vachuska, Thomas},
	urldate = {2020-12-31},
	date = {2020},
	file = {Software-Defined Networks\: A Systems Approach:/home/fordrl/Zotero/storage/MZ589RXH/Software-Defined Networks A Systems Approach.html:text/html},
}

@online{peterson_computer_2020,
	title = {Computer Networks: A Systems Approach — Computer Networks: A Systems Approach Version 6.2-dev documentation},
	url = {https://book.systemsapproach.org/},
	author = {Peterson, Larry and Davie, Bruce},
	urldate = {2020-12-31},
	date = {2020},
	file = {Computer Networks\: A Systems Approach — Computer Networks\: A Systems Approach Version 6.2-dev documentation:/home/fordrl/Zotero/storage/WUGRVXJ6/book.systemsapproach.org.html:text/html},
}

@article{vacca_systematic_2021,
	title = {A systematic literature review of blockchain and smart contract development: Techniques, tools, and open challenges},
	volume = {174},
	issn = {0164-1212},
	url = {http://www.sciencedirect.com/science/article/pii/S0164121220302818},
	doi = {10.1016/j.jss.2020.110891},
	shorttitle = {A systematic literature review of blockchain and smart contract development},
	abstract = {Blockchain platforms and languages for writing smart contracts are becoming increasingly popular. However, smart contracts and blockchain applications are developed through non-standard software life-cycles, in which, for instance, delivered applications can hardly be updated or bugs resolved by releasing a new version of the software. Therefore, this systematic literature review oriented to software engineering aims at highlighting current problems and possible solutions concerning smart contracts and blockchain applications development. In this paper, we analyze 96 articles (written from 2016 to 2020) presenting solutions to tackle software engineering-specific challenges related to the development, test, and security assessment of blockchain-oriented software. In particular, we review papers (that appeared in international journals and conferences) relating to six specific topics: smart contract testing, smart contract code analysis, smart contract metrics, smart contract security, Dapp performance, and blockchain applications. Beyond the systematic review of the techniques, tools, and approaches that have been proposed in the literature to address the issues posed by the development of blockchain-based software, for each of the six aforementioned topics, we identify open challenges that require further research.},
	pages = {110891},
	journaltitle = {Journal of Systems and Software},
	shortjournal = {Journal of Systems and Software},
	author = {Vacca, Anna and Di Sorbo, Andrea and Visaggio, Corrado A. and Canfora, Gerardo},
	urldate = {2021-01-20},
	date = {2021-04-01},
	langid = {english},
	keywords = {Empirical study, Ethereum, Smart contract, Software engineering for blockchain technologies, Software metrics, Software quality},
	file = {ScienceDirect Snapshot:/home/fordrl/Zotero/storage/6J5ZI7N4/S0164121220302818.html:text/html},
}

@inproceedings{tanaka_coq_2021,
	location = {New York, {NY}, {USA}},
	title = {Coq to C translation with partial evaluation},
	isbn = {978-1-4503-8305-9},
	url = {https://doi.org/10.1145/3441296.3441394},
	doi = {10.1145/3441296.3441394},
	series = {{PEPM} 2021},
	abstract = {Coq proof assistant can be used to prove various properties of programs written in the Gallina language. It is also possible to translate Gallina programs to {OCaml} programs. However, {OCaml} is not suitable for low-level programs. Therefore, we are developing a Coq plugin for Gallina to C translation. This plugin transforms functions written in Gallina into a form as close to C as possible within Gallina. This transformation includes partial evaluation, which improves execution efficiency and eliminates polymorphism and dependent types. We can easily verify in Coq that this transformation does not change the execution result, and thus it is highly reliable. And Gallina functions after this transformation can be easily translated to C.},
	pages = {14--31},
	booktitle = {Proceedings of the 2021 {ACM} {SIGPLAN} Workshop on Partial Evaluation and Program Manipulation},
	publisher = {Association for Computing Machinery},
	author = {Tanaka, Akira},
	urldate = {2021-01-20},
	date = {2021-01-18},
	keywords = {Coq, C, compiler, Gallina, partial evaluation, tail recursion, translator, verification},
	file = {Full Text PDF:/home/fordrl/Zotero/storage/W79ZA39N/Tanaka - 2021 - Coq to C translation with partial evaluation.pdf:application/pdf},
}

@online{noauthor_open_nodate,
	title = {Open {vSwitch} 2.15.90 documentation},
	url = {https://docs.openvswitch.org/en/latest/},
	urldate = {2021-01-20},
	file = {Open vSwitch 2.15.90 documentation:/home/fordrl/Zotero/storage/QX39SMZT/Open vSwitch 2.15.90 documentation.html:text/html},
}

@report{muller_concise_2020,
	title = {Concise Outlines for a Complex Logic: A Proof Outline Checker for {TaDA}},
	rights = {http://rightsstatements.org/page/{InC}-{NC}/1.0/},
	url = {https://www.research-collection.ethz.ch/handle/20.500.11850/456833},
	shorttitle = {Concise Outlines for a Complex Logic},
	pages = {2010.07080},
	institution = {Cornell University},
	type = {Working Paper},
	author = {Müller, Peter and Wolf, Felix A. and Schwerhoff, Malte},
	urldate = {2021-01-20},
	date = {2020-10},
	langid = {english},
	doi = {10.3929/ethz-b-000456825},
	note = {Accepted: 2020-12-17T12:02:04Z
Publication Title: {arXiv}},
	file = {Snapshot:/home/fordrl/Zotero/storage/A69PBS2Y/456833.html:text/html;Full Text PDF:/home/fordrl/Zotero/storage/CSHR25Q4/Müller et al. - 2020 - Concise Outlines for a Complex Logic A Proof Outl.pdf:application/pdf},
}

@software{noauthor_infersharp_2021,
	title = {infersharp},
	rights = {{MIT} License         ,                 {MIT} License},
	url = {https://github.com/microsoft/infersharp},
	abstract = {Infer\# is an interprocedural and scalable static code analyzer for C\#. Via the capabilities of Facebook\&\#39;s Infer, this tool detects null pointer dereferences and resource leak.},
	publisher = {Microsoft},
	urldate = {2021-01-20},
	date = {2021-01-20},
	note = {original-date: 2020-07-02T19:22:01Z},
}

@software{noauthor_qsharp-language_2021,
	title = {qsharp-language},
	rights = {{MIT} License         ,                 {MIT} License},
	url = {https://github.com/microsoft/qsharp-language},
	abstract = {Official repository for design of the quantum programming language Q\# and its core libraries},
	publisher = {Microsoft},
	urldate = {2021-01-20},
	date = {2021-01-20},
	note = {original-date: 2020-09-11T23:31:17Z},
}

@online{noauthor_infer_2020,
	title = {Infer\#: Interprocedural Memory Safety Analysis For C\#},
	url = {https://devblogs.microsoft.com/dotnet/infer-interprocedural-memory-safety-analysis-for-c/},
	shorttitle = {Infer\#},
	abstract = {Announcing the public release of Infer\#, which brings the interprocedural static analysis capabilities of Infer to the .{NET} community.},
	titleaddon = {.{NET} Blog},
	urldate = {2021-01-20},
	date = {2020-12-08},
	langid = {american},
	file = {Snapshot:/home/fordrl/Zotero/storage/YXUR835W/infer-interprocedural-memory-safety-analysis-for-c.html:text/html},
}

@report{ozdemir_unifying_2020,
	title = {Unifying Compilers for {SNARKs}, {SMT}, and More},
	url = {http://eprint.iacr.org/2020/1586},
	abstract = {The programming languages community, the cryptography community, and others rely on translating programs in high-level source languages (e.g., C) to logical constraint representations. Unfortunately, building compilers for this task is difficult and time consuming. In this work, we show that all of these communities can build upon a shared compiler infrastructure, because they all share a common abstraction: stateless, non-deterministic computations that we call existentially quantified circuits, or {EQCs}.



To make our approach concrete we create {CirC}, an infrastructure for building compilers to {EQCs}. {CirC} makes it easy to add support for new {EQCs}: we build support for two, one used by the {PL} community and one used by the cryptography community, in \${\textbackslash}approx\$2000 {LOC}. It’s also easy to extend {CirC} to support new source languages: we build a feature complete compiler for a cryptographic language in one week and \${\textbackslash}approx\$700 {LOC}, whereas the reference compiler for the same language took years to write, comprises \${\textbackslash}approx\$24000 {LOC}, and produces worse-performing output than our compiler. Finally, {CirC} enables novel applications that combine multiple {EQCs}. For example, we build the first pipeline that (1) automatically identifies bugs in programs, then (2) automatically constructs cryptographic proofs of the bugs' existence.},
	number = {1586},
	author = {Ozdemir, Alex and Brown, Fraser and Wahby, Riad S.},
	urldate = {2021-01-20},
	date = {2020},
	keywords = {implementation, zero knowledge},
	file = {ePrint IACR Full Text PDF:/home/fordrl/Zotero/storage/KM5JYEAC/Ozdemir et al. - 2020 - Unifying Compilers for SNARKs, SMT, and More.pdf:application/pdf;ePrint IACR Snapshot:/home/fordrl/Zotero/storage/FG4MIQGN/1586.html:text/html},
}

@article{chhak_towards_2020,
	title = {Towards Formally Verified Compilation of Tag-Based Policy Enforcement},
	url = {http://arxiv.org/abs/2012.10313},
	abstract = {Hardware-assisted reference monitoring is receiving increasing attention as a way to improve the security of existing software. One example is the {PIPE} architecture extension, which attaches metadata tags to register and memory values and executes tag-based rules at each machine instruction to enforce a software-defined security policy. To use {PIPE} effectively, engineers should be able to write security policies in terms of source-level concepts like functions, local variables, and structured control operators, which are not visible at machine level. It is the job of the compiler to generate {PIPE}-aware machine code that enforces these source-level policies. The compiler thus becomes part of the monitored system's trusted computing base -- and hence a prime candidate for verification. To formalize compiler correctness in this setting, we extend the source language semantics with its own form of user-specified tag-based monitoring, and show that the compiler preserves that monitoring behavior. The challenges of compilation include mapping source-level monitoring policies to instruction-level tag rules, preserving fail-stop behaviors, and satisfying the surprisingly complex preconditions for conventional optimizations. In this paper, we describe the design and verification of Tagine, a small prototype compiler that translates a simple tagged {WHILE} language to a tagged register transfer language and performs simple optimizations. Tagine is based on the {RTLgen} and Deadcode phases of the {CompCert} compiler, and hence is written and verified in Coq. This work is a first step toward verification of a full-scale compiler for a realistic tagged source language.},
	journaltitle = {{arXiv}:2012.10313 [cs]},
	author = {Chhak, C. H. R. and Tolmach, Andrew and Anderson, Sean},
	urldate = {2021-01-20},
	date = {2020-12-18},
	eprinttype = {arxiv},
	eprint = {2012.10313},
	keywords = {Computer Science - Cryptography and Security},
	file = {arXiv.org Snapshot:/home/fordrl/Zotero/storage/USXWFHWI/2012.html:text/html;arXiv Fulltext PDF:/home/fordrl/Zotero/storage/INIDETNS/Chhak et al. - 2020 - Towards Formally Verified Compilation of Tag-Based.pdf:application/pdf},
}

@article{haslbeck_veried_nodate,
	title = {Veriﬁed Fine-Grained Algorithm Analysis Down to {LLVM}},
	abstract = {We present a framework to verify both, functional correctness and worst-case complexity of practically eﬃcient algorithms. We implemented a stepwise reﬁnement approach, using the novel concept of resource currencies to naturally structure the resource analysis along the reﬁnement chain, and allow a ﬁne-grained analysis of operation counts. Our framework targets the {LLVM} intermediate representation. We extend its semantics from earlier work with a cost model. As case study, we verify the correctness and O(n log n) worst-case complexity of an implementation of the introsort algorithm, whose performance is on par with the state-of-the-art implementation found in the {GNU} C++ Library.},
	pages = {28},
	author = {Haslbeck, Maximilian P L and Lammich, Peter},
	langid = {english},
	file = {Haslbeck and Lammich - Veriﬁed Fine-Grained Algorithm Analysis Down to LL.pdf:/home/fordrl/Zotero/storage/6G9VIYXH/Haslbeck and Lammich - Veriﬁed Fine-Grained Algorithm Analysis Down to LL.pdf:application/pdf},
}

@article{schoolderman_efficient_2020,
	title = {Efficient Verification of Optimized Code: Correct High-speed Curve25519},
	url = {http://arxiv.org/abs/2012.09919},
	shorttitle = {Efficient Verification of Optimized Code},
	abstract = {Code that is highly optimized poses a problem for program-level verification. Programmers can employ various clever tricks that are non-trivial to reason about. For cryptography on low-power devices, it is nonetheless crucial that implementations be functionally correct, secure, and efficient. These are usually crafted in hand-optimized machine code that eschew conventional control flow as much as possible. We have formally verified such code: a library which implements elliptic curve cryptography on 8-bit {AVR} microcontrollers. The chosen implementation is the most efficient currently known for this microarchitecture. It consists of over 3000 lines of assembly instructions. Building on earlier work, we use the Why3 platform to model the code and generate verification conditions, which are proven using automated provers. The approach is re-usable and adaptable, and allows for validation. Furthermore, an error in the original implementation was found and corrected, at the same time reducing its memory footprint. This shows that practical verification of cutting-edge code is not only possible, but can in fact add to its efficiency -- and is clearly necessary.},
	journaltitle = {{arXiv}:2012.09919 [cs]},
	author = {Schoolderman, Marc and Moerman, Jonathan and Smetsers, Sjaak and van Eekelen, Marko},
	urldate = {2021-01-20},
	date = {2020-12-17},
	eprinttype = {arxiv},
	eprint = {2012.09919},
	keywords = {Computer Science - Cryptography and Security, Computer Science - Logic in Computer Science, F.3, E.3},
	file = {arXiv.org Snapshot:/home/fordrl/Zotero/storage/QCY9G2EE/2012.html:text/html;arXiv Fulltext PDF:/home/fordrl/Zotero/storage/9IHI9YEY/Schoolderman et al. - 2020 - Efficient Verification of Optimized Code Correct .pdf:application/pdf},
}

@book{martin_mastering_2013,
	location = {Clifton Park, {NY}},
	edition = {6. ed},
	title = {Mastering {CMake}: a cross-platform build system ; covers installing and running {CMake} ; details converting existing build processes to {CMake} ; create powerful cross-platform build scripts},
	isbn = {978-1-930934-26-9},
	shorttitle = {Mastering {CMake}},
	pagetotal = {640},
	publisher = {Kitware},
	author = {Martin, Ken and Hoffman, Bill and Cedilnik, Andy},
	date = {2013},
	note = {{OCLC}: 869872480},
	file = {mastering-cmake.pdf:/home/fordrl/Zotero/storage/ZJ8TN7IN/mastering-cmake.pdf:application/pdf;Table of Contents PDF:/home/fordrl/Zotero/storage/J9EPKEK2/Martin et al. - 2013 - Mastering CMake a cross-platform build system \; c.pdf:application/pdf},
}

@incollection{feng_correct-by-construction_2018,
	location = {Cham},
	title = {Correct-by-Construction Implementation of Runtime Monitors Using Stepwise Refinement},
	volume = {10998},
	isbn = {978-3-319-99932-6 978-3-319-99933-3},
	url = {http://link.springer.com/10.1007/978-3-319-99933-3_3},
	pages = {31--49},
	booktitle = {Dependable Software Engineering. Theories, Tools, and Applications},
	publisher = {Springer International Publishing},
	author = {Zhang, Teng and Wiegley, John and Giannakopoulos, Theophilos and Eakman, Gregory and Pit-Claudel, Clément and Lee, Insup and Sokolsky, Oleg},
	editor = {Feng, Xinyu and Müller-Olm, Markus and Yang, Zijiang},
	urldate = {2019-01-31},
	date = {2018},
	doi = {10.1007/978-3-319-99933-3_3},
	file = {Zhang et al. - 2018 - Correct-by-Construction Implementation of Runtime .pdf:/home/fordrl/Zotero/storage/TFNK7T59/Zhang et al. - 2018 - Correct-by-Construction Implementation of Runtime .pdf:application/pdf},
}

@article{pit-claudel_extensible_nodate,
	title = {Extensible Extraction of Efﬁcient Imperative Programs with Foreign Functions, Manually Managed Memory, and Proofs},
	url = {http://pit-claudel.fr/clement/papers/fiat-to-facade.pdf},
	abstract = {We present an original approach to sound program extraction in a proof assistant, using syntax-driven automation to derive correct-by-construction imperative programs from nondeterministic functional source code. Our approach does not require committing to a single inﬂexible compilation strategy and instead makes it straightforward to create domainspeciﬁc code translators. In addition to a small set of core definitions, our framework is a large, user-extensible collection of compilation rules each phrased to handle speciﬁc language constructs, code patterns, or data manipulations. By mixing and matching these pieces of logic, users can easily tailor extraction to their own domains and programs, getting maximum performance and ensuring correctness of the resulting assembly code. Using this approach, we complete the ﬁrst proof-generating pipeline that goes automatically from high-level speciﬁcations to assembly code. In our main case study, the original speciﬁcations are phrased to resemble {SQL}-style queries, while the ﬁnal assembly code does manual memory management, calls out to foreign data structures and functions, and is suitable to deploy on resource-constrained platforms. The pipeline runs entirely within the Coq proof assistant, leading to ﬁnal, linked assembly code inside Coq with overall full-functional-correctness proofs in separation logic.},
	pages = {14},
	author = {Pit-Claudel, Clément and Wang, Peng and Delaware, Benjamin and Gross, Jason and Chlipala, Adam},
	langid = {english},
	note = {clement/fiat-to-facade.pdg},
	file = {Pit-Claudel et al. - Extensible Extraction of Efﬁcient Imperative Progr.pdf:/home/fordrl/Zotero/storage/PBAPDPGG/Pit-Claudel et al. - Extensible Extraction of Efﬁcient Imperative Progr.pdf:application/pdf},
}

@software{chlipala_formal_2019,
	title = {Formal Reasoning About Programs - Github},
	url = {https://github.com/achlipala/frap},
	author = {Chlipala, Adam},
	urldate = {2019-01-31},
	date = {2019-01-31},
	note = {original-date: 2016-02-02T18:43:56Z},
	file = {frap_book.pdf:/home/fordrl/Zotero/storage/W5SBG74C/frap_book.pdf:application/pdf},
}

@article{chlipala_certied_nodate,
	title = {Certiﬁed Programming with Dependent Types},
	pages = {369},
	author = {Chlipala, Adam},
	langid = {english},
	file = {Chlipala - Certiﬁed Programming with Dependent Types.pdf:/home/fordrl/Zotero/storage/DYCT99N4/Chlipala - Certiﬁed Programming with Dependent Types.pdf:application/pdf},
}

@book{chlipala_certified_2013,
	location = {Cambridge, {MA}},
	title = {Certified programming with dependent types: a pragmatic introduction to the Coq proof assistant},
	isbn = {978-0-262-02665-9},
	url = {http://adam.chlipala.net/cpdt/},
	shorttitle = {Certified programming with dependent types},
	pagetotal = {424},
	publisher = {The {MIT} Press},
	author = {Chlipala, Adam},
	date = {2013},
	keywords = {Automatic theorem proving, Computer programming, Computer programs, Coq (Electronic resource)},
}

@article{chlipala_introduction_nodate,
	title = {An Introduction to Programming and Proving with Dependent Types in Coq},
	volume = {3},
	abstract = {Computer proof assistants vary along many dimensions. Among the mature implementations, the Coq system is distinguished by two key features. First, we have support for programming with
dependent types in the tradition of type theory, based on dependent function types and inductive type families. Second, we have a domain-specific language for coding correct-by-construction proof automation. Though the Coq user community has grown quite large, neither of the aspects
I highlight is widely used. In this tutorial, I aim to provide a pragmatic introduction to both, showing how they can bring significant improvements in productivity.},
	pages = {93},
	number = {2},
	journaltitle = {Journal of Formalized Reasoning},
	author = {Chlipala, Adam},
	langid = {english},
	note = {chlipala/1978-4445-1-{PB}.pdf},
	file = {Chlipala - An Introduction to Programming and Proving with De.pdf:/home/fordrl/Zotero/storage/KS4N39J7/Chlipala - An Introduction to Programming and Proving with De.pdf:application/pdf},
}

@thesis{chargueraud_characteristic_2010,
	location = {Paris, France},
	title = {Characteristic Formulae for Mechanized Program Verification},
	abstract = {This dissertation describes a new approach to program veri cation,
based on characteristic formulae. The characteristic formula of a program
is a higher-order logic formula that describes the behavior of that
program, in the sense that it is sound and complete with respect to
the semantics. This formula can be exploited in an interactive theorem
prover to establish that the program satis es a speci cation expressed
in the style of Separation Logic, with respect to total correctness.
The characteristic formula of a program is automatically generated
from its source code alone. In particular, there is no need to annotate the
source code with speci cations or loop invariants, as such information
can be given in interactive proof scripts. One key feature of characteristic
formulae is that they are of linear size and that they can be prettyprinted
in a way that closely resemble the source code they describe, even
though they do not refer to the syntax of the programming language.
Characteristic formulae serve as a basis for a tool, called {CFML}, that
supports the veri cation of Caml programs using the Coq proof assistant.
{CFML} has been employed to verify about half of the content of
Okasaki's book on purely functional data structures, and to verify several
imperative data structures such as mutable lists, sparse arrays and
union- nd. {CFML} also supports reasoning on higher-order imperative
functions, such as functions in {CPS} form and higher-order iterators},
	pagetotal = {185},
	institution = {{UNIVERSITÉ} {PARIS}.{DIDEROT}},
	type = {phdthesis},
	author = {Charguéraud, Arthur},
	date = {2010-12-16},
	langid = {english},
	note = {chargueraud/chargueraud\_thesis\_final.pdf},
	file = {Charguéraud - Characteristic Formulae for Mechanized Program Ver.pdf:/home/fordrl/Zotero/storage/PZZIGKPW/Charguéraud - Characteristic Formulae for Mechanized Program Ver.pdf:application/pdf},
}

@inproceedings{chargueraud_characteristic_2011,
	location = {New York, {NY}, {USA}},
	title = {Characteristic Formulae for the Verification of Imperative Programs},
	isbn = {978-1-4503-0865-6},
	url = {http://doi.acm.org/10.1145/2034773.2034828},
	doi = {10.1145/2034773.2034828},
	series = {{ICFP} '11},
	abstract = {In previous work, we introduced an approach to program verification based on characteristic formulae. The approach consists of generating a higher-order logic formula from the source code of a program. This characteristic formula is constructed in such a way that it gives a sound and complete description of the semantics of that program. The formula can thus be exploited in an interactive proof assistant to formally verify that the program satisfies a particular specification. This previous work was, however, only concerned with purely-functional programs. In the present paper, we describe the generalization of characteristic formulae to an imperative programming language. In this setting, characteristic formulae involve specifications expressed in the style of Separation Logic. They also integrate the frame rule, which enables local reasoning. We have implemented a tool based on characteristic formulae. This tool, called {CFML}, supports the verification of imperative Caml programs using the Coq proof assistant. Using {CFML}, we have formally verified nontrivial imperative algorithms, as well as {CPS} functions, higher-order iterators, and programs involving higher-order stores.},
	pages = {418--430},
	booktitle = {Proceedings of the 16th {ACM} {SIGPLAN} International Conference on Functional Programming},
	publisher = {{ACM}},
	author = {Charguéraud, Arthur},
	urldate = {2019-01-31},
	date = {2011},
	keywords = {characteristic formula, interactive verification, total correctness},
	file = {ACM Full Text PDF:/home/fordrl/Zotero/storage/2GURSGU7/Charguéraud - 2011 - Characteristic Formulae for the Verification of Im.pdf:application/pdf},
}

@inproceedings{chargueraud_program_2010,
	location = {New York, {NY}, {USA}},
	title = {Program Verification Through Characteristic Formulae},
	isbn = {978-1-60558-794-3},
	url = {http://doi.acm.org/10.1145/1863543.1863590},
	doi = {10.1145/1863543.1863590},
	series = {{ICFP} '10},
	abstract = {This paper describes {CFML}, the first program verification tool based on characteristic formulae. Given the source code of a pure Caml program, this tool generates a logical formula that implies any valid post-condition for that program. One can then prove that the program satisfies a given specification by reasoning interactively about the characteristic formula using a proof assistant such as Coq. Our characteristic formulae improve over Honda et al's total characteristic assertion pairs in that they are expressible in standard higher-order logic, allowing to exploit them in practice to verify programs using existing proof assistants. Our technique has been applied to formally verify more than half of the content of Okasaki's Purely Functional Data Structures reference book},
	pages = {321--332},
	booktitle = {Proceedings of the 15th {ACM} {SIGPLAN} International Conference on Functional Programming},
	publisher = {{ACM}},
	author = {Charguéraud, Arthur},
	urldate = {2019-01-31},
	date = {2010},
	keywords = {characteristic formula, total correctness, functional program},
	file = {ACM Full Text PDF:/home/fordrl/Zotero/storage/LP9W7JLK/Charguéraud - 2010 - Program Verification Through Characteristic Formul.pdf:application/pdf},
}

@inproceedings{gu_certified_2018,
	location = {New York, {NY}, {USA}},
	title = {Certified Concurrent Abstraction Layers},
	isbn = {978-1-4503-5698-5},
	url = {http://doi.acm.org/10.1145/3192366.3192381},
	doi = {10.1145/3192366.3192381},
	series = {{PLDI} 2018},
	abstract = {Concurrent abstraction layers are ubiquitous in modern computer systems because of the pervasiveness of multithreaded programming and multicore hardware. Abstraction layers are used to hide the implementation details (e.g., fine-grained synchronization) and reduce the complex dependencies among components at different levels of abstraction. Despite their obvious importance, concurrent abstraction layers have not been treated formally. This severely limits the applicability of layer-based techniques and makes it difficult to scale verification across multiple concurrent layers.   In this paper, we present {CCAL}---a fully mechanized programming toolkit developed under the {CertiKOS} project---for specifying, composing, compiling, and linking certified concurrent abstraction layers. {CCAL} consists of three technical novelties: a new game-theoretical, strategy-based compositional semantic model for concurrency (and its associated program verifiers), a set of formal linking theorems for composing multithreaded and multicore concurrent layers, and a new {CompCertX} compiler that supports certified thread-safe compilation and linking. The {CCAL} toolkit is implemented in Coq and supports layered concurrent programming in both C and assembly. It has been successfully applied to build a fully certified concurrent {OS} kernel with fine-grained locking.},
	pages = {646--661},
	booktitle = {Proceedings of the 39th {ACM} {SIGPLAN} Conference on Programming Language Design and Implementation},
	publisher = {{ACM}},
	author = {Gu, Ronghui and Shao, Zhong and Kim, Jieung and Wu, Xiongnan (Newman) and Koenig, Jérémie and Sjöberg, Vilhelm and Chen, Hao and Costanzo, David and Ramananandro, Tahina},
	urldate = {2019-01-31},
	date = {2018},
	keywords = {abstraction layer, certified compilers, certified {OS} kernels, concurrency, modularity, Verification},
	file = {ACM Full Text PDF:/home/fordrl/Zotero/storage/84F5S82K/Gu et al. - 2018 - Certified Concurrent Abstraction Layers.pdf:application/pdf},
}

@article{costanzo_end--end_nodate,
	title = {End-to-End Veriﬁcation of Information-Flow Security for C and Assembly Programs - Tech Report},
	url = {http://flint.cs.yale.edu/certikos/publications/security-tr.pdf},
	abstract = {Protecting the conﬁdentiality of information manipulated by a computing system is one of the most important challenges facing today’s cybersecurity community. A promising step toward conquering this challenge is to formally verify that the end-to-end behavior of the computing system really satisﬁes various information-ﬂow policies. Unfortunately, because today’s system software still consists of both C and assembly programs, the end-to-end veriﬁcation necessarily requires that we not only prove the security properties of individual components, but also carefully preserve these properties through compilation and cross-language linking.},
	pages = {21},
	author = {Costanzo, David and Shao, Zhong and Gu, Ronghui},
	langid = {english},
	note = {certikos/pldi16-certikos-security-tr.pdf},
	file = {Costanzo et al. - End-to-End Veriﬁcation of Information-Flow Securit.pdf:/home/fordrl/Zotero/storage/L2E38WJM/Costanzo et al. - End-to-End Veriﬁcation of Information-Flow Securit.pdf:application/pdf},
}

@inproceedings{gu_certikos:_2016,
	location = {Berkeley, {CA}, {USA}},
	title = {{CertiKOS}: An Extensible Architecture for Building Certified Concurrent {OS} Kernels},
	isbn = {978-1-931971-33-1},
	url = {http://dl.acm.org/citation.cfm?id=3026877.3026928},
	series = {{OSDI}'16},
	shorttitle = {{CertiKOS}},
	abstract = {Complete formal verification of a non-trivial concurrent {OS} kernel is widely considered a grand challenge. We present a novel compositional approach for building certified concurrent {OS} kernels. Concurrency allows interleaved execution of kernel/user modules across different layers of abstraction. Each such layer can have a different set of observable events. We insist on formally specifying these layers and their observable events, and then verifying each kernel module at its proper abstraction level. To support certified linking with other {CPUs} or threads, we prove a strong contextual refinement property for every kernel function, which states that the implementation of each such function will behave like its specification under any kernel/user context with any valid interleaving. We have successfully developed a practical concurrent {OS} kernel and verified its (contextual) functional correctness in Coq. Our certified kernel is written in 6500 lines of C and x86 assembly and runs on stock x86 multicore machines. To our knowledge, this is the first proof of functional correctness of a complete, general-purpose concurrent {OS} kernel with fine-grained locking.},
	pages = {653--669},
	booktitle = {Proceedings of the 12th {USENIX} Conference on Operating Systems Design and Implementation},
	publisher = {{USENIX} Association},
	author = {Gu, Ronghui and Shao, Zhong and Chen, Hao and Wu, Xiongnan and Kim, Jieung and Sjöberg, Vilhelm and Costanzo, David},
	urldate = {2019-01-31},
	date = {2016},
	file = {Gu et al. - 2016 - CertiKOS An Extensible Architecture for Building .pdf:/home/fordrl/Zotero/storage/A928RE7F/Gu et al. - 2016 - CertiKOS An Extensible Architecture for Building .pdf:application/pdf},
}

@article{herlihy_linearizability:_1990,
	title = {Linearizability: A Correctness Condition for Concurrent Objects},
	volume = {12},
	issn = {0164-0925},
	url = {http://doi.acm.org/10.1145/78969.78972},
	doi = {10.1145/78969.78972},
	shorttitle = {Linearizability},
	abstract = {A concurrent object is a data object shared by concurrent processes. Linearizability is a correctness condition for concurrent objects that exploits the semantics of abstract data types. It permits a high degree of concurrency, yet it permits programmers to specify and reason about concurrent objects using known techniques from the sequential domain. Linearizability provides the illusion that each operation applied by concurrent processes takes effect instantaneously at some point between its invocation and its response, implying that the meaning of a concurrent object's operations can be given by pre- and post-conditions. This paper defines linearizability, compares it to other correctness conditions, presents and demonstrates a method for proving the correctness of implementations, and shows how to reason about concurrent objects, given they are linearizable.},
	pages = {463--492},
	number = {3},
	journaltitle = {{ACM} Trans. Program. Lang. Syst.},
	author = {Herlihy, Maurice P. and Wing, Jeannette M.},
	urldate = {2019-01-31},
	date = {1990-07},
	file = {ACM Full Text PDF:/home/fordrl/Zotero/storage/XCLSDXNI/Herlihy and Wing - 1990 - Linearizability A Correctness Condition for Concu.pdf:application/pdf},
}

@article{murawski_invitation_2016,
	title = {An Invitation to Game Semantics},
	volume = {3},
	issn = {2372-3491},
	url = {http://doi.acm.org/10.1145/2948896.2948902},
	doi = {10.1145/2948896.2948902},
	abstract = {Game semantics is a flexible semantic theory that has led in recent years to an unprecedented number of full abstraction results for various programming paradigms. We present a gentle introduction to the subject, focussing on high-level ideas and examples with a view to providing a bridge to more technical literature.},
	pages = {56--67},
	number = {2},
	journaltitle = {{ACM} {SIGLOG} News},
	author = {Murawski, Andrzej S. and Tzevelekos, Nikos},
	urldate = {2019-01-31},
	date = {2016-05},
	file = {ACM Full Text PDF:/home/fordrl/Zotero/storage/ITYEIVIF/Murawski and Tzevelekos - 2016 - An Invitation to Game Semantics.pdf:application/pdf},
}

@inproceedings{gu_deep_2015,
	location = {New York, {NY}, {USA}},
	title = {Deep Specifications and Certified Abstraction Layers},
	isbn = {978-1-4503-3300-9},
	url = {http://doi.acm.org/10.1145/2676726.2676975},
	doi = {10.1145/2676726.2676975},
	series = {{POPL} '15},
	abstract = {Modern computer systems consist of a multitude of abstraction layers (e.g., {OS} kernels, hypervisors, device drivers, network protocols), each of which defines an interface that hides the implementation details of a particular set of functionality. Client programs built on top of each layer can be understood solely based on the interface, independent of the layer implementation. Despite their obvious importance, abstraction layers have mostly been treated as a system concept; they have almost never been formally specified or verified. This makes it difficult to establish strong correctness properties, and to scale program verification across multiple layers. In this paper, we present a novel language-based account of abstraction layers and show that they correspond to a strong form of abstraction over a particularly rich class of specifications which we call deep specifications. Just as data abstraction in typed functional languages leads to the important representation independence property, abstraction over deep specification is characterized by an important implementation independence property: any two implementations of the same deep specification must have contextually equivalent behaviors. We present a new layer calculus showing how to formally specify, program, verify, and compose abstraction layers. We show how to instantiate the layer calculus in realistic programming languages such as C and assembly, and how to adapt the {CompCert} verified compiler to compile certified C layers such that they can be linked with assembly layers. Using these new languages and tools, we have successfully developed multiple certified {OS} kernels in the Coq proof assistant, the most realistic of which consists of 37 abstraction layers, took less than one person year to develop, and can boot a version of Linux as a guest.},
	pages = {595--608},
	booktitle = {Proceedings of the 42Nd Annual {ACM} {SIGPLAN}-{SIGACT} Symposium on Principles of Programming Languages},
	publisher = {{ACM}},
	author = {Gu, Ronghui and Koenig, Jérémie and Ramananandro, Tahina and Shao, Zhong and Wu, Xiongnan (Newman) and Weng, Shu-Chun and Zhang, Haozhong and Guo, Yu},
	urldate = {2019-01-31},
	date = {2015},
	keywords = {abstraction layer, certified compilers, modularity, certified os kernels, deep specification, program verification},
	file = {ACM Full Text PDF:/home/fordrl/Zotero/storage/7DPCTJMC/Gu et al. - 2015 - Deep Specifications and Certified Abstraction Laye.pdf:application/pdf},
}

@book{bowman_j1:_nodate,
	title = {J1: a small Forth {CPU} Core for {FPGAs}},
	shorttitle = {J1},
	abstract = {Abstract—This paper describes a 16-bit Forth {CPU} core, intended for {FPGAs}. The instruction set closely matches the Forth programming language, simplifying cross-compilation. Because it has higher throughput than comparable {CPU} cores, it can stream uncompressed video over Ethernet using a simple software loop.The entire system (source Verilog,cross compiler, and {TCP}/{IP} networking code) is published under the {BSD} license. The core is less than 200 lines of Verilog, and operates reliably at 80 {MHz} in a Xilinx Spartan R○-3E {FPGA}, delivering approximately 100 {ANS} Forth {MIPS}. I.},
	author = {Bowman, James},
	file = {Citeseer - Snapshot:/home/fordrl/Zotero/storage/W6VSU9EW/summary.html:text/html;Citeseer - Full Text PDF:/home/fordrl/Zotero/storage/T8LQY54B/Bowman - J1 a small Forth CPU Core for FPGAs.pdf:application/pdf},
}

@inproceedings{boulier_next_2017,
	title = {The next 700 syntactical models of type theory},
	url = {https://hal.inria.fr/hal-01445835/document},
	doi = {10.1145/3018610.3018620},
	abstract = {A family of syntactic models for the calculus of construction with universes ({CC} ω) is described, all of them preserving conversion of the calculus definitionally, and thus giving rise directly to a program transformation of {CC} ω into itself. Those models are based on the remark that negative type constructors (e.g., dependent product, coinductive types or universes) are underspecified in type theory—which leaves some freedom on extra intensional specifications. The model construction can be seen as a compilation phase from a complex type theory into a simpler type theory. Such models can be used to derive (the negative part of) independence results with respect to {CC} ω , such as functional extensional-ity, propositional extensionality, univalence or the fact that bisimulation on a coinductive type may not coincide with equality. They can also be used to add new principles to the theory, which we illustrate by defining a version of {CC} ω with ad-hoc polymorphism that shows in particular that para-metricity is not an implicit requirement of type theory. The correctness of some of the models/program transformations have been checked in the {COQ} proof assistant and have been instrumented as a {COQ} plugin.},
	eventtitle = {Certified Programs and Proofs ({CPP} 2017)},
	pages = {182 -- 194},
	author = {Boulier, Simon and Pédrot, Pierre-Marie and Tabareau, Nicolas},
	urldate = {2019-01-31},
	date = {2017-01-16},
	langid = {english},
	file = {Snapshot:/home/fordrl/Zotero/storage/VKLAKHTH/hal-01445835.html:text/html;Full Text PDF:/home/fordrl/Zotero/storage/63IAMKPN/Boulier et al. - 2017 - The next 700 syntactical models of type theory.pdf:application/pdf},
}

@thesis{sherman_making_2017,
	location = {Cambridge, {MA}},
	title = {Making Discrete Decisions Based on Continuous Values},
	url = {http://adam.chlipala.net/theses/sherman_sm.pdf},
	abstract = {Many safety-critical software systems are cyber-physical systems that compute with continuous values; confirming their safety requires guaranteeing the accuracy of their computations. It is impossible for these systems to compute (total and deterministic) discrete computations (e.g., decisions) based on connected input spaces such as R. We propose a programming language based on constructive topology, whose types are spaces and programs are executable continuous maps, that facilitates making formal guarantees of accuracy of computed results. We demonstrate that discrete decisions can be made based on continuous values by permitting nondeterminism. This thesis describes variants of the programming language allowing nondeterminism and/or partiality, and introduces two tools for creating nondeterministic programs on spaces. Overlapping pattern matching is a generalization of pattern matching in functional programming, where patterns need not represent decidable predicates and also may overlap, allowing potentially nondeterministic behavior in overlapping regions. Binary covers, which are pairs of predicates such that at least one of them holds, yield a formal logic for constructing approximate decision procedures.},
	pagetotal = {105},
	institution = {{MIT}},
	type = {Master of Science},
	author = {Sherman, Benjamin},
	date = {2017-06},
	langid = {english},
	note = {ben-sherman/sm-thesis.pdf},
	file = {Sherman - Making Discrete Decisions Based on Continuous Valu.pdf:/home/fordrl/Zotero/storage/KF9N82CU/Sherman - Making Discrete Decisions Based on Continuous Valu.pdf:application/pdf},
}

@article{bedford_coqatoo:_nodate,
	title = {Coqatoo: Generating Natural Language Versions of Coq Proofs - Slides},
	pages = {16},
	author = {Bedford, Andrew},
	langid = {english},
	file = {Bedford - Generating Natural Language Versions of Coq Proofs.pdf:/home/fordrl/Zotero/storage/NKL4736M/Bedford - Generating Natural Language Versions of Coq Proofs.pdf:application/pdf},
}

@article{bedford_coqatoo:_2017,
	title = {Coqatoo: Generating Natural Language Versions of Coq Proofs},
	url = {http://arxiv.org/abs/1712.03894},
	shorttitle = {Coqatoo},
	abstract = {Due to their numerous advantages, formal proofs and proof assistants, such as Coq, are becoming increasingly popular. However, one disadvantage of using proof assistants is that the resulting proofs can sometimes be hard to read and understand, particularly for less-experienced users. To address this issue, we have implemented a tool capable of generating natural language versions of Coq proofs called Coqatoo, which we present in this paper.},
	journaltitle = {{arXiv}:1712.03894 [cs]},
	author = {Bedford, Andrew},
	urldate = {2019-01-31},
	date = {2017-12-11},
	eprinttype = {arxiv},
	eprint = {1712.03894},
	keywords = {Computer Science - Programming Languages},
	file = {arXiv.org Snapshot:/home/fordrl/Zotero/storage/UBK7X3KY/1712.html:text/html;arXiv\:1712.03894 PDF:/home/fordrl/Zotero/storage/HUTDVY7Z/Bedford - 2017 - Coqatoo Generating Natural Language Versions of C.pdf:application/pdf},
}

@inproceedings{mine_taking_2016,
	location = {Toulouse, France},
	title = {Taking Static Analysis to the Next Level: Proving the Absence of Run-Time Errors and Data Races with Astrée},
	url = {https://hal.archives-ouvertes.fr/hal-01271552},
	shorttitle = {Taking Static Analysis to the Next Level},
	abstract = {We present an extension of Astrée to concurrent C software. Astrée is a sound static analyzer for run-time errors previously limited to sequential C software. Our extension employs a scalable abstraction which covers all possible thread interleavings, and soundly reports all run-time errors and data races: when the analyzer does not report any alarm, the program is proven free from those classes of errors. We show how this extension is able to support a variety of operating systems (such as {POSIX} threads, {ARINC} 653, {OSEK}/{AUTOSAR}) and report on experimental results obtained on concurrent software from different domains, including large industrial software.},
	booktitle = {8th European Congress on Embedded Real Time Software and Systems ({ERTS} 2016)},
	author = {Miné, Antoine and Mauborgne, Laurent and Rival, Xavier and Feret, Jerome and Cousot, Patrick and Kästner, Daniel and Wilhelm, Stephan and Ferdinand, Christian},
	urldate = {2019-01-31},
	date = {2016-01},
	file = {HAL PDF Full Text:/home/fordrl/Zotero/storage/76NS6CAS/Miné et al. - 2016 - Taking Static Analysis to the Next Level Proving .pdf:application/pdf},
}

@article{kastner_astree:_nodate,
	title = {Astree: Proving the Absence of Runtime Errors},
	url = {https://www.di.ens.fr/~rival/papers/erts10.pdf},
	abstract = {Safety-critical embedded software has to satisfy stringent quality requirements. Testing and validation consumes a large – and growing – fraction of development cost. The last years have seen the emergence of semantics-based static analysis tools in various application areas, from runtime error analysis to worst-case execution time prediction. Their appeal is that they have the potential to reduce testing eﬀort while providing 100\% coverage, thus enhancing safety. Static runtime error analysis is applicable to large industryscale projects and produces a list of deﬁnite runtime errors and of potential runtime errors which might be true errors or false alarms. In the past, often only the deﬁnite errors were ﬁxed because manually inspecting each alarm was too time-consuming due to a large number of false alarms. Therefore no proof of the absence of runtime errors could be given. In this article the parameterizable static analyzer Astr´ee is presented. By specialization and parameterization Astr´ee can be adapted to the software under analysis. This enables Astr´ee to eﬃciently compute precise results. Astr´ee has successfully been used to analyze large-scale safety-critical avionics software with zero false alarms.},
	pages = {9},
	author = {Kästner, D and Wilhelm, S and Nenova, S and Miné, A and Rival, X and Mauborgne, L and Feret, J and Cousot, P and Cousot, R},
	langid = {english},
	note = {astree/astee-proving-absence-rte.pdf},
	file = {Kästner et al. - Astree Proving the Absence of Runtime Errors.pdf:/home/fordrl/Zotero/storage/USSVMPAS/Kästner et al. - Astree Proving the Absence of Runtime Errors.pdf:application/pdf},
}

@article{monniaux_parallel_2005,
	title = {The parallel implementation of the Astr{\textbackslash}'\{e\}e static analyzer},
	volume = {3780},
	url = {http://arxiv.org/abs/cs/0701191},
	doi = {10.1007/11575467_7},
	abstract = {The Astr{\textbackslash}'\{e\}e static analyzer is a specialized tool that can prove the absence of runtime errors, including arithmetic overflows, in large critical programs. Keeping analysis times reasonable for industrial use is one of the design objectives. In this paper, we discuss the parallel implementation of the analysis.},
	pages = {86--96},
	journaltitle = {{arXiv}:cs/0701191},
	author = {Monniaux, David},
	urldate = {2019-01-31},
	date = {2005},
	eprinttype = {arxiv},
	eprint = {cs/0701191},
	keywords = {Computer Science - Programming Languages, D.2.4, Computer Science - Performance},
	file = {arXiv.org Snapshot:/home/fordrl/Zotero/storage/M3ZXKGYR/0701191.html:text/html;arXiv\:cs/0701191 PDF:/home/fordrl/Zotero/storage/XJI5L7X9/Monniaux - 2005 - The parallel implementation of the Astr'\{e\}e stat.pdf:application/pdf},
}

@inproceedings{kastner_program_2015,
	location = {Paris, France},
	title = {Program Analysis on Evolving Software},
	url = {https://hal.archives-ouvertes.fr/hal-01192985},
	abstract = {Static analysis is well-suited for continuous verification during the software development stage since it only works on the source code and does not require a running system for testing. However, applying the program analysis during software development means that the analysis has to cope with evolving software and evolving analyzer configurations, especially in a model-based development process. In this article we present a unique history-aware concept for program analysis that has been developed for the static analyzer Astrée. It not only provides the ability to backtrack and access previous versions of the analysis configuration, it can also automatically determine the differences between two analysis configurations and relate them to the correct source code versions. Users can explicitly create a revision, i.e. a snapshot of the analysis project; changes of the source code, analysis options, analysis directives and results in different revisions are automatically detected and highlighted. The analyzer provides automatic correctness checks for all specified analysis directives, e.g., to tune the precision of the analyzer or provide information about the environment. This makes software verification applicable during the implementation stage, significantly reduces the effort to adapt the analyzer configuration to new source code versions, and makes analysis results on previous software versions easily reproducible.},
	booktitle = {{CARS} 2015 - Critical Automotive applications: Robustness \& Safety},
	author = {Kästner, Daniel and Pohland, Jan},
	editor = {Roy, Matthieu},
	urldate = {2019-01-31},
	date = {2015-09},
	file = {HAL PDF Full Text:/home/fordrl/Zotero/storage/LEVP5BEU/Kästner and Pohland - 2015 - Program Analysis on Evolving Software.pdf:application/pdf},
}

@inproceedings{appel_verified_2012,
	location = {Berlin, Heidelberg},
	title = {Verified Software Toolchain},
	isbn = {978-3-642-28890-6},
	url = {http://dx.doi.org/10.1007/978-3-642-28891-3_2},
	doi = {10.1007/978-3-642-28891-3_2},
	series = {{NFM}'12},
	abstract = {The software toolchain includes static analyzers to check assertions about programs; optimizing compilers to translate programs to machine language; operating systems and libraries to supply context for programs. Our Verified Software Toolchain verifies with machine-checked proofs that the assertions claimed at the top of the toolchain really hold in the machine-language program, running in the operating-system context, on a weakly-consistent-shared-memory machine. Our verification approach is modular, in that proofs about operating systems or concurrency libraries are oblivious of the programming language or machine language, proofs about compilers are oblivious of the program logic used to verify static analyzers, and so on. The approach is scalable, in that each component is verified in the semantic idiom most natural for that component. Finally, the verification is foundational: the trusted base for proofs of observable properties of the machine-language program includes only the operational semantics of the machine language, not the source language, the compiler, the program logic, or any other part of the toolchain--even when these proofs are carried out by source-level static analyzers. In this paper I explain the construction of a a verified toolchain, using the Coq proof assistant. I will illustrate with shape analysis for C programs based on separation logic.},
	pages = {2--2},
	booktitle = {Proceedings of the 4th International Conference on {NASA} Formal Methods},
	publisher = {Springer-Verlag},
	author = {Appel, Andrew W.},
	urldate = {2019-01-31},
	date = {2012},
	file = {Submitted Version:/home/fordrl/Zotero/storage/I5S7W94U/Appel - 2012 - Verified Software Toolchain.pdf:application/pdf},
}

@inproceedings{stewart_verified_2012,
	location = {New York, {NY}, {USA}},
	title = {Verified Heap Theorem Prover by Paramodulation},
	isbn = {978-1-4503-1054-3},
	url = {http://doi.acm.org/10.1145/2364527.2364531},
	doi = {10.1145/2364527.2364531},
	series = {{ICFP} '12},
	abstract = {We present {VeriStar}, a verified theorem prover for a decidable subset of separation logic. Together with {VeriSmall} [3], a proved-sound Smallfoot-style program analysis for C minor, {VeriStar} demonstrates that fully machine-checked static analyses equipped with efficient theorem provers are now within the reach of formal methods. As a pair, {VeriStar} and {VeriSmall} represent the first application of the Verified Software Toolchain [4], a tightly integrated collection of machine-verified program logics and compilers giving foundational correctness guarantees. {VeriStar} is (1) purely functional, (2) machine-checked, (3) end-to-end, (4) efficient and (5) modular. By purely functional, we mean it is implemented in Gallina, the pure functional programming language embedded in the Coq theorem prover. By machine-checked, we mean it has a proof in Coq that when the prover says "valid", the checked entailment holds in a proved-sound separation logic for C minor. By end-to-end, we mean that when the static analysis+theorem prover says a C minor program is safe, the program will be compiled to a semantically equivalent assembly program that runs on real hardware. By efficient, we mean that the prover implements a state-of-the-art algorithm for deciding heap entailments and uses highly tuned verified functional data structures. By modular, we mean that {VeriStar} can be retrofitted to other static analyses as a plug-compatible entailment checker and its soundness proof can easily be ported to other separation logics.},
	pages = {3--14},
	booktitle = {Proceedings of the 17th {ACM} {SIGPLAN} International Conference on Functional Programming},
	publisher = {{ACM}},
	author = {Stewart, Gordon and Beringer, Lennart and Appel, Andrew W.},
	urldate = {2019-01-31},
	date = {2012},
	keywords = {theorem proving, paramodulation, separation logic},
	file = {ACM Full Text PDF:/home/fordrl/Zotero/storage/99IVRGUA/Stewart et al. - 2012 - Verified Heap Theorem Prover by Paramodulation.pdf:application/pdf},
}

@incollection{jouannaud_verismall:_2011,
	location = {Berlin, Heidelberg},
	title = {{VeriSmall}: Verified Smallfoot Shape Analysis},
	volume = {7086},
	isbn = {978-3-642-25378-2 978-3-642-25379-9},
	url = {http://link.springer.com/10.1007/978-3-642-25379-9_18},
	shorttitle = {{VeriSmall}},
	pages = {231--246},
	booktitle = {Certified Programs and Proofs},
	publisher = {Springer Berlin Heidelberg},
	author = {Appel, Andrew W.},
	editor = {Jouannaud, Jean-Pierre and Shao, Zhong},
	urldate = {2019-01-31},
	date = {2011},
	doi = {10.1007/978-3-642-25379-9_18},
	file = {Submitted Version:/home/fordrl/Zotero/storage/98T3SKZJ/Appel - 2011 - VeriSmall Verified Smallfoot Shape Analysis.pdf:application/pdf},
}

@article{appel_verification_2015,
	title = {Verification of a Cryptographic Primitive: {SHA}-256},
	volume = {37},
	issn = {0164-0925},
	url = {http://doi.acm.org/10.1145/2701415},
	doi = {10.1145/2701415},
	shorttitle = {Verification of a Cryptographic Primitive},
	abstract = {This article presents a full formal machine-checked verification of a C program: the {OpenSSL} implementation of {SHA}-256. This is an interactive proof of functional correctness in the Coq proof assistant, using the Verifiable C program logic. Verifiable C is a separation logic for the C language, proved sound with respect to the operational semantics for C, connected to the {CompCert} verified optimizing C compiler.},
	pages = {7:1--7:31},
	number = {2},
	journaltitle = {{ACM} Trans. Program. Lang. Syst.},
	author = {Appel, Andrew W.},
	urldate = {2019-01-31},
	date = {2015-04},
	keywords = {Cryptography},
	file = {ACM Full Text PDF:/home/fordrl/Zotero/storage/8N6RDMZK/Appel - 2015 - Verification of a Cryptographic Primitive SHA-256.pdf:application/pdf},
}

@book{appel_verifiabble_2014,
	location = {Cambridge},
	title = {Verifiabble C, Version 2.2},
	isbn = {978-1-107-25655-2},
	url = {http://ebooks.cambridge.org/ref/id/CBO9781107256552},
	publisher = {Cambridge University Press},
	author = {Appel, Andrew W. and Dockins, Robert and Hobor, Aquinas and Beringer, Lennart and Dodds, Josiah and Stewart, Gordon and Blazy, Sandrine and Leroy, Xavier},
	urldate = {2019-01-31},
	date = {2014},
	langid = {english},
	doi = {10.1017/CBO9781107256552},
	file = {Verifiable C Version 2.2:/home/fordrl/Zotero/storage/GRBISGXR/Appel et al. - 2014 - Program Logics for Certified Compilers.pdf:application/pdf},
}

@incollection{hutchison_verified_2014,
	location = {Berlin, Heidelberg},
	title = {Verified Compilation for Shared-Memory C},
	volume = {8410},
	isbn = {978-3-642-54832-1 978-3-642-54833-8},
	url = {http://link.springer.com/10.1007/978-3-642-54833-8_7},
	pages = {107--127},
	booktitle = {Programming Languages and Systems},
	publisher = {Springer Berlin Heidelberg},
	author = {Beringer, Lennart and Stewart, Gordon and Dockins, Robert and Appel, Andrew W.},
	editor = {Shao, Zhong},
	editorb = {Hutchison, David and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M. and Mattern, Friedemann and Mitchell, John C. and Naor, Moni and Nierstrasz, Oscar and Pandu Rangan, C. and Steffen, Bernhard and Sudan, Madhu and Terzopoulos, Demetri and Tygar, Doug and Vardi, Moshe Y. and Weikum, Gerhard},
	editorbtype = {redactor},
	urldate = {2019-01-31},
	date = {2014},
	doi = {10.1007/978-3-642-54833-8_7,},
	note = {appel/shmemc.pdf is a preview},
	file = {Full Text:/home/fordrl/Zotero/storage/TXJ95W6N/Beringer et al. - 2014 - Verified Compilation for Shared-Memory C.pdf:application/pdf},
}

@article{cao_vst-floyd:_2018,
	title = {{VST}-Floyd: A Separation Logic Tool to Verify Correctness of C Programs},
	volume = {61},
	issn = {0168-7433},
	url = {https://doi.org/10.1007/s10817-018-9457-5},
	doi = {10.1007/s10817-018-9457-5},
	shorttitle = {{VST}-Floyd},
	abstract = {The Verified Software Toolchain builds foundational machine-checked proofs of the functional correctness of C programs. Its program logic, Verifiable C, is a shallowly embedded higher-order separation Hoare logic which is proved sound in Coq with respect to the operational semantics of {CompCert} Clight. This paper introduces {VST}-Floyd, a verification assistant which offers a set of semiautomatic tactics helping users build functional correctness proofs for C programs using Verifiable C.},
	pages = {367--422},
	number = {1},
	journaltitle = {J. Autom. Reason.},
	author = {Cao, Qinxiang and Beringer, Lennart and Gruetter, Samuel and Dodds, Josiah and Appel, Andrew W.},
	urldate = {2019-01-31},
	date = {2018-06},
	keywords = {Program verification, Proof automation, Separation logic, Symbolic execution},
	file = {Cao et al. - 2018 - VST-Floyd A Separation Logic Tool to Verify Corre.pdf:/home/fordrl/Zotero/storage/FCBL8RIJ/Cao et al. - 2018 - VST-Floyd A Separation Logic Tool to Verify Corre.pdf:application/pdf},
}

@inproceedings{hobor_theory_2010,
	location = {New York, {NY}, {USA}},
	title = {A Theory of Indirection via Approximation},
	isbn = {978-1-60558-479-9},
	url = {http://doi.acm.org/10.1145/1706299.1706322},
	doi = {10.1145/1706299.1706322},
	series = {{POPL} '10},
	abstract = {Building semantic models that account for various kinds of indirect reference has traditionally been a difficult problem. Indirect reference can appear in many guises, such as heap pointers, higher-order functions, object references, and shared-memory mutexes. We give a general method to construct models containing indirect reference by presenting a "theory of indirection". Our method can be applied in a wide variety of settings and uses only simple, elementary mathematics. In addition to various forms of indirect reference, the resulting models support powerful features such as impredicative quantification and equirecursion; moreover they are compatible with the kind of powerful substructural accounting required to model (higher-order) separation logic. In contrast to previous work, our model is easy to apply to new settings and has a simple axiomatization, which is complete in the sense that all models of it are isomorphic. Our proofs are machine-checked in Coq.},
	pages = {171--184},
	booktitle = {Proceedings of the 37th Annual {ACM} {SIGPLAN}-{SIGACT} Symposium on Principles of Programming Languages},
	publisher = {{ACM}},
	author = {Hobor, Aquinas and Dockins, Robert and Appel, Andrew W.},
	urldate = {2019-01-31},
	date = {2010},
	keywords = {indirection theory, step-indexed models},
	file = {ACM Full Text PDF:/home/fordrl/Zotero/storage/LDZGVN4K/Hobor et al. - 2010 - A Theory of Indirection via Approximation.pdf:application/pdf},
}

@inproceedings{conchon_increasing_2016,
	title = {Increasing Proofs Automation Rate of Atelier-B Thanks to Alt-Ergo},
	isbn = {978-3-319-33951-1},
	series = {Lecture Notes in Computer Science},
	abstract = {In this paper, we report on our recent improvements in the Alt-Ergo {SMT} solver to make it effective in discharging proof obligations ({POs}) translated from the Atelier-B framework. In particular, we made important modifications in its internal data structures to boost performances of its core decision procedures, we improved quantifiers instantiation heuristics, and enhanced the interaction between the {SAT} solver and the decision procedures. We also introduced a new plugin architecture to facilitate experiments with different {SAT} engines, and implemented a profiling plugin to track and identify “bottlenecks” when a formula requires a long time to be discharged, or makes the solver timeout. Experiments made with more than 10,000 {POs} generated from real industrial B projects show significant improvements compared to both previous versions of Alt-Ergo and Atelier-B’s automatic main prover.},
	pages = {243--253},
	booktitle = {Reliability, Safety, and Security of Railway Systems. Modelling, Analysis, Verification, and Certification},
	publisher = {Springer International Publishing},
	author = {Conchon, Sylvain and Iguernlala, Mohamed},
	editor = {Lecomte, Thierry and Pinger, Ralf and Romanovsky, Alexander},
	date = {2016},
	langid = {english},
	note = {alt-ergo/Alt-Ergo--Atelier-B--{RSSR}-2016.pdf},
	keywords = {B method, B proof obligations, {SMT} solvers},
	file = {Conchon and Iguernlala - Increasing Proofs Automation Rate of Thanks to Ate.pdf:/home/fordrl/Zotero/storage/RG6FY56C/Conchon and Iguernlala - Increasing Proofs Automation Rate of Thanks to Ate.pdf:application/pdf},
}

@inproceedings{conchon_alt-ergo_2018,
	location = {Oxford, United Kingdom},
	title = {Alt-Ergo 2.2},
	url = {https://hal.inria.fr/hal-01960203},
	abstract = {Alt-Ergo is an {SMT} solver jointly developed by Université Paris-Sud and the {OCamlPro} company. The first version was released in 2006. Since then, its architecture has been continuously adapted for proving formulas generated by software development frameworks. As type systems with polymorphism arise naturally is such platforms, the design of Alt-Ergo has been guided (and constrained) by a native-and non {SMT}-{LIB} compliant-input language for a polymorphic first-order logic. In this paper, we present the last version of Alt-Ergo, its architecture and main features. The main recent work is a support for a conservative polymorphic extension of the {SMT}-{LIB} 2 standard. We measure Alt-Ergo's performances with this new frontend on a set of benchmarks coming from the deductive program verification systems Frama-C, {SPARK} 2014, Why3 and Atelier-B, as well as from the {SMT}-{LIB} benchmarks library.},
	booktitle = {{SMT} Workshop: International Workshop on Satisfiability Modulo Theories},
	author = {Conchon, Sylvain and Coquereau, Albin and Iguernlala, Mohamed and Mebsout, Alain},
	urldate = {2019-01-31},
	date = {2018-07},
	note = {alt-ergo/Alt-Ergo-2.2--{SMT}-Workshop-2018.pdf},
	file = {HAL PDF Full Text:/home/fordrl/Zotero/storage/WC8K3BIA/Conchon et al. - 2018 - Alt-Ergo 2.2.pdf:application/pdf},
}

@article{altenkirch_quotient_2018,
	title = {Quotient inductive-inductive types},
	volume = {10803},
	url = {http://arxiv.org/abs/1612.02346},
	doi = {10.1007/978-3-319-89366-2_16},
	abstract = {Higher inductive types ({HITs}) in Homotopy Type Theory ({HoTT}) allow the definition of datatypes which have constructors for equalities over the defined type. {HITs} generalise quotient types and allow to define types which are not sets in the sense of {HoTT} (i.e. do not satisfy uniqueness of equality proofs) such as spheres, suspensions and the torus. However, there are also interesting uses of {HITs} to define sets, such as the Cauchy reals, the partiality monad, and the internal, total syntax of type theory. In each of these examples we define several types that depend on each other mutually, i.e. they are inductive-inductive definitions. We call those {HITs} quotient inductive-inductive types ({QIITs}). Although there has been recent progress on the general theory of {HITs}, there isn't yet a theoretical foundation of the combination of equality constructors and induction-induction, despite having many interesting applications. In the present paper we present a first step towards a semantic definition of {QIITs}. In particular, we give an initial-algebra semantics and show that this is equivalent to the section induction principle, which justifies the intuitively expected elimination rules.},
	pages = {293--310},
	journaltitle = {{arXiv}:1612.02346 [cs]},
	author = {Altenkirch, Thorsten and Capriotti, Paolo and Dijkstra, Gabe and Kraus, Nicolai and Forsberg, Fredrik Nordvall},
	urldate = {2019-01-31},
	date = {2018},
	eprinttype = {arxiv},
	eprint = {1612.02346,},
	note = {altenkirch/Quotient\_inductive-inductive\_types.pdf},
	keywords = {Computer Science - Logic in Computer Science, 03B15 (Primary) 18C10 (Secondary)},
	file = {arXiv.org Snapshot:/home/fordrl/Zotero/storage/BQTKDAZL/1612.html:text/html;arXiv\:1612.02346 PDF:/home/fordrl/Zotero/storage/I6YHMRQZ/Altenkirch et al. - 2018 - Quotient inductive-inductive types.pdf:application/pdf},
}

@inproceedings{hritcu_micro-policies:_2015,
	location = {Prague, Czech Republic},
	title = {Micro-Policies: Formally Verified, Tag-Based Security Monitors},
	isbn = {978-1-4503-3661-1},
	url = {http://dl.acm.org/citation.cfm?doid=2786558.2786560},
	doi = {10.1145/2786558.2786560},
	shorttitle = {Micro-Policies},
	eventtitle = {the 10th {ACM} Workshop},
	pages = {1--1},
	booktitle = {Proceedings of the 10th {ACM} Workshop on Programming Languages and Analysis for Security - {PLAS}'15},
	publisher = {{ACM} Press},
	author = {Hriţcu, Cǎtǎlin},
	urldate = {2019-01-31},
	date = {2015},
	langid = {english},
	note = {amorim/nicro-policies.pdf},
}

@article{qureshi_formal_nodate,
	title = {Formal Modelling and Analysis of Mission-Critical Software in Military Avionics Systems},
	url = {http://crpit.com/confpapers/CRPITV69Qureshi.pdf},
	abstract = {A typical avionics mission system of a military aircraft is a complex real-time system consisting of a mission control computer, different kinds of sensors, navigation and communication subsystems, and various displays and stores; all interconnected by a number of serial data buses. The mission capability is increasingly implemented in the mission-critical software and the robustness of this software is vital for mission success. The complexity and real-time requirements of mission systems represent major challenges to the Australian Defence Force during new acquisitions, upgrades and maintenance. This paper describes the experiences on a joint research project between the University of South Australia and Australia’s Defence Science and Technology Organisation into the modelling and analysis of avionics mission systems. The paper provides a summary of the key aspects of our previous research work on the modelling of a generic mission system using Coloured Petri Nets and the analysis of task scheduling on the mission computer. Finally, the paper briefly discusses the extension of the generic model to obtain a formal model of the mission system of the {AP}3C Orion maritime surveillance aircraft..},
	pages = {11},
	journaltitle = {11th Australian Workshop on Safety Related Programmable Systems ({SCS}’06)},
	author = {Qureshi, Zahid H},
	langid = {english},
	file = {Qureshi - Formal Modelling and Analysis of Mission-Critical .pdf:/home/fordrl/Zotero/storage/9N3AY53T/Qureshi - Formal Modelling and Analysis of Mission-Critical .pdf:application/pdf},
}

@inproceedings{ohearn_categorical_2015,
	location = {Washington, {DC}, {USA}},
	title = {From Categorical Logic to Facebook Engineering},
	isbn = {978-1-4799-8875-4},
	url = {https://doi.org/10.1109/LICS.2015.11},
	doi = {10.1109/LICS.2015.11},
	series = {{LICS} '15},
	pages = {17--20},
	booktitle = {Proceedings of the 2015 30th Annual {ACM}/{IEEE} Symposium on Logic in Computer Science ({LICS})},
	publisher = {{IEEE} Computer Society},
	author = {O'Hearn, Peter},
	urldate = {2019-01-31},
	date = {2015},
	file = {ACM Full Text PDF:/home/fordrl/Zotero/storage/TX6UGV37/O'Hearn - 2015 - From Categorical Logic to Facebook Engineering.pdf:application/pdf},
}

@article{brookes_semantics_2007,
	title = {A semantics for concurrent separation logic},
	volume = {375},
	issn = {03043975},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0304397506009248},
	doi = {10.1016/j.tcs.2006.12.034},
	pages = {227--270},
	number = {1},
	journaltitle = {Theoretical Computer Science},
	author = {Brookes, Stephen},
	urldate = {2019-01-31},
	date = {2007-05},
	langid = {english},
	file = {Submitted Version:/home/fordrl/Zotero/storage/E2WWQBZ9/Brookes - 2007 - A semantics for concurrent separation logic.pdf:application/pdf},
}

@article{brookes_concurrent_2016,
	title = {Concurrent Separation Logic},
	volume = {3},
	issn = {2372-3491},
	url = {http://doi.acm.org/10.1145/2984450.2984457},
	doi = {10.1145/2984450.2984457},
	pages = {47--65},
	number = {3},
	journaltitle = {{ACM} {SIGLOG} News},
	author = {Brookes, Stephen and O'Hearn, Peter W.},
	date = {2016-08},
}

@inproceedings{ohearn_continuous_2018,
	location = {Oxford, United Kingdom},
	title = {Continuous Reasoning: Scaling the impact of formal methods},
	isbn = {978-1-4503-5583-4},
	url = {http://dl.acm.org/citation.cfm?doid=3209108.3209109},
	doi = {10.1145/3209108.3209109},
	shorttitle = {Continuous Reasoning},
	eventtitle = {the 33rd Annual {ACM}/{IEEE} Symposium},
	pages = {13--25},
	booktitle = {Proceedings of the 33rd Annual {ACM}/{IEEE} Symposium on Logic in Computer Science  - {LICS} '18},
	publisher = {{ACM} Press},
	author = {O'Hearn, Peter W.},
	urldate = {2019-01-31},
	date = {2018},
	langid = {english},
	file = {Full Text:/home/fordrl/Zotero/storage/CTESDFKX/O'Hearn - 2018 - Continuous Reasoning Scaling the impact of formal.pdf:application/pdf},
}

@article{gorogiannis_true_2019,
	title = {A true positives theorem for a static race detector},
	volume = {3},
	issn = {24751421},
	url = {http://dl.acm.org/citation.cfm?doid=3302515.3290370},
	doi = {10.1145/3290370},
	pages = {1--29},
	issue = {{POPL}},
	journaltitle = {Proceedings of the {ACM} on Programming Languages},
	author = {Gorogiannis, Nikos and O'Hearn, Peter W. and Sergey, Ilya},
	urldate = {2019-01-31},
	date = {2019-01-02},
	langid = {english},
	file = {Submitted Version:/home/fordrl/Zotero/storage/4765ZUM2/Gorogiannis et al. - 2019 - A true positives theorem for a static race detecto.pdf:application/pdf},
}

@article{jung_rustbelt:_2017,
	title = {{RustBelt}: securing the foundations of the rust programming language},
	volume = {2},
	issn = {24751421},
	url = {http://dl.acm.org/citation.cfm?doid=3177123.3158154},
	doi = {10.1145/3158154},
	shorttitle = {{RustBelt}},
	pages = {1--34},
	issue = {{POPL}},
	journaltitle = {Proceedings of the {ACM} on Programming Languages},
	author = {Jung, Ralf and Jourdan, Jacques-Henri and Krebbers, Robbert and Dreyer, Derek},
	urldate = {2019-01-31},
	date = {2017-12-27},
	langid = {english},
	file = {Full Text:/home/fordrl/Zotero/storage/8KU8PUZ4/Jung et al. - 2017 - RustBelt securing the foundations of the rust pro.pdf:application/pdf},
}

@inproceedings{krishnan_modelling_2018,
	location = {Bengaluru},
	title = {Modelling and validating 1553B protocol using the {SPIN} model checker},
	isbn = {978-1-5386-1182-1},
	url = {http://ieeexplore.ieee.org/document/8328247/},
	doi = {10.1109/COMSNETS.2018.8328247},
	eventtitle = {2018 10th International Conference on Communication Systems \& Networks ({COMSNETS})},
	pages = {472--475},
	booktitle = {2018 10th International Conference on Communication Systems \& Networks ({COMSNETS})},
	publisher = {{IEEE}},
	author = {Krishnan, Ranjani and Lalithambika, V R},
	urldate = {2019-01-31},
	date = {2018-01},
	note = {1553B/08328247.pdf},
}

@article{calcagno_compositional_2011,
	title = {Compositional Shape Analysis by Means of Bi-Abduction},
	volume = {58},
	issn = {00045411},
	url = {http://dl.acm.org/citation.cfm?doid=2049697.2049700},
	doi = {10.1145/2049697.2049700},
	pages = {1--66},
	number = {6},
	journaltitle = {Journal of the {ACM}},
	author = {Calcagno, Cristiano and Distefano, Dino and O’Hearn, Peter W. and Yang, Hongseok},
	urldate = {2019-01-30},
	date = {2011-12-01},
	langid = {english},
	file = {Submitted Version:/home/fordrl/Zotero/storage/F7XZGISE/Calcagno et al. - 2011 - Compositional Shape Analysis by Means of Bi-Abduct.pdf:application/pdf},
}

@article{ishtiaq_bi_2011,
	title = {{BI} As an Assertion Language for Mutable Data Structures},
	volume = {46},
	issn = {0362-1340},
	url = {http://doi.acm.org/10.1145/1988042.1988050},
	doi = {10.1145/1988042.1988050},
	abstract = {Reynolds has developed a logic for reasoning about mutable data structures in which the pre- and postconditions are written in an intuitionistic logic enriched with a spatial form of conjunction. We investigate the approach from the point of view of the logic {BI} of bunched implications of O'Hearn and Pym. We begin by giving a model in which the law of the excluded middle holds, thus showing that the approach is compatible with classical logic. The relationship between the intuitionistic and classical versions of the system is established by a translation, analogous to a translation from intuitionistic logic into the modal logic S4. We also consider the question of completeness of the axioms. {BI}'s spatial implication is used to express weakest preconditions for object-component assignments, and an axiom for allocating a cons cell is shown to be complete under an interpretation of triples that allows a command to be applied to states with dangling pointers. We make this latter a feature, by incorporating an operation, and axiom, for disposing of memory. Finally, we describe a local character enjoyed by specifications in the logic, and show how this enables a class of frame axioms, which say what parts of the heap don't change, to be inferred automatically.},
	pages = {84--96},
	number = {4},
	journaltitle = {{SIGPLAN} Not.},
	author = {Ishtiaq, Samin and O'Hearn, Peter W.},
	urldate = {2019-02-01},
	date = {2011-05},
	file = {ACM Full Text PDF:/home/fordrl/Zotero/storage/FT687HNC/Ishtiaq and O'Hearn - 2011 - BI As an Assertion Language for Mutable Data Struc.pdf:application/pdf},
}

@article{wenzel_isabelle/isar_2018,
	title = {The Isabelle/Isar Reference Manual},
	url = {https://core.ac.uk/display/22830292},
	abstract = {Intelligible semi-automated reasoning (Isar) is a generic approach to readable formal proof documents. It sets out to bridge the semantic gap between any internal notions of proof based on primitive inferences and tactics, and an appropriate level of abstraction for user-level work. The Isar formal proof language has been designed to satisfy quite contradictory requirements, being both \&quot;declarative\&quot; and immediately \&quot;executable\&quot;, by virtue of the Isar/{VM}  interpreter. The Isabelle/Isar system provides an interpreter for the Isar formal proof language. The input may consist either of proper document constructors, or improper auxiliary commands (for diagnostics, exploration etc.). Proof texts consisting of proper elements only admit a purely static reading, thus being intelligible later without requiring dynamic replay that is so typical for traditional proof scripts. Any of the Isabelle/Isar commands may be executed in single-steps, so basically the interpreter has a proof text debugger ..},
	author = {Wenzel, Markus},
	urldate = {2019-02-01},
	date = {2018},
	langid = {english},
	file = {Wenzel - The IsabelleIsar Reference Manual.pdf:/home/fordrl/Zotero/storage/R6VSCXHR/Wenzel - The IsabelleIsar Reference Manual.pdf:application/pdf;Snapshot:/home/fordrl/Zotero/storage/M7HKI4WD/22830292.html:text/html},
}

@article{paulson_foundation_2000,
	title = {The Foundation of a Generic Theorem Prover},
	url = {http://arxiv.org/abs/cs/9301105},
	abstract = {Isabelle is an interactive theorem prover that supports a variety of logics. It represents rules as propositions (not as functions) and builds proofs by combining rules. These operations constitute a meta-logic (or `logical framework') in which the object-logics are formalized. Isabelle is now based on higher-order logic -- a precise and well-understood foundation. Examples illustrate use of this meta-logic to formalize logics and proofs. Axioms for first-order logic are shown sound and complete. Backwards proof is formalized by meta-reasoning about object-level entailment. Higher-order logic has several practical advantages over other meta-logics. Many proof techniques are known, such as Huet's higher-order unification procedure.},
	journaltitle = {{arXiv}:cs/9301105},
	author = {Paulson, Lawrence C.},
	urldate = {2019-02-01},
	date = {2000-10-30},
	eprinttype = {arxiv},
	eprint = {cs/9301105},
	keywords = {Computer Science - Logic in Computer Science, F.3.1, F.4.1},
	file = {arXiv.org Snapshot:/home/fordrl/Zotero/storage/SLUTEXCX/9301105.html:text/html;arXiv\:cs/9301105 PDF:/home/fordrl/Zotero/storage/Y5PBFBXS/Paulson - 2000 - The Foundation of a Generic Theorem Prover.pdf:application/pdf},
}

@article{jung_iris_2018,
	title = {Iris from the ground up: A modular foundation for higher-order concurrent separation logic},
	volume = {28},
	issn = {0956-7968, 1469-7653},
	url = {https://www.cambridge.org/core/journals/journal-of-functional-programming/article/iris-from-the-ground-up-a-modular-foundation-for-higherorder-concurrent-separation-logic/26301B518CE2C52796BFA12B8BAB5B5F},
	doi = {10.1017/S0956796818000151},
	shorttitle = {Iris from the ground up},
	abstract = {Iris is a framework for higher-order concurrent separation logic, which has been implemented in the Coq proof assistant and deployed very effectively in a wide variety of verification projects. Iris was designed with the express goal of simplifying and consolidating the foundations of modern separation logics, but it has evolved over time, and the design and semantic foundations of Iris itself have yet to be fully written down and explained together properly in one place. Here, we attempt to fill this gap, presenting a reasonably complete picture of the latest version of Iris (version 3.1), from first principles and in one coherent narrative.},
	journaltitle = {Journal of Functional Programming},
	author = {Jung, Ralf and Krebbers, Robbert and Jourdan, Jacques-Henri and Bizjak, Aleš and Birkedal, Lars and Dreyer, Derek},
	urldate = {2019-02-01},
	date = {2018},
	langid = {english},
	file = {Snapshot:/home/fordrl/Zotero/storage/3QJUK97X/26301B518CE2C52796BFA12B8BAB5B5F.html:text/html},
}

@inproceedings{nelson_hyperkernel:_2017,
	location = {Shanghai, China},
	title = {Hyperkernel: Push-Button Verification of an {OS} Kernel - Slides},
	isbn = {978-1-4503-5085-3},
	url = {http://dl.acm.org/citation.cfm?doid=3132747.3132748},
	doi = {10.1145/3132747.3132748},
	shorttitle = {Hyperkernel},
	eventtitle = {the 26th Symposium},
	pages = {252--269},
	booktitle = {Proceedings of the 26th Symposium on Operating Systems Principles  - {SOSP} '17},
	publisher = {{ACM} Press},
	author = {Nelson, Luke and Sigurbjarnarson, Helgi and Zhang, Kaiyuan and Johnson, Dylan and Bornholt, James and Torlak, Emina and Wang, Xi},
	urldate = {2019-02-01},
	date = {2017},
	langid = {english},
	file = {Nelson et al. - 2017 - Hyperkernel Push-Button Verification of an OS Ker.pdf:/home/fordrl/Zotero/storage/WR6NX9HN/Nelson et al. - 2017 - Hyperkernel Push-Button Verification of an OS Ker.pdf:application/pdf},
}

@inproceedings{nelson_hyperkernel:_2017-1,
	location = {New York, {NY}, {USA}},
	title = {Hyperkernel: Push-Button Verification of an {OS} Kernel},
	isbn = {978-1-4503-5085-3},
	url = {http://doi.acm.org/10.1145/3132747.3132748},
	doi = {10.1145/3132747.3132748},
	series = {{SOSP} '17},
	shorttitle = {Hyperkernel},
	abstract = {This paper describes an approach to designing, implementing, and formally verifying the functional correctness of an {OS} kernel, named Hyperkernel, with a high degree of proof automation and low proof burden. We base the design of Hyperkernel's interface on xv6, a Unix-like teaching operating system. Hyperkernel introduces three key ideas to achieve proof automation: it finitizes the kernel interface to avoid unbounded loops or recursion; it separates kernel and user address spaces to simplify reasoning about virtual memory; and it performs verification at the {LLVM} intermediate representation level to avoid modeling complicated C semantics. We have verified the implementation of Hyperkernel with the Z3 {SMT} solver, checking a total of 50 system calls and other trap handlers. Experience shows that Hyperkernel can avoid bugs similar to those found in xv6, and that the verification of Hyperkernel can be achieved with a low proof burden.},
	pages = {252--269},
	booktitle = {Proceedings of the 26th Symposium on Operating Systems Principles},
	publisher = {{ACM}},
	author = {Nelson, Luke and Sigurbjarnarson, Helgi and Zhang, Kaiyuan and Johnson, Dylan and Bornholt, James and Torlak, Emina and Wang, Xi},
	urldate = {2019-02-01},
	date = {2017},
	file = {ACM Full Text PDF:/home/fordrl/Zotero/storage/79Z44YVX/Nelson et al. - 2017 - Hyperkernel Push-Button Verification of an OS Ker.pdf:application/pdf},
}

@article{adams_common_2015,
	title = {The Common {HOL} Platform},
	volume = {186},
	issn = {2075-2180},
	url = {http://arxiv.org/abs/1507.08718},
	doi = {10.4204/EPTCS.186.6},
	abstract = {The Common {HOL} project aims to facilitate porting source code and proofs between members of the {HOL} family of theorem provers. At the heart of the project is the Common {HOL} Platform, which defines a standard {HOL} theory and {API} that aims to be compatible with all {HOL} systems. So far, {HOL} Light and hol90 have been adapted for conformance, and {HOL} Zero was originally developed to conform. In this paper we provide motivation for a platform, give an overview of the Common {HOL} Platform's theory and {API} components, and show how to adapt legacy systems. We also report on the platform's successful application in the hand-translation of a few thousand lines of source code from {HOL} Light to {HOL} Zero.},
	pages = {42--56},
	journaltitle = {Electronic Proceedings in Theoretical Computer Science},
	author = {Adams, Mark},
	urldate = {2019-02-01},
	date = {2015-07-30},
	eprinttype = {arxiv},
	eprint = {1507.08718},
	keywords = {Computer Science - Logic in Computer Science, Computer Science - Digital Libraries},
	file = {arXiv.org Snapshot:/home/fordrl/Zotero/storage/T6XBJWLE/1507.html:text/html;arXiv\:1507.08718 PDF:/home/fordrl/Zotero/storage/4DPSDJ3D/Adams - 2015 - The Common HOL Platform.pdf:application/pdf},
}

@inproceedings{lahiri_symdiff:_2012,
	title = {{SYMDIFF}: A Language-Agnostic Semantic Diff Tool for Imperative Programs},
	isbn = {978-3-642-31424-7},
	series = {Lecture Notes in Computer Science},
	shorttitle = {{SYMDIFF}},
	abstract = {In this paper, we describe {SymDiff}, a language-agnostic tool for equivalence checking and displaying semantic (behavioral) differences over imperative programs. The tool operates on an intermediate verification language Boogie, for which translations exist from various source languages such as C, C\# and x86. We discuss the tool and the front-end interface to target various source languages. Finally, we provide a brief description of the front-end for C programs.},
	pages = {712--717},
	booktitle = {Computer Aided Verification},
	publisher = {Springer Berlin Heidelberg},
	author = {Lahiri, Shuvendu K. and Hawblitzel, Chris and Kawaguchi, Ming and Rebêlo, Henrique},
	editor = {Madhusudan, P. and Seshia, Sanjit A.},
	date = {2012},
	langid = {english},
	keywords = {Equivalence Check, Imperative Language, Imperative Program, Source Language, Symbolic Execution},
	file = {Springer Full Text PDF:/home/fordrl/Zotero/storage/NDSQ5WIC/Lahiri et al. - 2012 - SYMDIFF A Language-Agnostic Semantic Diff Tool fo.pdf:application/pdf},
}

@article{yang_safe_2011,
	title = {Safe to the last instruction: automated verification of a type-safe operating system},
	volume = {54},
	issn = {00010782},
	url = {http://dl.acm.org/citation.cfm?doid=2043174.2043197},
	doi = {10.1145/2043174.2043197},
	shorttitle = {Safe to the last instruction},
	pages = {123},
	number = {12},
	journaltitle = {Communications of the {ACM}},
	author = {Yang, Jean and Hawblitzel, Chris},
	urldate = {2019-02-01},
	date = {2011-12-01},
	langid = {english},
	file = {Full Text:/home/fordrl/Zotero/storage/NJ2ZPC4C/Yang and Hawblitzel - 2011 - Safe to the last instruction automated verificati.pdf:application/pdf},
}

@inproceedings{lahiri_automatic_2015,
	title = {Automatic Rootcausing for Program Equivalence Failures in Binaries},
	isbn = {978-3-319-21690-4},
	series = {Lecture Notes in Computer Science},
	abstract = {Equivalence checking of imperative programs has several applications including compiler validation and cross-version verification. Debugging equivalence failures can be tedious for large examples, especially for low-level binary programs. In this paper, we formalize a simple yet precise notion of verifiable rootcause for equivalence failures that leverages semantic similarity between two programs. Unlike existing works on program repair, our definition of rootcause avoids the need for a template of fixes or the need for a complete repair to ensure equivalence. We show progressively weaker checks for detecting rootcauses that can be applicable even when multiple fixes are required to make the two programs equivalent. We provide optimizations based on Maximum Satisfiability ({MAXSAT}) and binary search to prune the search space of such rootcauses. We have implemented the techniques in {SymDiff} and provide an evaluation on a set of real-world compiler validation binary benchmarks.},
	pages = {362--379},
	booktitle = {Computer Aided Verification},
	publisher = {Springer International Publishing},
	author = {Lahiri, Shuvendu K. and Sinha, Rohit and Hawblitzel, Chris},
	editor = {Kroening, Daniel and Păsăreanu, Corina S.},
	date = {2015},
	langid = {english},
	file = {Lahiri et al. - 2015 - Automatic Rootcausing for Program Equivalence Fail.pdf:/home/fordrl/Zotero/storage/LJCRZ2BD/Lahiri et al. - 2015 - Automatic Rootcausing for Program Equivalence Fail.pdf:application/pdf},
}

@inproceedings{hawblitzel_automated_2015,
	title = {Automated and Modular Refinement Reasoning for Concurrent Programs},
	url = {https://link.springer.com/chapter/10.1007/978-3-319-21668-3_26},
	doi = {10.1007/978-3-319-21668-3_26},
	abstract = {We present civl, a language and verifier for concurrent programs based on automated and modular refinement reasoning. civlsupports reasoning about a concurrent program at many levels of abstraction....},
	eventtitle = {International Conference on Computer Aided Verification},
	pages = {449--465},
	booktitle = {Computer Aided Verification},
	publisher = {Springer, Cham},
	author = {Hawblitzel, Chris and Petrank, Erez and Qadeer, Shaz and Tasiran, Serdar},
	urldate = {2019-02-01},
	date = {2015-07-18},
	langid = {english},
	file = {Hawblitzel et al. - 2015 - Automated and Modular Refinement Reasoning for Con.pdf:/home/fordrl/Zotero/storage/X2AJPSSW/Hawblitzel et al. - 2015 - Automated and Modular Refinement Reasoning for Con.pdf:application/pdf;Snapshot:/home/fordrl/Zotero/storage/89G4CJY3/10.html:text/html},
}

@inproceedings{hawblitzel_ironfleet:_2015,
	location = {New York, {NY}, {USA}},
	title = {{IronFleet}: Proving Practical Distributed Systems Correct},
	isbn = {978-1-4503-3834-9},
	url = {http://doi.acm.org/10.1145/2815400.2815428},
	doi = {10.1145/2815400.2815428},
	series = {{SOSP} '15},
	shorttitle = {{IronFleet}},
	abstract = {Distributed systems are notorious for harboring subtle bugs. Verification can, in principle, eliminate these bugs a priori, but verification has historically been difficult to apply at full-program scale, much less distributed-system scale. We describe a methodology for building practical and provably correct distributed systems based on a unique blend of {TLA}-style state-machine refinement and Hoare-logic verification. We demonstrate the methodology on a complex implementation of a Paxos-based replicated state machine library and a lease-based sharded key-value store. We prove that each obeys a concise safety specification, as well as desirable liveness requirements. Each implementation achieves performance competitive with a reference system. With our methodology and lessons learned, we aim to raise the standard for distributed systems from "tested" to "correct."},
	pages = {1--17},
	booktitle = {Proceedings of the 25th Symposium on Operating Systems Principles},
	publisher = {{ACM}},
	author = {Hawblitzel, Chris and Howell, Jon and Kapritsos, Manos and Lorch, Jacob R. and Parno, Bryan and Roberts, Michael L. and Setty, Srinath and Zill, Brian},
	urldate = {2019-02-01},
	date = {2015},
	file = {ACM Full Text PDF:/home/fordrl/Zotero/storage/RP6MRQV6/Hawblitzel et al. - 2015 - IronFleet Proving Practical Distributed Systems C.pdf:application/pdf},
}

@article{hawblitzel_ironclad_nodate,
	title = {Ironclad Apps: End-to-End Security via Automated Full-System Veriﬁcation},
	abstract = {An Ironclad App lets a user securely transmit her data to a remote machine with the guarantee that every instruction executed on that machine adheres to a formal abstract speciﬁcation of the app’s behavior. This does more than eliminate implementation vulnerabilities such as buffer overﬂows, parsing errors, or data leaks; it tells the user exactly how the app will behave at all times. We provide these guarantees via complete, low-level software veriﬁcation. We then use cryptography and secure hardware to enable secure channels from the veriﬁed software to remote users. To achieve such complete veriﬁcation, we developed a set of new and modiﬁed tools, a collection of techniques and engineering disciplines, and a methodology focused on rapid development of veriﬁed systems software. We describe our methodology, formal results, and lessons we learned from building a full stack of veriﬁed software. That software includes a veriﬁed kernel; veriﬁed drivers; veriﬁed system and crypto libraries including {SHA}, {HMAC}, and {RSA}; and four Ironclad Apps.},
	pages = {18},
	author = {Hawblitzel, Chris and Howell, Jon and Lorch, Jacob R and Narayan, Arjun and Parno, Bryan and Zhang, Danfeng and Zill, Brian},
	langid = {english},
	file = {Hawblitzel et al. - Ironclad Apps End-to-End Security via Automated F.pdf:/home/fordrl/Zotero/storage/W6P597PJ/Hawblitzel et al. - Ironclad Apps End-to-End Security via Automated F.pdf:application/pdf},
}

@article{fournet_deploying_nodate,
	title = {Deploying a Veriﬁed Secure Implementation of the {HTTPS} Ecosystem},
	pages = {10},
	author = {Fournet, Cedric and Hawblitzel, Chris and Parno, Bryan and Swamy, Nikhil},
	langid = {english},
	file = {Fournet et al. - Deploying a Veriﬁed Secure Implementation of the H.pdf:/home/fordrl/Zotero/storage/4TJJYC6N/Fournet et al. - Deploying a Veriﬁed Secure Implementation of the H.pdf:application/pdf},
}

@incollection{hutchison_fresh_2009,
	location = {Berlin, Heidelberg},
	title = {A Fresh Look at Separation Algebras and Share Accounting},
	volume = {5904},
	isbn = {978-3-642-10671-2 978-3-642-10672-9},
	url = {http://link.springer.com/10.1007/978-3-642-10672-9_13},
	abstract = {Separation Algebras serve as models of Separation Logics; Share Accounting allows reasoning about concurrent-read/exclusive-write resources in Separation Logic. In designing a Concurrent Separation Logic and in mechanizing proofs of its soundness, we found previous axiomatizations of separation algebras and previous systems of share accounting to be useful but ﬂawed. We adjust the axioms of separation algebras; we demonstrate an operator calculus for constructing new separation algebras; we present a more powerful system of share accounting with a new, simple model; and we provide a reusable Coq development.},
	pages = {161--177},
	booktitle = {Programming Languages and Systems},
	publisher = {Springer Berlin Heidelberg},
	author = {Dockins, Robert and Hobor, Aquinas and Appel, Andrew W.},
	editor = {Hu, Zhenjiang},
	editorb = {Hutchison, David and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M. and Mattern, Friedemann and Mitchell, John C. and Naor, Moni and Nierstrasz, Oscar and Pandu Rangan, C. and Steffen, Bernhard and Sudan, Madhu and Terzopoulos, Demetri and Tygar, Doug and Vardi, Moshe Y. and Weikum, Gerhard},
	editorbtype = {redactor},
	urldate = {2019-02-01},
	date = {2009},
	langid = {english},
	doi = {10.1007/978-3-642-10672-9_13},
	file = {Dockins et al. - 2009 - A Fresh Look at Separation Algebras and Share Acco.pdf:/home/fordrl/Zotero/storage/47RRWA4Y/Dockins et al. - 2009 - A Fresh Look at Separation Algebras and Share Acco.pdf:application/pdf},
}

@inproceedings{spector-zabusky_total_2018,
	location = {New York, {NY}, {USA}},
	title = {Total Haskell is Reasonable Coq},
	isbn = {978-1-4503-5586-5},
	url = {http://doi.acm.org/10.1145/3167092},
	doi = {10.1145/3167092},
	series = {{CPP} 2018},
	abstract = {We would like to use the Coq proof assistant to mechanically verify properties of Haskell programs. To that end, we present a tool, named {\textless}tt{\textgreater}hs-to-coq{\textless}/tt{\textgreater}, that translates total Haskell programs into Coq programs via a shallow embedding. We apply our tool in three case studies – a lawful {\textless}tt{\textgreater}Monad{\textless}/tt{\textgreater} instance, “Hutton’s razor”, and an existing data structure library – and prove their correctness. These examples show that this approach is viable: both that {\textless}tt{\textgreater}hs-to-coq{\textless}/tt{\textgreater} applies to existing Haskell code, and that the output it produces is amenable to verification.},
	pages = {14--27},
	booktitle = {Proceedings of the 7th {ACM} {SIGPLAN} International Conference on Certified Programs and Proofs},
	publisher = {{ACM}},
	author = {Spector-Zabusky, Antal and Breitner, Joachim and Rizkallah, Christine and Weirich, Stephanie},
	urldate = {2019-02-01},
	date = {2018},
	keywords = {Coq, verification, Haskell},
	file = {ACM Full Text PDF:/home/fordrl/Zotero/storage/WVT2FG9M/Spector-Zabusky et al. - 2018 - Total Haskell is Reasonable Coq.pdf:application/pdf},
}

@article{harrison_hol_2013,
	title = {The {HOL} Light Theory of Euclidean Space},
	volume = {50},
	issn = {0168-7433, 1573-0670},
	url = {http://link.springer.com/10.1007/s10817-012-9250-9},
	doi = {10.1007/s10817-012-9250-9},
	pages = {173--190},
	number = {2},
	journaltitle = {Journal of Automated Reasoning},
	author = {Harrison, John},
	urldate = {2019-02-01},
	date = {2013-02},
	langid = {english},
	file = {Harrison - 2013 - The HOL Light Theory of Euclidean Space.pdf:/home/fordrl/Zotero/storage/65KRY862/Harrison - 2013 - The HOL Light Theory of Euclidean Space.pdf:application/pdf},
}

@article{harper_framework_1993,
	title = {A Framework for Defining Logics},
	volume = {40},
	issn = {0004-5411},
	url = {http://doi.acm.org/10.1145/138027.138060},
	doi = {10.1145/138027.138060},
	abstract = {The Edinburgh Logical Framework ({LF}) provides a means to define (or present) logics. It is based on a general treatment of syntax, rules, and proofs by means of a typed \&lgr;-calculus with dependent types. Syntax is treated in a style similar to, but more general than, Martin-Lo¨f's system of arities. The treatment of rules and proofs focuses on his notion of a judgment. Logics are represented in {LF} via a new principle, the judgments as types principle, whereby each judgment is identified with the type of its proofs. This allows for a smooth treatment of discharge and variable occurence conditions and leads to a uniform treatment of rules and proofs whereby rules are viewed as proofs of higher-order judgments and proof checking is reduced to type checking. The practical benefit of our treatment of formal systems is that logic-independent tools, such as proof editors and proof checkers, can be constructed.},
	pages = {143--184},
	number = {1},
	journaltitle = {J. {ACM}},
	author = {Harper, Robert and Honsell, Furio and Plotkin, Gordon},
	urldate = {2019-02-01},
	date = {1993-01},
	keywords = {formal systems, interactive theorem proving, proof checking, typed lambda calculus},
	file = {ACM Full Text PDF:/home/fordrl/Zotero/storage/VEYR93NU/Harper et al. - 1993 - A Framework for Defining Logics.pdf:application/pdf},
}

@article{ramsey_applicative_2006,
	title = {An Applicative Control-Flow Graph Based on Huet's Zipper},
	volume = {148},
	issn = {1571-0661},
	url = {http://www.sciencedirect.com/science/article/pii/S1571066106001289},
	doi = {10.1016/j.entcs.2005.11.042},
	series = {Proceedings of the {ACM}-{SIGPLAN} Workshop on {ML} ({ML} 2005)},
	abstract = {We are using {ML} to build a compiler that does low-level optimization. To support optimizations in classic imperative style, we built a control-flow graph using mutable pointers and other mutable state in the nodes. This decision proved unfortunate: the mutable flow graph was big and complex, and it led to many bugs. We have replaced it by a smaller, simpler, applicative flow graph based on Huet's [Huet, Gérard, 1997. The Zipper. Journal of Functional Programming, 7(5):549–554. Functional Pearl] zipper. The new flow graph is a success; this paper presents its design and shows how it leads to a gratifyingly simple implementation of the dataflow framework developed by [Lerner, Sorin, David Grove, and Craig Chambers. 2002. Composing dataflow analyses and transformations. Conference Record of the 29th Annual {ACM} Symposium on Principles of Programming Languages, in {SIGPLAN} Notices, 31(1):270–282].},
	pages = {105--126},
	number = {2},
	journaltitle = {Electronic Notes in Theoretical Computer Science},
	shortjournal = {Electronic Notes in Theoretical Computer Science},
	author = {Ramsey, Norman and Dias, João},
	urldate = {2019-02-01},
	date = {2006-03-24},
	keywords = {optimization, applicative data structures, compilers, control-flow graphs, dataflow analysis},
	file = {ScienceDirect Full Text PDF:/home/fordrl/Zotero/storage/A52SVHPL/Ramsey and Dias - 2006 - An Applicative Control-Flow Graph Based on Huet's .pdf:application/pdf;ScienceDirect Snapshot:/home/fordrl/Zotero/storage/PT5VGVPI/S1571066106001289.html:text/html},
}

@inproceedings{mokhov_algebraic_2017,
	location = {New York, {NY}, {USA}},
	title = {Algebraic Graphs with Class (Functional Pearl)},
	isbn = {978-1-4503-5182-9},
	url = {http://doi.acm.org/10.1145/3122955.3122956},
	doi = {10.1145/3122955.3122956},
	series = {Haskell 2017},
	abstract = {The paper presents a minimalistic and elegant approach to working with graphs in Haskell. It is built on a rigorous mathematical foundation --- an algebra of graphs --- that allows us to apply equational reasoning for proving the correctness of graph transformation algorithms. Algebraic graphs let us avoid partial functions typically caused by `malformed graphs' that contain an edge referring to a non-existent vertex. This helps to liberate {APIs} of existing graph libraries from partial functions.   The algebra of graphs can represent directed, undirected, reflexive and transitive graphs, as well as hypergraphs, by appropriately choosing the set of underlying axioms. The flexibility of the approach is demonstrated by developing a library for constructing and transforming polymorphic graphs.},
	pages = {2--13},
	booktitle = {Proceedings of the 10th {ACM} {SIGPLAN} International Symposium on Haskell},
	publisher = {{ACM}},
	author = {Mokhov, Andrey},
	urldate = {2019-02-01},
	date = {2017},
	keywords = {Haskell, algebra, graph theory},
	file = {ACM Full Text PDF:/home/fordrl/Zotero/storage/5HHBHF8J/Mokhov - 2017 - Algebraic Graphs with Class (Functional Pearl).pdf:application/pdf},
}

@inproceedings{gonthier_how_2011,
	location = {New York, {NY}, {USA}},
	title = {How to Make Ad Hoc Proof Automation Less Ad Hoc},
	isbn = {978-1-4503-0865-6},
	url = {http://doi.acm.org/10.1145/2034773.2034798},
	doi = {10.1145/2034773.2034798},
	series = {{ICFP} '11},
	abstract = {Most interactive theorem provers provide support for some form of user-customizable proof automation. In a number of popular systems, such as Coq and Isabelle, this automation is achieved primarily through tactics, which are programmed in a separate language from that of the prover's base logic. While tactics are clearly useful in practice, they can be difficult to maintain and compose because, unlike lemmas, their behavior cannot be specified within the expressive type system of the prover itself. We propose a novel approach to proof automation in Coq that allows the user to specify the behavior of custom automated routines in terms of Coq's own type system. Our approach involves a sophisticated application of Coq's canonical structures, which generalize Haskell type classes and facilitate a flexible style of dependently-typed logic programming. Specifically, just as Haskell type classes are used to infer the canonical implementation of an overloaded term at a given type, canonical structures can be used to infer the canonical proof of an overloaded lemma for a given instantiation of its parameters. We present a series of design patterns for canonical structure programming that enable one to carefully and predictably coax Coq's type inference engine into triggering the execution of user-supplied algorithms during unification, and we illustrate these patterns through several realistic examples drawn from Hoare Type Theory. We assume no prior knowledge of Coq and describe the relevant aspects of Coq type inference from first principles.},
	pages = {163--175},
	booktitle = {Proceedings of the 16th {ACM} {SIGPLAN} International Conference on Functional Programming},
	publisher = {{ACM}},
	author = {Gonthier, Georges and Ziliani, Beta and Nanevski, Aleksandar and Dreyer, Derek},
	urldate = {2019-02-01},
	date = {2011},
	keywords = {interactive theorem proving, canonical structures, coq, custom proof automation, hoare type theory, tactics, type classes},
	file = {ACM Full Text PDF:/home/fordrl/Zotero/storage/2TR7VDJX/Gonthier et al. - 2011 - How to Make Ad Hoc Proof Automation Less Ad Hoc.pdf:application/pdf},
}

@article{gonthier_introduction_2010,
	title = {An introduction to small scale reflection in Coq},
	volume = {3},
	rights = {Copyright (c) 2010 Georges Gonthier, Assia Mahboubi},
	issn = {1972-5787},
	url = {https://jfr.unibo.it/article/view/1979},
	doi = {10.6092/issn.1972-5787/1979},
	abstract = {This tutorial presents the {SSReflect} extension to the Coq system. This extension consists of an extension to the Coq language of script, and of a set of libraries, originating from the formal proof of the Four Color theorem. This tutorial proposes a guided tour in some of the basic libraries distributed in the {SSReflect} package. It focuses on the application of the small scale reflection methodology to the formalization of finite objects in intuitionistic type theory.},
	pages = {95--152},
	number = {2},
	journaltitle = {Journal of Formalized Reasoning},
	author = {Gonthier, Georges and Mahboubi, Assia},
	urldate = {2019-02-01},
	date = {2010},
	langid = {english},
	file = {Snapshot:/home/fordrl/Zotero/storage/ZX32HUEX/1979.html:text/html;Full Text PDF:/home/fordrl/Zotero/storage/GAA6PEIJ/Gonthier and Mahboubi - 2010 - An introduction to small scale reflection in Coq.pdf:application/pdf},
}

@inproceedings{filinski_representing_1999,
	location = {New York, {NY}, {USA}},
	title = {Representing Layered Monads},
	isbn = {978-1-58113-095-9},
	url = {http://doi.acm.org/10.1145/292540.292557},
	doi = {10.1145/292540.292557},
	series = {{POPL} '99},
	abstract = {There has already been considerable research on constructing modular, monad-based specifications of computational effects (state, exceptions, nondeterminism, etc.) in programming languages. We present a simple framework in this tradition, based on a Church-style effect-typing system for an {ML}-like language. The semantics of this language is formally defined by a series of monadic translations, each one expanding away a layer of effects. Such a layered specification is easy to reason about, but its direct implementation (whether by parameterized interpretation or by actual translation) is often prohibitively inefficient.By exploiting deeper semantic properties of monads, however, it is also possible to derive a vastly more efficient implementation: we show that each layer of effects can be uniformly simulated by continuation-passing, and further that multiple such layers can themselves be simulated by a standard semantics for call/cc and mutable state. Thus, even multi-effect programs can be executed in Scheme or {SML}/{NJ} at full native speed, generalizing an earlier single-effect result. As an example, we show how a simple resumption-based semantics of concurrency allows us to directly simulate a shared-state program across all possible dynamic interleavings of execution threads.},
	pages = {175--188},
	booktitle = {Proceedings of the 26th {ACM} {SIGPLAN}-{SIGACT} Symposium on Principles of Programming Languages},
	publisher = {{ACM}},
	author = {Filinski, Andrzej},
	urldate = {2019-02-01},
	date = {1999},
	file = {ACM Full Text PDF:/home/fordrl/Zotero/storage/973MQ2DE/Filinski - 1999 - Representing Layered Monads.pdf:application/pdf},
}

@inproceedings{filinski_representing_1994,
	location = {New York, {NY}, {USA}},
	title = {Representing Monads},
	isbn = {978-0-89791-636-3},
	url = {http://doi.acm.org/10.1145/174675.178047},
	doi = {10.1145/174675.178047},
	series = {{POPL} '94},
	abstract = {We show that any monad whose unit and extension operations are expressible as purely functional terms can be embedded in a call-by-value language with “composable continuations”. As part of the development, we extend Meyer and Wand's characterization of the relationship between continuation-passing and direct style to one for continuation-passing vs. general “monadic” style. We further show that the composable-continuations construct can itself be represented using ordinary, non-composable first-class continuations and a single piece of state. Thus, in the presence of two specific computational effects - storage and escapes - any expressible monadic structure (e.g., nondeterminism as represented by the list monad) can be added as a purely definitional extension, without requiring a reinterpretation of the whole language. The paper includes an implementation of the construction (in Standard {ML} with some New Jersey extensions) and several examples.},
	pages = {446--457},
	booktitle = {Proceedings of the 21st {ACM} {SIGPLAN}-{SIGACT} Symposium on Principles of Programming Languages},
	publisher = {{ACM}},
	author = {Filinski, Andrzej},
	urldate = {2019-02-01},
	date = {1994},
	file = {ACM Full Text PDF:/home/fordrl/Zotero/storage/474UWRAK/Filinski - 1994 - Representing Monads.pdf:application/pdf},
}

@article{ahman_recalling_2017,
	title = {Recalling a Witness: Foundations and Applications of Monotonic State},
	volume = {2},
	issn = {2475-1421},
	url = {http://doi.acm.org/10.1145/3158153},
	doi = {10.1145/3158153},
	shorttitle = {Recalling a Witness},
	abstract = {We provide a way to ease the verification of programs whose state evolves monotonically. The main idea is that a property witnessed in a prior state can be soundly recalled in the current state, provided (1) state evolves according to a given preorder, and (2) the property is preserved by this preorder. In many scenarios, such monotonic reasoning yields concise modular proofs, saving the need for explicit program invariants. We distill our approach into the monotonic-state monad, a general yet compact interface for Hoare-style reasoning about monotonic state in a dependently typed language. We prove the soundness of the monotonic-state monad and use it as a unified foundation for reasoning about monotonic state in the F⋆ verification system. Based on this foundation, we build libraries for various mutable data structures like monotonic references and apply these libraries at scale to the verification of several distributed applications.},
	pages = {65:1--65:30},
	issue = {{POPL}},
	journaltitle = {Proc. {ACM} Program. Lang.},
	author = {Ahman, Danel and Fournet, Cédric and Hriţcu, Cătălin and Maillard, Kenji and Rastogi, Aseem and Swamy, Nikhil},
	urldate = {2019-02-01},
	date = {2017-12},
	keywords = {Formal Foundations, Hoare Logic, Modular Reasoning, Monotonic References, Monotonic-State Monad, Program Verification, Secure File Transfer, State Continuity},
	file = {ACM Full Text PDF:/home/fordrl/Zotero/storage/T2Z4NUBR/Ahman et al. - 2017 - Recalling a Witness Foundations and Applications .pdf:application/pdf},
}

@article{hritcu_quest_nodate,
	title = {The Quest for Formally Secure Compartmentalizing Compilation},
	abstract = {Severe low-level vulnerabilities abound in today’s computer systems, allowing cyber-attackers to remotely gain full control. This happens in big part because our programming languages, compilation chains, and architectures too often trade o security for e ciency. The semantics of mainstream low-level languages like C is inherently insecure, and even for safer languages, all guarantees are lost when interacting with low-level code, for instance when using low-level libraries. This habilitation presents my ongoing quest to build formally secure compartmentalizing compilation chains that defend against such attacks. In particular, we propose several formal de nitions that characterize what it means for a compartmentalizing compilation chain to be secure, both in the case of safe and of unsafe source languages.},
	pages = {96},
	author = {Hriţcu, Cătălin},
	langid = {english},
	file = {Hriţcu - The Quest for Formally Secure Compartmentalizing Com.pdf:/home/fordrl/Zotero/storage/GGGX8C7Q/Hriţcu - The est for Formally Secure Compartmentalizing Com.pdf:application/pdf},
}

@inproceedings{ahman_dijkstra_2017,
	location = {New York, {NY}, {USA}},
	title = {Dijkstra Monads for Free},
	isbn = {978-1-4503-4660-3},
	url = {http://doi.acm.org/10.1145/3009837.3009878},
	doi = {10.1145/3009837.3009878},
	series = {{POPL} 2017},
	abstract = {Dijkstra monads enable a dependent type theory to be enhanced with support for specifying and verifying effectful code via weakest preconditions. Together with their closely related counterparts, Hoare monads, they provide the basis on which verification tools like F*, Hoare Type Theory ({HTT}), and Ynot are built. We show that Dijkstra monads can be derived "for free" by applying a continuation-passing style ({CPS}) translation to the standard monadic definitions of the underlying computational effects. Automatically deriving Dijkstra monads in this way provides a correct-by-construction and efficient way of reasoning about user-defined effects in dependent type theories. We demonstrate these ideas in {EMF}*, a new dependently typed calculus, validating it via both formal proof and a prototype implementation within F*. Besides equipping F* with a more uniform and extensible effect system, {EMF}* enables a novel mixture of intrinsic and extrinsic proofs within F*.},
	pages = {515--529},
	booktitle = {Proceedings of the 44th {ACM} {SIGPLAN} Symposium on Principles of Programming Languages},
	publisher = {{ACM}},
	author = {Ahman, Danel and Hriţcu, Cătălin and Maillard, Kenji and Martínez, Guido and Plotkin, Gordon and Protzenko, Jonathan and Rastogi, Aseem and Swamy, Nikhil},
	urldate = {2019-02-01},
	date = {2017},
	keywords = {proof assistants, verification, dependent types, effectful programming},
	file = {ACM Full Text PDF:/home/fordrl/Zotero/storage/79A2MM4V/Ahman et al. - 2017 - Dijkstra Monads for Free.pdf:application/pdf},
}

@article{swamy_verifying_2013,
	title = {Verifying Higher-order Programs with the Dijkstra Monad},
	url = {https://www.microsoft.com/en-us/research/publication/verifying-higher-order-programs-with-the-dijkstra-monad/},
	abstract = {Modern programming languages, ranging from Haskell and {ML}, to {JavaScript}, C\# and Java, all make extensive use of higher-order state. This paper advocates a new verification methodology for higher-order stateful programs, based on a new monad of predicate transformers called the Dijkstra monad. Using the Dijkstra monad has a number of benefits. First, the monad …},
	author = {Swamy, Nikhil and Chen, Juan and Livshits, Ben},
	urldate = {2019-02-01},
	date = {2013-06-01},
	langid = {american},
	file = {Snapshot:/home/fordrl/Zotero/storage/NVGHR97J/verifying-higher-order-programs-with-the-dijkstra-monad.html:text/html;Full Text PDF:/home/fordrl/Zotero/storage/DTN54LGK/Swamy et al. - 2013 - Verifying Higher-order Programs with the Dijkstra .pdf:application/pdf},
}

@article{dijkstra_guarded_1975,
	title = {Guarded Commands, Nondeterminacy and Formal Derivation of Programs},
	volume = {18},
	issn = {0001-0782},
	url = {http://doi.acm.org/10.1145/360933.360975},
	doi = {10.1145/360933.360975},
	abstract = {So-called “guarded commands” are introduced as a building block for alternative and repetitive constructs that allow nondeterministic program components for which at least the activity evoked, but possibly even the final state, is not necessarily uniquely determined by the initial state. For the formal derivation of programs expressed in terms of these constructs, a calculus will be be shown.},
	pages = {453--457},
	number = {8},
	journaltitle = {Commun. {ACM}},
	author = {Dijkstra, Edsger W.},
	urldate = {2019-02-01},
	date = {1975-08},
	keywords = {case-construction, correctness proof, derivation of programs, nondeterminancy, program semantics, programming language semantics, programming languages, programming methodology, repetition, sequencing primitives, termination},
	file = {ACM Full Text PDF:/home/fordrl/Zotero/storage/4XF5W5ZR/Dijkstra - 1975 - Guarded Commands, Nondeterminacy and Formal Deriva.pdf:application/pdf},
}

@inproceedings{blatter_static_2018,
	title = {Static and Dynamic Verification of Relational Properties on Self-composed C Code},
	isbn = {978-3-319-92994-1},
	series = {Lecture Notes in Computer Science},
	abstract = {Function contracts are a well-established way of formally specifying the intended behavior of a function. However, they usually only describe what should happen during a single call. Relational properties, on the other hand, link several function calls. They include such properties as non-interference, continuity and monotonicity. Other examples relate sequences of function calls, for instance, to show that decrypting an encrypted message with the appropriate key gives back the original message. Such properties cannot be expressed directly in the traditional setting of modular deductive verification, but are amenable to verification through self-composition. This paper presents a verification technique dedicated to relational properties in C programs and its implementation in the form of a Frama-C plugin called {RPP} and based on self-composition. It supports functions with side effects and recursive functions. The proposed approach makes it possible to prove a relational property, to check it at runtime, to generate a counterexample using testing and to use it as a hypothesis in the subsequent verification. Our initial experiments on existing benchmarks confirm that the proposed technique is helpful for static and dynamic analysis of relational properties.},
	pages = {44--62},
	booktitle = {Tests and Proofs},
	publisher = {Springer International Publishing},
	author = {Blatter, Lionel and Kosmatov, Nikolai and Le Gall, Pascale and Prevosto, Virgile and Petiot, Guillaume},
	editor = {Dubois, Catherine and Wolff, Burkhart},
	date = {2018},
	langid = {english},
	keywords = {Deductive verification, Dynamic verification, Frama-C, Relational properties, Self-composition, Specification},
	file = {Blatter et al. - 2018 - Static and Dynamic Verification of Relational Prop.pdf:/home/fordrl/Zotero/storage/4HABAVL9/Blatter et al. - 2018 - Static and Dynamic Verification of Relational Prop.pdf:application/pdf},
}

@article{petiot_your_2015,
	title = {Your Proof Fails? Testing Helps to Find the Reason},
	url = {http://arxiv.org/abs/1508.01691},
	shorttitle = {Your Proof Fails?},
	abstract = {Applying deductive verification to formally prove that a program respects its formal specification is a very complex and time-consuming task due in particular to the lack of feedback in case of proof failures. Along with a non-compliance between the code and its specification (due to an error in at least one of them), possible reasons of a proof failure include a missing or too weak specification for a called function or a loop, and lack of time or simply incapacity of the prover to finish a particular proof. This work proposes a new methodology where test generation helps to identify the reason of a proof failure and to exhibit a counter-example clearly illustrating the issue. We describe how to transform an annotated C program into C code suitable for testing and illustrate the benefits of the method on comprehensive examples. The method has been implemented in {STADY}, a plugin of the software analysis platform {FRAMA}-C. Initial experiments show that detecting non-compliances and contract weaknesses allows to precisely diagnose most proof failures.},
	journaltitle = {{arXiv}:1508.01691 [cs]},
	author = {Petiot, Guillaume and Kosmatov, Nikolai and Botella, Bernard and Giorgetti, Alain and Julliand, Jacques},
	urldate = {2019-02-01},
	date = {2015-08-07},
	eprinttype = {arxiv},
	eprint = {1508.01691},
	keywords = {D.2.4, Computer Science - Software Engineering, D.2.5},
	file = {arXiv.org Snapshot:/home/fordrl/Zotero/storage/QZ7UD9YV/1508.html:text/html;arXiv\:1508.01691 PDF:/home/fordrl/Zotero/storage/HKJL6G88/Petiot et al. - 2015 - Your Proof Fails Testing Helps to Find the Reason.pdf:application/pdf},
}

@article{petiot_how_2018,
	title = {How testing helps to diagnose proof failures},
	volume = {30},
	issn = {1433-299X},
	url = {https://doi.org/10.1007/s00165-018-0456-4},
	doi = {10.1007/s00165-018-0456-4},
	abstract = {Applying deductive verification to formally prove that a program respects its formal specification is a very complex and time-consuming task due in particular to the lack of feedback in case of proof failures. Along with a non-compliance between the code and its specification (due to an error in at least one of them), possible reasons of a proof failure include a missing or too weak specification for a called function or a loop, and lack of time or simply incapacity of the prover to finish a particular proof. This work proposes a methodology where test generation helps to identify the reason of a proof failure and to exhibit a counterexample clearly illustrating the issue. We define the categories of proof failures, introduce two subcategories of contract weaknesses (single and global ones), and examine their properties. We describe how to transform a C program formally specified in an executable specification language into C code suitable for testing, and illustrate the benefits of the method on comprehensive examples. The method has been implemented in {StaDy}, a plugin of the software analysis platform Frama-C. Initial experiments show that detecting non-compliances and contract weaknesses allows to precisely diagnose most proof failures.},
	pages = {629--657},
	number = {6},
	journaltitle = {Formal Aspects of Computing},
	shortjournal = {Form Asp Comp},
	author = {Petiot, Guillaume and Kosmatov, Nikolai and Botella, Bernard and Giorgetti, Alain and Julliand, Jacques},
	urldate = {2019-02-01},
	date = {2018-11-01},
	langid = {english},
	keywords = {Deductive verification, Frama-C, Specification, Proof debugging, Test generation},
	file = {Submitted Version:/home/fordrl/Zotero/storage/7PS4JCYI/Petiot et al. - 2018 - How testing helps to diagnose proof failures.pdf:application/pdf},
}

@article{blanchard_concurrent_2017,
	title = {From Concurrent Programs to Simulating Sequential Programs: Correctness of a Transformation},
	volume = {253},
	issn = {2075-2180},
	url = {http://arxiv.org/abs/1708.07226},
	doi = {10.4204/EPTCS.253.9},
	shorttitle = {From Concurrent Programs to Simulating Sequential Programs},
	abstract = {Frama-C is a software analysis framework that provides a common infrastructure and a common behavioral specification language to plugins that implement various static and dynamic analyses of C programs. Most plugins do not support concurrency. We have proposed Conc2Seq, a Frama-C plugin based on program transformation, capable to leverage the existing huge code base of plugins and to handle concurrent C programs. In this paper we formalize and sketch the proof of correctness of the program transformation principle behind Conc2Seq, and present an effort towards the full mechanization of both the formalization and proofs with the proof assistant Coq.},
	pages = {109--123},
	journaltitle = {Electronic Proceedings in Theoretical Computer Science},
	author = {Blanchard, Allan and Loulergue, Frédéric and Kosmatov, Nikolai},
	urldate = {2019-02-01},
	date = {2017-08-23},
	eprinttype = {arxiv},
	eprint = {1708.07226},
	keywords = {Computer Science - Programming Languages},
	file = {arXiv.org Snapshot:/home/fordrl/Zotero/storage/E2K4HQ84/1708.html:text/html;arXiv\:1708.07226 PDF:/home/fordrl/Zotero/storage/DKA444GJ/Blanchard et al. - 2017 - From Concurrent Programs to Simulating Sequential .pdf:application/pdf},
}

@article{brahmi_formalise_nodate,
	title = {Formalise to automate: deployment of a safe and cost-efﬁcient process for avionics software -Extended},
	abstract = {For over a decade, Airbus have been introducing formal techniques into the veriﬁcation processes of some of their avionics software products, to cope with the steady increase of the size and complexity of related avionics systems. These techniques have come of age for large-scale industrial deployment. All design and veriﬁcation processes are currently being revised to take maximum advantage from them, i.e. improve industrial efﬁciency while maintaining the safety and reliability of avionics systems.},
	pages = {17},
	author = {Brahmi, Abderrahmane and Delmas, David and Essoussi, Mohamed Habib and Randimbivololona, Famantanantsoa and Informatics, {CEPRESY} and Nauzere, La and Atki, Abdellatif and Marie, Thomas},
	langid = {english},
	file = {Brahmi et al. - Formalise to automate deployment of a safe and co.pdf:/home/fordrl/Zotero/storage/TDP2UBY6/Brahmi et al. - Formalise to automate deployment of a safe and co.pdf:application/pdf},
}

@inproceedings{brahmi_formalise_2018,
	location = {Toulouse, France},
	title = {Formalise to automate: deployment of a safe and cost-efficient process for avionics software},
	url = {https://hal.archives-ouvertes.fr/hal-01708332},
	shorttitle = {Formalise to automate},
	abstract = {For over a decade, Airbus have been introducing formal techniques into the verification processes of some of their avionics software products, to cope with the steady increase of the size and complexity of related avionics systems. These techniques have come of age for large-scale industrial deployment. All design and verification processes are currently being revised to take maximum advantage from them, i.e. improve industrial efficiency while maintaining the safety and reliability of avionics systems. To achieve this goal, all human-engineered design artefacts are being formalised using languages with well-defined syntaxes and semantics, in order to allow for the automatic generation of all subsequent, computable design or verification artefacts, and the preparation of the input data for non computable activities. To this aim, several domain-specific languages and related compilers have been developed internally, which cover all design activities, and bridge the gaps to integrate external tools into the overall development processes, e.g. sound, semantics-based, static analysis tools. For instance, the formalisation of detailed designs in the form of function contracts expressed in a first-order logic-based language allows for a hybrid approach to unit verification. Designs may be compiled down to {ACSL} [5] contracts, allowing for program proof with Frama-C [22], or they may be compiled down to test contracts, allowing for semi-automatic unit tests.},
	booktitle = {9th European Congress on Embedded Real Time Software and Systems ({ERTS} 2018)},
	author = {Brahmi, Abderrahmane and Delmas, David and Essoussi, Mohamed Habib and Randimbivololona, Famantanantsoa and Atki, Abdellatif and Marie, Thomas},
	urldate = {2019-02-01},
	date = {2018-01},
	keywords = {static analysis, domain-specific languages, avionics software, compilation, design, development process, {DO}-178C, formal methods, formalisation, industrial application},
	file = {HAL PDF Full Text:/home/fordrl/Zotero/storage/3NK7R5HC/Brahmi et al. - 2018 - Formalise to automate deployment of a safe and co.pdf:application/pdf},
}

@article{delignat-lavaud_implementing_2017,
	title = {Implementing and Proving the {TLS} 1.3 Record Layer},
	url = {https://www.microsoft.com/en-us/research/publication/implementing-proving-tls-1-3-record-layer/},
	abstract = {The record layer is the main bridge between {TLS} applications and internal sub-protocols. Its core functionality is an elaborate form of authenticated encryption: streams of messages for each sub-protocol (handshake, alert, and application data) are fragmented, multiplexed, and encrypted with optional padding to hide their lengths. Conversely, the sub-protocols may provide fresh keys or signal …},
	author = {Delignat-Lavaud, Antoine and Fournet, Cédric and Kohlweiss, Markulf and Protzenko, Jonathan and Rastogi, Aseem and Swamy, Nikhil and Zanella-Beguelin, Santiago and Bhargavan, Karthikeyan and Pan, Jianyang and Zinzindohoue, Jean Karim},
	urldate = {2019-02-01},
	date = {2017-08-17},
	langid = {american},
	file = {Snapshot:/home/fordrl/Zotero/storage/HYVJCGU9/implementing-proving-tls-1-3-record-layer.html:text/html;Full Text PDF:/home/fordrl/Zotero/storage/DB23BSB5/Delignat-Lavaud et al. - 2017 - Implementing and Proving the TLS 1.3 Record Layer.pdf:application/pdf},
}

@incollection{parigot_tactic_2000,
	location = {Berlin, Heidelberg},
	title = {A Tactic Language for the System Coq},
	volume = {1955},
	isbn = {978-3-540-41285-4},
	url = {http://link.springer.com/10.1007/3-540-44404-1_7},
	pages = {85--95},
	booktitle = {Logic for Programming and Automated Reasoning},
	publisher = {Springer Berlin Heidelberg},
	author = {Delahaye, David},
	editor = {Parigot, Michel and Voronkov, Andrei},
	urldate = {2019-02-01},
	date = {2000},
	langid = {english},
	doi = {10.1007/3-540-44404-1_7},
	file = {Submitted Version:/home/fordrl/Zotero/storage/7N982YMB/Delahaye - 2000 - A Tactic Language for the System Coq.pdf:application/pdf},
}

@inproceedings{ekici_smtcoq:_2017,
	title = {{SMTCoq}: A Plug-In for Integrating {SMT} Solvers into Coq},
	isbn = {978-3-319-63390-9},
	series = {Lecture Notes in Computer Science},
	shorttitle = {{SMTCoq}},
	abstract = {This paper describes {SMTCoq}, a plug-in for the integration of external solvers into the Coq proof assistant. Based on a checker for generic first-order proof certificates fully implemented and proved correct in Coq, {SMTCoq} offers facilities to check answers from external {SAT} and {SMT} solvers and to increase Coq’s automation using such solvers, all in a safe way. The current version supports proof certificates produced by the {SAT} solver {ZChaff}, for propositional logic, and the {SMT} solvers {veriT} and {CVC}4, for the quantifier-free fragment of the combined theory of fixed-size bit vectors, functional arrays with extensionality, linear integer arithmetic, and uninterpreted function symbols.},
	pages = {126--133},
	booktitle = {Computer Aided Verification},
	publisher = {Springer International Publishing},
	author = {Ekici, Burak and Mebsout, Alain and Tinelli, Cesare and Keller, Chantal and Katz, Guy and Reynolds, Andrew and Barrett, Clark},
	editor = {Majumdar, Rupak and Kunčak, Viktor},
	date = {2017},
	langid = {english},
	file = {Ekici et al. - 2017 - SMTCoq A Plug-In for Integrating SMT Solvers into.pdf:/home/fordrl/Zotero/storage/HR5VZETR/Ekici et al. - 2017 - SMTCoq A Plug-In for Integrating SMT Solvers into.pdf:application/pdf},
}

@article{hunt_warren_a._industrial_2017,
	title = {Industrial hardware and software verification with {ACL}2},
	volume = {375},
	url = {https://royalsocietypublishing.org/doi/10.1098/rsta.2015.0399},
	doi = {10.1098/rsta.2015.0399},
	abstract = {The {ACL}2 theorem prover has seen sustained industrial use since the mid-1990s. Companies that have used {ACL}2 regularly include {AMD}, Centaur Technology, {IBM}, Intel, Kestrel Institute, Motorola/Freescale, Oracle and Rockwell Collins. This paper introduces {ACL}2 and focuses on how and why {ACL}2 is used in industry. {ACL}2 is well-suited to its industrial application to numerous software and hardware systems, because it is an integrated programming/proof environment supporting a subset of the {ANSI} standard Common Lisp programming language. As a programming language {ACL}2 permits the coding of efficient and robust programs; as a prover {ACL}2 can be fully automatic but provides many features permitting domain-specific human-supplied guidance at various levels of abstraction. {ACL}2 specifications and models often serve as efficient execution engines for the modelled artefacts while permitting formal analysis and proof of properties. Crucially, {ACL}2 also provides support for the development and verification of other formal analysis tools. However, {ACL}2 did not find its way into industrial use merely because of its technical features. The core {ACL}2 user/development community has a shared vision of making mechanized verification routine when appropriate and has been committed to this vision for the quarter century since the Computational Logic, Inc., Verified Stack. The community has focused on demonstrating the viability of the tool by taking on industrial projects (often at the expense of not being able to publish much).This article is part of the themed issue ‘Verified trustworthy software systems’.},
	pages = {20150399},
	number = {2104},
	journaltitle = {Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences},
	shortjournal = {Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences},
	author = {{Hunt Warren A.} and {Kaufmann Matt} and {Moore J Strother} and {Slobodova Anna}},
	urldate = {2019-02-01},
	date = {2017-10-13},
	file = {Snapshot:/home/fordrl/Zotero/storage/VVZ2CQLI/rsta.2015.html:text/html;Full Text PDF:/home/fordrl/Zotero/storage/FB2ESHYL/Hunt Warren A. et al. - 2017 - Industrial hardware and software verification with.pdf:application/pdf},
}

@article{white_neil_formal_2017,
	title = {Formal verification: will the seedling ever flower?},
	volume = {375},
	url = {https://royalsocietypublishing.org/doi/10.1098/rsta.2015.0402},
	doi = {10.1098/rsta.2015.0402},
	shorttitle = {Formal verification},
	abstract = {In one sense, formal specification and verification have been highly successful: techniques have been developed in pioneering academic research, transferred to software companies through training and partnerships, and successfully deployed in systems with national significance. Altran {UK} has been in the vanguard of this movement. This paper summarizes some of our key deployments of formal techniques over the past 20 years, including both security- and safety-critical systems. The impact of formal techniques, however, remains within an industrial niche, and while government and suppliers across industry search for solutions to the problems of poor-quality software, the wider software industry remains resistant to adoption of this proven solution. We conclude by reflecting on some of the challenges we face as a community in ensuring that formal techniques achieve their true potential impact on society.This article is part of the themed issue ‘Verified trustworthy software systems’.},
	pages = {20150402},
	number = {2104},
	journaltitle = {Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences},
	shortjournal = {Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences},
	author = {{White Neil} and {Matthews Stuart} and {Chapman Roderick}},
	urldate = {2019-02-01},
	date = {2017-10-13},
	file = {Snapshot:/home/fordrl/Zotero/storage/SZBRJG4C/rsta.2015.html:text/html;Full Text PDF:/home/fordrl/Zotero/storage/CPL6R6HS/White Neil et al. - 2017 - Formal verification will the seedling ever flower.pdf:application/pdf},
}

@article{david_cristina_program_2017,
	title = {Program synthesis: challenges and opportunities},
	volume = {375},
	url = {https://royalsocietypublishing.org/doi/10.1098/rsta.2015.0403},
	doi = {10.1098/rsta.2015.0403},
	shorttitle = {Program synthesis},
	abstract = {Program synthesis is the mechanized construction of software, dubbed ‘self-writing code’. Synthesis tools relieve the programmer from thinking about how the problem is to be solved; instead, the programmer only provides a description of what is to be achieved. Given a specification of what the program should do, the synthesizer generates an implementation that provably satisfies this specification. From a logical point of view, a program synthesizer is a solver for second-order existential logic. Owing to the expressiveness of second-order logic, program synthesis has an extremely broad range of applications. We survey some of these applications as well as recent trends in the algorithms that solve the program synthesis problem. In particular, we focus on an approach that has raised the profile of program synthesis and ushered in a generation of new synthesis tools, namely counter-example-guided inductive synthesis ({CEGIS}). We provide a description of the {CEGIS} architecture, followed by recent algorithmic improvements. We conjecture that the capacity of program synthesis engines will see further step change, in a manner that is transparent to the applications, which will open up an even broader range of use-cases.This article is part of the themed issue ‘Verified trustworthy software systems’.},
	pages = {20150403},
	number = {2104},
	journaltitle = {Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences},
	shortjournal = {Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences},
	author = {{David Cristina} and {Kroening Daniel}},
	urldate = {2019-02-01},
	date = {2017-10-13},
	file = {Snapshot:/home/fordrl/Zotero/storage/IULWXC2L/rsta.2015.html:text/html;Full Text PDF:/home/fordrl/Zotero/storage/N5ZN828M/David Cristina and Kroening Daniel - 2017 - Program synthesis challenges and opportunities.pdf:application/pdf},
}

@article{appel_andrew_w._position_2017,
	title = {Position paper: the science of deep specification},
	volume = {375},
	url = {https://royalsocietypublishing.org/doi/10.1098/rsta.2016.0331},
	doi = {10.1098/rsta.2016.0331},
	shorttitle = {Position paper},
	abstract = {We introduce our efforts within the project ‘The science of deep specification’ to work out the key formal underpinnings of industrial-scale formal specifications of software and hardware components, anticipating a world where large verified systems are routinely built out of smaller verified components that are also used by many other projects. We identify an important class of specification that has already been used in a few experiments that connect strong component-correctness theorems across the work of different teams. To help popularize the unique advantages of that style, we dub it deep specification, and we say that it encompasses specifications that are rich, two-sided, formal and live (terms that we define in the article). Our core team is developing a proof-of-concept system (based on the Coq proof assistant) whose specification and verification work is divided across largely decoupled subteams at our four institutions, encompassing hardware microarchitecture, compilers, operating systems and applications, along with cross-cutting principles and tools for effective specification. We also aim to catalyse interest in the approach, not just by basic researchers but also by users in industry.This article is part of the themed issue ‘Verified trustworthy software systems’.},
	pages = {20160331},
	number = {2104},
	journaltitle = {Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences},
	shortjournal = {Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences},
	author = {{Appel Andrew W.} and {Beringer Lennart} and {Chlipala Adam} and {Pierce Benjamin C.} and {Shao Zhong} and {Weirich Stephanie} and {Zdancewic Steve}},
	urldate = {2019-02-01},
	date = {2017-10-13},
	file = {Snapshot:/home/fordrl/Zotero/storage/492EXHEP/rsta.2016.html:text/html;Full Text PDF:/home/fordrl/Zotero/storage/6IKBBI2V/Appel Andrew W. et al. - 2017 - Position paper the science of deep specification.pdf:application/pdf},
}

@article{batty_mark_compositional_2017,
	title = {Compositional relaxed concurrency},
	volume = {375},
	url = {https://royalsocietypublishing.org/doi/10.1098/rsta.2015.0406},
	doi = {10.1098/rsta.2015.0406},
	abstract = {There is a broad design space for concurrent computer processors: they can be optimized for low power, low latency or high throughput. This freedom to tune each processor design to its niche has led to an increasing diversity of machines, from powerful pocketable devices to those responsible for complex and critical tasks, such as car guidance systems. Given this context, academic concurrency research sounds notes of both caution and optimism. Caution because recent work has uncovered flaws in the way we explain the subtle memory behaviour of concurrent systems: specifications have been shown to be incorrect, leading to bugs throughout the many layers of the system. And optimism because our tools and methods for verifying the correctness of concurrent code—although built above an idealized model of concurrency—are becoming more mature. This paper looks at the way we specify the memory behaviour of concurrent systems and suggests a new direction. Currently, there is a siloed approach, with each processor and programming language specified separately in an incomparable way. But this does not match the structure of our programs, which may use multiple processors and languages together. Instead we propose a compositional approach, where program components carry with them a description of the sort of concurrency they rely on, and there is a mechanism for composing these. This will support not only components written for the multiple varied processors found in a modern system but also those that use idealized models of concurrency, providing a sound footing for mature verification techniques.This article is part of the themed issue ‘Verified trustworthy software systems’.},
	pages = {20150406},
	number = {2104},
	journaltitle = {Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences},
	shortjournal = {Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences},
	author = {{Batty Mark}},
	urldate = {2019-02-01},
	date = {2017-10-13},
	file = {Snapshot:/home/fordrl/Zotero/storage/2VP9GJZV/rsta.2015.html:text/html;Full Text PDF:/home/fordrl/Zotero/storage/F3KZSHAP/Batty Mark - 2017 - Compositional relaxed concurrency.pdf:application/pdf},
}

@article{klein_gerwin_provably_2017,
	title = {Provably trustworthy systems},
	volume = {375},
	url = {https://royalsocietypublishing.org/doi/10.1098/rsta.2015.0404},
	doi = {10.1098/rsta.2015.0404},
	abstract = {We present recent work on building and scaling trustworthy systems with formal, machine-checkable proof from the ground up, including the operating system kernel, at the level of binary machine code. We first give a brief overview of the {seL}4 microkernel verification and how it can be used to build verified systems. We then show two complementary techniques for scaling these methods to larger systems: proof engineering, to estimate verification effort; and code/proof co-generation, for scalable development of provably trustworthy applications.This article is part of the themed issue ‘Verified trustworthy software systems’.},
	pages = {20150404},
	number = {2104},
	journaltitle = {Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences},
	shortjournal = {Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences},
	author = {{Klein Gerwin} and {Andronick June} and {Keller Gabriele} and {Matichuk Daniel} and {Murray Toby} and {O'Connor Liam}},
	urldate = {2019-02-01},
	date = {2017-10-13},
	file = {Snapshot:/home/fordrl/Zotero/storage/XR76Z7EA/rsta.2015.html:text/html;Full Text PDF:/home/fordrl/Zotero/storage/5NUUJ5IV/Klein Gerwin et al. - 2017 - Provably trustworthy systems.pdf:application/pdf},
}

@article{delaware_narcissus:_2018,
	title = {Narcissus: Deriving Correct-By-Construction Decoders and Encoders from Binary Formats},
	url = {https://arxiv.org/abs/1803.04870v2},
	shorttitle = {Narcissus},
	abstract = {It is a neat result from functional programming that libraries of parser
combinators can support rapid construction of decoders for quite a range of
formats. With a little more work, the same combinator program can denote both a
decoder and an encoder. Unfortunately, the real world is full of gnarly
formats, as with the packet formats that make up the standard Internet protocol
stack. Most past parser-combinator approaches cannot handle these formats, and
the few exceptions require redundancy -- one part of the natural grammar needs
to be hand-translated into hints in multiple parts of a parser program. We show
how to recover very natural and nonredundant format specifications, covering
all popular network packet formats and generating both decoders and encoders
automatically. The catch is that we use the Coq proof assistant to derive both
kinds of artifacts using tactics, automatically, in a way that guarantees that
they form inverses of each other. We used our approach to reimplement packet
processing for a full Internet protocol stack, inserting our replacement into
the {OCaml}-based {MirageOS} unikernel, resulting in minimal performance
degradation.},
	author = {Delaware, Benjamin and Suriyakarn, Sorawit and Pit--Claudel, Clément and Ye, Qianchuan and Chlipala, Adam},
	urldate = {2019-02-01},
	date = {2018-03-13},
	langid = {english},
	file = {Snapshot:/home/fordrl/Zotero/storage/JEN8SSZV/1803.html:text/html;Full Text PDF:/home/fordrl/Zotero/storage/HPDJVDBJ/Delaware et al. - 2018 - Narcissus Deriving Correct-By-Construction Decode.pdf:application/pdf},
}

@article{choi_kami:_2017,
	title = {Kami: A Platform for High-level Parametric Hardware Specification and Its Modular Verification},
	volume = {1},
	issn = {2475-1421},
	url = {http://doi.acm.org/10.1145/3110268},
	doi = {10.1145/3110268},
	shorttitle = {Kami},
	abstract = {It has become fairly standard in the programming-languages research world to verify functional programs in proof assistants using induction, algebraic simplification, and rewriting. In this paper, we introduce Kami, a Coq library that enables similar expressive and modular reasoning for hardware designs expressed in the style of the Bluespec language. We can specify, implement, and verify realistic designs entirely within Coq, ending with automatic extraction into a pipeline that bottoms out in {FPGAs}. Our methodology, using labeled transition systems, has been evaluated in a case study verifying an infinite family of multicore systems, with cache-coherent shared memory and pipelined cores implementing (the base integer subset of) the {RISC}-V instruction set.},
	pages = {24:1--24:30},
	issue = {{ICFP}},
	journaltitle = {Proc. {ACM} Program. Lang.},
	author = {Choi, Joonwon and Vijayaraghavan, Muralidaran and Sherman, Benjamin and Chlipala, Adam and {Arvind}},
	urldate = {2019-02-01},
	date = {2017-08},
	keywords = {formal verification, proof assistants, hardware},
	file = {ACM Full Text PDF:/home/fordrl/Zotero/storage/MC26D45K/Choi et al. - 2017 - Kami A Platform for High-level Parametric Hardwar.pdf:application/pdf},
}

@article{fisher_kathleen_hacms_2017,
	title = {The {HACMS} program: using formal methods to eliminate exploitable bugs},
	volume = {375},
	url = {https://royalsocietypublishing.org/doi/10.1098/rsta.2015.0401},
	doi = {10.1098/rsta.2015.0401},
	shorttitle = {The {HACMS} program},
	abstract = {For decades, formal methods have offered the promise of verified software that does not have exploitable bugs. Until recently, however, it has not been possible to verify software of sufficient complexity to be useful. Recently, that situation has changed. {SeL}4 is an open-source operating system microkernel efficient enough to be used in a wide range of practical applications. Its designers proved it to be fully functionally correct, ensuring the absence of buffer overflows, null pointer exceptions, use-after-free errors, etc., and guaranteeing integrity and confidentiality. The {CompCert} Verifying C Compiler maps source C programs to provably equivalent assembly language, ensuring the absence of exploitable bugs in the compiler. A number of factors have enabled this revolution, including faster processors, increased automation, more extensive infrastructure, specialized logics and the decision to co-develop code and correctness proofs rather than verify existing artefacts. In this paper, we explore the promise and limitations of current formal-methods techniques. We discuss these issues in the context of {DARPA}’s {HACMS} program, which had as its goal the creation of high-assurance software for vehicles, including quadcopters, helicopters and automobiles.This article is part of the themed issue ‘Verified trustworthy software systems’.},
	pages = {20150401},
	number = {2104},
	journaltitle = {Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences},
	shortjournal = {Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences},
	author = {{Fisher Kathleen} and {Launchbury John} and {Richards Raymond}},
	urldate = {2019-02-01},
	date = {2017-10-13},
	file = {Snapshot:/home/fordrl/Zotero/storage/Z7N5TJNE/rsta.2015.html:text/html;Full Text PDF:/home/fordrl/Zotero/storage/P6Z2SRJK/Fisher Kathleen et al. - 2017 - The HACMS program using formal methods to elimina.pdf:application/pdf},
}

@inproceedings{petcher_foundational_2015,
	title = {The Foundational Cryptography Framework},
	isbn = {978-3-662-46666-7},
	url = {http://www.cs.cornell.edu/~jgm/papers/FCF.pdf},
	series = {Lecture Notes in Computer Science},
	abstract = {We present the Foundational Cryptography Framework ({FCF}) for developing and checking complete proofs of security for cryptographic schemes within a proof assistant. This is a general-purpose framework that is capable of modeling and reasoning about a wide range of cryptographic schemes, security definitions, and assumptions. Security is proven in the computational model, and the proof provides concrete bounds as well as asymptotic conclusions. {FCF} provides a language for probabilistic programs, a theory that is used to reason about programs, and a library of tactics and definitions that are useful in proofs about cryptography. The framework is designed to leverage fully the existing theory and capabilities of the Coq proof assistant in order to reduce the effort required to develop proofs.},
	pages = {53--72},
	booktitle = {Principles of Security and Trust},
	publisher = {Springer Berlin Heidelberg},
	author = {Petcher, Adam and Morrisett, Greg},
	editor = {Focardi, Riccardo and Myers, Andrew},
	date = {2015},
	langid = {english},
	keywords = {Coq, Cryptography, Proof Assistant, Protocol Verification},
	file = {Petcher and Morrisett - 2015 - The Foundational Cryptography Framework.pdf:/home/fordrl/Zotero/storage/8JFX6AUD/Petcher and Morrisett - 2015 - The Foundational Cryptography Framework.pdf:application/pdf},
}

@article{harrison_formal_2008,
	title = {Formal Proof—Theory and Practice},
	volume = {55},
	pages = {12},
	number = {11},
	author = {Harrison, John},
	date = {2008},
	langid = {english},
	file = {Harrison - 2008 - Formal Proof—Theory and Practice.pdf:/home/fordrl/Zotero/storage/AUC8R3WS/Harrison - 2008 - Formal Proof—Theory and Practice.pdf:application/pdf},
}

@article{wiedijk_formal_2008,
	title = {Formal Proof—Getting Started},
	volume = {55},
	pages = {7},
	number = {11},
	author = {Wiedijk, Freek},
	date = {2008},
	langid = {english},
	file = {Wiedijk - 2008 - Formal Proof—Getting Started.pdf:/home/fordrl/Zotero/storage/J3KGYSKG/Wiedijk - 2008 - Formal Proof—Getting Started.pdf:application/pdf},
}

@article{gonthier_formal_2008,
	title = {Formal Proof—The Four- Color Theorem},
	volume = {55},
	pages = {12},
	number = {11},
	author = {Gonthier, Georges},
	date = {2008},
	langid = {english},
	file = {Gonthier - 2008 - Formal Proof—The Four- Color Theorem.pdf:/home/fordrl/Zotero/storage/2DIXM75Q/Gonthier - 2008 - Formal Proof—The Four- Color Theorem.pdf:application/pdf},
}

@online{chlipala_end_nodate,
	title = {{THE} {END} {OF} {HISTORY}? {USING} A {PROOF} {ASSISTANT} {TO} {REPLACE} {LANGUAGE} {DESIGN} {WITH} {LIBRARY} {DESIGN}},
	url = {https://snapl.org/2017/abstracts/Chlipala.html},
	abstract = {Functionality of software systems has exploded in part because of advances in programming-language support for packaging reusable functionality as libraries. Developers benefit from the uniformity that comes of exposing many interfaces in the same language, as opposed to stringing together hodgepodges of command-line tools. Domain-specific languages may be viewed as an evolution of the power of reusable interfaces, when those interfaces become so flexible as to deserve to be called programming languages. However, common approaches to domain-specific languages give up many of the hard-won advantages of library-building in a rich common language, and even the traditional approach poses significant challenges in learning new {APIs}. We suggest that instead of continuing to develop new domain-specific languages, our community should embrace library-based ecosystems within very expressive languages that mix programming and theorem proving. Our prototype framework Fiat, a library for the Coq proof assistant, turns languages into easily comprehensible libraries via the key idea of modularizing functionality and performance away from each other, the former via macros that desugar into higher-order logic and the latter via optimization scripts that derive efficient code from logical programs.},
	author = {Chlipala, Adam and Delaware, Benjamin and Duchovni, Samuel and Gross, Jason and Pit-Claudel, Clément and Suriyakarn, Sorawit and Wang, Peng and ye, Katherine},
	urldate = {2019-02-01},
	file = {SNAPL 2017.pdf:/home/fordrl/Zotero/storage/M7L2Z5GW/SNAPL 2017.pdf:application/pdf;SNAPL 2017:/home/fordrl/Zotero/storage/2SE673GH/Chlipala.html:text/html},
}

@inproceedings{delaware_fiat:_2015,
	location = {New York, {NY}, {USA}},
	title = {Fiat: Deductive Synthesis of Abstract Data Types in a Proof Assistant},
	isbn = {978-1-4503-3300-9},
	url = {http://doi.acm.org/10.1145/2676726.2677006},
	doi = {10.1145/2676726.2677006},
	series = {{POPL} '15},
	shorttitle = {Fiat},
	abstract = {We present Fiat, a library for the Coq proof assistant supporting refinement of declarative specifications into efficient functional programs with a high degree of automation. Each refinement process leaves a proof trail, checkable by the normal Coq kernel, justifying its soundness. We focus on the synthesis of abstract data types that package methods with private data. We demonstrate the utility of our framework by applying it to the synthesis of query structures -- abstract data types with {SQL}-like query and insert operations. Fiat includes a library for writing specifications of query structures in {SQL}-inspired notation, expressing operations over relations (tables) in terms of mathematical sets. This library includes a suite of tactics for automating the refinement of specifications into efficient, correct-by-construction {OCaml} code. Using these tactics, a programmer can generate such an implementation completely automatically by only specifying the equivalent of {SQL} indexes, data structures capturing useful views of the abstract data. Throughout we speculate on the new programming modularity possibilities enabled by an automated refinement system with proved-correct rules.},
	pages = {689--700},
	booktitle = {Proceedings of the 42Nd Annual {ACM} {SIGPLAN}-{SIGACT} Symposium on Principles of Programming Languages},
	publisher = {{ACM}},
	author = {Delaware, Benjamin and Pit-Claudel, Clément and Gross, Jason and Chlipala, Adam},
	urldate = {2019-02-01},
	date = {2015},
	keywords = {deductive synthesis, mechanized derivation of abstract data types},
	file = {ACM Full Text PDF:/home/fordrl/Zotero/storage/N7HNG7DV/Delaware et al. - 2015 - Fiat Deductive Synthesis of Abstract Data Types i.pdf:application/pdf},
}

@inproceedings{sozeau_equations:_2010,
	title = {Equations: A Dependent Pattern-Matching Compiler},
	isbn = {978-3-642-14052-5},
	series = {Lecture Notes in Computer Science},
	shorttitle = {Equations},
	abstract = {We present a compiler for definitions made by pattern matching on inductive families in the Coq system. It allows to write structured, recursive dependently-typed functions as a set of equations, automatically find their realization in the core type theory and generate proofs to ease reasoning on them. It provides a complete package to define and reason on functions in the proof assistant, substantially reducing the boilerplate code and proofs one usually has to write, also hiding the intricacies related to the use of dependent types and complex recursion schemes.},
	pages = {419--434},
	booktitle = {Interactive Theorem Proving},
	publisher = {Springer Berlin Heidelberg},
	author = {Sozeau, Matthieu},
	editor = {Kaufmann, Matt and Paulson, Lawrence C.},
	date = {2010},
	langid = {english},
	keywords = {Proof Assistant, Recursive Call, Split Node, Type Theory, User Node},
	file = {Sozeau - 2010 - Equations A Dependent Pattern-Matching Compiler.pdf:/home/fordrl/Zotero/storage/FSGZK8IK/Sozeau - 2010 - Equations A Dependent Pattern-Matching Compiler.pdf:application/pdf;equations.pdf:/home/fordrl/Zotero/storage/FLLAR78Y/equations.pdf:application/pdf},
}

@article{chen_project_nodate,
	title = {Project Report on {DeepSpecDB}},
	abstract = {Recent years have witnessed a rapid development of mainmemory database systems thanks to the growingly aﬀordable memory. {DeepSpecDB} is another main-memory database management system implemented in C with deep speciﬁcation and end-to-end veriﬁcation guaranteeing the correctness of the system.},
	pages = {35},
	author = {Chen, Yixuan},
	langid = {english},
	file = {Chen - Project Report on DeepSpecDB.pdf:/home/fordrl/Zotero/storage/HNLI2SEC/Chen - Project Report on DeepSpecDB.pdf:application/pdf},
}

@article{barriere_vst_nodate,
	title = {{VST} Veriﬁcation of B+Trees with Cursors},
	abstract = {The {DeepSpecDB} project aims to deﬁne, specify and verify a high-performance concurrent in-memory database system. Based on {MassTree}, it uses B+Trees, a well-studied key-value data structure. Our sequential B+Trees library uses cursors, introduced in the database engine {SQLite}. Such cursors reduce the complexity of operations when dealing with partially sorted data. We deﬁne a Coq formal model for such trees, then use it to specify and prove the correctness of the C implementation using the Veriﬁed Software Toolchain.},
	pages = {19},
	author = {Barriere, Aurele and Appel, Andrew},
	langid = {english},
	file = {Barriere and Appel - VST Veriﬁcation of B+Trees with Cursors.pdf:/home/fordrl/Zotero/storage/8NTCGXZV/Barriere and Appel - VST Veriﬁcation of B+Trees with Cursors.pdf:application/pdf},
}

@article{anand_typed_nodate,
	title = {Typed Template Coq},
	abstract = {Template-Coq1 is a plugin for Coq, originally implemented by Malecha [7], which provides a reifier for Coq terms and global declarations, as represented in the Coq kernel, as well as a denotation command. Initially, it was developed for the purpose of writing functions on Coq’s {AST} in Gallina. Recently, its use was extended for the needs of the {CertiCoq} certified compiler project [2], which uses it as its front-end language and to derive parametricity properties [1], and the work of [5] on extracting Coq terms to a {CBV} λ-calculus. However, the syntax currently lacks semantics, be it typing semantics or operational semantics, which should reflect, as formal specifications in Coq, the semantics of Coq itself. This is an issue for {CertiCoq} where both a non-deterministic small step semantics and a deterministic call-by-value big step semantics had to be defined and preserved, without an “official” reference specification to refer to. Our hope with this work is to remedy this situation and provide a formal semantics of Coq’s implemented type theory, that can independently be refined and studied. By implementing a (partial) independent checker in Coq, we can also help formalize certified translations from Coq to Coq (Section 3).},
	pages = {2},
	author = {Anand, Abhishek and Tabareau, Simon Boulier Nicolas and Sozeau, Matthieu},
	langid = {english},
	file = {Anand et al. - Typed Template Coq.pdf:/home/fordrl/Zotero/storage/3GZEWLIT/Anand et al. - Typed Template Coq.pdf:application/pdf},
}

@article{leino_well-founded_2016,
	title = {Well-Founded Functions and Extreme Predicates in Dafny: A Tutorial},
	volume = {40},
	url = {https://www.microsoft.com/en-us/research/publication/well-founded-functions-extreme-predicates-dafny-tutorial/},
	shorttitle = {Well-Founded Functions and Extreme Predicates in Dafny},
	abstract = {A recursive function is well defined if its every recursive call corresponds a decrease in some well-founded order. Such well-founded functions are useful for example in computer programs when computing a value from some input. A boolean function can also be defined as an extreme solution to a recurrence relation, that is, as a least …},
	author = {Leino, Rustan},
	urldate = {2019-01-31},
	date = {2016-12-28},
	langid = {american},
	file = {Snapshot:/home/fordrl/Zotero/storage/L5BADAPF/well-founded-functions-extreme-predicates-dafny-tutorial.html:text/html;Full Text PDF:/home/fordrl/Zotero/storage/55G4TL2T/Leino - 2016 - Well-Founded Functions and Extreme Predicates in D.pdf:application/pdf},
}

@article{leino_verified_2016,
	title = {Verified Calculations},
	url = {https://www.microsoft.com/en-us/research/publication/verified-calculations/},
	abstract = {Calculational proofs—proofs by stepwise formula manipulation—are praised for their rigor, readability, and elegance. It seems desirable to reuse this style, often employed on paper, in the context of mechanized reasoning, and in particular, program verification. This work leverages the power of {SMT} solvers to machine-check calculational proofs at the level of detail they are usually …},
	author = {Leino, Rustan and Polikarpova, Nadia},
	urldate = {2019-01-31},
	date = {2016-12-28},
	langid = {american},
	file = {Snapshot:/home/fordrl/Zotero/storage/HHI48KJD/verified-calculations.html:text/html;Full Text PDF:/home/fordrl/Zotero/storage/E2KFJ246/Leino and Polikarpova - 2016 - Verified Calculations.pdf:application/pdf},
}

@article{parkinson_relationship_nodate,
	title = {The Relationship between Separation Logic and Implicit Dynamic Frames},
	volume = {6602},
	abstract = {Separation logic is a concise method for specifying programs that manipulate dynamically allocated storage. Partially inspired by separation logic, Implicit Dynamic Frames has recently been proposed, aiming at ﬁrst-order tool support. In this paper, we provide a total heap semantics for a standard separation logic, and prove it equivalent to the standard model. With small adaptations, we then show how to give a direct semantics to implicit dynamic frames and show this semantics correctly captures the existing deﬁnitions. This precisely connects the two logics. As a consequence of this connection, we show that a fragment of separation logic can be faithfully encoded in a ﬁrst-order automatic veriﬁcation tool (Chalice).},
	pages = {439--458},
	journaltitle = {{LNCS}},
	author = {Parkinson, Matthew J and Summers, Alexander J},
	langid = {english},
	note = {{ESOP} 2011},
	file = {Parkinson and Summers - The Relationship between Separation Logic and Impl.pdf:/home/fordrl/Zotero/storage/LMRQWFDB/Parkinson and Summers - The Relationship between Separation Logic and Impl.pdf:application/pdf},
}

@article{leino_compiling_2016,
	title = {Compiling Hilbert's epsilon Operator},
	volume = {35},
	url = {https://www.microsoft.com/en-us/research/publication/compiling-hilberts-%cf%b5-operator/},
	abstract = {Hilbert’s epsilon (ϵ) operator is a binder that picks an arbitrary element from a nonempty set. The operator is typically used in logics and proof engines. This paper contributes a discussion of considerations in supporting this operator in a programming language. More specifically, the paper presents the design choices made around supporting this operator in …},
	journaltitle = {{LPAR}-20. 20th International Conferences on Logic for Programming, Artificial Intelligence and Reasoning},
	author = {Leino, Rustan},
	urldate = {2019-01-31},
	date = {2016-12-28},
	langid = {american},
	file = {Snapshot:/home/fordrl/Zotero/storage/NMJWCA8C/compiling-hilberts-ϵ-operator.html:text/html;Full Text PDF:/home/fordrl/Zotero/storage/WIX4KMWE/Leino - 2016 - Compiling Hilbert's Ïµ Operator.pdf:application/pdf},
}

@article{koenig_programming_2016,
	title = {Programming Language Features for Refinement},
	url = {https://www.microsoft.com/en-us/research/publication/programming-language-features-refinement/},
	abstract = {Algorithmic and data refinement are well studied topics that provide a mathematically rigorous approach to gradually introducing details in the implementation of software. Program refinements are performed in the context of some programming language, but mainstream languages lack features for recording the sequence of refinement steps in the program text. To experiment with the combination …},
	author = {Koenig, Jason and Leino, Rustan},
	urldate = {2019-01-31},
	date = {2016-12-28},
	langid = {american},
	file = {Snapshot:/home/fordrl/Zotero/storage/MF44ARJ2/programming-language-features-refinement.html:text/html;Full Text PDF:/home/fordrl/Zotero/storage/2F7P595B/Koenig and Leino - 2016 - Programming Language Features for Refinement.pdf:application/pdf},
}

@article{leino_fine-grained_2016,
	title = {Fine-grained Caching of Verification Results},
	volume = {9206},
	url = {https://www.microsoft.com/en-us/research/publication/fine-grained-caching-verification-results/},
	abstract = {Developing provably correct programs is an incremental process that often involves a series of interactions with a program verifier. To increase the responsiveness of the program verifier during such interactions, we designed a system for fine-grained caching of verification results. The caching system uses the program’s call graph and control-flow graph to focus the verification …},
	author = {Leino, Rustan and Wüstholz, Valentin},
	urldate = {2019-01-31},
	date = {2016-12-28},
	langid = {american},
	file = {Snapshot:/home/fordrl/Zotero/storage/DCH5FZKS/fine-grained-caching-verification-results.html:text/html;Full Text PDF:/home/fordrl/Zotero/storage/4WMA66J9/Leino and Wüstholz - 2016 - Fine-grained Caching of Verification Results.pdf:application/pdf},
}

@article{leino_stepwise_2016,
	title = {Stepwise Refinement of Heap-Manipulating Code in Chalice},
	url = {https://www.microsoft.com/en-us/research/publication/stepwise-refinement-heap-manipulating-code-chalice/},
	abstract = {Stepwise refinement is a well-studied technique for developing a program from an abstract description to a concrete implementation. This paper describes a system with automated tool support for refinement, powered by a stateof-the-art verification engine that uses an {SMT} solver. Unlike previous refinement systems, users of the presented system interact only via declarations in the …},
	author = {Leino, Rustan and Yessenov, Kuat},
	urldate = {2019-01-31},
	date = {2016-12-29},
	langid = {american},
	file = {Snapshot:/home/fordrl/Zotero/storage/6YWHWCEJ/stepwise-refinement-heap-manipulating-code-chalice.html:text/html;Full Text PDF:/home/fordrl/Zotero/storage/8RNI6Q8U/Leino and Yessenov - 2016 - Stepwise Refinement of Heap-Manipulating Code in C.pdf:application/pdf},
}

@article{leino_verification_2016,
	title = {Verification of Concurrent Programs with Chalice},
	url = {https://www.microsoft.com/en-us/research/publication/verification-concurrent-programs-chalice/},
	abstract = {A program verifier is a tool that allows developers to prove that their code satisfies its specification for every possible input and every thread schedule. These lecture notes describe a verifier for concurrent programs called Chalice. Chalice’s verification methodology centers around permissions and permission transfer. In particular, a memory location may be accessed by a …},
	author = {Leino, Rustan and Müller, Peter and Smans, Jan},
	urldate = {2019-01-31},
	date = {2016-12-29},
	langid = {american},
	file = {Snapshot:/home/fordrl/Zotero/storage/C9ZBR9ZX/verification-concurrent-programs-chalice.html:text/html;Full Text PDF:/home/fordrl/Zotero/storage/ZMNMZ55Z/Leino et al. - 2016 - Verification of Concurrent Programs with Chalice.pdf:application/pdf},
}

@article{hatcliff_behavioral_2012,
	title = {Behavioral Interface Specification Languages},
	volume = {44},
	issn = {0360-0300},
	url = {http://doi.acm.org/10.1145/2187671.2187678},
	doi = {10.1145/2187671.2187678},
	abstract = {Behavioral interface specification languages provide formal code-level annotations, such as preconditions, postconditions, invariants, and assertions that allow programmers to express the intended behavior of program modules. Such specifications are useful for precisely documenting program behavior, for guiding implementation, and for facilitating agreement between teams of programmers in modular development of software. When used in conjunction with automated analysis and program verification tools, such specifications can support detection of common code vulnerabilities, capture of light-weight application-specific semantic properties, generation of test cases and test oracles, and full formal program verification. This article surveys behavioral interface specification languages with a focus toward automatic program verification and with a view towards aiding the Verified Software Initiative—a fifteen-year, cooperative, international project directed at the scientific challenges of large-scale software verification.},
	pages = {16:1--16:58},
	number = {3},
	journaltitle = {{ACM} Comput. Surv.},
	author = {Hatcliff, John and Leavens, Gary T. and Leino, K. Rustan M. and Müller, Peter and Parkinson, Matthew},
	urldate = {2019-01-31},
	date = {2012-06},
	keywords = {separation logic, Abstraction, assertion, behavioral subtyping, frame conditions, interface specification language, invariant, {JML}, postcondition, precondition, {SPARK}, Spec\#},
	file = {ACM Full Text PDF:/home/fordrl/Zotero/storage/F4MQHIJH/Hatcliff et al. - 2012 - Behavioral Interface Specification Languages.pdf:application/pdf},
}

@article{amin_computing_2016,
	title = {Computing with an {SMT} Solver},
	volume = {8570},
	url = {https://www.microsoft.com/en-us/research/publication/computing-smt-solver/},
	abstract = {Satisfiability modulo theories ({SMT}) solvers that support quantifier instantiations via matching triggers can be programmed to give practical support for user-defined theories. Care must be taken to avoid so-called matching loops, which may prevent termination of the solver. By design, such avoidance limits the extent to which the {SMT} solver is able to apply the …},
	author = {Amin, Nada and Leino, Rustan and Rompf, Tiark},
	urldate = {2019-01-31},
	date = {2016-12-28},
	langid = {american},
	file = {Snapshot:/home/fordrl/Zotero/storage/PMXMDKIE/computing-smt-solver.html:text/html;Full Text PDF:/home/fordrl/Zotero/storage/TD5DRRJV/Amin et al. - 2016 - Computing with an SMT Solver.pdf:application/pdf},
}

@article{leino_co-induction_2013,
	title = {Co-Induction Simply: Automatic Co-Inductive Proofs in a Program Verifier},
	url = {https://www.microsoft.com/en-us/research/publication/co-induction-simply-automatic-co-inductive-proofs-in-a-program-verifier/},
	shorttitle = {Co-Induction Simply},
	abstract = {Program verification relies heavily on induction, which has received decades of attention in mechanical verification tools. When program correctness is best described by infinite structures, program verification is usefully aided also by co-induction, which has not benefited from the same degree of tool support. Co-induction is complicated to work with in interactive proof assistants and …},
	author = {Leino, Rustan and Moskal, Michal},
	urldate = {2019-01-31},
	date = {2013-07-12},
	langid = {american},
	file = {Snapshot:/home/fordrl/Zotero/storage/DXHEKVNI/co-induction-simply-automatic-co-inductive-proofs-in-a-program-verifier.html:text/html;Full Text PDF:/home/fordrl/Zotero/storage/UEL7SVLY/Leino and Moskal - 2013 - Co-Induction Simply Automatic Co-Inductive Proofs.pdf:application/pdf},
}

@inproceedings{christakis_collaborative_2012,
	title = {Collaborative Verification and Testing with Explicit Assumptions},
	isbn = {978-3-642-32759-9},
	series = {Lecture Notes in Computer Science},
	abstract = {Many mainstream static code checkers make a number of compromises to improve automation, performance, and accuracy. These compromises include not checking certain program properties as well as making implicit, unsound assumptions. Consequently, the results of such static checkers do not provide definite guarantees about program correctness, which makes it unclear which properties remain to be tested. We propose a technique for collaborative verification and testing that makes compromises of static checkers explicit such that they can be compensated for by complementary checkers or testing. Our experiments suggest that our technique finds more errors and proves more properties than static checking alone, testing alone, and combinations that do not explicitly document the compromises made by static checkers. Our technique is also useful to obtain small test suites for partially-verified programs.},
	pages = {132--146},
	booktitle = {{FM} 2012: Formal Methods},
	publisher = {Springer Berlin Heidelberg},
	author = {Christakis, Maria and Müller, Peter and Wüstholz, Valentin},
	editor = {Giannakopoulou, Dimitra and Méry, Dominique},
	date = {2012},
	langid = {english},
	keywords = {Symbolic Execution, Static Checker, Test Case Generation, Testing Tool, Tool Chain},
	file = {Christakis et al. - 2012 - Collaborative Verification and Testing with Explic.pdf:/home/fordrl/Zotero/storage/N3T6EIWH/Christakis et al. - 2012 - Collaborative Verification and Testing with Explic.pdf:application/pdf},
}

@article{leino_assertional_2015,
	title = {An Assertional Proof of the Stability and Correctness of Natural Mergesort},
	volume = {17},
	issn = {1529-3785},
	url = {http://doi.acm.org/10.1145/2814571},
	doi = {10.1145/2814571},
	abstract = {We present a mechanically verified implementation of the sorting algorithm Natural Mergesort that consists of a few methods specified by their contracts of pre/post conditions. Methods are annotated with assertions that allow the automatic verification of the contract satisfaction. This program-proof is made using the state-of-the-art verifier Dafny. We verify not only the standard sortedness property, but also that the algorithm performs a stable sort. Throughout the article, we provide and explain the complete text of the program-proof.},
	pages = {6:1--6:22},
	number = {1},
	journaltitle = {{ACM} Trans. Comput. Logic},
	author = {Leino, K. Rustan M. and Lucio, Paqui},
	urldate = {2019-01-31},
	date = {2015-11},
	keywords = {theorem proving, Verification, formal methods, dafny, natural mergesort, software engineering, sorting, stability},
	file = {ACM Full Text PDF:/home/fordrl/Zotero/storage/KNJPYQ9I/Leino and Lucio - 2015 - An Assertional Proof of the Stability and Correctn.pdf:application/pdf},
}

@article{polikarpova_structuring_2019,
	title = {Structuring the Synthesis of Heap-manipulating Programs},
	volume = {3},
	issn = {2475-1421},
	url = {http://doi.acm.org/10.1145/3290385},
	doi = {10.1145/3290385},
	abstract = {This paper describes a deductive approach to synthesizing imperative programs with pointers from declarative specifications expressed in Separation Logic. Our synthesis algorithm takes as input a pair of assertions—a pre- and a postcondition—which describe two states of the symbolic heap, and derives a program that transforms one state into the other, guided by the shape of the heap. Our approach to program synthesis is grounded in proof theory: we introduce the novel framework of Synthetic Separation Logic ({SSL}), which generalises the classical notion of heap entailment P ⊢ Q to incorporate a possibility of transforming a heap satisfying an assertion P into a heap satisfying an assertion Q. A synthesized program represents a proof term for a transforming entailment statement P ↝ Q, and the synthesis procedure corresponds to a proof search. The derived programs are, thus, correct by construction, in the sense that they satisfy the ascribed pre/postconditions, and are accompanied by complete proof derivations, which can be checked independently.  We have implemented a proof search engine for {SSL} in a form of the program synthesizer called {SuSLik}. For efficiency, the engine exploits properties of {SSL} rules, such as invertibility and commutativity of rule applications on separate heaps, to prune the space of derivations it has to consider. We explain and showcase the use of {SSL} on characteristic examples, describe the design of {SuSLik}, and report on our experience of using it to synthesize a series of benchmark programs manipulating heap-based linked data structures.},
	pages = {72:1--72:30},
	issue = {{POPL}},
	journaltitle = {Proc. {ACM} Program. Lang.},
	author = {Polikarpova, Nadia and Sergey, Ilya},
	urldate = {2019-01-31},
	date = {2019-01},
	keywords = {Type Theory, Program Synthesis, Proof Systems, Separation Logic},
	file = {ACM Full Text PDF:/home/fordrl/Zotero/storage/LR6EKQYG/Polikarpova and Sergey - 2019 - Structuring the Synthesis of Heap-manipulating Pro.pdf:application/pdf},
}

@inproceedings{bohrer_veriphy:_2018,
	location = {Philadelphia, {PA}, {USA}},
	title = {{VeriPhy}: verified controller executables from verified cyber-physical system models},
	isbn = {978-1-4503-5698-5},
	url = {http://dl.acm.org/citation.cfm?doid=3192366.3192406},
	doi = {10.1145/3192366.3192406},
	shorttitle = {{VeriPhy}},
	eventtitle = {the 39th {ACM} {SIGPLAN} Conference},
	pages = {617--630},
	booktitle = {Proceedings of the 39th {ACM} {SIGPLAN} Conference on Programming Language Design and Implementation  - {PLDI} 2018},
	publisher = {{ACM} Press},
	author = {Bohrer, Brandon and Tan, Yong Kiam and Mitsch, Stefan and Myreen, Magnus O. and Platzer, André},
	urldate = {2019-01-31},
	date = {2018},
	langid = {english},
}

@collection{beckert_verification_2006,
	location = {Berlin, Heidelberg},
	title = {Verification of Object-Oriented Software. The {KeY} Approach},
	volume = {4334},
	isbn = {978-3-540-68977-5},
	url = {http://link.springer.com/10.1007/978-3-540-69061-0},
	series = {Lecture Notes in Computer Science},
	publisher = {Springer Berlin Heidelberg},
	editor = {Beckert, Bernhard and Hähnle, Reiner and Schmitt, Peter H.},
	urldate = {2019-01-31},
	date = {2006},
	langid = {english},
	doi = {10.1007/978-3-540-69061-0},
	file = {Beckert et al. - 2006 - Verification of Object-Oriented Software. The KeY .pdf:/home/fordrl/Zotero/storage/BRH2UR4H/Beckert et al. - 2006 - Verification of Object-Oriented Software. The KeY .pdf:application/pdf},
}

@article{platzer_complete_2017,
	title = {A Complete Uniform Substitution Calculus for Differential Dynamic Logic},
	volume = {59},
	issn = {0168-7433, 1573-0670},
	url = {http://arxiv.org/abs/1601.06183},
	doi = {10.1007/s10817-016-9385-1},
	abstract = {This article introduces a relatively complete proof calculus for differential dynamic logic ({dL}) that is entirely based on uniform substitution, a proof rule that substitutes a formula for a predicate symbol everywhere. Uniform substitutions make it possible to use axioms instead of axiom schemata, thereby substantially simplifying implementations. Instead of subtle schema variables and soundness-critical side conditions on the occurrence patterns of logical variables to restrict infinitely many axiom schema instances to sound ones, the resulting calculus adopts only a finite number of ordinary {dL} formulas as axioms, which uniform substitutions instantiate soundly. The static semantics of differential dynamic logic and the soundness-critical restrictions it imposes on proof steps is captured exclusively in uniform substitutions and variable renamings as opposed to being spread in delicate ways across the prover implementation. In addition to sound uniform substitutions, this article introduces differential forms for differential dynamic logic that make it possible to internalize differential invariants, differential substitutions, and derivatives as first-class axioms to reason about differential equations axiomatically. The resulting axiomatization of differential dynamic logic is proved to be sound and relatively complete.},
	pages = {219--265},
	number = {2},
	journaltitle = {Journal of Automated Reasoning},
	author = {Platzer, André},
	urldate = {2019-01-31},
	date = {2017-08},
	eprinttype = {arxiv},
	eprint = {1601.06183},
	keywords = {Computer Science - Programming Languages, Computer Science - Logic in Computer Science, F.3.1, F.3.2, F.4.1, 03F03, 03B70, 34A38, I.2.3, Mathematics - Logic},
	file = {arXiv.org Snapshot:/home/fordrl/Zotero/storage/R9XNPMRW/1601.html:text/html;arXiv\:1601.06183 PDF:/home/fordrl/Zotero/storage/8URQWUMX/Platzer - 2017 - A Complete Uniform Substitution Calculus for Diffe.pdf:application/pdf},
}

@book{platzer_logical_2018,
	location = {Cham},
	title = {Logical Foundations of Cyber-Physical Systems - Slides},
	isbn = {978-3-319-63587-3 978-3-319-63588-0},
	url = {http://link.springer.com/10.1007/978-3-319-63588-0},
	publisher = {Springer International Publishing},
	author = {Platzer, André},
	urldate = {2019-01-31},
	date = {2018},
	langid = {english},
	doi = {10.1007/978-3-319-63588-0},
	file = {Platzer - 2018 - Logical Foundations of Cyber-Physical Systems.pdf:/home/fordrl/Zotero/storage/XG3XYH4A/Platzer - 2018 - Logical Foundations of Cyber-Physical Systems.pdf:application/pdf},
}

@incollection{felty_keymaera_2015,
	location = {Cham},
	title = {{KeYmaera} X: An Axiomatic Tactical Theorem Prover for Hybrid Systems},
	volume = {9195},
	isbn = {978-3-319-21400-9 978-3-319-21401-6},
	url = {http://link.springer.com/10.1007/978-3-319-21401-6_36},
	shorttitle = {{KeYmaera} X},
	abstract = {{KeYmaera} X is a theorem prover for differential dynamic logic ({dL}), a logic for specifying and verifying properties of hybrid systems. Reasoning about complicated hybrid systems models requires support for sophisticated proof techniques, efﬁcient computation, and a user interface that crystallizes salient properties of the system. {KeYmaera} X allows users to specify custom proof search techniques as tactics, execute these tactics in parallel, and interface with partial proofs via an extensible user interface.},
	pages = {527--538},
	booktitle = {Automated Deduction - {CADE}-25},
	publisher = {Springer International Publishing},
	author = {Fulton, Nathan and Mitsch, Stefan and Quesel, Jan-David and Völp, Marcus and Platzer, André},
	editor = {Felty, Amy P. and Middeldorp, Aart},
	urldate = {2019-01-31},
	date = {2015},
	langid = {english},
	doi = {10.1007/978-3-319-21401-6_36},
	file = {Fulton et al. - 2015 - KeYmaera X An Axiomatic Tactical Theorem Prover f.pdf:/home/fordrl/Zotero/storage/WHPK2YJR/Fulton et al. - 2015 - KeYmaera X An Axiomatic Tactical Theorem Prover f.pdf:application/pdf},
}

@book{platzer_logical_2018-1,
	title = {Logical Foundations of Cyber-Physical Systems},
	isbn = {978-3-319-63587-3},
	url = {https://www.springer.com/gp/book/9783319635873},
	abstract = {Cyber-physical systems ({CPSs}) combine cyber capabilities, such as computation or communication, with physical capabilities, such as motion or other physical processes. Cars, aircraft, and robots are prime examples, because they move physically in space in a way that is determined by discrete computerized control algorithms. Designing these algorithms is challenging due to their tight coupling with physical behavior, while it is vital that these algorithms be correct because we rely on them for safety-critical tasks. This textbook teaches undergraduate students the core principles behind {CPSs}. It shows them how to develop models and controls; identify safety specifications and critical properties; reason rigorously about {CPS} models; leverage multi-dynamical systems compositionality to tame {CPS} complexity; identify required control constraints; verify {CPS} models of appropriate scale in logic; and develop an intuition for operational effects. The book is supported with homework exercises, lecture videos, and slides.},
	publisher = {Springer International Publishing},
	author = {Platzer, Andre},
	urldate = {2019-01-31},
	date = {2018},
	langid = {english},
	file = {Snapshot:/home/fordrl/Zotero/storage/TA7J9P9Y/9783319635873.html:text/html},
}

@incollection{hutchison_verifying_2007,
	location = {Berlin, Heidelberg},
	title = {Verifying Object-Oriented Programs with {KeY}: A Tutorial},
	volume = {4709},
	isbn = {978-3-540-74791-8 978-3-540-74792-5},
	url = {http://link.springer.com/10.1007/978-3-540-74792-5_4},
	shorttitle = {Verifying Object-Oriented Programs with {KeY}},
	abstract = {This paper is a tutorial on performing formal speciﬁcation and semi-automatic veriﬁcation of Java programs with the formal software development tool {KeY}. This tutorial aims to ﬁll the gap between elementary introductions using toy examples and state-of-art case studies by going through a self-contained, yet non-trivial, example. It is hoped that this contributes to explain the problems encountered in veriﬁcation of imperative, object-oriented programs to a readership outside the limited community of active researchers.},
	pages = {70--101},
	booktitle = {Formal Methods for Components and Objects},
	publisher = {Springer Berlin Heidelberg},
	author = {Ahrendt, Wolfgang and Beckert, Bernhard and Hähnle, Reiner and Rümmer, Philipp and Schmitt, Peter H.},
	editor = {de Boer, Frank S. and Bonsangue, Marcello M. and Graf, Susanne and de Roever, Willem-Paul},
	editorb = {Hutchison, David and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M. and Mattern, Friedemann and Mitchell, John C. and Naor, Moni and Nierstrasz, Oscar and Pandu Rangan, C. and Steffen, Bernhard and Sudan, Madhu and Terzopoulos, Demetri and Tygar, Doug and Vardi, Moshe Y. and Weikum, Gerhard},
	editorbtype = {redactor},
	urldate = {2019-01-31},
	date = {2007},
	langid = {english},
	doi = {10.1007/978-3-540-74792-5_4},
	file = {Ahrendt et al. - 2007 - Verifying Object-Oriented Programs with KeY A Tut.pdf:/home/fordrl/Zotero/storage/DYP7E6HN/Ahrendt et al. - 2007 - Verifying Object-Oriented Programs with KeY A Tut.pdf:application/pdf},
}

@article{platzer_differential_2008,
	title = {Differential Dynamic Logic for Hybrid Systems},
	volume = {41},
	issn = {0168-7433, 1573-0670},
	url = {http://link.springer.com/10.1007/s10817-008-9103-8},
	doi = {10.1007/s10817-008-9103-8},
	pages = {143--189},
	number = {2},
	journaltitle = {Journal of Automated Reasoning},
	author = {Platzer, André},
	urldate = {2019-01-31},
	date = {2008-08},
	langid = {english},
	file = {Submitted Version:/home/fordrl/Zotero/storage/RNX9KZZM/Platzer - 2008 - Differential Dynamic Logic for Hybrid Systems.pdf:application/pdf},
}

@article{platzer_differential_2015,
	title = {Differential Game Logic},
	volume = {17},
	issn = {1529-3785},
	url = {http://doi.acm.org/10.1145/2817824},
	doi = {10.1145/2817824},
	abstract = {Differential game logic ({dGL}) is a logic for specifying and verifying properties of hybrid games, i.e., games that combine discrete, continuous, and adversarial dynamics. Unlike hybrid systems, hybrid games allow choices in the system dynamics to be resolved adversarially by different players with different objectives. The logic {dGL} can be used to study the existence of winning strategies for such hybrid games, i.e., ways of resolving the player’s choices in some way so that he wins by achieving his objective for all choices of the opponent. Hybrid games are determined, i.e., from each state, one player has a winning strategy, yet computing their winning regions may take transfinitely many steps. The logic {dGL}, nevertheless, has a sound and complete axiomatization relative to any expressive logic. Separating axioms are identified that distinguish hybrid games from hybrid systems. Finally, {dGL} is proved to be strictly more expressive than the corresponding logic of hybrid systems by characterizing the expressiveness of both.},
	pages = {1:1--1:51},
	number = {1},
	journaltitle = {{ACM} Trans. Comput. Logic},
	author = {Platzer, André},
	urldate = {2019-01-31},
	date = {2015-11},
	keywords = {axiomatization, expressiveness, Game logic, hybrid games},
	file = {ACM Full Text PDF:/home/fordrl/Zotero/storage/35WLKIMB/Platzer - 2015 - Differential Game Logic.pdf:application/pdf},
}

@inbook{platzer_differential_2018,
	location = {Cham},
	title = {Differential Equations \& Differential Invariants},
	isbn = {978-3-319-63587-3 978-3-319-63588-0},
	url = {http://link.springer.com/10.1007/978-3-319-63588-0_10},
	pages = {287--322},
	booktitle = {Logical Foundations of Cyber-Physical Systems},
	publisher = {Springer International Publishing},
	author = {Platzer, André},
	bookauthor = {Platzer, André},
	urldate = {2019-01-31},
	date = {2018},
	langid = {english},
	doi = {10.1007/978-3-319-63588-0_10},
	file = {Platzer - 2018 - Differential Equations & Differential Invariants.pdf:/home/fordrl/Zotero/storage/PS8YT9GP/Platzer - 2018 - Differential Equations & Differential Invariants.pdf:application/pdf},
}

@inproceedings{crary_modules_2017,
	location = {New York, {NY}, {USA}},
	title = {Modules, Abstraction, and Parametric Polymorphism},
	isbn = {978-1-4503-4660-3},
	url = {http://doi.acm.org/10.1145/3009837.3009892},
	doi = {10.1145/3009837.3009892},
	series = {{POPL} 2017},
	abstract = {Reynolds's Abstraction theorem forms the mathematical foundation for data abstraction. His setting was the polymorphic lambda calculus. Today, many modern languages, such as the {ML} family, employ rich module systems designed to give more expressive support for data abstraction than the polymorphic lambda calculus, but analogues of the Abstraction theorem for such module systems have lagged far behind.   We give an account of the Abstraction theorem for a modern module calculus supporting generative and applicative functors, higher-order functors, sealing, and translucent signatures. The main issues to be overcome are: (1) the fact that modules combine both types and terms, so they must be treated as both simultaneously, (2) the effect discipline that models the distinction between transparent and opaque modules, and (3) a very rich language of type constructors supporting singleton kinds. We define logical equivalence for modules and show that it coincides with contextual equivalence. This substantiates the folk theorem that modules are good for data abstraction. All our proofs are formalized in Coq.},
	pages = {100--113},
	booktitle = {Proceedings of the 44th {ACM} {SIGPLAN} Symposium on Principles of Programming Languages},
	publisher = {{ACM}},
	author = {Crary, Karl},
	urldate = {2019-01-31},
	date = {2017},
	note = {crary/crary-mapp.pdf},
	keywords = {parametricity, Abstraction, logical relations, modules},
	file = {ACM Full Text PDF:/home/fordrl/Zotero/storage/NL7K5PQH/Crary - 2017 - Modules, Abstraction, and Parametric Polymorphism.pdf:application/pdf},
}

@book{bertot_interactive_2004,
	location = {Berlin ; New York},
	title = {Interactive theorem proving and program development: Coq'Art: the calculus of inductive constructions},
	isbn = {978-3-540-20854-9},
	url = {http://www.labri.fr/perso/casteran/CoqArt/index.html},
	series = {Texts in theoretical computer science},
	shorttitle = {Interactive theorem proving and program development},
	pagetotal = {469},
	publisher = {Springer},
	author = {Bertot, Yves and Castéran, P.},
	date = {2004},
	note = {{OCLC}: ocm55514299},
	keywords = {Automatic theorem proving, Computer programming},
}

@incollection{chaudhuri_trigger_2016,
	location = {Cham},
	title = {Trigger Selection Strategies to Stabilize Program Verifiers},
	volume = {9779},
	isbn = {978-3-319-41527-7 978-3-319-41528-4},
	url = {http://link.springer.com/10.1007/978-3-319-41528-4_20},
	pages = {361--381},
	booktitle = {Computer Aided Verification},
	publisher = {Springer International Publishing},
	author = {Leino, K. R. M. and Pit-Claudel, Clément},
	editor = {Chaudhuri, Swarat and Farzan, Azadeh},
	urldate = {2019-01-31},
	date = {2016},
	doi = {10.1007/978-3-319-41528-4_20},
	file = {Leino and Pit-Claudel - 2016 - Trigger Selection Strategies to Stabilize Program .pdf:/home/fordrl/Zotero/storage/455BEULC/Leino and Pit-Claudel - 2016 - Trigger Selection Strategies to Stabilize Program .pdf:application/pdf},
}

@incollection{urban_roscoq:_2015,
	location = {Cham},
	title = {{ROSCoq}: Robots Powered by Constructive Reals},
	volume = {9236},
	isbn = {978-3-319-22101-4 978-3-319-22102-1},
	url = {http://link.springer.com/10.1007/978-3-319-22102-1_3},
	shorttitle = {{ROSCoq}},
	pages = {34--50},
	booktitle = {Interactive Theorem Proving},
	publisher = {Springer International Publishing},
	author = {Anand, Abhishek and Knepper, Ross},
	editor = {Urban, Christian and Zhang, Xingyuan},
	urldate = {2019-02-08},
	date = {2015},
	doi = {10.1007/978-3-319-22102-1_3},
	file = {Anand and Knepper - 2015 - ROSCoq Robots Powered by Constructive Reals.pdf:/home/fordrl/Zotero/storage/NZKLDCG7/Anand and Knepper - 2015 - ROSCoq Robots Powered by Constructive Reals.pdf:application/pdf},
}

@online{noauthor_lean_nodate,
	title = {Lean Forward: Usable Computer-Checked Proofs and Computations},
	url = {https://lean-forward.github.io/},
	urldate = {2019-02-08},
	file = {Lean Forward:/home/fordrl/Zotero/storage/7M6VIYMY/lean-forward.github.io.html:text/html},
}

@inproceedings{ye_verified_2019,
	location = {New York, {NY}, {USA}},
	title = {A Verified Protocol Buffer Compiler},
	isbn = {978-1-4503-6222-1},
	url = {http://doi.acm.org/10.1145/3293880.3294105},
	doi = {10.1145/3293880.3294105},
	series = {{CPP} 2019},
	pages = {222--233},
	booktitle = {Proceedings of the 8th {ACM} {SIGPLAN} International Conference on Certified Programs and Proofs},
	publisher = {{ACM}},
	author = {Ye, Qianchuan and Delaware, Benjamin},
	date = {2019},
	note = {https://www.cs.purdue.edu/homes/bendy/Narcissus/{VerifiedProtoBuff}.html},
	keywords = {Coq, Program verification, Serialization},
	file = {Ye and Delaware - 2019 - A Verified Protocol Buffer Compiler.pdf:/home/fordrl/Zotero/storage/RSBG9JMH/Ye and Delaware - 2019 - A Verified Protocol Buffer Compiler.pdf:application/pdf},
}

@report{gonthier_small_2015,
	title = {A Small Scale Reflection Extension for the Coq system},
	url = {https://hal.inria.fr/inria-00258384/document},
	abstract = {This is the user manual of Ssreflect, a set of extensions to the proof scripting language of the Coq proof assistant. While these extensions were developed to support a particular proof methodology - small-scale reflection - most of them actually are of a quite general nature, improving the functionality of Coq in basic areas such as script layout and structuring, proof context management, and rewriting. Consequently, and in spite of the title of this document, most of the extensions described here should be of interest for all Coq users, whether they embrace small-scale reflection or not.},
	institution = {Inria Saclay Ile de France},
	type = {report},
	author = {Gonthier, Georges and Mahboubi, Assia and Tassi, Enrico},
	urldate = {2019-02-05},
	date = {2015},
	langid = {english},
	file = {Snapshot:/home/fordrl/Zotero/storage/WAP8HJ4N/inria-00258384v16.html:text/html;Full Text PDF:/home/fordrl/Zotero/storage/KDEK8FJA/Gonthier et al. - 2015 - A Small Scale Reflection Extension for the Coq sys.pdf:application/pdf},
}

@article{sozeau_subset_nodate,
	title = {Subset coercions in Coq},
	abstract = {Abstract. We propose a new language for writing programs with de-pendent types on top of the Coq proof assistant. This language permits to establish a phase distinction between writing and proving algorithms in the Coq environment. Concretely, this means allowing to write al-gorithms as easily as in a practical functional programming language whilst giving them as rich a specification as desired and proving that the code meets the specification using the whole Coq proof apparatus. This is achieved by extending conversion to an equivalence which re-lates types and subsets based on them, a technique originating from the “Predicate subtyping ” feature of {PVS} and following mathematical con-vention. The typing judgements can be translated to the Calculus of (Co-)Inductive Constructions (Cic) by means of an interpretation which inserts coercions at the appropriate places. These coercions can con-tain existential variables representing the propositional parts of the final term, corresponding to proof obligations (or {PVS} type-checking condi-tions). A prototype implementation of this process is integrated with the Coq environment. 1},
	pages = {237--252},
	journaltitle = {Springer-Verlag {LNCS}},
	author = {Sozeau, Matthieu},
	file = {Citeseer - Full Text PDF:/home/fordrl/Zotero/storage/XLS49AVP/Sozeau - Subset coercions in Coq.pdf:application/pdf;Citeseer - Snapshot:/home/fordrl/Zotero/storage/MNYEZ764/summary.html:text/html},
}

@incollection{mohamed_first-class_2008,
	location = {Berlin, Heidelberg},
	title = {First-Class Type Classes - {TPHOLs} Talk},
	volume = {5170},
	isbn = {978-3-540-71065-3 978-3-540-71067-7},
	url = {http://link.springer.com/10.1007/978-3-540-71067-7_23},
	pages = {278--293},
	booktitle = {Theorem Proving in Higher Order Logics},
	publisher = {Springer Berlin Heidelberg},
	author = {Sozeau, Matthieu and Oury, Nicolas},
	editor = {Mohamed, Otmane Ait and Muñoz, César and Tahar, Sofiène},
	urldate = {2019-02-01},
	date = {2008},
	langid = {english},
	doi = {10.1007/978-3-540-71067-7_23},
	file = {Sozeau and Oury - 2008 - First-Class Type Classes.pdf:/home/fordrl/Zotero/storage/ZNXCN3GH/Sozeau and Oury - 2008 - First-Class Type Classes.pdf:application/pdf},
}

@book{sozeau_first-class_2008,
	title = {First-class type classes},
	abstract = {Abstract. Type Classes have met a large success in Haskell and Isabelle, as a solution for sharing notations by overloading and for specifying with abstract structures by quantification on contexts. However, both systems are limited by second-class implementations of these constructs, and these limitations are only overcomed by ad-hoc extensions to the respective systems. We propose an embedding of type classes into a dependent type theory that is first-class and supports some of the most popular extensions right away. The implementation is correspondingly cheap, general and integrates well inside the system, as we have experimented in Coq. We show how it can be used to help structured programming and proving by way of examples. 1},
	author = {Sozeau, Matthieu and Oury, Nicolas},
	date = {2008},
	file = {Citeseer - Full Text PDF:/home/fordrl/Zotero/storage/378JZIWP/Sozeau and Oury - 2008 - First-class type classes.pdf:application/pdf;Citeseer - Snapshot:/home/fordrl/Zotero/storage/UEWAJUHF/summary.html:text/html},
}

@online{calcagno_moving_nodate,
	title = {Moving Fast with Software Verification},
	url = {https://research.fb.com/publications/moving-fast-with-software-verification},
	abstract = {For organisations like Facebook, high quality software is important. However, the pace of change and increasing complexity of modern code makes it difficult to produce error free software. Available tools are often lacking in helping programmers develop more reliable and secure applications.},
	titleaddon = {Facebook Research},
	author = {Calcagno, Cristiano and Distefano, Dino and Dubreil, Jeremy and O'Hearn, Peter},
	urldate = {2019-02-01},
	langid = {american},
	file = {Moving Fast with Software Verification.pdf:/home/fordrl/Zotero/storage/5FPGIE6K/Moving Fast with Software Verification.pdf:application/pdf;Snapshot:/home/fordrl/Zotero/storage/FFZ2PSBG/moving-fast-with-software-verification.html:text/html},
}

@article{shrobe_trust-management_2009,
	title = {Trust-Management, Intrusion-Tolerance, Accountability, and Reconstitution Architecture ({TIARA})},
	url = {https://apps.dtic.mil/dtic/tr/fulltext/u2/a511350.pdf},
	abstract = {This report describes the Trust-management, Intrusion-tolerance, Accountability, and Reconstitution Architecture ({TIARA}) system,
a broad design effort including novel computer architecture, operating system and application middleware. {TIARA} illustrates that a
highly secure computer system can be designed without sacrificing performance. {TIARA} involves three major sub-efforts: A
hardware security tagged architecture ({STA}) that tags each word of the computer’s memory with metadata such as the data type and
compartment of the data. The {STA} hardware enforces access rules controlling which principals are allowed to perform which
operations on which data. This allows the construction of a novel Zero-kernel Operating System ({ZKOS}) that has no single all
privileged kernel and that provides strong guarantees against penetration. Finally {TIARA} provides a level of application middleware
that enforces architectural level constraints and maintains the provenance of application data. All common exploits are preventable
by the {TIARA} architecture and this incurs only a minor increase in chip area.},
	pages = {133},
	issue = {{AFRL}-{RI}-{RS}-{TR}-2009-271},
	author = {Shrobe, Howard and {DeHon}, Andre and Knight, Thomas},
	date = {2009-12},
	langid = {english},
	file = {Trust-Management, Intrusion-Tolerance, Accountabil.pdf:/home/fordrl/Zotero/storage/QA4ZCYDJ/Trust-Management, Intrusion-Tolerance, Accountabil.pdf:application/pdf},
}

@online{minsky_real_nodate,
	title = {Real World {OCaml}},
	url = {http://dev.realworldocaml.org/},
	author = {Minsky, Yaron and Madhavapeddy, Anil and Hickey, Jason},
	urldate = {2019-02-01},
	file = {Real World OCaml:/home/fordrl/Zotero/storage/H2TNKC6U/dev.realworldocaml.org.html:text/html},
}

@online{leroy_ocaml_nodate,
	title = {{OCaml} Home Page},
	url = {https://ocaml.org/},
	author = {Leroy, Xavier},
	urldate = {2019-02-01},
	file = {OCaml – OCaml:/home/fordrl/Zotero/storage/GH352N3D/ocaml.org.html:text/html},
}

@software{jacobs_verifast/verifast:_2019,
	title = {verifast/verifast: Research prototype tool for modular formal verification of C and Java programs},
	rights = {View license},
	url = {https://github.com/verifast/verifast},
	shorttitle = {Research prototype tool for modular formal verification of C and Java programs},
	publisher = {verifast},
	author = {Jacobs, Bart},
	urldate = {2019-02-01},
	date = {2019-01-25},
	note = {original-date: 2013-11-19T08:57:02Z},
}

@online{pottier_menhir_nodate,
	title = {Menhir Reference Manual (version 20181113)},
	url = {http://gallium.inria.fr/~fpottier/menhir/manual.html},
	author = {Pottier, Francois and {REgis}-Gianas, Yan},
	urldate = {2019-02-01},
	file = {Menhir Reference Manual (version 20181113).pdf:/home/fordrl/Zotero/storage/P7ZHFCWM/Menhir Reference Manual (version 20181113).pdf:application/pdf;Menhir Reference Manual (version 20181113):/home/fordrl/Zotero/storage/P8JV42LL/manual.html:text/html},
}

@online{patterson_compositional_nodate,
	title = {On Compositional Compiler Correctness and Fully Abstract Compilation - {POPL} 2018},
	url = {https://popl18.sigplan.org/event/prisc-2018-on-compositional-compiler-correctness-and-fully-abstract-compilation},
	author = {Patterson, Daniel and Ahmed, Amal},
	urldate = {2019-02-01},
	file = {On Compositional Compiler Correctness and Fully Abstract Compilation - POPL 2018:/home/fordrl/Zotero/storage/3WP6IYAC/prisc-2018-on-compositional-compiler-correctness-and-fully-abstract-compilation.html:text/html},
}

@online{wikibook_latex_nodate,
	title = {{LaTeX} - Wikibooks, open books for an open world},
	url = {https://en.wikibooks.org/wiki/LaTeX},
	author = {wikibook},
	urldate = {2019-02-01},
	file = {LaTeX - Wikibooks, open books for an open world.pdf:/home/fordrl/Zotero/storage/6K57KTSZ/LaTeX - Wikibooks, open books for an open world.pdf:application/pdf;LaTeX - Wikibooks, open books for an open world:/home/fordrl/Zotero/storage/6ML74WS9/LaTeX.html:text/html},
}

@online{lamport_specifying_nodate,
	title = {Specifying Systems},
	url = {https://lamport.azurewebsites.net/tla/book.html},
	author = {Lamport, Leslie},
	urldate = {2019-02-01},
	file = {Specifying Systems.pdf:/home/fordrl/Zotero/storage/2XZL6LR2/Specifying Systems.pdf:application/pdf;Specifying Systems:/home/fordrl/Zotero/storage/KYBHG99K/book.html:text/html},
}

@online{kubota_foundations_nodate,
	title = {Foundations of Mathematics – Owl of Minerva Press},
	url = {http://owlofminerva.net/foundations-of-mathematics/},
	author = {Kubota, Ken},
	urldate = {2019-02-01},
	langid = {american},
	file = {Snapshot:/home/fordrl/Zotero/storage/TBEEJ37H/foundations-of-mathematics.html:text/html},
}

@online{kaiser_destruct_nodate,
	title = {A “destruct” Tactic for Mtac2 - {POPL} 2018},
	url = {https://popl18.sigplan.org/event/coqpl-2018-a-destruct-tactic-for-mtac2},
	author = {Kaiser, Jan-Oliver and Ziliani, Beta},
	urldate = {2019-02-01},
	file = {A “destruct” Tactic for Mtac2 - POPL 2018.pdf:/home/fordrl/Zotero/storage/LQW2W8LV/A “destruct” Tactic for Mtac2 - POPL 2018.pdf:application/pdf;A “destruct” Tactic for Mtac2 - POPL 2018:/home/fordrl/Zotero/storage/P2PWXNIY/coqpl-2018-a-destruct-tactic-for-mtac2.html:text/html},
}

@online{birkedal_iris_nodate,
	title = {Iris Tutorial},
	url = {https://iris-project.org/tutorial-material.html},
	author = {Birkedal, Lars and Bizjak, Aleš},
	urldate = {2019-02-01},
	file = {Iris Tutorial:/home/fordrl/Zotero/storage/WF7L6JWA/tutorial-material.html:text/html},
}

@online{jung_iris_nodate,
	title = {Iris Project},
	url = {https://iris-project.org/},
	author = {Jung, Ralf},
	urldate = {2019-02-01},
	file = {Iris Project:/home/fordrl/Zotero/storage/2R8EYKZ5/iris-project.org.html:text/html},
}

@article{voevodsky_homotopy_nodate,
	title = {Homotopy Type Theory: Univalent Foundations of Mathematics},
	pages = {490},
	author = {Voevodsky, Vladimir},
	langid = {english},
	file = {Homotopy Type Theory Univalent Foundations of Mat.pdf:/home/fordrl/Zotero/storage/933KJZF5/Homotopy Type Theory Univalent Foundations of Mat.pdf:application/pdf},
}

@online{swamy_project_nodate,
	title = {Project Everest - Verified Secure Implementations of the {HTTPS} Ecosystem},
	url = {https://www.microsoft.com/en-us/research/project/project-everest-verified-secure-implementations-https-ecosystem/},
	abstract = {This project proposes to deﬁnitively solve the problem of a brittle {HTTPS} ecosystem by constructing a more secure, high performance, standards-compliant, veriﬁed implementation of the full {HTTPS} ecosystem. Unlike other veriﬁed software projects, our expedition aims to deploy Everest within existing software as a drop-in replacement in mainstream web browsers, servers, and other popular tools.},
	titleaddon = {Microsoft Research},
	author = {Swamy, Nikhil},
	urldate = {2019-02-01},
	langid = {american},
	file = {Snapshot:/home/fordrl/Zotero/storage/PZSK85HV/project-everest-verified-secure-implementations-https-ecosystem.html:text/html},
}

@software{syme_fsharp_2019,
	title = {The Fsharp Compiler, Core Library \& Tools (F\# Software Foundation Repository): fsharp/fsharp},
	rights = {{MIT}},
	url = {https://github.com/fsharp/fsharp},
	shorttitle = {The F\# Compiler, Core Library \& Tools (F\# Software Foundation Repository)},
	publisher = {F\# Software Foundation Repositories},
	author = {Syme, Don},
	urldate = {2019-02-01},
	date = {2019-01-30},
	note = {original-date: 2010-12-13T00:19:52Z},
}

@software{syme_fsharp_2019-1,
	title = {Fsharp design: {RFCs} and docs related to the F\# language design process,},
	url = {https://github.com/fsharp/fslang-design},
	shorttitle = {{RFCs} and docs related to the F\# language design process, see https},
	publisher = {F\# Software Foundation Repositories},
	author = {Syme, Don},
	urldate = {2019-02-01},
	date = {2019-01-29},
	note = {original-date: 2014-06-25T13:07:35Z},
}

@online{melquiond_why3_nodate,
	title = {Why3},
	url = {http://why3.lri.fr/},
	author = {Melquiond, Guillaume},
	urldate = {2019-02-01},
	file = {Why3:/home/fordrl/Zotero/storage/RE6KJZXJ/why3.lri.fr.html:text/html},
}

@online{jeannet_apron_nodate,
	title = {{APRON} numerical abstract domain library},
	url = {http://apron.cri.ensmp.fr/library/},
	author = {Jeannet, Bertrand and Miné, Antoine},
	urldate = {2019-02-01},
	file = {APRON numerical abstract domain library.pdf:/home/fordrl/Zotero/storage/EN24RJTG/APRON numerical abstract domain library.pdf:application/pdf;APRON numerical abstract domain library:/home/fordrl/Zotero/storage/KPYS6U8G/library.html:text/html},
}

@online{cea_frama-c_nodate,
	title = {Frama-C},
	url = {https://frama-c.com/},
	author = {cea},
	urldate = {2019-02-01},
	file = {Frama-C:/home/fordrl/Zotero/storage/8D695LDW/frama-c.com.html:text/html},
}

@software{sozeau_metacoq_2019,
	title = {{MetaCoq} - Metaprogramming in Coq (Was template-coq)},
	rights = {{MIT}},
	url = {https://github.com/MetaCoq/metacoq},
	publisher = {{MetaCoq}},
	author = {Sozeau, Matthieu},
	urldate = {2019-02-01},
	date = {2019-01-22},
	note = {original-date: 2017-10-19T11:10:54Z},
}

@online{anand_towards_nodate,
	title = {Towards Certified Meta-Programming with Typed Template-Coq {\textbar} {SpringerLink}},
	url = {https://link.springer.com/chapter/10.1007%2F978-3-319-94821-8_2},
	abstract = {Template-Coq (https://template-coq.github.io/template-coq) is a plugin for Coq, originally implemented by Malecha [18], which provides a reifier for Coq terms and global declarations, as represented in the Coq kernel, as well as a denotation command. Initially, it was developed for the purpose of writing functions on Coq’s {AST} in Gallina. Recently, it was used in the {CertiCoq} certified compiler project [4], as its front-end language, to derive parametricity properties [3], and to extract Coq terms to a {CBV}   𝜆 -calculus [13]. However, the syntax lacked semantics, be it typing semantics or operational semantics, which should reflect, as formal specifications in Coq, the semantics of Coq’s type theory itself. The tool was also rather bare bones, providing only rudimentary quoting and unquoting commands. We generalize it to handle the entire Calculus of Inductive Constructions ({CIC}), as implemented by Coq, including the kernel’s declaration structures for definitions and inductives, and implement a monad for general manipulation of Coq’s logical environment. We demonstrate how this setup allows Coq users to define many kinds of general purpose plugins, whose correctness can be readily proved in the system itself, and that can be run efficiently after extraction. We give a few examples of implemented plugins, including a parametricity translation. We also advocate the use of Template-Coq as a foundation for higher-level tools.},
	author = {Anand, Abhishek and Boulier, Simon and Cohen, Cyril and Sozeau, Matthieu and Tabareau, Nicolas},
	urldate = {2019-02-01},
	file = {Towards Certified Meta-Programming with Typed T em.pdf:/home/fordrl/Zotero/storage/2SRA4KVS/Towards Certified Meta-Programming with Typed T em.pdf:application/pdf;Towards Certified Meta-Programming with Typed T emplate-C oq | SpringerLink:/home/fordrl/Zotero/storage/8VTIEBSI/10.html:text/html},
}

@software{appel_deepspecdb_2019,
	title = {{DeepSpecDB} - github},
	rights = {View license},
	url = {https://github.com/PrincetonUniversity/DeepSpecDB},
	publisher = {{PrincetonUniversity}},
	author = {Appel, Andrew W.},
	urldate = {2019-02-01},
	date = {2019-01-31},
	note = {original-date: 2017-11-30T14:24:30Z},
}

@online{adewale_implementing_nodate,
	title = {Implementing a high-performance key-value store using a trie of B+-Trees with cursors {\textbar} Computer Science Department at Princeton University},
	url = {https://www.cs.princeton.edu/research/techreps/TR-004-18},
	abstract = {Abstract
In this paper, we discuss the implementation of a serial main-memory key-value store based on Masstree[6]. Similar to Masstree, the key-value store is implemented as a trie-like tree of B+-Trees, where each B+-Tree is responsible for a xed-length slice of a variable-length key. However, one of the major dierences between our key-value store and Masstree is that our B+-tree implementation (a component of the key-value store) takes linear time to insert a set of sorted records. This is compared to a traditional B+-tree implementation that would take linearithmic time. Moreover, partially sorting a sequence of operation leads to substantial performance gains. This is made possible using a data structure for navigating B+-trees called a B+-tree cursor. As our next operation is amortized constant time, our B+-tree does not need to maintain cross links between leaf nodes. We also briefy show that this same data structure can be extended to the trie of B+-Trees to ensure amortized linear time for bulk insertion of key-value pairs in the key-value store. We were inspired with this idea of B+-Tree cursors from the {SQLite} [5] B-tree source code.},
	author = {Adewale, Oluwatosin},
	urldate = {2019-02-01},
	file = {Implementing a high-performance key-value store us.pdf:/home/fordrl/Zotero/storage/HAARNTAN/Implementing a high-performance key-value store us.pdf:application/pdf;Implementing a high-performance key-value store using a trie of B+-Trees with cursors | Computer Science Department at Princeton University:/home/fordrl/Zotero/storage/ZNDWIDJ3/TR-004-18.html:text/html},
}

@online{appel_certicoq:_nodate,
	title = {{CertiCoq}: A verified compiler for Coq - {POPL} 2017},
	url = {https://popl17.sigplan.org/event/main-certicoq-a-verified-compiler-for-coq},
	author = {Appel, Andrew W.},
	urldate = {2019-02-01},
	file = {CertiCoq A verified compiler for Coq - POPL 2017.pdf:/home/fordrl/Zotero/storage/FPWSH4GR/CertiCoq A verified compiler for Coq - POPL 2017.pdf:application/pdf;CertiCoq\: A verified compiler for Coq - POPL 2017:/home/fordrl/Zotero/storage/E3YEVA9B/main-certicoq-a-verified-compiler-for-coq.html:text/html},
}

@article{sozeau_typed_nodate,
	title = {Typed Template Coq - Slides},
	pages = {11},
	author = {Sozeau, Matthieu},
	langid = {english},
	file = {Typed Template Coq.pdf:/home/fordrl/Zotero/storage/4PGZZ48U/Typed Template Coq.pdf:application/pdf},
}

@online{sozeau_typed_nodate-1,
	title = {Typed Template Coq - {POPL} 2018},
	url = {https://popl18.sigplan.org/event/coqpl-2018-typed-template-coq},
	author = {Sozeau, Matthieu},
	urldate = {2019-02-01},
	file = {Typed Template Coq - POPL 2018:/home/fordrl/Zotero/storage/YNUW6KVH/coqpl-2018-typed-template-coq.html:text/html},
}

@online{acm_msc2010_nodate,
	title = {{MSC}2010 database},
	url = {https://mathscinet.ams.org/msc/msc2010.html},
	author = {acm},
	urldate = {2019-02-01},
	file = {MSC2010 database:/home/fordrl/Zotero/storage/D2RWK6JM/msc2010.html:text/html},
}

@online{acm_acm_nodate,
	title = {{ACM} Classification Codes},
	url = {https://cran.r-project.org/web/classifications/ACM.html},
	author = {acm},
	urldate = {2019-02-01},
	file = {ACM Classification Codes:/home/fordrl/Zotero/storage/Q64UNUSQ/ACM.html:text/html},
}

@online{czajka_coqhammer:_nodate,
	title = {{CoqHammer}: Strong Automation for Program Verification - {CoqPL} 2018},
	url = {https://popl18.sigplan.org/event/coqpl-2018-coqhammer-strong-automation-for-program-verification},
	abstract = {We present {CoqHammer}: the first full hammer system for
the Coq proof assistant. The system translates Coq logic
to untyped first-order logic and uses external automated
theorem provers ({ATPs}) to prove the translations of user
given conjectures. Based on the output of the {ATPs}, the
conjecture is then re-proved in the logic of Coq using an
eauto-type proof search algorithm. Together with machinelearning
based selection of relevant premises this constitutes
a full hammer system.
The performance of the overall procedure has been evaluated
in a bootstrapping scenario emulating the development
of the Coq standard library. Over 40\% of the theorems in
the Coq standard library can be proved in a push-button
mode in about 40 seconds of real time on a 8-{CPU} system.
This offers a huge saving of human work in programming
language formalizations.},
	author = {Czajka, Lukasz and Kaliszyk, Cezary},
	urldate = {2019-01-31},
	file = {Czajka-Kaliszyk-CoqPL18-Slides.pdf:/home/fordrl/Zotero/storage/9XNB7DCK/Czajka-Kaliszyk-CoqPL18-Slides.pdf:application/pdf;CzajkaKaliszyk-CoqPL18-coqhammer.pdf:/home/fordrl/Zotero/storage/E9SCXEBU/CzajkaKaliszyk-CoqPL18-coqhammer.pdf:application/pdf;CoqHammer\: Strong Automation for Program Verification - POPL 2018:/home/fordrl/Zotero/storage/QP8A5J8F/coqpl-2018-coqhammer-strong-automation-for-program-verification.html:text/html},
}

@online{ahrendt_deductive_nodate,
	title = {Deductive Software Verification – The {KeY} {BookFrom} Theory to Practice – The {KeY} Project},
	url = {https://www.key-project.org/thebook2/},
	author = {Ahrendt, Wolfgang},
	urldate = {2019-01-31},
	langid = {american},
	note = {cyber-physical/{KeY} directory has pdfs for the chapters.},
	file = {Snapshot:/home/fordrl/Zotero/storage/S6JS29Q6/thebook2.html:text/html},
}

@online{platzer_keymaera_nodate,
	title = {{KeYmaera} X: Documentation},
	url = {http://www.ls.cs.cmu.edu/KeYmaeraX/documentation.html},
	author = {Platzer, André},
	urldate = {2019-01-31},
	file = {KeYmaera X\: Documentation:/home/fordrl/Zotero/storage/YGNHU67P/documentation.html:text/html},
}

@online{absint_compcert_nodate,
	title = {{CompCert} - Publications},
	url = {http://compcert.inria.fr/publi.html},
	author = {Absint},
	urldate = {2019-01-31},
	file = {CompCert - Publications:/home/fordrl/Zotero/storage/98Y2B9GJ/publi.html:text/html},
}

@incollection{hermanns_local_2006,
	location = {Berlin, Heidelberg},
	title = {A Local Shape Analysis Based on Separation Logic},
	volume = {3920},
	isbn = {978-3-540-33056-1 978-3-540-33057-8},
	url = {http://link.springer.com/10.1007/11691372_19},
	abstract = {We describe a program analysis for linked list programs where the abstract domain uses formulae from separation logic.},
	pages = {287--302},
	booktitle = {Tools and Algorithms for the Construction and Analysis of Systems},
	publisher = {Springer Berlin Heidelberg},
	author = {Distefano, Dino and O’Hearn, Peter W. and Yang, Hongseok},
	editor = {Hermanns, Holger and Palsberg, Jens},
	urldate = {2019-02-01},
	date = {2006},
	langid = {english},
	doi = {10.1007/11691372_19},
	file = {Distefano et al. - 2006 - A Local Shape Analysis Based on Separation Logic.pdf:/home/fordrl/Zotero/storage/SYDSVSRA/Distefano et al. - 2006 - A Local Shape Analysis Based on Separation Logic.pdf:application/pdf},
}

@incollection{ohearn_local_2001,
	title = {Local Reasoning about Programs that Alter Data Structures},
	isbn = {978-3-540-44802-0},
	series = {Lecture Notes in Computer Science},
	abstract = {We describe an extension of Hoare’s logic for reasoning about programs that alter data structures. We consider a low-level storage model based on a heap with associated lookup, update, allocation and deallocation operations, and unrestricted address arithmetic. The assertion language is based on a possible worlds model of the logic of bunched implications, and includes spatial conjunction and implication connectives alongside those of classical logic. Heap operations are axiomatized using what we call the “small axioms”, each of which mentions only those cells accessed by a particular command. Through these and a number of examples we show that the formalism supports local reasoning: A specification and proof can concentrate on only those cells in memory that a program accesses.This paper builds on earlier work by Burstall, Reynolds, Ishtiaq and O’Hearn on reasoning about data structures.},
	pages = {1--19},
	booktitle = {Computer Science Logic},
	publisher = {Springer Berlin Heidelberg},
	author = {O’Hearn, Peter and Reynolds, John and Yang, Hongseok},
	editor = {Fribourg, Laurent},
	date = {2001},
	langid = {english},
	keywords = {Hoare Logic, Frame Problem, Local Reasoning, Memory Fault, Weak Precondition},
	file = {O’Hearn et al. - 2001 - Local Reasoning about Programs that Alter Data Str.pdf:/home/fordrl/Zotero/storage/EFFA7GBR/O’Hearn et al. - 2001 - Local Reasoning about Programs that Alter Data Str.pdf:application/pdf;O’Hearn et al. - 2001 - Local Reasoning about Programs that Alter Data Str.pdf:/home/fordrl/Zotero/storage/DSQLQ2IN/O’Hearn et al. - 2001 - Local Reasoning about Programs that Alter Data Str.pdf:application/pdf},
}

@inproceedings{berdine_smallfoot:_2006,
	title = {Smallfoot: Modular Automatic Assertion Checking with Separation Logic},
	isbn = {978-3-540-36750-5},
	series = {Lecture Notes in Computer Science},
	shorttitle = {Smallfoot},
	abstract = {Separation logic is a program logic for reasoning about programs that manipulate pointer data structures. We describe Smallfoot, a tool for checking certain lightweight separation logic specifications. The assertions describe the shapes of data structures rather than their detailed contents, and this allows reasoning to be fully automatic. The presentation in the paper is tutorial in style. We illustrate what the tool can do via examples which are oriented toward novel aspects of separation logic, namely: avoidance of frame axioms (which say what a procedure does not change); embracement of “dirty” features such as memory disposal and address arithmetic; information hiding in the presence of pointers; and modular reasoning about concurrent programs.},
	pages = {115--137},
	booktitle = {Formal Methods for Components and Objects},
	publisher = {Springer Berlin Heidelberg},
	author = {Berdine, Josh and Calcagno, Cristiano and O’Hearn, Peter W.},
	editor = {de Boer, Frank S. and Bonsangue, Marcello M. and Graf, Susanne and de Roever, Willem-Paul},
	date = {2006},
	langid = {english},
	keywords = {Symbolic Execution, Separation Logic, Free List, Information Hiding, Tree Predicate},
	file = {Berdine et al. - 2006 - Smallfoot Modular Automatic Assertion Checking wi.pdf:/home/fordrl/Zotero/storage/RU9SZ96Q/Berdine et al. - 2006 - Smallfoot Modular Automatic Assertion Checking wi.pdf:application/pdf},
}

@book{andrew_oracle_2008,
	title = {Oracle Semantics Aquinas Hobor},
	abstract = {We define a Concurrent Separation Logic with first-class locks and threads for the C language, and prove its soundness in Coq with re-spect to a compilable operataional semantics. We define the language Concurrent C minor, an extension of the C minor language of Leroy. C minor was designed as the highest-level intermediate language in the {CompCert} certified {ANSI} C compiler, and we add to it lock, unlock, and fork statements to make Concurrent C minor, giving it a standard Pthreads style of concurrency. We define a Concurrent Separation Logic for Concurrent C minor, which extends the original Concurrent Separation Logic of O’Hearn to handle first-class locks and threads. We then prove the soundness of the logic with respect to the opera-tional semantics of the language. First, we define an erased concurrent operational semantics for Concurrent C minor that is a reasonable ab-},
	author = {Andrew, Advisor},
	date = {2008},
	file = {Citeseer - Full Text PDF:/home/fordrl/Zotero/storage/KI5U9GHB/Andrew - 2008 - Oracle Semantics Aquinas Hobor.pdf:application/pdf;Citeseer - Snapshot:/home/fordrl/Zotero/storage/G77WVBCV/summary.html:text/html},
}

@book{amorim_verified_2013,
	title = {A Verified Information-Flow Architecture (Long version)},
	abstract = {{SAFE} is a clean-slate effort to build a highly secure computer system, including pervasive mechanisms for tracking and limiting information flows. At the lowest level, the {SAFE} hardware supports fine-grained programmable tags, with efficient and flexible propagation and combination of tags as instructions are executed. The operating system virtualizes these generic facilities to present an information-flow abstract machine, on which user programs can label sensitive data with rich confidentiality and integrity policies. We present a formal, machine-checked model of the key information-flow mechanisms of the {SAFE} hardware and software, together with an end-to-end proof of noninterference for this model.},
	author = {Amorim, Arthur Azevedo de and Collins, Nathan and {DeHon}, André and Demange, Delphine and Hritcu, Cătălin and Pichardie, David and Pierce, Benjamin C. and Pollack, Randy and Tolmach, Andrew},
	date = {2013},
	file = {Citeseer - Snapshot:/home/fordrl/Zotero/storage/M7W2QFG9/summary.html:text/html;Citeseer - Full Text PDF:/home/fordrl/Zotero/storage/2YMYHR23/Amorim et al. - 2013 - A Verified Information-Flow Architecture (Long ver.pdf:application/pdf},
}

@inproceedings{azevedo_de_amorim_verified_2014,
	location = {New York, {NY}, {USA}},
	title = {A Verified Information-flow Architecture},
	isbn = {978-1-4503-2544-8},
	url = {http://doi.acm.org/10.1145/2535838.2535839},
	doi = {10.1145/2535838.2535839},
	series = {{POPL} '14},
	abstract = {{SAFE} is a clean-slate design for a highly secure computer system, with pervasive mechanisms for tracking and limiting information flows. At the lowest level, the {SAFE} hardware supports fine-grained programmable tags, with efficient and flexible propagation and combination of tags as instructions are executed. The operating system virtualizes these generic facilities to present an information-flow abstract machine that allows user programs to label sensitive data with rich confidentiality policies. We present a formal, machine-checked model of the key hardware and software mechanisms used to control information flow in {SAFE} and an end-to-end proof of noninterference for this model.},
	pages = {165--178},
	booktitle = {Proceedings of the 41st {ACM} {SIGPLAN}-{SIGACT} Symposium on Principles of Programming Languages},
	publisher = {{ACM}},
	author = {Azevedo de Amorim, Arthur and Collins, Nathan and {DeHon}, André and Demange, Delphine and Hriţcu, Cătălin and Pichardie, David and Pierce, Benjamin C. and Pollack, Randy and Tolmach, Andrew},
	urldate = {2019-02-01},
	date = {2014},
	keywords = {formal verification, security, clean-slate design, information-flow control, refinement, tagged architecture},
	file = {ACM Full Text PDF:/home/fordrl/Zotero/storage/9CDWT8UT/Azevedo de Amorim et al. - 2014 - A Verified Information-flow Architecture.pdf:application/pdf},
}

@article{krebbers_type_2011,
	title = {Type classes for efficient exact real arithmetic in Coq},
	url = {http://arxiv.org/abs/1106.3448},
	doi = {10.2168/LMCS-9(1:01)2013},
	abstract = {Floating point operations are fast, but require continuous effort on the part of the user in order to ensure that the results are correct. This burden can be shifted away from the user by providing a library of exact analysis in which the computer handles the error estimates. Previously, we [Krebbers/Spitters 2011] provided a fast implementation of the exact real numbers in the Coq proof assistant. Our implementation improved on an earlier implementation by O'Connor by using type classes to describe an abstract specification of the underlying dense set from which the real numbers are built. In particular, we used dyadic rationals built from Coq's machine integers to obtain a 100 times speed up of the basic operations already. This article is a substantially expanded version of [Krebbers/Spitters 2011] in which the implementation is extended in the various ways. First, we implement and verify the sine and cosine function. Secondly, we create an additional implementation of the dense set based on Coq's fast rational numbers. Thirdly, we extend the hierarchy to capture order on undecidable structures, while it was limited to decidable structures before. This hierarchy, based on type classes, allows us to share theory on the naturals, integers, rationals, dyadics, and reals in a convenient way. Finally, we obtain another dramatic speed-up by avoiding evaluation of termination proofs at runtime.},
	journaltitle = {{arXiv}:1106.3448 [cs, math]},
	author = {Krebbers, Robbert and Spitters, Bas},
	urldate = {2019-02-01},
	date = {2011-06-17},
	eprinttype = {arxiv},
	eprint = {1106.3448},
	keywords = {Computer Science - Logic in Computer Science, D.2.4, F.4.1, G.1, Mathematics - Numerical Analysis},
	file = {arXiv.org Snapshot:/home/fordrl/Zotero/storage/489A4YCS/1106.html:text/html;arXiv\:1106.3448 PDF:/home/fordrl/Zotero/storage/2LLH7TZN/Krebbers and Spitters - 2011 - Type classes for efficient exact real arithmetic i.pdf:application/pdf},
}

@inproceedings{holzl_type_2013,
	title = {Type Classes and Filters for Mathematical Analysis in Isabelle/{HOL}},
	isbn = {978-3-642-39634-2},
	series = {Lecture Notes in Computer Science},
	abstract = {The theory of analysis in Isabelle/{HOL} derives from earlier formalizations that were limited to specific concrete types: ℝ, ℂ and ℝ n . Isabelle’s new analysis theory unifies and generalizes these earlier efforts. The improvements are centered on two primary contributions: a generic theory of limits based on filters, and a new hierarchy of type classes that includes various topological, metric, vector, and algebraic spaces. These let us apply many results in multivariate analysis to types which are not Euclidean spaces, such as the extended real numbers, bounded continuous functions, or finite maps.},
	pages = {279--294},
	booktitle = {Interactive Theorem Proving},
	publisher = {Springer Berlin Heidelberg},
	author = {Hölzl, Johannes and Immler, Fabian and Huffman, Brian},
	editor = {Blazy, Sandrine and Paulin-Mohring, Christine and Pichardie, David},
	date = {2013},
	langid = {english},
	keywords = {Topology, Euclidean vector spaces, Filters, Isabelle/{HOL}, Limits, Mathematical analysis, Type classes},
	file = {Hölzl et al. - 2013 - Type Classes and Filters for Mathematical Analysis.pdf:/home/fordrl/Zotero/storage/PAGHJGKC/Hölzl et al. - 2013 - Type Classes and Filters for Mathematical Analysis.pdf:application/pdf},
}

@article{boldo_formalization_2016,
	title = {Formalization of Real Analysis: A Survey of Proof Assistants and Libraries},
	volume = {26},
	url = {https://hal.inria.fr/hal-00806920/document},
	doi = {10.1017/S0960129514000437},
	shorttitle = {Formalization of Real Analysis},
	abstract = {In the recent years, numerous proof systems have improved enough to be used for formally verifying non-trivial mathematical results. They, however, have different purposes and it is not always easy to choose which one is adapted to undertake a formalization effort. In this survey, we focus on properties related to real analysis: real numbers, arithmetic operators, limits, differentiability, integrability, and so on. We have chosen to look into the formalizations provided in standard by the following systems: Coq, {HOL}4, {HOL} Light, Isabelle/{HOL}, Mizar, {ProofPower}-{HOL}, and {PVS}. We have also accounted for large developments that play a similar role or extend standard libraries: {ACL}2(r) for {ACL}2, C-{CoRN}/{MathClasses} for Coq, and the {NASA} {PVS} library. This survey presents how real numbers have been defined in these various provers and how the notions of real analysis described above have been formalized. We also look at the methods of automation these systems provide for real analysis.},
	pages = {1196--1233},
	number = {7},
	journaltitle = {Mathematical Structures in Computer Science},
	author = {Boldo, Sylvie and Lelay, Catherine and Melquiond, Guillaume},
	urldate = {2019-02-01},
	date = {2016-10},
	langid = {english},
	file = {Snapshot:/home/fordrl/Zotero/storage/6E5738FR/hal-00806920v2.html:text/html;Full Text PDF:/home/fordrl/Zotero/storage/LKG9S93Z/Boldo et al. - 2016 - Formalization of Real Analysis A Survey of Proof .pdf:application/pdf},
}

@misc{boldo_coquelicot:_2013,
	title = {Coquelicot: A User-Friendly Library of Real Analysis for Coq},
	url = {https://hal.inria.fr/hal-00860648/document},
	shorttitle = {Coquelicot},
	abstract = {Real analysis is pervasive to many applications, if only because it is a suitable tool for modeling physical or socio-economical systems. As such, its support is warranted in proof assistants, so that the users have a way to formally verify mathematical theorems and correctness of critical systems. The Coq system comes with an axiomatization of standard real numbers and a library of theorems on real analysis. Unfortunately, this standard library is lacking some widely used results. For instance, power series are not developed further than their definition. Moreover, the definitions of integrals and derivatives are based on dependent types, which make them especially cumbersome to use in practice. To palliate these inadequacies, we have designed a user-friendly library: Coquelicot. An easier way of writing formulas and theorem statements is achieved by relying on total functions in place of dependent types for limits, derivatives, integrals, power series, and so on. To help with the proof process, the library comes with a comprehensive set of theorems that cover not only these notions, but also some extensions such as parametric integrals, two-dimensional differentiability, asymptotic behaviors. It also offers some automations for performing differentiability proofs. Moreover, Coquelicot is a conservative extension of Coq's standard library and we provide correspondence theorems between the two libraries. We have exercised the library on several use cases: in an exam at university entry level, for the definitions and properties of Bessel functions, and for the solution of the one-dimensional wave equation.},
	author = {Boldo, Sylvie and Lelay, Catherine and Melquiond, Guillaume},
	urldate = {2019-02-01},
	date = {2013-09-10},
	langid = {english},
	file = {Snapshot:/home/fordrl/Zotero/storage/FSB8NLLY/hal-00860648v1.html:text/html;Full Text PDF:/home/fordrl/Zotero/storage/WYXEI9GV/Boldo et al. - 2013 - Coquelicot A User-Friendly Library of Real Analys.pdf:application/pdf},
}

@article{immler_verified_2018,
	title = {A Verified {ODE} Solver and the Lorenz Attractor},
	volume = {61},
	issn = {1573-0670},
	url = {https://doi.org/10.1007/s10817-017-9448-y},
	doi = {10.1007/s10817-017-9448-y},
	abstract = {A rigorous numerical algorithm, formally verified with Isabelle/{HOL}, is used to certify the computations that Tucker used to prove chaos for the Lorenz attractor. The verification is based on a formalization of a diverse variety of mathematics and algorithms. Formalized mathematics include ordinary differential equations and Poincaré maps. Algorithms include low level approximation schemes based on Runge–Kutta methods and affine arithmetic. On a high level, reachability analysis is guided by static hybridization and adaptive step-size control and splitting. The algorithms are systematically refined towards an implementation that can be executed on Tucker’s original input data.},
	pages = {73--111},
	number = {1},
	journaltitle = {Journal of Automated Reasoning},
	shortjournal = {J Autom Reasoning},
	author = {Immler, Fabian},
	urldate = {2019-02-01},
	date = {2018-06-01},
	langid = {english},
	keywords = {Isabelle/{HOL}, Lorenz attractor, Ordinary differential equation, Poincaré map, Rigorous numerics},
	file = {Springer Full Text PDF:/home/fordrl/Zotero/storage/9487Y7HE/Immler - 2018 - A Verified ODE Solver and the Lorenz Attractor.pdf:application/pdf},
}

@unpublished{boldo_round-off_2018,
	title = {Round-off error and exceptional behavior analysis of explicit Runge-Kutta methods},
	url = {https://hal.archives-ouvertes.fr/hal-01883843},
	abstract = {Numerical integration schemes are mandatory to understand complex behaviors of dynamical systems described by ordinary differential equations. Implementation of these numerical methods involve floating-point computations and propagation of round-off errors. This paper presents a new fine-grained analysis of round-off errors in explicit Runge-Kutta integration methods, taking into account exceptional behaviors, such as underflow and overflow. Linear stability properties play a central role in the proposed approach. For a large class of Runge-Kutta methods applied on linear problems, a tight bound of the round-off errors is provided. A simple test is defined and ensures the absence of underflow and a tighter round-off error bound. The absence of overflow is guaranteed as linear stability properties imply that (computed) solutions are non-increasing.},
	author = {Boldo, Sylvie and Faissole, Florian and Chapoutot, Alexandre},
	urldate = {2019-02-01},
	date = {2018-09},
	keywords = {Linear stability, Numerical integration, Overflow, Round-off error, Runge-Kutta method, Underflow},
	file = {HAL PDF Full Text:/home/fordrl/Zotero/storage/STNM4VEB/Boldo et al. - 2018 - Round-off error and exceptional behavior analysis .pdf:application/pdf},
}

@inproceedings{boldo_round-off_2017,
	location = {London, United Kingdom},
	title = {Round-off Error Analysis of Explicit One-Step Numerical Integration Methods},
	url = {https://hal.archives-ouvertes.fr/hal-01581794},
	doi = {10.1109/ARITH.2017.22},
	abstract = {Ordinary differential equations are ubiquitous in scientific computing. Solving exactly these equations is usually not possible, except for special cases, hence the use of numerical schemes to get a discretized solution. We are interested in such numerical integration methods, for instance Euler's method or the Runge-Kutta methods. As they are implemented using floating-point arithmetic, round-off errors occur. In order to guarantee their accuracy, we aim at providing bounds on the round-off errors of explicit one-step numerical integration methods. Our methodology is to apply a fine-grained analysis to these numerical algorithms. Our originality is that our floating-point analysis takes advantage of the linear stability of the scheme, a mathematical property that vouches the scheme is well-behaved.},
	booktitle = {24th {IEEE} Symposium on Computer Arithmetic},
	author = {Boldo, Sylvie and Faissole, Florian and Chapoutot, Alexandre},
	urldate = {2019-02-01},
	date = {2017-07},
	keywords = {Floating-Point, Numerical Integration, Ordinary Differential Equation, Round-Off Error, Runge-Kutta Methods, Stability},
	file = {HAL PDF Full Text:/home/fordrl/Zotero/storage/T6FAQZYN/Boldo et al. - 2017 - Round-off Error Analysis of Explicit One-Step Nume.pdf:application/pdf},
}

@article{martin-dorel_proving_2016,
	title = {Proving Tight Bounds on Univariate Expressions with Elementary Functions in Coq},
	volume = {57},
	issn = {1573-0670},
	url = {https://doi.org/10.1007/s10817-015-9350-4},
	doi = {10.1007/s10817-015-9350-4},
	abstract = {The verification of floating-point mathematical libraries requires computing numerical bounds on approximation errors. Due to the tightness of these bounds and the peculiar structure of approximation errors, such a verification is out of the reach of generic tools such as computer algebra systems. In fact, the inherent difficulty of computing such bounds often mandates a formal proof of them. In this paper, we present a tactic for the Coq proof assistant that is designed to automatically and formally prove bounds on univariate expressions. It is based on a formalization of floating-point and interval arithmetic, associated with an on-the-fly computation of Taylor expansions. All the computations are performed inside Coq’s logic, in a reflexive setting. This paper also compares our tactic with various existing tools on a large set of examples.},
	pages = {187--217},
	number = {3},
	journaltitle = {Journal of Automated Reasoning},
	shortjournal = {J Autom Reasoning},
	author = {Martin-Dorel, Érik and Melquiond, Guillaume},
	urldate = {2019-02-01},
	date = {2016-10-01},
	langid = {english},
	keywords = {Coq proof assistant, Decision procedure, Floating-point arithmetic, Formal proof, Interval arithmetic, Nonlinear arithmetic},
	file = {Submitted Version:/home/fordrl/Zotero/storage/VKBLSM3J/Martin-Dorel and Melquiond - 2016 - Proving Tight Bounds on Univariate Expressions wit.pdf:application/pdf},
}

@incollection{hutchison_improving_2012,
	location = {Berlin, Heidelberg},
	title = {Improving Real Analysis in Coq: A User-Friendly Approach to Integrals and Derivatives},
	volume = {7679},
	isbn = {978-3-642-35307-9 978-3-642-35308-6},
	url = {http://link.springer.com/10.1007/978-3-642-35308-6_22},
	shorttitle = {Improving Real Analysis in Coq},
	abstract = {Veriﬁcation of numerical analysis programs requires dealing with derivatives and integrals. High conﬁdence in this process can be achieved using a formal proof checker, such as Coq. Its standard library provides an axiomatization of real numbers and various lemmas about real analysis, which may be used for this purpose. Unfortunately, its deﬁnitions of derivative and integral are unpractical as they are partial functions that demand a proof term. This proof term makes the handling of mathematical formulas cumbersome and does not conform to traditional analysis. Other proof assistants usually do not suﬀer from this issue; for instance, they may rely on Hilbert’s epsilon to get total operators. In this paper, we propose a way to deﬁne total operators for derivative and integral without having to extend Coq’s standard axiomatization of real numbers. We proved the compatibility of our deﬁnitions with the standard library’s in order to leverage existing results. We also greatly improved automation for real analysis proofs that use Coq standard deﬁnitions. We exercised our approach on lemmas involving iterated partial derivatives and diﬀerentiation under the integral sign, that were missing from the formal proof of a numerical program solving the wave equation.},
	pages = {289--304},
	booktitle = {Certified Programs and Proofs},
	publisher = {Springer Berlin Heidelberg},
	author = {Boldo, Sylvie and Lelay, Catherine and Melquiond, Guillaume},
	editor = {Hawblitzel, Chris and Miller, Dale},
	editorb = {Hutchison, David and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M. and Mattern, Friedemann and Mitchell, John C. and Naor, Moni and Nierstrasz, Oscar and Pandu Rangan, C. and Steffen, Bernhard and Sudan, Madhu and Terzopoulos, Demetri and Tygar, Doug and Vardi, Moshe Y. and Weikum, Gerhard},
	editorbtype = {redactor},
	urldate = {2019-02-01},
	date = {2012},
	langid = {english},
	doi = {10.1007/978-3-642-35308-6_22},
	file = {Boldo et al. - 2012 - Improving Real Analysis in Coq A User-Friendly Ap.pdf:/home/fordrl/Zotero/storage/4BBRWC9Y/Boldo et al. - 2012 - Improving Real Analysis in Coq A User-Friendly Ap.pdf:application/pdf},
}

@article{van_renesse_paxos_2015,
	title = {Paxos Made Moderately Complex},
	volume = {47},
	issn = {0360-0300},
	url = {http://doi.acm.org/10.1145/2673577},
	doi = {10.1145/2673577},
	abstract = {This article explains the full reconfigurable multidecree Paxos (or multi-Paxos) protocol. Paxos is by no means a simple protocol, even though it is based on relatively simple invariants. We provide pseudocode and explain it guided by invariants. We initially avoid optimizations that complicate comprehension. Next we discuss liveness, list various optimizations that make the protocol practical, and present variants of the protocol.},
	pages = {42:1--42:36},
	number = {3},
	journaltitle = {{ACM} Comput. Surv.},
	author = {Van Renesse, Robbert and Altinbuken, Deniz},
	urldate = {2019-02-01},
	date = {2015-02},
	keywords = {consensus, Replicated state machines, voting},
	file = {ACM Full Text PDF:/home/fordrl/Zotero/storage/WITY9Q45/Van Renesse and Altinbuken - 2015 - Paxos Made Moderately Complex.pdf:application/pdf},
}

@inproceedings{lampson_abcds_2001,
	location = {New York, {NY}, {USA}},
	title = {The {ABCD}'s of Paxos},
	isbn = {978-1-58113-383-7},
	url = {http://doi.acm.org/10.1145/383962.383969},
	doi = {10.1145/383962.383969},
	series = {{PODC} '01},
	abstract = {We explain how consensus is used to implement replicated state machines, the general mechanism for fault-tolerance. We describe an abstract version of Lamport's Paxos algorithm for asynchronous consensus. Then we derive the Byzantine, classic, and disk versions of Paxos from the abstract one, show how they are related to each other, and discuss the safety, liveness, and performance of each one.},
	pages = {13--},
	booktitle = {Proceedings of the Twentieth Annual {ACM} Symposium on Principles of Distributed Computing},
	publisher = {{ACM}},
	author = {Lampson, Butler},
	urldate = {2019-02-01},
	date = {2001},
	file = {ACM Full Text PDF:/home/fordrl/Zotero/storage/RSUUAANU/Lampson - 2001 - The ABCD's of Paxos.pdf:application/pdf},
}

@article{jacobs_verifast_2017,
	title = {The {VeriFast} Program Veriﬁer: A Tutorial},
	pages = {102},
	author = {Jacobs, Bart and Smans, Jan and Piessens, Frank},
	date = {2017-11-28},
	langid = {english},
	file = {Jacobs et al. - The VeriFast Program Veriﬁer A Tutorial.pdf:/home/fordrl/Zotero/storage/EUBUNUXD/Jacobs et al. - The VeriFast Program Veriﬁer A Tutorial.pdf:application/pdf},
}

@report{jacobs_verifast_2008,
	title = {The {VeriFast} program verifier},
	abstract = {This note describes a separation-logic-based approach for the spec-ification and verification of safety properties of pointer-manipulating imperative programs. We describe the approach for the C language. The safety properties to be verified are specified as annotations in the source code, in the form of function preconditions and post-conditions expressed as separation logic assertions. To enable rich specifications, the user may include additional annotations that de-fine inductive datatypes, primitive recursive pure functions over these datatypes, and abstract predicates (i.e. named, parameterized assertions). A restricted form of existential quantification is sup-ported in assertions in the form of pattern matching. Verification is based on forward symbolic execution, where memory is represented as a separate conjunction of points-to as-sertions and abstract predicate assertions, and data values are rep-},
	author = {Jacobs, Bart and Piessens, Frank},
	date = {2008},
	file = {Citeseer - Snapshot:/home/fordrl/Zotero/storage/5AS6HTW6/summary.html:text/html;Citeseer - Full Text PDF:/home/fordrl/Zotero/storage/92SEBWLL/Jacobs and Piessens - 2008 - The VeriFast program verifier.pdf:application/pdf},
}

@article{jacobs_featherweight_2015,
	title = {Featherweight {VeriFast}},
	volume = {11},
	issn = {18605974},
	url = {http://arxiv.org/abs/1507.07697},
	doi = {10.2168/LMCS-11(3:19)2015},
	abstract = {{VeriFast} is a leading research prototype tool for the sound modular verification of safety and correctness properties of single-threaded and multithreaded C and Java programs. It has been used as a vehicle for exploration and validation of novel program verification techniques and for industrial case studies; it has served well at a number of program verification competitions; and it has been used for teaching by multiple teachers independent of the authors. However, until now, while {VeriFast}'s operation has been described informally in a number of publications, and specific verification techniques have been formalized, a clear and precise exposition of how {VeriFast} works has not yet appeared. In this article we present for the first time a formal definition and soundness proof of a core subset of the {VeriFast} program verification approach. The exposition aims to be both accessible and rigorous: the text is based on lecture notes for a graduate course on program verification, and it is backed by an executable machine-readable definition and machine-checked soundness proof in Coq.},
	number = {3},
	journaltitle = {Logical Methods in Computer Science},
	author = {Jacobs, Bart and Vogels, Frédéric and Piessens, Frank},
	urldate = {2019-02-01},
	date = {2015-09-22},
	eprinttype = {arxiv},
	eprint = {1507.07697},
	keywords = {Computer Science - Logic in Computer Science},
	file = {arXiv\:1507.07697 PDF:/home/fordrl/Zotero/storage/6M9VGQ6K/Jacobs et al. - 2015 - Featherweight VeriFast.pdf:application/pdf;arXiv.org Snapshot:/home/fordrl/Zotero/storage/DVD7VF44/1507.html:text/html},
}

@article{costan_secure_2017,
	title = {Secure Processors Part {II}: Intel {SGX} Security Analysis and {MIT} Sanctum Architecture},
	volume = {11},
	issn = {1551-3939, 1551-3947},
	url = {http://www.nowpublishers.com/article/Details/EDA-052},
	doi = {10.1561/1000000052},
	shorttitle = {Secure Processors Part {II}},
	pages = {249--361},
	number = {3},
	journaltitle = {Foundations and Trends® in Electronic Design Automation},
	author = {Costan, Victor and Lebedev, Ilia and Devadas, Srinivas},
	urldate = {2019-02-01},
	date = {2017},
	langid = {english},
	file = {Costan et al. - 2017 - Secure Processors Part II Intel SGX Security Anal.pdf:/home/fordrl/Zotero/storage/64GE2MA5/Costan et al. - 2017 - Secure Processors Part II Intel SGX Security Anal.pdf:application/pdf},
}

@article{costan_secure_2017-1,
	title = {Secure Processors Part I: Background, Taxonomy for Secure Enclaves and Intel {SGX} Architecture},
	volume = {11},
	issn = {1551-3939, 1551-3947},
	url = {http://www.nowpublishers.com/article/Details/EDA-051},
	doi = {10.1561/1000000051},
	shorttitle = {Secure Processors Part I},
	pages = {1--248},
	number = {1},
	journaltitle = {Foundations and Trends® in Electronic Design Automation},
	author = {Costan, Victor and Lebedev, Ilia and Devadas, Srinivas},
	urldate = {2019-02-01},
	date = {2017},
	langid = {english},
	file = {Costan et al. - 2017 - Secure Processors Part I Background, Taxonomy for.pdf:/home/fordrl/Zotero/storage/2ZB798A8/Costan et al. - 2017 - Secure Processors Part I Background, Taxonomy for.pdf:application/pdf},
}

@inproceedings{costan_sanctum:_2016,
	title = {Sanctum: Minimal Hardware Extensions for Strong Software Isolation},
	url = {https://www.usenix.org/conference/usenixsecurity16/technical-sessions/presentation/costan},
	shorttitle = {Sanctum},
	eventtitle = {25th \{{USENIX}\} Security Symposium (\{{USENIX}\} Security 16)},
	pages = {857--874},
	author = {Costan, Victor and Lebedev, Ilia and Devadas, Srinivas},
	urldate = {2019-02-01},
	date = {2016},
	langid = {english},
	file = {Full Text PDF:/home/fordrl/Zotero/storage/XM5L2QXN/Costan et al. - 2016 - Sanctum Minimal Hardware Extensions for Strong So.pdf:application/pdf},
}

@book{gasser_building_1988,
	location = {New York},
	title = {Building a secure computer system},
	isbn = {978-0-442-23022-7},
	pagetotal = {288},
	publisher = {Van Nostrand Reinhold Co},
	author = {Gasser, Morrie},
	date = {1988},
	keywords = {Computer security, System design},
	file = {Gasser - 1988 - Building a secure computer system.pdf:/home/fordrl/Zotero/storage/DRV4KDU6/Gasser - 1988 - Building a secure computer system.pdf:application/pdf},
}

@article{patterson_compositional_nodate-1,
	title = {On Compositional Compiler Correctness and Fully Abstract Compilation},
	url = {https://popl18.sigplan.org/event/prisc-2018-on-compositional-compiler-correctness-and-fully-abstract-compilation},
	pages = {3},
	author = {Patterson, Daniel and Ahmed, Amal},
	langid = {english},
	file = {Patterson and Ahmed - On Compositional Compiler Correctness and Fully Ab.pdf:/home/fordrl/Zotero/storage/4BK4I6T7/Patterson and Ahmed - On Compositional Compiler Correctness and Fully Ab.pdf:application/pdf;Garillot2009_Chapter_PackagingMathematicalStructure.pdf:/home/fordrl/Zotero/storage/XFXC4QGZ/Garillot2009_Chapter_PackagingMathematicalStructure.pdf:application/pdf},
}

@inproceedings{costanzo_end--end_2016,
	location = {New York, {NY}, {USA}},
	title = {End-to-end Verification of Information-flow Security for C and Assembly Programs},
	isbn = {978-1-4503-4261-2},
	url = {http://doi.acm.org/10.1145/2908080.2908100},
	doi = {10.1145/2908080.2908100},
	series = {{PLDI} '16},
	abstract = {Protecting the confidentiality of information manipulated by a computing system is one of the most important challenges facing today's cybersecurity community. A promising step toward conquering this challenge is to formally verify that the end-to-end behavior of the computing system really satisfies various information-flow policies. Unfortunately, because today's system software still consists of both C and assembly programs, the end-to-end verification necessarily requires that we not only prove the security properties of individual components, but also carefully preserve these properties through compilation and cross-language linking. In this paper, we present a novel methodology for formally verifying end-to-end security of a software system that consists of both C and assembly programs. We introduce a general definition of observation function that unifies the concepts of policy specification, state indistinguishability, and whole-execution behaviors. We show how to use different observation functions for different levels of abstraction, and how to link different security proofs across abstraction levels using a special kind of simulation that is guaranteed to preserve state indistinguishability. To demonstrate the effectiveness of our new methodology, we have successfully constructed an end-to-end security proof, fully formalized in the Coq proof assistant, of a nontrivial operating system kernel (running on an extended {CompCert} x86 assembly machine model). Some parts of the kernel are written in C and some are written in assembly; we verify all of the code, regardless of language.},
	pages = {648--664},
	booktitle = {Proceedings of the 37th {ACM} {SIGPLAN} Conference on Programming Language Design and Implementation},
	publisher = {{ACM}},
	author = {Costanzo, David and Shao, Zhong and Gu, Ronghui},
	urldate = {2019-01-31},
	date = {2016},
	keywords = {Program Verification, Certified {OS} Kernels, Information Flow Control, Security Policy Specification, Security-Preserving Simulation},
	file = {ACM Full Text PDF:/home/fordrl/Zotero/storage/HCL3RZNR/Costanzo et al. - 2016 - End-to-end Verification of Information-flow Securi.pdf:application/pdf},
}

@online{luo_extended_nodate,
	title = {An Extended Calculus of Constructions},
	url = {http://www.lfcs.inf.ed.ac.uk/reports/90/ECS-LFCS-90-118/},
	author = {Luo, Zhaohui},
	urldate = {2019-02-01},
	file = {Zhaohui Luo - An Extended Calculus of Constructions.pdf:/home/fordrl/Zotero/storage/LXDDMBKD/Zhaohui Luo - An Extended Calculus of Constructions.pdf:application/pdf;Snapshot:/home/fordrl/Zotero/storage/7C9DFE56/ECS-LFCS-90-118.html:text/html},
}

@inproceedings{kang_crellvm:_2018,
	location = {New York, {NY}, {USA}},
	title = {Crellvm: Verified Credible Compilation for {LLVM}},
	isbn = {978-1-4503-5698-5},
	url = {http://doi.acm.org/10.1145/3192366.3192377},
	doi = {10.1145/3192366.3192377},
	series = {{PLDI} 2018},
	shorttitle = {Crellvm},
	abstract = {Production compilers such as {GCC} and {LLVM} are large complex software systems, for which achieving a high level of reliability is hard. Although testing is an effective method for finding bugs, it alone cannot guarantee a high level of reliability. To provide a higher level of reliability, many approaches that examine compilers' internal logics have been proposed. However, none of them have been successfully applied to major optimizations of production compilers. This paper presents Crellvm: a verified credible compilation framework for {LLVM}, which can be used as a systematic way of providing a high level of reliability for major optimizations in {LLVM}. Specifically, we augment an {LLVM} optimizer to generate translation results together with their correctness proofs, which can then be checked by a proof checker formally verified in Coq. As case studies, we applied our approach to two major optimizations of {LLVM}: register promotion mem2reg and global value numbering gvn, having found four new miscompilation bugs (two in each).},
	pages = {631--645},
	booktitle = {Proceedings of the 39th {ACM} {SIGPLAN} Conference on Programming Language Design and Implementation},
	publisher = {{ACM}},
	author = {Kang, Jeehoon and Kim, Yoonseung and Song, Youngju and Lee, Juneyoung and Park, Sanghoon and Shin, Mark Dongyeon and Kim, Yonghyun and Cho, Sungkeun and Choi, Joonwon and Hur, Chung-Kil and Yi, Kwangkeun},
	urldate = {2019-02-01},
	date = {2018},
	keywords = {{LLVM}, Coq, compiler verification, credible compilation, relational Hoare logic, translation validation},
	file = {ACM Full Text PDF:/home/fordrl/Zotero/storage/9BFDP4D4/Kang et al. - 2018 - Crellvm Verified Credible Compilation for LLVM.pdf:application/pdf},
}

@online{letouzey_certified_nodate,
	title = {Certified functional programming : Program extraction within Coq proof assistant},
	url = {https://www.researchgate.net/publication/280790704_Certified_functional_programming_Program_extraction_within_Coq_proof_assistant},
	shorttitle = {(8) ({PDF}) Certified functional programming},
	abstract = {{NOTA}: {THIS} {IS} {THE} {ENGLISH} {TRANSLATION} {OF} {MY} {FRENCH} {PHD} {MANUSCRIPT}. This work concerns the generation of programs which are certified to be correct by construction. These programs are obtained by extracting relevant information from constructive proofs made with the Coq proof assistant. Such a translation, named ``extraction'', of constructive proofs into functional programs is not new, and corresponds to an isomorphism known as Curry-Howard's. An extraction tool has been part of Coq assistant for a long time. But this old extraction tool suffered from several limitations: in particular, some Coq proofs were refused by it, whereas some others led to incorrect programs. In order to overcome these limitations, we built a completely new extraction tool for Coq, including both a new theory and a new implementation. Concerning theory, we developed new correctness proofs for this extraction mechanism. These new proofs are both complex and original. Concerning implementation, we focused on the generation of efficient and realistic code, which can be integrated in large-scale software developments, using modules and interfaces. Finally, we also present several case studies illustrating the capabilities of our new extraction. For example, we describe the certification of a modular library of finite set structures, and the production of programs about real exact arithmetic, starting from a formalization of constructive real analysis. These examples show the progress already achieved, even if the situation is not perfect yet, in particular in the last study.},
	titleaddon = {{ResearchGate}},
	author = {Letouzey, Pierre},
	urldate = {2019-02-01},
	langid = {english},
	file = {(8) (PDF) Certified functional programming  Progr.pdf:/home/fordrl/Zotero/storage/5IQA98EJ/(8) (PDF) Certified functional programming  Progr.pdf:application/pdf;Snapshot:/home/fordrl/Zotero/storage/V78NSVFJ/280790704_Certified_functional_programming_Program_extraction_within_Coq_proof_assistant.html:text/html},
}

@article{ebner_metaprogramming_2017,
	title = {A Metaprogramming Framework for Formal Verification},
	volume = {1},
	issn = {2475-1421},
	url = {http://doi.acm.org/10.1145/3110278},
	doi = {10.1145/3110278},
	abstract = {We describe the metaprogramming framework currently used in Lean, an interactive theorem prover based on dependent type theory. This framework extends Lean's object language with an {API} to some of Lean's internal structures and procedures, and provides ways of reflecting object-level expressions into the metalanguage. We provide evidence to show that our implementation is performant, and that it provides a convenient and flexible way of writing not only small-scale interactive tactics, but also more substantial kinds of automation.},
	pages = {34:1--34:29},
	issue = {{ICFP}},
	journaltitle = {Proc. {ACM} Program. Lang.},
	author = {Ebner, Gabriel and Ullrich, Sebastian and Roesch, Jared and Avigad, Jeremy and de Moura, Leonardo},
	urldate = {2019-02-01},
	date = {2017-08},
	keywords = {theorem proving, dependent type theory, metaprogramming, tactic language},
	file = {ACM Full Text PDF:/home/fordrl/Zotero/storage/BQCSENJ7/Ebner et al. - 2017 - A Metaprogramming Framework for Formal Verificatio.pdf:application/pdf},
}

@article{pakin_comprehensive_nodate,
	title = {The Comprehensive {LaTeX} Symbol List},
	abstract = {This document lists 14283 symbols and the corresponding {LATEX} commands that produce them. Some of these symbols are guaranteed to be available in every {LATEX} 2������ system; others require fonts and packages that may not accompany a given distribution and that therefore need to be installed. All of the fonts and packages used to prepare this document—as well as this document itself—are freely available from the Comprehensive {TEX} Archive Network (http://www.ctan.org/).},
	pages = {358},
	author = {Pakin, Scott},
	langid = {english},
	file = {Pakin - The Comprehensive LaTeX Symbol List.pdf:/home/fordrl/Zotero/storage/8ZIDMML6/Pakin - The Comprehensive LaTeX Symbol List.pdf:application/pdf},
}

@article{kubota_foundations_2016,
	title = {Foundations of Mathematics},
	url = {http://www.owlofminerva.net/doi/10.4444/100/111/},
	doi = {10.4444/100.111},
	author = {Kubota, Ken},
	urldate = {2019-02-01},
	date = {2016},
	langid = {english},
	file = {Kubota - 2016 - Foundations of Mathematics.pdf:/home/fordrl/Zotero/storage/LTUGMTBE/Kubota - 2016 - Foundations of Mathematics.pdf:application/pdf},
}

@inproceedings{hathhorn_defining_2015,
	location = {New York, {NY}, {USA}},
	title = {Defining the Undefinedness of C},
	isbn = {978-1-4503-3468-6},
	url = {http://doi.acm.org/10.1145/2737924.2737979},
	doi = {10.1145/2737924.2737979},
	series = {{PLDI} '15},
	abstract = {We present a ``negative'' semantics of the C11 language---a semantics that does not just give meaning to correct programs, but also rejects undefined programs. We investigate undefined behavior in C and discuss the techniques and special considerations needed for formally specifying it. We have used these techniques to modify and extend a semantics of C into one that captures undefined behavior. The amount of semantic infrastructure and effort required to achieve this was unexpectedly high, in the end nearly doubling the size of the original semantics. From our semantics, we have automatically extracted an undefinedness checker, which we evaluate against other popular analysis tools, using our own test suite in addition to a third-party test suite. Our checker is capable of detecting examples of all 77 categories of core language undefinedness appearing in the C11 standard, more than any other tool we considered. Based on this evaluation, we argue that our work is the most comprehensive and complete semantic treatment of undefined behavior in C, and thus of the C language itself.},
	pages = {336--345},
	booktitle = {Proceedings of the 36th {ACM} {SIGPLAN} Conference on Programming Language Design and Implementation},
	publisher = {{ACM}},
	author = {Hathhorn, Chris and Ellison, Chucky and Roşu, Grigore},
	urldate = {2019-02-01},
	date = {2015},
	keywords = {C11, K Framework, Programming language semantics, Undefined behavior},
	file = {ACM Full Text PDF:/home/fordrl/Zotero/storage/5UX692DD/Hathhorn et al. - 2015 - Defining the Undefinedness of C.pdf:application/pdf},
}

@article{arias_jscoq:_2017,
	title = {{jsCoq}: Towards Hybrid Theorem Proving Interfaces},
	volume = {239},
	issn = {2075-2180},
	url = {http://arxiv.org/abs/1701.07125},
	doi = {10.4204/EPTCS.239.2},
	shorttitle = {{jsCoq}},
	abstract = {We describe {jsCcoq}, a new platform and user environment for the Coq interactive proof assistant. The {jsCoq} system targets the {HTML}5-{ECMAScript} 2015 specification, and it is typically run inside a standards-compliant browser, without the need of external servers or services. Targeting educational use, {jsCoq} allows the user to start interaction with proof scripts right away, thanks to its self-contained nature. Indeed, a full Coq environment is packed along the proof scripts, easing distribution and installation. Starting to use {jsCoq} is as easy as clicking on a link. The current release ships more than 10 popular Coq libraries, and supports popular books such as Software Foundations or Certified Programming with Dependent Types. The new target platform has opened up new interaction and display possibilities. It has also fostered the development of some new Coq-related technology. In particular, we have implemented a new serialization-based protocol for interaction with the proof assistant, as well as a new package format for library distribution.},
	pages = {15--27},
	journaltitle = {Electronic Proceedings in Theoretical Computer Science},
	author = {Arias, Emilio Jesús Gallego and Pin, Benoît and Jouvelot, Pierre},
	urldate = {2019-02-01},
	date = {2017-01-24},
	eprinttype = {arxiv},
	eprint = {1701.07125},
	keywords = {Computer Science - Programming Languages, Computer Science - Logic in Computer Science, Computer Science - Machine Learning, Computer Science - Human-Computer Interaction},
	file = {arXiv.org Snapshot:/home/fordrl/Zotero/storage/6S4YQDBI/1701.html:text/html;arXiv\:1701.07125 PDF:/home/fordrl/Zotero/storage/KW34YHZU/Arias et al. - 2017 - jsCoq Towards Hybrid Theorem Proving Interfaces.pdf:application/pdf},
}

@inproceedings{brockschmidt_t2:_2016,
	title = {T2: Temporal Property Verification},
	isbn = {978-3-662-49674-9},
	series = {Lecture Notes in Computer Science},
	shorttitle = {T2},
	abstract = {We present the open-source tool T2, the first public release from the {TERMINATOR} project [9]. T2 has been extended over the past decade to support automatic temporal-logic proving techniques and to handle a general class of user-provided liveness and safety properties. Input can be provided in a native format and in C, via the support of the {LLVM} compiler framework. We briefly discuss T2’s architecture, its underlying techniques, and conclude with an experimental illustration of its competitiveness and directions for future extensions.},
	pages = {387--393},
	booktitle = {Tools and Algorithms for the Construction and Analysis of Systems},
	publisher = {Springer Berlin Heidelberg},
	author = {Brockschmidt, Marc and Cook, Byron and Ishtiaq, Samin and Khlaaf, Heidy and Piterman, Nir},
	editor = {Chechik, Marsha and Raskin, Jean-François},
	date = {2016},
	langid = {english},
	file = {Brockschmidt et al. - 2016 - T2 Temporal Property Verification.pdf:/home/fordrl/Zotero/storage/NTYHNVUJ/Brockschmidt et al. - 2016 - T2 Temporal Property Verification.pdf:application/pdf},
}

@article{crick_share_2014,
	title = {"Share and Enjoy": Publishing Useful and Usable Scientific Models},
	url = {http://arxiv.org/abs/1409.0367},
	shorttitle = {"Share and Enjoy"},
	abstract = {The reproduction and replication of reported scientific results is a hot topic within the academic community. The retraction of numerous studies from a wide range of disciplines, from climate science to bioscience, has drawn the focus of many commentators, but there exists a wider socio-cultural problem that pervades the scientific community. Sharing code, data and models often requires extra effort; this is currently seen as a significant overhead that may not be worth the time investment. Automated systems, which allow easy reproduction of results, offer the potential to incentivise a culture change and drive the adoption of new techniques to improve the efficiency of scientific exploration. In this paper, we discuss the value of improved access and sharing of the two key types of results arising from work done in the computational sciences: models and algorithms. We propose the development of an integrated cloud-based system underpinning computational science, linking together software and data repositories, toolchains, workflows and outputs, providing a seamless automated infrastructure for the verification and validation of scientific models and in particular, performance benchmarks.},
	journaltitle = {{arXiv}:1409.0367 [cs]},
	author = {Crick, Tom and Hall, Benjamin A. and Ishtiaq, Samin and Takeda, Kenji},
	urldate = {2019-02-01},
	date = {2014-09-01},
	eprinttype = {arxiv},
	eprint = {1409.0367},
	keywords = {Computer Science - Computational Engineering, Finance, and Science},
	file = {arXiv.org Snapshot:/home/fordrl/Zotero/storage/YWG36WKR/1409.html:text/html;arXiv\:1409.0367 PDF:/home/fordrl/Zotero/storage/LKKTEADA/Crick et al. - 2014 - Share and Enjoy Publishing Useful and Usable Sc.pdf:application/pdf},
}

@incollection{hutchison_seloger:_2013,
	location = {Berlin, Heidelberg},
	title = {{SeLoger}: A Tool for Graph-Based Reasoning in Separation Logic},
	volume = {8044},
	isbn = {978-3-642-39798-1 978-3-642-39799-8},
	url = {http://link.springer.com/10.1007/978-3-642-39799-8_55},
	shorttitle = {{SeLoger}},
	abstract = {This paper introduces the tool {SeLoger}, which is a reasoner for satisﬁability and entailment in a fragment of separation logic with pointers and linked lists. {SeLoger} builds upon and extends graphbased algorithms that have recently been introduced in order to settle both decision problems in polynomial time. Running {SeLoger} on standard benchmarks shows that the tool outperforms current state-of-theart tools by orders of magnitude.},
	pages = {790--795},
	booktitle = {Computer Aided Verification},
	publisher = {Springer Berlin Heidelberg},
	author = {Haase, Christoph and Ishtiaq, Samin and Ouaknine, Joël and Parkinson, Matthew J.},
	editor = {Sharygina, Natasha and Veith, Helmut},
	editorb = {Hutchison, David and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M. and Mattern, Friedemann and Mitchell, John C. and Naor, Moni and Nierstrasz, Oscar and Pandu Rangan, C. and Steffen, Bernhard and Sudan, Madhu and Terzopoulos, Demetri and Tygar, Doug and Vardi, Moshe Y. and Weikum, Gerhard},
	editorbtype = {redactor},
	urldate = {2019-02-01},
	date = {2013},
	langid = {english},
	doi = {10.1007/978-3-642-39799-8_55},
	file = {Haase et al. - 2013 - SeLoger A Tool for Graph-Based Reasoning in Separ.pdf:/home/fordrl/Zotero/storage/PQPRK2IX/Haase et al. - 2013 - SeLoger A Tool for Graph-Based Reasoning in Separ.pdf:application/pdf},
}

@article{ross_exterminators_2005,
	title = {The exterminators [software bugs]},
	volume = {42},
	doi = {10.1109/MSPEC.2005.1502527},
	abstract = {This paper describes a sound methodology developed at Praxis High Integrity Systems for detecting and exterminating bugs during all stages of a software project. To develop software, the London-based software house uses mathematically based techniques, known as formal methods, which require that programmers begin their work not by writing code but rather by stringing together special symbols that represent the program's logic. Like a mathematical theorem, these symbol strings can be checked to verify that they form logically correct statements. Once the programmer has checked that the program doesn't have logical flaws, it's a relatively simple matter to convert those symbols into programming code. With an average of less than one error in every 10,000 lines of delivered code, Praxis claims a bug rate that is at least 50 times better than the industry standard.},
	pages = {36--41},
	number = {9},
	journaltitle = {{IEEE} Spectrum},
	author = {Ross, P. E.},
	date = {2005-09},
	keywords = {formal methods, software engineering, bug-free software, Computer bugs, formal logic, Logic, mathematical logic, Praxis High Integrity Systems, program debugging, software bugs, software development, software engineering methods, software experts, software project},
}

@article{furia_autoproof:_2017,
	title = {{AutoProof}: auto-active functional verification of object-oriented programs},
	volume = {19},
	issn = {1433-2787},
	url = {https://doi.org/10.1007/s10009-016-0419-0},
	doi = {10.1007/s10009-016-0419-0},
	shorttitle = {{AutoProof}},
	abstract = {Auto-active verifiers provide a level of automation intermediate between fully automatic and interactive: users supply code with annotations as input while benefiting from a high level of automation in the back-end. This paper presents {AutoProof}, a state-of-the-art auto-active verifier for object-oriented sequential programs with complex functional specifications. {AutoProof} fully supports advanced object-oriented features and a powerful methodology for framing and class invariants, which make it applicable in practice to idiomatic object-oriented patterns. The paper focuses on describing {AutoProof} ’s interface, design, and implementation features, and demonstrates {AutoProof} ’s performance on a rich collection of benchmark problems. The results attest {AutoProof} ’s competitiveness among tools in its league on cutting-edge functional verification of object-oriented programs.},
	pages = {697--716},
	number = {6},
	journaltitle = {International Journal on Software Tools for Technology Transfer},
	shortjournal = {Int J Softw Tools Technol Transfer},
	author = {Furia, Carlo A. and Nordio, Martin and Polikarpova, Nadia and Tschannen, Julian},
	urldate = {2019-09-23},
	date = {2017-11-01},
	langid = {english},
	keywords = {Auto-active verification, Functional verification, Object-oriented verification, Verification benchmarks},
	file = {Full Text:/home/fordrl/Zotero/storage/FD9CX7PQ/Furia et al. - 2017 - AutoProof auto-active functional verification of .pdf:application/pdf},
}

@article{bjorner_manifest_2017,
	title = {Manifest domains: analysis and description},
	volume = {29},
	issn = {1433-299X},
	url = {https://doi.org/10.1007/s00165-016-0385-z},
	doi = {10.1007/s00165-016-0385-z},
	shorttitle = {Manifest domains},
	abstract = {We show that manifest domains, an understanding of which are a prerequisite for software requirements prescriptions, can be precisely described: narrated and formalised. We show that such manifest domains can be understood as a collection of endurant, that is, basically spatial entities: parts, components and materials, and perdurant, that is, basically temporal entities: actions, events and behaviours. We show that parts can be modeled in terms of external qualities whether: atomic or composite parts, having internal qualities: unique identifications, mereologies, which model relations between parts, and attributes. We show that the manifest domain analysis endeavour can be supported by a calculus of manifest domain analysis prompts: is\_entity, is\_endurant, is\_perdurant, is\_part, is\_component, is\_material, is\_atomic, is\_composite, has\_components, has\_materials, has\_concrete\_type, attribute\_names, is\_stationary, etcetera; and show how the manifest domain description endeavour can be supported by a calculus of manifest domain description prompts: observe\_part\_sorts, observe\_part\_type, observe\_components, observe\_materials, observe\_unique\_identifier, observe\_mereology, observe\_attributes. We show how to model attributes, essentially following Michael Jackson (Software requirements \& specifications: a lexicon of practice, principles and prejudices. {ACM} Press, Addison-Wesley, Reading, 1995), but with a twist: The attribute model introduces the attribute analysis prompts is\_static\_attribute, is\_dynamic\_attribute, is\_inert\_attribute, is\_reactive\_attribute, is\_active\_attribute, is\_autonomous\_attribute, is\_biddable\_attribute and is\_programmable\_attribute. The twist suggests ways of modeling “access” to the values of these kinds of attributes: the static attributes by simply “copying” them, once, the reactive and programmable attributes by “carrying” them as function parameters whose values are kept always updated, and the remaining, the external\_attributes, by inquiring, when needed, as to their value, as if they were always offered on {CSP}-like channels (Hoare, Communicating sequential processes. C.A.R. Hoare series in computer science. Prentice-Hall International, London, 2004). We show how to model essential aspects of perdurants in terms of their signatures based on the concepts of endurants. And we show how one can “compile” descriptions of endurant parts into descriptions of perdurant behaviours. We do not show prompt calculi for perdurants. The above contributions express a method with principles, techniques and tools for constructing domain descriptions. It is important to realise that we do not wish to nor claim that the method can describe all that it is interesting to know about domains.},
	pages = {175--225},
	number = {2},
	journaltitle = {Formal Aspects of Computing},
	shortjournal = {Form Asp Comp},
	author = {Bjørner, Dines},
	urldate = {2019-09-23},
	date = {2017-03-01},
	langid = {english},
	keywords = {Analysis \& description, Domain engineering, Manifest domains, Prompt calculi},
	file = {Submitted Version:/home/fordrl/Zotero/storage/KPC4Q6PV/Bjørner - 2017 - Manifest domains analysis and description.pdf:application/pdf},
}

@incollection{hutchison_40_2014,
	location = {Cham},
	title = {40 Years of Formal Methods: Some Obstacles and Some Possibilities?},
	volume = {8442},
	isbn = {978-3-319-06409-3 978-3-319-06410-9},
	url = {http://link.springer.com/10.1007/978-3-319-06410-9_4},
	shorttitle = {40 Years of Formal Methods},
	pages = {42--61},
	booktitle = {{FM} 2014: Formal Methods},
	publisher = {Springer International Publishing},
	author = {Bjørner, Dines and Havelund, Klaus},
	editor = {Jones, Cliff and Pihlajasaari, Pekka and Sun, Jun},
	editorb = {Hutchison, David and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M. and Kobsa, Alfred and Mattern, Friedemann and Mitchell, John C. and Naor, Moni and Nierstrasz, Oscar and Pandu Rangan, C. and Steffen, Bernhard and Terzopoulos, Demetri and Tygar, Doug and Weikum, Gerhard},
	editorbtype = {redactor},
	urldate = {2019-09-23},
	date = {2014},
	langid = {english},
	doi = {10.1007/978-3-319-06410-9_4},
	file = {Bjørner and Havelund - 2014 - 40 Years of Formal Methods Some Obstacles and Som.pdf:/home/fordrl/Zotero/storage/4H2GEJ6B/Bjørner and Havelund - 2014 - 40 Years of Formal Methods Some Obstacles and Som.pdf:application/pdf},
}

@article{hoare_verifying_2003,
	title = {The Verifying Compiler: A Grand Challenge for Computing Research},
	volume = {50},
	issn = {0004-5411},
	url = {http://doi.acm.org/10.1145/602382.602403},
	doi = {10.1145/602382.602403},
	shorttitle = {The Verifying Compiler},
	abstract = {This contribution proposes a set of criteria that distinguish a grand challenge in science or engineering from the many other kinds of short-term or long-term research problems that engage the interest of scientists and engineers. As an example drawn from Computer Science, it revives an old challenge: the construction and application of a verifying compiler that guarantees correctness of a program before running it.},
	pages = {63--69},
	number = {1},
	journaltitle = {J. {ACM}},
	author = {Hoare, Tony},
	urldate = {2019-09-17},
	date = {2003-01},
	file = {ACM Full Text PDF:/home/fordrl/Zotero/storage/LN7AL2B6/Hoare - 2003 - The Verifying Compiler A Grand Challenge for Comp.pdf:application/pdf},
}

@article{ringer_qed_2019,
	title = {{QED} at Large: A Survey of Engineering of Formally Verified Software},
	volume = {5},
	issn = {2325-1107, 2325-1131},
	url = {https://www.nowpublishers.com/article/Details/PGL-045},
	doi = {10.1561/2500000045},
	shorttitle = {{QED} at Large},
	abstract = {{QED} at Large: A Survey of Engineering of Formally Verified Software},
	pages = {102--281},
	number = {2},
	journaltitle = {Foundations and Trends® in Programming Languages},
	shortjournal = {{PGL}},
	author = {Ringer, Talia and Palmskog, Karl and Sergey, Ilya and Gligoric, Milos and Tatlock, Zachary},
	urldate = {2019-09-10},
	date = {2019-09-03},
	file = {Snapshot:/home/fordrl/Zotero/storage/VLMVNE56/PGL-045.html:text/html;Full Text PDF:/home/fordrl/Zotero/storage/BNSN99RP/Ringer et al. - 2019 - QED at Large A Survey of Engineering of Formally .pdf:application/pdf},
}

@software{noauthor_hazel_2019,
	title = {Hazel, a live functional programming environment with typed holes: hazelgrove/hazel},
	rights = {{MIT}},
	url = {https://github.com/hazelgrove/hazel},
	shorttitle = {Hazel, a live functional programming environment with typed holes},
	publisher = {hazelgrove},
	urldate = {2019-08-30},
	date = {2019-08-20},
	note = {original-date: 2017-01-27T02:14:05Z},
}

@online{noauthor_hazel_nodate,
	title = {Hazel, a live functional programming environment featuring typed holes.},
	url = {http://hazel.org/},
	urldate = {2019-08-30},
	file = {Hazel, a live functional programming environment featuring typed holes.:/home/fordrl/Zotero/storage/THGUDSZA/hazel.org.html:text/html},
}

@inproceedings{padon_ivy:_2016,
	location = {New York, {NY}, {USA}},
	title = {Ivy: Safety Verification by Interactive Generalization},
	isbn = {978-1-4503-4261-2},
	url = {http://doi.acm.org/10.1145/2908080.2908118},
	doi = {10.1145/2908080.2908118},
	series = {{PLDI} '16},
	shorttitle = {Ivy},
	abstract = {Despite several decades of research, the problem of formal verification of infinite-state systems has resisted effective automation. We describe a system --- Ivy --- for interactively verifying safety of infinite-state systems. Ivy's key principle is that whenever verification fails, Ivy graphically displays a concrete counterexample to induction. The user then interactively guides generalization from this counterexample. This process continues until an inductive invariant is found. Ivy searches for universally quantified invariants, and uses a restricted modeling language. This ensures that all verification conditions can be checked algorithmically. All user interactions are performed using graphical models, easing the user's task. We describe our initial experience with verifying several distributed protocols.},
	pages = {614--630},
	booktitle = {Proceedings of the 37th {ACM} {SIGPLAN} Conference on Programming Language Design and Implementation},
	publisher = {{ACM}},
	author = {Padon, Oded and {McMillan}, Kenneth L. and Panda, Aurojit and Sagiv, Mooly and Shoham, Sharon},
	urldate = {2019-08-30},
	date = {2016},
	note = {event-place: Santa Barbara, {CA}, {USA}},
	keywords = {counterexamples to induction, distributed systems, invariant inference, safety verification},
	file = {ACM Full Text PDF:/home/fordrl/Zotero/storage/IDEQDLZ7/Padon et al. - 2016 - Ivy Safety Verification by Interactive Generaliza.pdf:application/pdf},
}

@inproceedings{mullen_oeuf:_2018,
	location = {New York, {NY}, {USA}},
	title = {ŒUf: Minimizing the Coq Extraction {TCB}},
	isbn = {978-1-4503-5586-5},
	url = {http://doi.acm.org/10.1145/3167089},
	doi = {10.1145/3167089},
	series = {{CPP} 2018},
	shorttitle = {ŒUf},
	abstract = {Verifying systems by implementing them in the programming language of a proof assistant (e.g., Gallina for Coq) lets us directly leverage the full power of the proof assistant for verifying the system. But, to execute such an implementation requires extraction, a large complicated process that is in the trusted computing base ({TCB}).  This paper presents Œuf, a verified compiler from a subset of Gallina to assembly. Œuf’s correctness theorem ensures that compilation preserves the semantics of the source Gallina program. We describe how Œuf’s specification can be used as a foreign function interface to reason about the interaction between compiled Gallina programs and surrounding shim code. Additionally, Œufmaintains a small {TCB} for its front-end by reflecting Gallina programs to Œufsource and automatically ensuring equivalence using computational denotation. This design enabled us to implement some early compiler passes (e.g., lambda lifting) in the untrusted reflection and ensure their correctness via translation validation. To evaluate Œuf, we compile Appel’s {SHA}256 specification from Gallina to x86 and write a shim for the generated code, yielding a verified sha256sum implementation with a small {TCB}.},
	pages = {172--185},
	booktitle = {Proceedings of the 7th {ACM} {SIGPLAN} International Conference on Certified Programs and Proofs},
	publisher = {{ACM}},
	author = {Mullen, Eric and Pernsteiner, Stuart and Wilcox, James R. and Tatlock, Zachary and Grossman, Dan},
	urldate = {2019-08-30},
	date = {2018},
	note = {event-place: Los Angeles, {CA}, {USA}},
	keywords = {Coq, Compilers, Formal Verification, Verified Systems},
	file = {ACM Full Text PDF:/home/fordrl/Zotero/storage/LRDLZB4D/Mullen et al. - 2018 - ŒUf Minimizing the Coq Extraction TCB.pdf:application/pdf},
}

@book{manna_temporal_1995,
	location = {New York},
	title = {Temporal Verification of Reactive Systems: Safety},
	isbn = {978-0-387-94459-3},
	url = {https://www.springer.com/gp/book/9780387944593},
	series = {Manna,Z.;Pnueli,A.:Temporal Logic of Reactive Systems},
	shorttitle = {Temporal Verification of Reactive Systems},
	abstract = {This book is about the verification of reactive systems. A reactive system is a system that maintains an ongoing interaction with its environment, as opposed to computing some final value on termination. The family of reactive systems includes many classes of programs whose correct and reliable construction is con­ sidered to be particularly challenging, including concurrent programs, embedded and process control programs, and operating systems. Typical examples of such systems are an air traffic control system, programs controlling mechanical devices such as a train, or perpetually ongoing processes such as a nuclear reactor. With the expanding use of computers in safety-critical areas, where failure is potentially disastrous, correctness is crucial. This has led to the introduction of formal verification techniques, which give both users and designers of software and hardware systems greater confidence that the systems they build meet the desired specifications. Framework The approach promoted in this book is based on the use of temporal logic for specifying properties of reactive systems, and develops an extensive verification methodology for proving that a system meets its temporal specification. Reactive programs must be specified in terms of their ongoing behavior, and temporal logic provides an expressive and natural language for specifying this behavior. Our framework for specifying and verifying temporal properties of reactive systems is based on the following four components: 1. A computational model to describe the behavior of reactive systems. The model adopted in this book is that of a Fair Transition System ({FTS}).},
	publisher = {Springer-Verlag},
	author = {Manna, Zohar and Pnueli, Amir},
	urldate = {2019-08-29},
	date = {1995},
	langid = {english},
	file = {Snapshot:/home/fordrl/Zotero/storage/JF92NIX9/9780387944593.html:text/html},
}

@article{feldman_inferring_2019,
	title = {Inferring Inductive Invariants from Phase Structures},
	url = {http://arxiv.org/abs/1905.07739},
	abstract = {Infinite-state systems such as distributed protocols are challenging to verify using interactive theorem provers or automatic verification tools. Of these techniques, deductive verification is highly expressive but requires the user to annotate the system with inductive invariants. To relieve the user from this labor-intensive and challenging task, invariant inference aims to find inductive invariants automatically. Unfortunately, when applied to infinite-state systems such as distributed protocols, existing inference techniques often diverge, which limits their applicability. This paper proposes user-guided invariant inference based on phase invariants, which capture the different logical phases of the protocol. Users conveys their intuition by specifying a phase structure, an automaton with edges labeled by program transitions; the tool automatically infers assertions that hold in the automaton's states, resulting in a full safety proof.The additional structure from phases guides the inference procedure towards finding an invariant. Our results show that user guidance by phase structures facilitates successful inference beyond the state of the art. We find that phase structures are pleasantly well matched to the intuitive reasoning routinely used by domain experts to understand why distributed protocols are correct, so that providing a phase structure reuses this existing intuition.},
	journaltitle = {{arXiv}:1905.07739 [cs]},
	author = {Feldman, Yotam M. Y. and Wilcox, James R. and Shoham, Sharon and Sagiv, Mooly},
	urldate = {2019-08-26},
	date = {2019-05-19},
	eprinttype = {arxiv},
	eprint = {1905.07739},
	keywords = {Computer Science - Programming Languages},
	file = {arXiv.org Snapshot:/home/fordrl/Zotero/storage/BGNWGZEP/1905.html:text/html;arXiv\:1905.07739 PDF:/home/fordrl/Zotero/storage/HK3TF24F/Feldman et al. - 2019 - Inferring Inductive Invariants from Phase Structur.pdf:application/pdf},
}

@misc{bjorner_programming_nodate,
	title = {Programming Z3},
	url = {http://theory.stanford.edu/~nikolaj/programmingz3.html},
	abstract = {This tutorial provides a programmer's introduction to the Satisfiability Modulo Theories Solver Z3. It describes how to use Z3 through scripts, provided in the Python scripting language, and it describes several of the algorithms underlying the decision procedures within Z3. It aims to broadly cover almost all available features of Z3 and the essence of the underlying algorithms.},
	author = {Bjørner, Nikolaj and de Moura, Leonardo and Nachmanson, lev and Wintersteiger, Christoph},
}

@article{yurichev_sat/smt_nodate,
	title = {{SAT}/{SMT} by Example},
	pages = {555},
	author = {Yurichev, Dennis},
	langid = {english},
	file = {Yurichev - SATSMT by Example.pdf:/home/fordrl/Zotero/storage/K7ATB273/Yurichev - SATSMT by Example.pdf:application/pdf},
}

@article{bardin_bringing_2019,
	title = {Bringing {CP}, {SAT} and {SMT} together: Next Challenges in Constraint Solving (Dagstuhl Seminar 19062)},
	volume = {9},
	issn = {2192-5283},
	url = {http://drops.dagstuhl.de/opus/volltexte/2019/10857},
	doi = {10.4230/DagRep.9.2.27},
	shorttitle = {Bringing {CP}, {SAT} and {SMT} together},
	pages = {27--47},
	number = {2},
	journaltitle = {Dagstuhl Reports},
	author = {Bardin, Sébastien and Bjørner, Nikolaj and Cadar, Cristian},
	editor = {Bardin, Sébastien and Bjørner, Nikolaj S. and Cadar, Cristian},
	urldate = {2019-08-23},
	date = {2019},
	keywords = {Automated Decision Procedures, Constraint Programming, {SAT}, {SMT}},
	file = {Full Text PDF:/home/fordrl/Zotero/storage/4YE7JBES/Bardin et al. - 2019 - Bringing CP, SAT and SMT together Next Challenges.pdf:application/pdf;Snapshot:/home/fordrl/Zotero/storage/SUY2UKQZ/10857.html:text/html},
}

@inproceedings{selsam_guiding_2019,
	title = {Guiding High-Performance {SAT} Solvers with Unsat-Core Predictions},
	isbn = {978-3-030-24258-9},
	series = {Lecture Notes in Computer Science},
	abstract = {The {NeuroSAT} neural network architecture was introduced in [37] for predicting properties of propositional formulae. When trained to predict the satisfiability of toy problems, it was shown to find solutions and unsatisfiable cores on its own. However, the authors saw “no obvious path” to using the architecture to improve the state-of-the-art. In this work, we train a simplified {NeuroSAT} architecture to directly predict the unsatisfiable cores of real problems. We modify several state-of-the-art {SAT} solvers to periodically replace their variable activity scores with {NeuroSAT}’s prediction of how likely the variables are to appear in an unsatisfiable core. The modified {MiniSat} solves 10\% more problems on {SATCOMP}-2018 within the standard 5,000 second timeout than the original does. The modified Glucose solves 11\% more problems than the original, while the modified Z3 solves 6\% more. The gains are even greater when the training is specialized for a specific distribution of problems; on a benchmark of hard problems from a scheduling domain, the modified Glucose solves 20\% more problems than the original does within a one-hour timeout. Our results demonstrate that {NeuroSAT} can provide effective guidance to high-performance {SAT} solvers on real problems.},
	pages = {336--353},
	booktitle = {Theory and Applications of Satisfiability Testing – {SAT} 2019},
	publisher = {Springer International Publishing},
	author = {Selsam, Daniel and Bjørner, Nikolaj},
	editor = {Janota, Mikoláš and Lynce, Inês},
	date = {2019},
	langid = {english},
}

@inproceedings{hoder_z_2011,
	title = {μZ– An Efficient Engine for Fixed Points with Constraints},
	isbn = {978-3-642-22110-1},
	series = {Lecture Notes in Computer Science},
	abstract = {The μZ tool is a scalable, efficient engine for fixed points with constraints. It supports high-level declarative fixed point constraints over a combination of built-in and plugin domains. The built-in domains include formulas presented to the {SMT} solver Z3 and domains known from abstract interpretation. We present the interface to μZ, a number of the domains, and a set of examples illustrating the use of μZ.},
	pages = {457--462},
	booktitle = {Computer Aided Verification},
	publisher = {Springer Berlin Heidelberg},
	author = {Hoder, Kryštof and Bjørner, Nikolaj and de Moura, Leonardo},
	editor = {Gopalakrishnan, Ganesh and Qadeer, Shaz},
	date = {2011},
	langid = {english},
	keywords = {Abstract Interpretation, Abstract Machine, Default Representation, Hash Table, Relational Algebra},
	file = {Springer Full Text PDF:/home/fordrl/Zotero/storage/BJ3ZGIBR/Hoder et al. - 2011 - μZ– An Efficient Engine for Fixed Points with Cons.pdf:application/pdf},
}

@online{noauthor_mezzo_nodate,
	title = {The Mezzo programming language},
	url = {http://protz.github.io/mezzo/},
	urldate = {2019-08-05},
	file = {protzenko-phd-final.pdf:/home/fordrl/Zotero/storage/W4X3TH6D/protzenko-phd-final.pdf:application/pdf;The Mezzo programming language:/home/fordrl/Zotero/storage/VFGBN4CQ/mezzo.html:text/html},
}

@article{gueneau_procrastination_nodate,
	title = {Procrastination},
	abstract = {We present a small Coq library for collecting side conditions and deferring their proof.},
	pages = {7},
	author = {Guéneau, Armaël},
	langid = {english},
	file = {Procrastination.pdf:/home/fordrl/Zotero/storage/JHZQEC2E/Procrastination.pdf:application/pdf},
}

@inproceedings{mullen_oeuf:_2018-1,
	location = {New York, {NY}, {USA}},
	title = {ŒUf: Minimizing the Coq Extraction {TCB}},
	isbn = {978-1-4503-5586-5},
	url = {http://doi.acm.org/10.1145/3167089},
	doi = {10.1145/3167089},
	series = {{CPP} 2018},
	shorttitle = {ŒUf},
	abstract = {Verifying systems by implementing them in the programming language of a proof assistant (e.g., Gallina for Coq) lets us directly leverage the full power of the proof assistant for verifying the system. But, to execute such an implementation requires extraction, a large complicated process that is in the trusted computing base ({TCB}).  This paper presents Œuf, a verified compiler from a subset of Gallina to assembly. Œuf’s correctness theorem ensures that compilation preserves the semantics of the source Gallina program. We describe how Œuf’s specification can be used as a foreign function interface to reason about the interaction between compiled Gallina programs and surrounding shim code. Additionally, Œufmaintains a small {TCB} for its front-end by reflecting Gallina programs to Œufsource and automatically ensuring equivalence using computational denotation. This design enabled us to implement some early compiler passes (e.g., lambda lifting) in the untrusted reflection and ensure their correctness via translation validation. To evaluate Œuf, we compile Appel’s {SHA}256 specification from Gallina to x86 and write a shim for the generated code, yielding a verified sha256sum implementation with a small {TCB}.},
	pages = {172--185},
	booktitle = {Proceedings of the 7th {ACM} {SIGPLAN} International Conference on Certified Programs and Proofs},
	publisher = {{ACM}},
	author = {Mullen, Eric and Pernsteiner, Stuart and Wilcox, James R. and Tatlock, Zachary and Grossman, Dan},
	urldate = {2019-07-30},
	date = {2018},
	note = {event-place: Los Angeles, {CA}, {USA}},
	keywords = {Coq, Compilers, Formal Verification, Verified Systems},
	file = {poplws18cpp-id12.pdf:/home/fordrl/Zotero/storage/EFMYGWDQ/poplws18cpp-id12.pdf:application/pdf},
}

@inproceedings{fogarty_concoqtion:_2007,
	location = {New York, {NY}, {USA}},
	title = {Concoqtion: Indexed Types Now!},
	isbn = {978-1-59593-620-2},
	url = {http://doi.acm.org/10.1145/1244381.1244400},
	doi = {10.1145/1244381.1244400},
	series = {{PEPM} '07},
	shorttitle = {Concoqtion},
	abstract = {Almost twenty years after the pioneering efforts of Cardelli, the programming languages community is vigorously pursuing ways to incorporate Fω-style indexed types into programming languages. This paper advocates Concoqtion, a practical approach to adding such highly expressive types to full-fledged programming languages. The approach is applied to {MetaOCaml} using the Coq proof checker to conservatively extend Hindley-Milner type inference. The implementation of {MetaOCaml} Concoqtion requires minimal modifications to the syntax, the type checker, and the compiler; and yields a language comparable in notation to the leading proposals. The resulting language provides unlimited expressiveness in the type system while maintaining decidability. Furthermore, programmers can take advantage of a wide range of libraries not only for the programming language but also for the indexed types. Programming in {MetaOCaml} Concoqtion is illustrated with small examples and a case study implementing a statically-typed domain-specific language.},
	pages = {112--121},
	booktitle = {Proceedings of the 2007 {ACM} {SIGPLAN} Symposium on Partial Evaluation and Semantics-based Program Manipulation},
	publisher = {{ACM}},
	author = {Fogarty, Seth and Pasalic, Emir and Siek, Jeremy and Taha, Walid},
	urldate = {2019-07-07},
	date = {2007},
	note = {event-place: Nice, France},
	file = {ACM Full Text PDF:/home/fordrl/Zotero/storage/W3TQFYD3/Fogarty et al. - 2007 - Concoqtion Indexed Types Now!.pdf:application/pdf},
}

@article{brady_idris_2013,
	title = {Idris, a general-purpose dependently typed programming language: Design and implementation},
	volume = {23},
	issn = {0956-7968, 1469-7653},
	url = {https://www.cambridge.org/core/product/identifier/S095679681300018X/type/journal_article},
	doi = {10.1017/S095679681300018X},
	shorttitle = {Idris, a general-purpose dependently typed programming language},
	abstract = {Many components of a dependently-typed programming language are by now well understood, for example the underlying type theory, type checking, uniﬁcation and evaluation. How to combine these components into a realistic and usable high-level language is, however, folklore, discovered anew by successive language implementators. In this paper, I describe the implementation of {IDRIS}, a new dependently-typed functional programming language. {IDRIS} is intended to be a general purpose programming language and as such provides high-level concepts such as implicit syntax, type classes and do notation. I describe the high-level language and the underlying type theory, and present a tactic-based method for elaborating concrete high-level syntax with implicit arguments and type classes into a fully explicit type theory. Furthermore, I show how this method facilitates the implementation of new high-level language constructs.},
	pages = {552--593},
	number = {5},
	journaltitle = {Journal of Functional Programming},
	author = {Brady, Edwin},
	urldate = {2019-06-30},
	date = {2013-09},
	langid = {english},
	file = {Brady - 2013 - Idris, a general-purpose dependently typed program.pdf:/home/fordrl/Zotero/storage/BUP9HMTA/Brady - 2013 - Idris, a general-purpose dependently typed program.pdf:application/pdf},
}

@inproceedings{harrison_can_1997,
	title = {Can abstract interpretation become a mainstream compiler technology?},
	isbn = {978-3-540-69576-9},
	series = {Lecture Notes in Computer Science},
	abstract = {Abstract interpretation has enormous promise and yet remains at the margins of compiler practice. In this talk I will argue that abstract interpretation cannot become a mainstream compiler technlogy until its computational, algorithmic aspects are as well-developed as its mathematical, foundational aspects have been to date. I will put the problem into perspective by comparing abstract interpretation to dataflow analysis, for which a well-developed body of compuational methods exists. This comparison reveals that abstract interpretation is most appropriately seen as a method for specifying problems (that is, equations to be solved), and not as a method for specifying solutions (that is, algorithms for solving equations). In particular, efficient solution methods for the equations that arise from abstract interpretations are seldom obvious from the surface of the equations themselves. In other words, the “algorithms” that are strongly suggested by an abstract interpretation, in which the semantic domains are viewed as “data structures, the semantic functions as procedures”, and a simple fixed point engine used to integrate these parts into a workable whole, is naive and is at best suitable for use in prototyping program analyzers. This point of view calls into question the casual dismissal of abstract interpretation as inefficient, by questioning what can be inferred about the complexity of an abstract interpretation problem by superficial examination of the domains and semantic functions involved.},
	pages = {395--395},
	booktitle = {Static Analysis},
	publisher = {Springer Berlin Heidelberg},
	author = {Harrison, Luddy},
	editor = {Van Hentenryck, Pascal},
	date = {1997},
	langid = {english},
}

@article{ammarguellat_control-flow_1992,
	title = {A control-flow normalization algorithm and its complexity},
	volume = {18},
	issn = {0098-5589},
	doi = {10.1109/32.126773},
	abstract = {A single method for normalizing the control-flow of programs to facilitate program transformations, program analysis, and automatic parallelization is presented. While previous methods result in programs whose control flowgraphs are reducible, programs normalized by this technique satisfy a stronger condition than reducibility and are therefore simpler in their syntax and structure than with previous methods. In particular, all control-flow cycles are normalized into single-entry, single-exit while loops and all {GOTOs} are eliminated. Furthermore, the method avoids problems of code replication that are characteristic of node-splitting techniques. This restructuring obviates the control dependence graph, since afterwards control dependence relations are manifest in the syntax tree of the program. Transformations that effect this normalization are presented, and the complexity of the method is studied.{\textless}{\textgreater}},
	pages = {237--251},
	number = {3},
	journaltitle = {{IEEE} Transactions on Software Engineering},
	author = {Ammarguellat, Z.},
	date = {1992-03},
	keywords = {graph theory, Algorithm design and analysis, Automatic control, automatic parallelization, complexity, computational complexity, control dependence relations, control flowgraphs, control-flow cycles, control-flow normalization algorithm, Data analysis, {GOTOs}, node-splitting techniques, parallel algorithms, Pathology, Performance analysis, Program processors, structured programming, syntax tree, Tree graphs},
	file = {Ammarguellat - 1992 - A control-flow normalization algorithm and its com.pdf:/home/fordrl/Zotero/storage/ZU9CD6QL/Ammarguellat - 1992 - A control-flow normalization algorithm and its com.pdf:application/pdf;IEEE Xplore Abstract Record:/home/fordrl/Zotero/storage/2W69UCHL/126773.html:text/html},
}

@inproceedings{erosa_taming_1994,
	title = {Taming control flow: a structured approach to eliminating goto statements},
	doi = {10.1109/ICCL.1994.288377},
	shorttitle = {Taming control flow},
	abstract = {In designing optimizing and parallelizing compilers, it is often simpler and more efficient to deal with programs that have structured control flow. Although most programmers naturally program in a structured fashion, there remain many important programs and benchmarks that include some number of goto statements, thus rendering the entire program unstructured. Such unstructured programs cannot be handled with compilers built with analyses and transformations for structured programs. In this paper we present a straight-forward algorithm to structure C programs by eliminating all goto statements. The method works directly on a high-level abstract syntax tree ({AST}) representation of the program and could easily be integrated into any compiler that uses an {AST}-based intermediate representation. The actual algorithm proceeds by eliminating each goto by first applying a sequence of goto-movement transformations followed by the appropriate goto-elimination transformation. We have implemented the method in the {McCAT} ({McGill} Compiler Architecture Testbed) optimizing/parallelizing C compiler and we present experimental results that demonstrate that the method is both efficient and effective.{\textless}{\textgreater}},
	eventtitle = {Proceedings of 1994 {IEEE} International Conference on Computer Languages ({ICCL}'94)},
	pages = {229--240},
	booktitle = {Proceedings of 1994 {IEEE} International Conference on Computer Languages ({ICCL}'94)},
	author = {Erosa, A. M. and Hendren, L. J.},
	date = {1994-05},
	keywords = {Computer science, Optimizing compilers, Program processors, {AST} representation, C language, C programs, control flow, Design optimization, Flow graphs, goto statements, goto-elimination, goto-movement transformations, high-level abstract syntax tree, Information analysis, intermediate representation, {McCAT}, {McGill} Compiler Architecture Testbed, optimizing compilers, parallel programming, parallelizing compilers, program compilers, Programming profession, Software engineering, Software testing, Switches},
	file = {Erosa and Hendren - 1994 - Taming control flow a structured approach to elim.pdf:/home/fordrl/Zotero/storage/P6UHYZ9B/Erosa and Hendren - 1994 - Taming control flow a structured approach to elim.pdf:application/pdf;IEEE Xplore Abstract Record:/home/fordrl/Zotero/storage/6LYT77BR/288377.html:text/html},
}

@article{hoang_spark_2015,
	title = {{SPARK} 2014 and {GNATprove}},
	volume = {17},
	issn = {1433-2787},
	url = {https://doi.org/10.1007/s10009-014-0322-5},
	doi = {10.1007/s10009-014-0322-5},
	abstract = {Extensive and expensive testing is the method most widely used for gaining confidence in safety-critical software. With a few exceptions, such as {SPARK}, formal verification is rarely used in industry due to its high cost and level of skill required. The grand challenge of building a verifying compiler for static formal verification of programs aims at bringing formal verification to non-expert users of powerful programming languages. This challenge has nurtured competition and collaboration among verification tool builders; an example is the {VerifyThis} competition Huisman et al. (http://digbib.ubka.uni-karlsruhe.de/volltexte/1000034373, 2013). In this paper, we describe our approach to popularising formal verification in the design of the {SPARK} 2014 language and the associated formal verification tool {GNATprove}. In particular, we present our solution to combining tests and proofs, which provides a cost-competitive way to develop software to standards such as do-178. At the heart of our technique are executable contracts, and the ability to both test and prove those. We use running examples from the {VerifyThis} 2012 competition and discuss the results of using our tools on those problems.},
	pages = {695--707},
	number = {6},
	journaltitle = {International Journal on Software Tools for Technology Transfer},
	shortjournal = {Int J Softw Tools Technol Transfer},
	author = {Hoang, Duc and Moy, Yannick and Wallenburg, Angela and Chapman, Roderick},
	urldate = {2019-06-11},
	date = {2015-11-01},
	langid = {english},
	keywords = {Static analysis, Program verification, Deductive verification, {SPARK}, Ada, Verifying compiler},
	file = {Hoang et al. - 2015 - SPARK 2014 and GNATprove.pdf:/home/fordrl/Zotero/storage/XPLCF9EM/Hoang et al. - 2015 - SPARK 2014 and GNATprove.pdf:application/pdf},
}

@online{chapman_fumble_nodate,
	title = {The Fumble Programmer},
	url = {https://proteancode.com/wp-content/uploads/2018/02/the_fumble_programmer.pdf},
	abstract = {This paper reflects on the need for formality, discipline and humility in
programming. Starting with the work of Turing, Dijkstra and Humphrey, this paper
goes on to cover our experience with the Personal Software Process, formal pro-
gramming with {SPARK}, and the impact of putting the two together.},
	author = {Chapman, Roderick},
}

@inproceedings{salvia_mixed_2019,
	title = {A Mixed Real and Floating-Point Solver},
	isbn = {978-3-030-20652-9},
	series = {Lecture Notes in Computer Science},
	abstract = {Reasoning about mixed real and floating-point constraints is essential for developing accurate analysis tools for floating-point programs. This paper presents {FPRoCK}, a prototype tool for solving mixed real and floating-point formulas. {FPRoCK} transforms a mixed formula into an equisatisfiable one over the reals. This formula is then solved using an off-the-shelf {SMT} solver. {FPRoCK} is also integrated with the {PRECiSA} static analyzer, which computes a sound estimation of the round-off error of a floating-point program. It is used to detect infeasible computational paths, thereby improving the accuracy of {PRECiSA}.},
	pages = {363--370},
	booktitle = {{NASA} Formal Methods},
	publisher = {Springer International Publishing},
	author = {Salvia, Rocco and Titolo, Laura and Feliú, Marco A. and Moscato, Mariano M. and Muñoz, César A. and Rakamarić, Zvonimir},
	editor = {Badger, Julia M. and Rozier, Kristin Yvonne},
	date = {2019},
	langid = {english},
	file = {nfm2019-stfmmr.pdf:/home/fordrl/Zotero/storage/HWBDNTMV/nfm2019-stfmmr.pdf:application/pdf},
}

@incollection{badger_extracting_2019,
	location = {Cham},
	title = {Extracting and Optimizing Formally Verified Code for Systems Programming},
	volume = {11460},
	isbn = {978-3-030-20651-2 978-3-030-20652-9},
	url = {http://link.springer.com/10.1007/978-3-030-20652-9_15},
	abstract = {{MCQC} is a compiler for extracting veriﬁed systems programs to low-level assembly, with no runtime or garbage collection requirements and an emphasis on performance. {MCQC} targets the Gallina functional language used in the Coq proof assistant. {MCQC} translates pure and recursive functions into C++17, while compiling monadic eﬀectful functions to imperative C++ system calls. With a few memory and performance optimizations, {MCQC} combines veriﬁability with memory and runtime performance. By handling eﬀectful and pure functions separately {MCQC} can generate executable veriﬁed code directly from Gallina, reducing the eﬀort of implementing and executing veriﬁed systems.},
	pages = {228--236},
	booktitle = {{NASA} Formal Methods},
	publisher = {Springer International Publishing},
	author = {Ioannidis, Eleftherios and Kaashoek, Frans and Zeldovich, Nickolai},
	editor = {Badger, Julia M. and Rozier, Kristin Yvonne},
	urldate = {2019-06-07},
	date = {2019},
	langid = {english},
	doi = {10.1007/978-3-030-20652-9_15},
	file = {Ioannidis et al. - 2019 - Extracting and Optimizing Formally Verified Code f.pdf:/home/fordrl/Zotero/storage/2F9TQKXK/Ioannidis et al. - 2019 - Extracting and Optimizing Formally Verified Code f.pdf:application/pdf},
}

@inproceedings{fleury_optimizing_2019,
	title = {Optimizing a Verified {SAT} Solver},
	isbn = {978-3-030-20652-9},
	series = {Lecture Notes in Computer Science},
	abstract = {In previous work, I verified a {SAT} solver with dedicated imperative data structures, including the two-watched-literal scheme. In this paper, I extend this formalization with four additional optimizations. The approach is still based on refining an abstract calculus to a deterministic program. In turn, an imperative version is synthesized from the latter, which is then exported to Standard {ML}. The first optimization is the extension with blocking literals. Then, the memory management is improved in order to implement the heuristics necessary to implement search restart and forget, which were subsequently implemented. This required changes to the abstract calculus. Finally, the solver uses machine words until they overflow before switching to unbounded integers. Performance has improved and is now closer to {MiniSAT} without preprocessing.},
	pages = {148--165},
	booktitle = {{NASA} Formal Methods},
	publisher = {Springer International Publishing},
	author = {Fleury, Mathias},
	editor = {Badger, Julia M. and Rozier, Kristin Yvonne},
	date = {2019},
	langid = {english},
}

@incollection{badger_towards_2019,
	location = {Cham},
	title = {Towards Full Proof Automation in Frama-C Using Auto-active Verification},
	volume = {11460},
	isbn = {978-3-030-20651-2 978-3-030-20652-9},
	url = {http://link.springer.com/10.1007/978-3-030-20652-9_6},
	abstract = {While deductive veriﬁcation is increasingly used on real-life code, making it fully automatic remains difﬁcult. The development of powerful {SMT} solvers has improved the situation, but some proofs still require interactive theorem provers in order to achieve full formal veriﬁcation. Auto-active veriﬁcation relies on additional guiding annotations (assertions, ghost code, lemma functions, etc.) and provides an important step towards a greater automation of the proof. However, the support of this methodology often remains partial and depends on the veriﬁcation tool. This paper presents an experience report on a complete functional veriﬁcation of several C programs from the literature and real-life code using auto-active veriﬁcation with the C software analysis platform {FRAMA}-C and its deductive veriﬁcation plugin {WP}. The goal is to use automatic solvers to verify properties that are classically veriﬁed with interactive provers. Based on our experience, we discuss the beneﬁts of this methodology and the current limitations of the tool, as well as proposals of new features to overcome them.},
	pages = {88--105},
	booktitle = {{NASA} Formal Methods},
	publisher = {Springer International Publishing},
	author = {Blanchard, Allan and Loulergue, Frédéric and Kosmatov, Nikolai},
	editor = {Badger, Julia M. and Rozier, Kristin Yvonne},
	urldate = {2019-06-07},
	date = {2019},
	langid = {english},
	doi = {10.1007/978-3-030-20652-9_6},
	file = {Blanchard et al. - 2019 - Towards Full Proof Automation in Frama-C Using Aut.pdf:/home/fordrl/Zotero/storage/446GURGV/Blanchard et al. - 2019 - Towards Full Proof Automation in Frama-C Using Aut.pdf:application/pdf},
}

@inproceedings{knaggs_practical_1993,
	title = {Practical and theoretical aspects of {FORTH} software development},
	abstract = {This is an investigation into the use of the Forth programming environment. The main areas of enquiry were: interfacing Forth to other languages; interfacing Forth and local area networks; and the use of {RISC} processors with stack based architecture such as the {NC}4000 and Harris {RTX} series. We describe how t o i n terface Forth a n d C. W e also provide a system with a multi-tasking interrupt driven interface to the Ibm {NetBios} networking software and a simple, generic, method of task activation through message passing. Many aspects of the investigation proved to be dependent on a more thorough theoretical underpinning for the Forth language. The use of a typeless parameter stack means that a programmer must concern himself with the intellectual burden of managing the parameter stack. The mismatching of stack elements can be the cause of subtle logic errors. We therefore investigated the possibility o f d e v eloping a type algebra" that would allow u s t o d e v elop a typed version of Forth. This thesis includes a theory for a type signature algebra" for the stack based argument passing method used by Forth. To support the use of multi-tasking we provide a simple, but formal, theory of concurrent tasks based on state machines that synchronise on events. This has a graphical notation for people who are not familiar with formal notations. We also looked at how formalisms might be used to deene a semantic model for the Forth language and how formalisms can help to deene the relationship between Forth's stack based virtual machine and register based target processors.},
	author = {Knaggs, Peter J.},
	date = {1993},
	keywords = {Central processing unit, Computer multitasking, Forth, Graphical user interface, Harris affine region detector, Integrated development environment, Message passing, {NetBIOS}, Programmer, Software development, Type signature, Virtual machine},
	file = {Full Text PDF:/home/fordrl/Zotero/storage/2YVPZMA2/Knaggs - 1993 - Practical and theoretical aspects of FORTH softwar.pdf:application/pdf},
}

@inproceedings{stoddart_forth_2012,
	title = {Forth Semantics for Compiler Verification},
	abstract = {Here we are interested in the semantics of Forth from the point of view of using Forth as a target language for a formally verified compiler for Ruth-R, a reversible sequential programming language we are currently developing. We limit out attention to those Forth operations and constructs which will be targetted by the Ruth-R compiler. To facilitate the comparison of meanings of source and target languages, we represent the semantics of Forth code by translation into a form which can be described using the ”prospective value” semantics we use for Ruth-R.},
	author = {Stoddart, Bill and Ritchie, C. and Dunne, Steve},
	date = {2012},
	keywords = {Compiler, Concurrent computing, Formal verification, Foundations, {HL}7PublishingSubSection {\textless}operations{\textgreater}, Programming language, Prospective search, Verification of Theories},
	file = {Full Text PDF:/home/fordrl/Zotero/storage/9HJDEX34/Stoddart et al. - 2012 - Forth Semantics for Compiler Verification.pdf:application/pdf},
}

@incollection{hutchison_picard_2013,
	location = {Berlin, Heidelberg},
	title = {The Picard Algorithm for Ordinary Differential Equations in Coq},
	volume = {7998},
	isbn = {978-3-642-39633-5 978-3-642-39634-2},
	url = {http://link.springer.com/10.1007/978-3-642-39634-2_34},
	abstract = {Ordinary Diﬀerential Equations ({ODEs}) are ubiquitous in physical applications of mathematics. The Picard-Lindelo¨f theorem is the ﬁrst fundamental theorem in the theory of {ODEs}. It allows one to solve diﬀerential equations numerically. We provide a constructive development of the Picard-Lindelo¨f theorem which includes a program together with suﬃcient conditions for its correctness. The proof/program is written in the Coq proof assistant and uses the implementation of eﬃcient real numbers from the {CoRN} library and the {MathClasses} library. Our proof makes heavy use of operators and functionals, functions on spaces of functions. This is faithful to the usual mathematical description, but a novel level of abstraction for certiﬁed exact real computation.},
	pages = {463--468},
	booktitle = {Interactive Theorem Proving},
	publisher = {Springer Berlin Heidelberg},
	author = {Makarov, Evgeny and Spitters, Bas},
	editor = {Blazy, Sandrine and Paulin-Mohring, Christine and Pichardie, David},
	editorb = {Hutchison, David and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M. and Mattern, Friedemann and Mitchell, John C. and Naor, Moni and Nierstrasz, Oscar and Pandu Rangan, C. and Steffen, Bernhard and Sudan, Madhu and Terzopoulos, Demetri and Tygar, Doug and Vardi, Moshe Y. and Weikum, Gerhard},
	editorbtype = {redactor},
	urldate = {2019-05-26},
	date = {2013},
	langid = {english},
	doi = {10.1007/978-3-642-39634-2_34},
	file = {Makarov and Spitters - 2013 - The Picard Algorithm for Ordinary Differential Equ.pdf:/home/fordrl/Zotero/storage/6J3Y858E/Makarov and Spitters - 2013 - The Picard Algorithm for Ordinary Differential Equ.pdf:application/pdf},
}

@incollection{davenport_computer_2011,
	location = {Berlin, Heidelberg},
	title = {Computer Certified Efficient Exact Reals in Coq},
	volume = {6824},
	isbn = {978-3-642-22672-4 978-3-642-22673-1},
	url = {http://link.springer.com/10.1007/978-3-642-22673-1_7},
	abstract = {Floating point operations are fast, but require continuous effort on the part of the user in order to ensure that the results are correct. This burden can be shifted away from the user by providing a library of exact analysis in which the computer handles the error estimates. We provide an implementation of the exact real numbers in the Coq proof assistant. This improves on the earlier Coq-implementation by O’Connor in two ways: we use dyadic rationals built from the machine integers and we optimize computation of power series by using approximate division. Moreover, we use type classes for clean mathematical interfaces. This appears to be the ﬁrst time that type classes are used in heavy computation. We obtain over a 100 times speed up of the basic operations and indications for improving the Coq system.},
	pages = {90--106},
	booktitle = {Intelligent Computer Mathematics},
	publisher = {Springer Berlin Heidelberg},
	author = {Krebbers, Robbert and Spitters, Bas},
	editor = {Davenport, James H. and Farmer, William M. and Urban, Josef and Rabe, Florian},
	urldate = {2019-05-26},
	date = {2011},
	langid = {english},
	doi = {10.1007/978-3-642-22673-1_7},
	file = {Krebbers and Spitters - 2011 - Computer Certified Efficient Exact Reals in Coq.pdf:/home/fordrl/Zotero/storage/LEETDCJM/Krebbers and Spitters - 2011 - Computer Certified Efficient Exact Reals in Coq.pdf:application/pdf},
}

@article{rand_formally_nodate,
	title = {Formally Verified Quantum Programming},
	pages = {222},
	author = {Rand, Robert},
	langid = {english},
	file = {Rand - Formally Verified Quantum Programming.pdf:/home/fordrl/Zotero/storage/RLFBPD4Y/Rand - Formally Verified Quantum Programming.pdf:application/pdf},
}

@article{mansky_verifying_nodate,
	title = {Verifying Concurrent Programs with {VST}},
	pages = {15},
	author = {Mansky, William},
	langid = {english},
	file = {Mansky - Verifying Concurrent Programs with VST.pdf:/home/fordrl/Zotero/storage/FZQ3YMV8/Mansky - Verifying Concurrent Programs with VST.pdf:application/pdf},
}

@inproceedings{koh_c_2019,
	location = {New York, {NY}, {USA}},
	title = {From C to Interaction Trees: Specifying, Verifying, and Testing a Networked Server},
	isbn = {978-1-4503-6222-1},
	url = {http://doi.acm.org/10.1145/3293880.3294106},
	doi = {10.1145/3293880.3294106},
	series = {{CPP} 2019},
	shorttitle = {From C to Interaction Trees},
	abstract = {We present the first formal verification of a networked server implemented in C. Interaction trees, a general structure for representing reactive computations, are used to tie together disparate verification and testing tools (Coq, {VST}, and {QuickChick}) and to axiomatize the behavior of the operating system on which the server runs ({CertiKOS}). The main theorem connects a specification of acceptable server behaviors, written in a straightforward “one client at a time” style, with the {CompCert} semantics of the C program. The variability introduced by low-level buffering of messages and interleaving of multiple {TCP} connections is captured using network refinement, a variant of observational refinement.},
	pages = {234--248},
	booktitle = {Proceedings of the 8th {ACM} {SIGPLAN} International Conference on Certified Programs and Proofs},
	publisher = {{ACM}},
	author = {Koh, Nicolas and Li, Yao and Li, Yishuai and Xia, Li-yao and Beringer, Lennart and Honoré, Wolf and Mansky, William and Pierce, Benjamin C. and Zdancewic, Steve},
	urldate = {2019-05-26},
	date = {2019},
	note = {event-place: Cascais, Portugal},
	keywords = {formal verification, interaction trees, network refinement, {QuickChick}, {TCP}, testing, {VST}},
	file = {ACM Full Text PDF:/home/fordrl/Zotero/storage/G7MPS9TF/Koh et al. - 2019 - From C to Interaction Trees Specifying, Verifying.pdf:application/pdf},
}

@inproceedings{da_rocha_pinto_tada:_2014,
	title = {{TaDA}: A Logic for Time and Data Abstraction},
	isbn = {978-3-662-44202-9},
	series = {Lecture Notes in Computer Science},
	shorttitle = {{TaDA}},
	abstract = {To avoid data races, concurrent operations should either be at distinct times or on distinct data. Atomicity is the abstraction that an operation takes effect at a single, discrete instant in time, with linearisability being a well-known correctness condition which asserts that concurrent operations appear to behave atomically. Disjointness is the abstraction that operations act on distinct data resource, with concurrent separation logics enabling reasoning about threads that appear to operate independently on disjoint resources.We present {TaDA}, a program logic that combines the benefits of abstract atomicity and abstract disjointness. Our key contribution is the introduction of atomic triples, which offer an expressive approach to specifying program modules. By building up examples, we show that {TaDA} supports elegant modular reasoning in a way that was not previously possible.},
	pages = {207--231},
	booktitle = {{ECOOP} 2014 – Object-Oriented Programming},
	publisher = {Springer Berlin Heidelberg},
	author = {da Rocha Pinto, Pedro and Dinsdale-Young, Thomas and Gardner, Philippa},
	editor = {Jones, Richard},
	date = {2014},
	langid = {english},
	keywords = {Abstract State, Data Abstraction, Label Transition System, Proof Rule, Shared Region},
	file = {da Rocha Pinto et al. - 2014 - TaDA A Logic for Time and Data Abstraction.pdf:/home/fordrl/Zotero/storage/YXE6B83X/da Rocha Pinto et al. - 2014 - TaDA A Logic for Time and Data Abstraction.pdf:application/pdf},
}

@article{hughes_why_1989,
	title = {Why Functional Programming Matters},
	volume = {32},
	issn = {0010-4620, 1460-2067},
	url = {https://academic.oup.com/comjnl/article-lookup/doi/10.1093/comjnl/32.2.98},
	doi = {10.1093/comjnl/32.2.98},
	abstract = {As software becomes more and more complex, it is more and more important to structure it well. Well-structured software is easy to write and to debug, and provides a collection of modules that can be reused to reduce future programming costs. In this paper we show that two features of functional languages in particular, higher-order functions and lazy evaluation, can contribute signiﬁcantly to modularity. As examples, we manipulate lists and trees, program several numerical algorithms, and implement the alpha-beta heuristic (an algorithm from Artiﬁcial Intelligence used in game-playing programs). We conclude that since modularity is the key to successful programming, functional programming oﬀers important advantages for software development.},
	pages = {98--107},
	number = {2},
	journaltitle = {The Computer Journal},
	author = {Hughes, J.},
	urldate = {2019-05-26},
	date = {1989-02-01},
	langid = {english},
	file = {Hughes - 1989 - Why Functional Programming Matters.pdf:/home/fordrl/Zotero/storage/3LZ6DT3E/Hughes - 1989 - Why Functional Programming Matters.pdf:application/pdf},
}

@article{noauthor_ieee_nodate,
	title = {{IEEE} Std 754™-2008 (Revision of {IEEE} Std 754-1985), {IEEE} Standard for Floating-Point Arithmetic},
	abstract = {Abstract: This standard specifies interchange and arithmetic formats and methods for binary and decimal floating-point arithmetic in computer programming environments. This standard specifies exception conditions and their default handling. An implementation of a floating-point system conforming to this standard may be realized entirely in software, entirely in hardware, or in any combination of software and hardware. For operations specified in the normative part of this standard, numerical results and exceptions are uniquely determined by the values of the input data, sequence of operations, and destination formats, all under user control.},
	pages = {70},
	langid = {english},
	file = {IEEE Std 754™-2008 (Revision of IEEE Std 754-1985).pdf:/home/fordrl/Zotero/storage/MT5IUVF8/IEEE Std 754™-2008 (Revision of IEEE Std 754-1985).pdf:application/pdf},
}

@report{noauthor_ieee_nodate-1,
	title = {{IEEE} Standard for Universal Verification Methodology Language Reference Manual},
	url = {http://ieeexplore.ieee.org/document/7932212/},
	abstract = {The Universal Verification Methodology ({UVM}) that can improve interoperability, reduce the cost of using intellectual property ({IP}) for new projects or electronic design automation ({EDA}) tools, and make it easier to reuse verification components is provided. Overall, using this standard will lower verification costs and improve design quality throughout the industry. The primary audiences for this standard are the implementors of the {UVM} base class library, the implementors of tools supporting the {UVM} base class library, and the users of the {UVM} base class library.},
	institution = {{IEEE}},
	urldate = {2019-05-26},
	langid = {english},
	doi = {10.1109/IEEESTD.2017.7932212},
	file = {IEEE Standard for Universal Verification Methodolo.pdf:/home/fordrl/Zotero/storage/6F8A2Z6Y/IEEE Standard for Universal Verification Methodolo.pdf:application/pdf},
}

@article{noauthor_ieee_nodate-2,
	title = {{IEEE} Std 1800™-2012 (Revision of {IEEE} Std 1800-2009) {IEEE} Standard for {SystemVerilog}—Unified Hardware Design, Specification, and Verification Language},
	abstract = {Abstract: The definition of the language syntax and semantics for {SystemVerilog}, which is a unified hardware design, specification, and verification language, is provided. This standard includes support for modeling hardware at the behavioral, register transfer level ({RTL}), and gate-level abstraction levels, and for writing testbenches using coverage, assertions, object-oriented programming, and constrained random verification. The standard also provides application programming interfaces ({APIs}) to foreign programming languages.},
	pages = {1315},
	langid = {english},
	file = {IEEE Std 1800™-2012 (Revision of IEEE Std 1800-200.pdf:/home/fordrl/Zotero/storage/88A583HL/IEEE Std 1800™-2012 (Revision of IEEE Std 1800-200.pdf:application/pdf},
}

@online{noauthor_handbook_nodate,
	title = {Handbook Of Floating Point Arithmetic Download {eBook} for Free},
	url = {http://ebook4scaricare.com/gratis/handbook-of-floating-point-arithmetic/},
	abstract = {Download handbook of floating point arithmetic ebook free in {PDF} and {EPUB} Format. handbook of floating point arithmetic also available in docx and mobi. Read handbook of floating point arithmetic online, read in mobile or Kindle.},
	urldate = {2019-05-26},
	langid = {american},
	file = {Handbook Of Floating Point Arithmetic Download eBo.pdf:/home/fordrl/Zotero/storage/F24UXIX3/Handbook Of Floating Point Arithmetic Download eBo.pdf:application/pdf},
}

@book{chailloux_developing_2000,
	location = {Paris},
	title = {Developing Applications with Objective Caml},
	isbn = {978-2-84177-121-9},
	publisher = {O'Reilly},
	author = {Chailloux, Emmanuel and Manoury, Pascal and Pagano, Bruno},
	date = {2000},
	langid = {english},
	note = {{OCLC}: 803160552},
	file = {Chailloux et al. - 2000 - Développement d'applications avec objective caml.pdf:/home/fordrl/Zotero/storage/MUB2AMXF/Chailloux et al. - 2000 - Développement d'applications avec objective caml.pdf:application/pdf},
}

@inproceedings{bidmeshki_vericoq:_2015,
	location = {Lisbon, Portugal},
	title = {{VeriCoq}: A Verilog-to-Coq converter for proof-carrying hardware automation},
	isbn = {978-1-4799-8391-9},
	url = {http://ieeexplore.ieee.org/document/7168562/},
	doi = {10.1109/ISCAS.2015.7168562},
	shorttitle = {{VeriCoq}},
	abstract = {Proof carrying hardware intellectual property ({PCHIP}) introduces a new framework in which a hardware (semiconductor) Intellectual Property ({IP}) is accompanied by formal proofs of certain security-related properties, ensuring that the acquired {IP} is trustworthy and free from hardware Trojans. In the {PCHIP} framework, conversion of the design from a hardware description language ({HDL}) to a formal representation is an essential step. Towards automating this process, herein we introduce {VeriCoq}, a converter of designs described in Register Transfer Level ({RTL}) Verilog to their corresponding representation in the Coq theorem proving language, based on the rules deﬁned in the {PCHIP} framework. {VeriCoq} supports most of the synthesizable Verilog constructs and is the ﬁrst step towards automating the entire framework, in order to simplify adoption of {PCHIP} by hardware {IP} developers and consumers and, thereby, increase {IP} trustworthiness.},
	eventtitle = {2015 {IEEE} International Symposium on Circuits and Systems ({ISCAS})},
	pages = {29--32},
	booktitle = {2015 {IEEE} International Symposium on Circuits and Systems ({ISCAS})},
	publisher = {{IEEE}},
	author = {Bidmeshki, Mohammad-Mahdi and Makris, Yiorgos},
	urldate = {2019-05-26},
	date = {2015-05},
	langid = {english},
	file = {Bidmeshki and Makris - 2015 - VeriCoq A Verilog-to-Coq converter for proof-carr.pdf:/home/fordrl/Zotero/storage/3CDKTVGC/Bidmeshki and Makris - 2015 - VeriCoq A Verilog-to-Coq converter for proof-carr.pdf:application/pdf},
}

@article{braibant_formal_2013,
	title = {Formal Verification of Hardware Synthesis},
	volume = {8044},
	url = {http://arxiv.org/abs/1301.4779},
	doi = {10.1007/978-3-642-39799-8_14},
	abstract = {We report on the implementation of a certified compiler for a high-level hardware description language ({HDL}) called Fe-Si ({FEatherweight} {SynthesIs}). Fe-Si is a simplified version of Bluespec, an {HDL} based on a notion of guarded atomic actions. Fe-Si is defined as a dependently typed deep embedding in Coq. The target language of the compiler corresponds to a synthesisable subset of Verilog or {VHDL}. A key aspect of our approach is that input programs to the compiler can be defined and proved correct inside Coq. Then, we use extraction and a Verilog back-end (written in {OCaml}) to get a certified version of a hardware design.},
	pages = {213--228},
	journaltitle = {{arXiv}:1301.4779 [cs]},
	author = {Braibant, Thomas and Chlipala, Adam},
	urldate = {2019-05-26},
	date = {2013},
	eprinttype = {arxiv},
	eprint = {1301.4779},
	keywords = {Computer Science - Programming Languages},
	file = {arXiv.org Snapshot:/home/fordrl/Zotero/storage/BAK6PZ7I/1301.html:text/html;arXiv\:1301.4779 PDF:/home/fordrl/Zotero/storage/M6XE2T6F/Braibant and Chlipala - 2013 - Formal Verification of Hardware Synthesis.pdf:application/pdf},
}

@book{power_formal_nodate,
	title = {A Formal Model of Forth Control Words in the Pi-Calculus},
	abstract = {Abstract: In this paper we develop a formal specification of aspects of the Forth programming language. We describe the operation of the Forth compiler as it translates Forth control words, dealing in particular with the interpretation of immediate words during compilation. Our goal here is to provide a basis for the study of safety properties of embedded systems, many of which are constructed using Forth or Forth-like languages. To this end we construct a model of the Forth compiler in the π-calculus, and have simulated its execution by animating this model using the Pict programming language.},
	author = {Power, James F. and Sinclair, David},
	file = {Citeseer - Full Text PDF:/home/fordrl/Zotero/storage/RXSMBBXT/Power and Sinclair - A Formal Model of Forth Control Words in the Pi-Ca.pdf:application/pdf;Citeseer - Snapshot:/home/fordrl/Zotero/storage/PB52X8ZE/summary.html:text/html},
}

@article{poial_forth_nodate,
	title = {Forth and Formal Language Theory},
	abstract = {Forth is an excellent programming paradigm, but it is also an interesting object of investigation for formal language theory. With its clear interface based on stacks Forth programs are easily generated by some formal system (e.g. syntax directed translation scheme). Usually it is possible to make such a formal system to generate only "useful" programs, but this subset of programs is often very small and does not cover interesting features of the Forth language itself.},
	pages = {6},
	author = {Poial, Jaanus},
	langid = {english},
	file = {Poial - Forth and Formal Language Theory.pdf:/home/fordrl/Zotero/storage/BBWF7DFT/Poial - Forth and Formal Language Theory.pdf:application/pdf},
}

@online{noauthor_algebraic_nodate,
	title = {Algebraic Specification of Stack Effects for Forth Programs},
	url = {https://www.researchgate.net/publication/269399251_Algebraic_Specification_of_Stack_Effects_for_Forth_Programs},
	abstract = {{ResearchGate} is a network dedicated to science and research. Connect, collaborate and discover scientific publications, jobs and conferences. All for free.},
	titleaddon = {{ResearchGate}},
	urldate = {2019-05-26},
	langid = {english},
}

@online{noauthor_ghc_nodate,
	title = {{GHC} User’s Guide — Glasgow Haskell Compiler 8.6.5 User's Guide},
	url = {https://downloads.haskell.org/~ghc/latest/docs/html/users_guide/index.html},
	urldate = {2019-05-26},
	file = {Welcome to the GHC User’s Guide — Glasgow Haskell Compiler 8.6.5 User's Guide:/home/fordrl/Zotero/storage/F8SX6JFV/index.html:text/html},
}

@article{jung_iris_2018-1,
	title = {Iris from the ground up: A modular foundation for higher-order concurrent separation logic},
	volume = {28},
	issn = {0956-7968, 1469-7653},
	url = {https://www.cambridge.org/core/product/identifier/S0956796818000151/type/journal_article},
	doi = {10.1017/S0956796818000151},
	shorttitle = {Iris from the ground up},
	abstract = {Iris is a framework for higher-order concurrent separation logic, which has been implemented in the Coq proof assistant and deployed very effectively in a wide variety of veriﬁcation projects. Iris was designed with the express goal of simplifying and consolidating the foundations of modern separation logics, but it has evolved over time, and the design and semantic foundations of Iris itself have yet to be fully written down and explained together properly in one place. Here, we attempt to ﬁll this gap, presenting a reasonably complete picture of the latest version of Iris (version 3.1), from ﬁrst principles and in one coherent narrative.},
	journaltitle = {Journal of Functional Programming},
	author = {Jung, Ralf and Krebbers, Robbert and Jourdan, Jacques-Henri and Bizjak, Aleš and Birkedal, Lars and Dreyer, Derek},
	urldate = {2019-05-26},
	date = {2018},
	langid = {english},
	file = {Jung et al. - 2018 - Iris from the ground up A modular foundation for .pdf:/home/fordrl/Zotero/storage/F8IP6QRI/Jung et al. - 2018 - Iris from the ground up A modular foundation for .pdf:application/pdf},
}

@inproceedings{menon_shakti-t:_2017,
	location = {New York, {NY}, {USA}},
	title = {Shakti-T: A {RISC}-V Processor with Light Weight Security Extensions},
	isbn = {978-1-4503-5266-6},
	url = {http://doi.acm.org/10.1145/3092627.3092629},
	doi = {10.1145/3092627.3092629},
	series = {{HASP} '17},
	shorttitle = {Shakti-T},
	abstract = {With increased usage of compute cores for sensitive applications, including e-commerce, there is a need to provide additional hardware support for securing information from memory based attacks. This work presents a unified hardware framework for handling spatial and temporal memory attacks. The paper integrates the proposed hardware framework with a {RISC}-V based micro-architecture with an enhanced application binary interface that enables software layers to use these features to protect sensitive data. We demonstrate the effectiveness of the proposed scheme through practical case studies in addition to taking the design through a {VLSI} {CAD} design flow. The proposed processor reduces the metadata storage overhead up to 4 x in comparison with the existing solutions, while incurring an area overhead of just 1914 {LUTs} and 2197 flip flops on an {FPGA}, without affecting the critical path delay of the processor.},
	pages = {2:1--2:8},
	booktitle = {Proceedings of the Hardware and Architectural Support for Security and Privacy},
	publisher = {{ACM}},
	author = {Menon, Arjun and Murugan, Subadra and Rebeiro, Chester and Gala, Neel and Veezhinathan, Kamakoti},
	urldate = {2019-05-26},
	date = {2017},
	note = {event-place: Toronto, {ON}, Canada},
	keywords = {Buffer Overflow, Memory Security, Secure Processor Architecture, Spatial Attacks, Tagged Architecture, Temporal Attacks},
	file = {ACM Full Text PDF:/home/fordrl/Zotero/storage/R3FUM3FC/Menon et al. - 2017 - Shakti-T A RISC-V Processor with Light Weight Sec.pdf:application/pdf},
}

@inproceedings{montagu_theory_2013,
	title = {A Theory of Information-Flow Labels},
	doi = {10.1109/CSF.2013.8},
	abstract = {The security literature offers a multitude of calculi, languages, and systems for information-flow control, each with some set of labels encoding security policies that can be attached to data and computations. The exact form of these labels varies widely, with different systems offering many different combinations of features addressing issues such as confidentiality, integrity, and policy ownership. This variation makes it difficult to compare the expressive power of different information-flow frameworks. To enable such comparisons, we introduce label algebras, an abstract interface for information-flow labels equipped with a notion of authority, and study several notions of embedding between them. The simplest is a straightforward notion of injection between label algebras, but this lacks a clear computational motivation and rejects some reasonable encodings between label models. We obtain a more refined account by defining a space of encodings parameterized by an interpretation of labels and authorities, thus giving a semantic flavor to the definition of encoding. We study the theory of semantic encodings and consider two specific instances, one based on the possible observations of boolean values and one based on the behavior of programs in a small lambda-calculus parameterized over an arbitrary label algebra. We use this framework to define and compare a number of concrete label algebras, including realizations of the familiar taint, endorsement, readers, and distrust models, as well as label algebras based on several existing programming languages and operating systems.},
	eventtitle = {2013 {IEEE} 26th Computer Security Foundations Symposium},
	pages = {3--17},
	booktitle = {2013 {IEEE} 26th Computer Security Foundations Symposium},
	author = {Montagu, B. and Pierce, B. C. and Pollack, R.},
	date = {2013-06},
	keywords = {Security, Semantics, Languages, Syntactics, programming languages, information-flow control, Algebra, Asbestos, Boolean algebra, Boolean values, calculus, computational motivation, decentralized label model ({DLM}), Design, {DIFC}, disjunction category model, encoding, Encoding, Flume, {HiStar}, Information flow control ({IFC}), information-flow frameworks, information-flow labels, {JIF}, label algebras, label models, labels encoding security policies, lambda-calculus, Lattices, {LIO}, Observers, operating systems, semantic encodings theory, telecommunication security, Theory},
	file = {IEEE Xplore Abstract Record:/home/fordrl/Zotero/storage/RBVYSQD8/6595817.html:text/html;IEEE Xplore Full Text PDF:/home/fordrl/Zotero/storage/82XHQZSG/Montagu et al. - 2013 - A Theory of Information-Flow Labels.pdf:application/pdf},
}

@unpublished{lescuyer_provencore:_2015,
	title = {{ProvenCore}: Towards a Verified Isolation Micro-Kernel},
	url = {https://zenodo.org/record/47990#.XOrmF-tKi24},
	shorttitle = {{ProvenCore}},
	abstract = {We report on an ongoing project aiming at a fully secure micro-kernel named {ProvenCore}. This operating system is both developed and specified in a single specification language called Smart. The Smart models are used to generate efficient C code and express low- and high-level properties of the implementation, and first among them guarantees of integrity and confidentiality for the various processes running on the kernel. {ProvenCore} is designed to be used as a secure world operating system in mobile devices, beneath a professional application platform or a Trusted Execution Environment.},
	author = {Lescuyer, Stéphane},
	urldate = {2019-05-26},
	date = {2015-01-20},
	keywords = {Certification Toolchain, Formal Proof, Isolation, Separation Kernel,},
	file = {Zenodo Full Text PDF:/home/fordrl/Zotero/storage/QQ2KC8RM/Lescuyer - 2015 - ProvenCore Towards a Verified Isolation Micro-Ker.pdf:application/pdf},
}

@article{lescuyer_provencore:_nodate,
	title = {{ProvenCore}: Towards a Verified Isolation Micro-Kernel},
	pages = {69},
	author = {Lescuyer, Stéphane},
	langid = {english},
	file = {Lescuyer - ProvenCore Towards a Verified Isolation Micro-Ker.pdf:/home/fordrl/Zotero/storage/IVKJ3U5P/Lescuyer - ProvenCore Towards a Verified Isolation Micro-Ker.pdf:application/pdf},
}

@inproceedings{goguen_unwinding_1984,
	location = {Oakland, {CA}, {USA}},
	title = {Unwinding and Inference Control},
	isbn = {978-0-8186-0532-1},
	url = {http://ieeexplore.ieee.org/document/6234812/},
	doi = {10.1109/SP.1984.10019},
	eventtitle = {1984 {IEEE} Symposium on Security and Privacy},
	pages = {75--75},
	booktitle = {1984 {IEEE} Symposium on Security and Privacy},
	publisher = {{IEEE}},
	author = {Goguen, Joseph A. and Meseguer, Jose},
	urldate = {2019-05-26},
	date = {1984-04},
	langid = {english},
	file = {Goguen and Meseguer - 1984 - Unwinding and Inference Control.pdf:/home/fordrl/Zotero/storage/4GBIR6L2/Goguen and Meseguer - 1984 - Unwinding and Inference Control.pdf:application/pdf},
}

@incollection{jajodia_termination-insensitive_2008,
	location = {Berlin, Heidelberg},
	title = {Termination-Insensitive Noninterference Leaks More Than Just a Bit},
	volume = {5283},
	isbn = {978-3-540-88312-8 978-3-540-88313-5},
	url = {http://link.springer.com/10.1007/978-3-540-88313-5_22},
	abstract = {Current tools for analysing information ﬂow in programs build upon ideas going back to Denning’s work from the 70’s. These systems enforce an imperfect notion of information ﬂow which has become known as terminationinsensitive noninterference. Under this version of noninterference, information leaks are permitted if they are transmitted purely by the program’s termination behaviour (i.e., whether it terminates or not). This imperfection is the price to pay for having a security condition which is relatively liberal (e.g. allowing whileloops whose termination may depend on the value of a secret) and easy to check. But what is the price exactly? We argue that, in the presence of output, the price is higher than the “one bit” often claimed informally in the literature, and effectively such programs can leak all of their secrets. In this paper we develop a deﬁnition of termination-insensitive noninterference suitable for reasoning about programs with outputs. We show that the deﬁnition generalises “batch-job” style deﬁnitions from the literature and that it is indeed satisﬁed by a Denning-style program analysis with output. Although more than a bit of information can be leaked by programs satisfying this condition, we show that the best an attacker can do is a brute-force attack, which means that the attacker cannot reliably (in a technical sense) learn the secret in polynomial time in the size of the secret. If we further assume that secrets are uniformly distributed, we show that the advantage the attacker gains when guessing the secret after observing a polynomial amount of output is negligible in the size of the secret.},
	pages = {333--348},
	booktitle = {Computer Security - {ESORICS} 2008},
	publisher = {Springer Berlin Heidelberg},
	author = {Askarov, Aslan and Hunt, Sebastian and Sabelfeld, Andrei and Sands, David},
	editor = {Jajodia, Sushil and Lopez, Javier},
	urldate = {2019-05-26},
	date = {2008},
	langid = {english},
	doi = {10.1007/978-3-540-88313-5_22},
	file = {Askarov et al. - 2008 - Termination-Insensitive Noninterference Leaks More.pdf:/home/fordrl/Zotero/storage/WPIGF9BJ/Askarov et al. - 2008 - Termination-Insensitive Noninterference Leaks More.pdf:application/pdf},
}

@inproceedings{sjosten_information_2018,
	title = {Information Flow Tracking for Side-Effectful Libraries},
	isbn = {978-3-319-92612-4},
	series = {Lecture Notes in Computer Science},
	abstract = {Dynamic information flow control is a promising technique for ensuring confidentiality and integrity of applications that manipulate sensitive information. While much progress has been made on increasingly powerful programming languages ranging from low-level machine languages to high-level languages for distributed systems, surprisingly little attention has been devoted to libraries and {APIs}. The state of the art is largely an all-or-nothing choice: either a shallow or deep library modeling approach. Seeking to break out of this restrictive choice, we formalize a general mechanism that tracks information flow for a language that includes higher-order functions, structured data types and references. A key feature of our approach is the model heap, a part of the memory, where security information is kept to enable the interaction between the labeled program and the unlabeled library. We provide a proof-of-concept implementation and report on experiments with a file system library. The system has been proved correct using Coq.},
	pages = {141--160},
	booktitle = {Formal Techniques for Distributed Objects, Components, and Systems},
	publisher = {Springer International Publishing},
	author = {Sjösten, Alexander and Hedin, Daniel and Sabelfeld, Andrei},
	editor = {Baier, Christel and Caires, Luís},
	date = {2018},
	langid = {english},
	file = {Sjösten et al. - 2018 - Information Flow Tracking for Side-Effectful Libra.pdf:/home/fordrl/Zotero/storage/IEF5SLLA/Sjösten et al. - 2018 - Information Flow Tracking for Side-Effectful Libra.pdf:application/pdf},
}

@inproceedings{chiricescu_safe:_2013,
	location = {Waltham, {MA}, {USA}},
	title = {{SAFE}: A clean-slate architecture for secure systems},
	isbn = {978-1-4799-1535-4 978-1-4799-3963-3},
	url = {http://ieeexplore.ieee.org/document/6699066/},
	doi = {10.1109/THS.2013.6699066},
	shorttitle = {{SAFE}},
	abstract = {{SAFE} is a large-scale, clean-slate co-design project encompassing hardware architecture, programming languages, and operating systems. Funded by {DARPA}, the goal of {SAFE} is to create a secure computing system from the ground up. {SAFE} hardware provides memory safety, dynamic type checking, and native support for dynamic information ﬂow control. The Breeze programming language leverages the security features of the underlying machine, and the “zero kernel” operating system avoids relying on any single privileged component for overall system security. The {SAFE} project is working towards formally verifying security properties of the runtime software. The {SAFE} system sets a new high-water mark for system security, allowing secure applications to be built on a solid foundation rather than on the inherently vulnerable conventional platforms available today.},
	eventtitle = {2013 {IEEE} International Conference on Technologies for Homeland Security ({HST})},
	pages = {570--576},
	booktitle = {2013 {IEEE} International Conference on Technologies for Homeland Security ({HST})},
	publisher = {{IEEE}},
	author = {Chiricescu, Silviu and {DeHon}, Andre and Demange, Delphine and Iyer, Suraj and Kliger, Aleksey and Morrisett, Greg and Pierce, Benjamin C. and Reubenstein, Howard and Smith, Jonathan M. and Sullivan, Gregory T. and Thomas, Arun and Tov, Jesse and White, Christopher M. and Wittenberg, David},
	urldate = {2019-05-26},
	date = {2013-11},
	langid = {english},
	file = {Chiricescu et al. - 2013 - SAFE A clean-slate architecture for secure system.pdf:/home/fordrl/Zotero/storage/MZKE6TJN/Chiricescu et al. - 2013 - SAFE A clean-slate architecture for secure system.pdf:application/pdf},
}

@article{hedin_perspective_nodate,
	title = {A Perspective on Information-Flow Control},
	abstract = {Information-ﬂow control tracks how information propagates through the program during execution to make sure that the program handles the information securely. Secure information ﬂow is comprised of two related aspects: information conﬁdentiality and information integrity — intuitively pertaining to the reading and writing of the information. The prevailing basic semantic notion of secure information ﬂow is noninterference, demanding independence of public (or, in the case of integrity, trusted) output from secret (or, in the case of integrity, untrusted) input. This document gives an account of the state-of-the-art in conﬁdentiality and integrity policies and their enforcement with a systematic formalization of four dominant formulations of noninterference: termination-insensitive, termination-sensitive, progress-insensitive, and progress-sensitive, cast in the setting of two minimal while languages.},
	pages = {29},
	author = {Hedin, Daniel and Sabelfeld, Andrei},
	langid = {english},
	file = {Hedin and Sabelfeld - A Perspective on Information-Flow Control.pdf:/home/fordrl/Zotero/storage/6KCTTWF6/Hedin and Sabelfeld - A Perspective on Information-Flow Control.pdf:application/pdf},
}

@article{dijkstra_political_1978,
	title = {On a Political Pamphlet from the Middle Ages},
	volume = {3},
	issn = {0163-5948},
	url = {http://doi.acm.org/10.1145/1005888.1005890},
	doi = {10.1145/1005888.1005890},
	pages = {14--16},
	number = {2},
	journaltitle = {{SIGSOFT} Softw. Eng. Notes},
	author = {Dijkstra, Edsger W. and {DeMillo}, R. A. and Lipton, R. J. and Perlis, A J.},
	urldate = {2019-05-26},
	date = {1978-04},
	file = {ACM Full Text PDF:/home/fordrl/Zotero/storage/NL8ZHB8J/Dijkstra et al. - 1978 - On a Political Pamphlet from the Middle Ages.pdf:application/pdf},
}

@article{de_millo_social_1979,
	title = {Social Processes and Proofs of Theorems and Programs},
	volume = {22},
	issn = {0001-0782},
	url = {http://doi.acm.org/10.1145/359104.359106},
	doi = {10.1145/359104.359106},
	abstract = {It is argued that formal verifications of programs, no matter how obtained, will not play the same key role in the development of computer science and software engineering as proofs do in mathematics. Furthermore the absence of continuity, the inevitability of change, and the complexity of specification of significantly many real programs make the formal verification process difficult to justify and manage. It is felt that ease of formal verification should not dominate program language design.},
	pages = {271--280},
	number = {5},
	journaltitle = {Commun. {ACM}},
	author = {De Millo, Richard A. and Lipton, Richard J. and Perlis, Alan J.},
	urldate = {2019-05-26},
	date = {1979-05},
	keywords = {formal mathematics, program verification, mathematical proofs, program specification},
	file = {ACM Full Text PDF:/home/fordrl/Zotero/storage/29EX5NRG/De Millo et al. - 1979 - Social Processes and Proofs of Theorems and Progra.pdf:application/pdf},
}

@article{weirich_specification_2017,
	title = {A Specification for Dependent Types in Haskell},
	volume = {1},
	issn = {2475-1421},
	url = {http://doi.acm.org/10.1145/3110275},
	doi = {10.1145/3110275},
	abstract = {We propose a core semantics for Dependent Haskell, an extension of Haskell with full-spectrum dependent types. Our semantics consists of two related languages. The first is a Curry-style dependently-typed language with nontermination, irrelevant arguments, and equality abstraction. The second, inspired by the Glasgow Haskell Compiler's core language {FC}, is its explicitly-typed analogue, suitable for implementation in {GHC}. All of our results---chiefly, type safety, along with theorems that relate these two languages---have been formalized using the Coq proof assistant. Because our work is backwards compatible with Haskell, our type safety proof holds in the presence of nonterminating computation. However, unlike other full-spectrum dependently-typed languages, such as Coq, Agda or Idris, because of this nontermination, Haskell's term language does not correspond to a consistent logic.},
	pages = {31:1--31:29},
	issue = {{ICFP}},
	journaltitle = {Proc. {ACM} Program. Lang.},
	author = {Weirich, Stephanie and Voizard, Antoine and de Amorim, Pedro Henrique Azevedo and Eisenberg, Richard A.},
	urldate = {2019-05-26},
	date = {2017-08},
	keywords = {Haskell, Dependent Types},
	file = {ACM Full Text PDF:/home/fordrl/Zotero/storage/G2TIF5IX/Weirich et al. - 2017 - A Specification for Dependent Types in Haskell.pdf:application/pdf},
}

@thesis{eisenberg_dependent_2016,
	location = {Philadelphia, {PA}, {USA}},
	title = {{DEPENDENT} {TYPES} {IN} {HASKELL}: {THEORY} {AND} {PRACTICE}},
	pagetotal = {351},
	institution = {Pennsylvania},
	type = {phdthesis},
	author = {Eisenberg, Richard A},
	date = {2016},
	langid = {english},
	file = {Eisenberg - DEPENDENT TYPES IN HASKELL THEORY AND PRACTICE.pdf:/home/fordrl/Zotero/storage/6XMQQ2G5/Eisenberg - DEPENDENT TYPES IN HASKELL THEORY AND PRACTICE.pdf:application/pdf},
}

@inproceedings{casinghino_combining_2014,
	location = {New York, {NY}, {USA}},
	title = {Combining Proofs and Programs in a Dependently Typed Language},
	isbn = {978-1-4503-2544-8},
	url = {http://doi.acm.org/10.1145/2535838.2535883},
	doi = {10.1145/2535838.2535883},
	series = {{POPL} '14},
	abstract = {Most dependently-typed programming languages either require that all expressions terminate (e.g. Coq, Agda, and Epigram), or allow infinite loops but are inconsistent when viewed as logics (e.g. Haskell, {ATS}, Ωmega. Here, we combine these two approaches into a single dependently-typed core language. The language is composed of two fragments that share a common syntax and overlapping semantics: a logic that guarantees total correctness, and a call-by-value programming language that guarantees type safety but not termination. The two fragments may interact: logical expressions may be used as programs; the logic may soundly reason about potentially nonterminating programs; programs can require logical proofs as arguments; and "mobile" program values, including proofs computed at runtime, may be used as evidence by the logic. This language allows programmers to work with total and partial functions uniformly, providing a smooth path from functional programming to dependently-typed programming.},
	pages = {33--45},
	booktitle = {Proceedings of the 41st {ACM} {SIGPLAN}-{SIGACT} Symposium on Principles of Programming Languages},
	publisher = {{ACM}},
	author = {Casinghino, Chris and Sjöberg, Vilhelm and Weirich, Stephanie},
	urldate = {2019-05-26},
	date = {2014},
	note = {event-place: San Diego, California, {USA}},
	keywords = {dependent types, termination, general recursion},
	file = {ACM Full Text PDF:/home/fordrl/Zotero/storage/28LRMA7M/Casinghino et al. - 2014 - Combining Proofs and Programs in a Dependently Typ.pdf:application/pdf},
}

@thesis{casinghino_combining_2014-1,
	location = {Philadelphia, {PA}, {USA}},
	title = {Combining Proofs and Programs},
	url = {https://www.seas.upenn.edu/~sweirich/papers/casinghino-thesis.pdf},
	institution = {University of Pennsylvania},
	type = {phdthesis},
	author = {Casinghino, Chris},
	urldate = {2019-05-26},
	date = {2014},
	langid = {english},
	file = {Weirich - 2011 - Combining Proofs and Programs.pdf:/home/fordrl/Zotero/storage/A8VI99N7/Weirich - 2011 - Combining Proofs and Programs.pdf:application/pdf},
}

@article{breitner_ready_2018,
	title = {Ready, Set, Verify! Applying Hs-to-coq to Real-world Haskell Code (Experience Report)},
	volume = {2},
	issn = {2475-1421},
	url = {http://doi.acm.org/10.1145/3236784},
	doi = {10.1145/3236784},
	abstract = {Good tools can bring mechanical verification to programs written in mainstream functional languages. We use {\textless}pre{\textgreater}hs-to-coq{\textless}/pre{\textgreater} to translate significant portions of Haskell’s {\textless}pre{\textgreater}containers{\textless}/pre{\textgreater} library into Coq, and verify it against specifications that we derive from a variety of sources including type class laws, the library’s test suite, and interfaces from Coq’s standard library. Our work shows that it is feasible to verify mature, widely-used, highly optimized, and unmodified Haskell code. We also learn more about the theory of weight-balanced trees, extend {\textless}pre{\textgreater}hs-to-coq{\textless}/pre{\textgreater} to handle partiality, and – since we found no bugs – attest to the superb quality of well-tested functional code.},
	pages = {89:1--89:16},
	issue = {{ICFP}},
	journaltitle = {Proc. {ACM} Program. Lang.},
	author = {Breitner, Joachim and Spector-Zabusky, Antal and Li, Yao and Rizkallah, Christine and Wiegley, John and Weirich, Stephanie},
	urldate = {2019-05-26},
	date = {2018-07},
	keywords = {Coq, verification, Haskell},
	file = {ACM Full Text PDF:/home/fordrl/Zotero/storage/T6BANJL6/Breitner et al. - 2018 - Ready, Set, Verify! Applying Hs-to-coq to Real-wor.pdf:application/pdf},
}

@article{gueneau_formal_nodate,
	title = {Formal Proof and Analysis of an Incremental Cycle Detection Algorithm},
	pages = {23},
	author = {Guéneau, Armaël and Jourdan, Jacques-Henri and Charguéraud, Arthur and Pottier, François},
	langid = {english},
	file = {Guéneau et al. - Formal Proof and Analysis of an Incremental Cycle .pdf:/home/fordrl/Zotero/storage/DGK59PVM/Guéneau et al. - Formal Proof and Analysis of an Incremental Cycle .pdf:application/pdf},
}

@inproceedings{timany_cumulative_2018,
	title = {Cumulative Inductive Types In Coq},
	doi = {10.4230/LIPIcs.FSCD.2018.29},
	abstract = {In order to avoid well-known paradoxes associated with self-referential definitions, higher-order dependent type theories stratify the theory using a countably infinite hierarchy of universes (also known as sorts), Type0 : Type1 : · · · . Such type systems are called cumulative if for any type A we have that A : Typei implies A : Typei+1. The Predicative Calculus of Inductive Constructions ({pCIC}) which forms the basis of the Coq proof assistant, is one such system. In this paper we present the Predicative Calculus of Cumulative Inductive Constructions ({pCuIC}) which extends the cumulativity relation to inductive types. We discuss cumulative inductive types as present in Coq 8.7 and their application to formalization and definitional translations. 2012 {ACM} Subject Classification Theory of computation → Type theory, Theory of computation → Lambda calculus},
	booktitle = {{FSCD}},
	author = {Timany, Amin and Sozeau, Matthieu},
	date = {2018},
	keywords = {Calculi, Calculus of constructions, Coq (software), Dependent type, Inductive type, Proof assistant, Type system},
	file = {Full Text PDF:/home/fordrl/Zotero/storage/BQY5D9QX/Timany and Sozeau - 2018 - Cumulative Inductive Types In Coq.pdf:application/pdf},
}

@article{gilbert_definitional_2019,
	title = {Definitional Proof-irrelevance Without K},
	volume = {3},
	issn = {2475-1421},
	url = {http://doi.acm.org/10.1145/3290316},
	doi = {10.1145/3290316},
	abstract = {Definitional equality—or conversion—for a type theory with a decidable type checking is the simplest tool to prove that two objects are the same, letting the system decide just using computation. Therefore, the more things are equal by conversion, the simpler it is to use a language based on type theory. Proof-irrelevance, stating that any two proofs of the same proposition are equal, is a possible way to extend conversion to make a type theory more powerful. However, this new power comes at a price if we integrate it naively, either by making type checking undecidable or by realizing new axioms—such as uniqueness of identity proofs ({UIP})—that are incompatible with other extensions, such as univalence. In this paper, taking inspiration from homotopy type theory, we propose a general way to extend a type theory with definitional proof irrelevance, in a way that keeps type checking decidable and is compatible with univalence. We provide a new criterion to decide whether a proposition can be eliminated over a type (correcting and improving the so-called singleton elimination of Coq) by using techniques coming from recent development on dependent pattern matching without {UIP}. We show the generality of our approach by providing implementations for both Coq and Agda, both of which are planned to be integrated in future versions of those proof assistants.},
	pages = {3:1--3:28},
	issue = {{POPL}},
	journaltitle = {Proc. {ACM} Program. Lang.},
	author = {Gilbert, Gaëtan and Cockx, Jesper and Sozeau, Matthieu and Tabareau, Nicolas},
	urldate = {2019-05-26},
	date = {2019-01},
	keywords = {proof assistants, proof irrelevance, type theory},
	file = {ACM Full Text PDF:/home/fordrl/Zotero/storage/KN2LAI29/Gilbert et al. - 2019 - Definitional Proof-irrelevance Without K.pdf:application/pdf},
}

@article{sozeau_metacoq_nodate,
	title = {The {MetaCoq} Project},
	abstract = {The {MetaCoq} project1 aims to provide a certiﬁed meta-programming environment in Coq. It builds on Template-Coq, a plugin for Coq originally implemented by Malecha (2014), which provided a reiﬁer for Coq terms and global declarations, as represented in the Coq kernel, as well as a denotation command. Recently, it was used in the {CertiCoq} certiﬁed compiler project (Anand et al., 2017), as its front-end language, to derive parametricity properties (Anand and Morrisett, 2018). However, the syntax lacked semantics, be it typing semantics or operational semantics, which should reﬂect, as formal speciﬁcations in Coq, the semantics of Coq’s type theory itself. The tool was also rather bare bones, providing only rudimentary quoting and unquoting commands. We generalize it to handle the entire Polymorphic Calculus of Cumulative Inductive Constructions ({pCUIC}), as implemented by Coq, including the kernel’s declaration structures for deﬁnitions and inductives, and implement a monad for general manipulation of Coq’s logical environment. We demonstrate how this setup allows Coq users to deﬁne many kinds of general purpose plugins, whose correctness can be readily proved in the system itself, and that can be run eﬃciently after extraction. We give a few examples of implemented plugins, including a parametricity translation and a certifying extraction to call-by-value λ-calculus. We also advocate the use of {MetaCoq} as a foundation for higher-level tools.},
	pages = {39},
	author = {Sozeau, Matthieu},
	langid = {english},
	file = {Sozeau - The MetaCoq Project.pdf:/home/fordrl/Zotero/storage/PXHZCWEL/Sozeau - The MetaCoq Project.pdf:application/pdf},
}

@software{noauthor_learning_2019,
	title = {A Learning Environment for Theorem Proving with the Coq proof assistant: princeton-vl/{CoqGym}},
	rights = {{BSD}-2-Clause},
	url = {https://github.com/princeton-vl/CoqGym},
	shorttitle = {A Learning Environment for Theorem Proving with the Coq proof assistant},
	publisher = {Princeton Vision \& Learning Lab},
	urldate = {2019-05-26},
	date = {2019-05-26},
	note = {original-date: 2019-05-24T22:31:20Z},
}

@article{yang_learning_2019,
	title = {Learning to Prove Theorems via Interacting with Proof Assistants},
	url = {http://arxiv.org/abs/1905.09381},
	abstract = {Humans prove theorems by relying on substantial high-level reasoning and problem-specific insights. Proof assistants offer a formalism that resembles human mathematical reasoning, representing theorems in higher-order logic and proofs as high-level tactics. However, human experts have to construct proofs manually by entering tactics into the proof assistant. In this paper, we study the problem of using machine learning to automate the interaction with proof assistants. We construct {CoqGym}, a large-scale dataset and learning environment containing 71K human-written proofs from 123 projects developed with the Coq proof assistant. We develop {ASTactic}, a deep learning-based model that generates tactics as programs in the form of abstract syntax trees ({ASTs}). Experiments show that {ASTactic} trained on {CoqGym} can generate effective tactics and can be used to prove new theorems not previously provable by automated methods. Code is available at https://github.com/princeton-vl/{CoqGym}.},
	journaltitle = {{arXiv}:1905.09381 [cs, stat]},
	author = {Yang, Kaiyu and Deng, Jia},
	urldate = {2019-05-26},
	date = {2019-05-21},
	eprinttype = {arxiv},
	eprint = {1905.09381},
	keywords = {Computer Science - Logic in Computer Science, Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Statistics - Machine Learning},
	file = {arXiv.org Snapshot:/home/fordrl/Zotero/storage/R3L7GILT/1905.html:text/html;arXiv\:1905.09381 PDF:/home/fordrl/Zotero/storage/A6VG6AAK/Yang and Deng - 2019 - Learning to Prove Theorems via Interacting with Pr.pdf:application/pdf},
}

@article{bansal_holist:_2019,
	title = {{HOList}: An Environment for Machine Learning of Higher-Order Theorem Proving (extended version)},
	url = {http://arxiv.org/abs/1904.03241},
	shorttitle = {{HOList}},
	abstract = {We present an environment, benchmark, and deep learning driven automated theorem prover for higher-order logic. Higher-order interactive theorem provers enable the formalization of arbitrary mathematical theories and thereby present an interesting, open-ended challenge for deep learning. We provide an open-source framework based on the {HOL} Light theorem prover that can be used as a reinforcement learning environment. {HOL} Light comes with a broad coverage of basic mathematical theorems on calculus and the formal proof of the Kepler conjecture, from which we derive a challenging benchmark for automated reasoning. We also present a deep reinforcement learning driven automated theorem prover, {DeepHOL}, with strong initial results on this benchmark.},
	journaltitle = {{arXiv}:1904.03241 [cs]},
	author = {Bansal, Kshitij and Loos, Sarah M. and Rabe, Markus N. and Szegedy, Christian and Wilcox, Stewart},
	urldate = {2019-05-26},
	date = {2019-04-05},
	eprinttype = {arxiv},
	eprint = {1904.03241},
	keywords = {Computer Science - Logic in Computer Science, Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
	file = {arXiv.org Snapshot:/home/fordrl/Zotero/storage/JANLZQ2R/1904.html:text/html;arXiv\:1904.03241 PDF:/home/fordrl/Zotero/storage/6KEIAT9S/Bansal et al. - 2019 - HOList An Environment for Machine Learning of Hig.pdf:application/pdf},
}

@video{strange_loop_proof_nodate,
	title = {"Proof Theory Impressionism: Blurring the Curry-Howard Line" by Dan Pittman},
	url = {https://www.youtube.com/watch?v=jrVPB-Ad5Gc&t=31s},
	shorttitle = {"Proof Theory Impressionism},
	author = {{Strange Loop}},
	urldate = {2019-03-22},
}

@article{altenkirch_why_nodate,
	title = {Why Dependent Types Matter},
	abstract = {We exhibit the rationale behind the design of Epigram, a dependently typed programming language and interactive program development system, using reﬁnements of a well known program—merge sort—as a running example. We discuss its relationship with other proposals to introduce aspects of dependent types into functional programming languages and sketch some topics for further work in this area.},
	pages = {21},
	author = {Altenkirch, Thorsten and {McBride}, Conor and {McKinna}, James},
	langid = {english},
	file = {Altenkirch et al. - Why Dependent Types Matter.pdf:/home/fordrl/Zotero/storage/MMP37DYK/Altenkirch et al. - Why Dependent Types Matter.pdf:application/pdf},
}

@inproceedings{mckinna_why_2006,
	location = {New York, {NY}, {USA}},
	title = {Why Dependent Types Matter},
	isbn = {978-1-59593-027-9},
	url = {http://doi.acm.org/10.1145/1111037.1111038},
	doi = {10.1145/1111037.1111038},
	series = {{POPL} '06},
	abstract = {Language designers have in recent years proposed a wealth of richer type systems for programming which seek to extend the range of statically enforced guarantees on data and code. Most such proposals have been evolutionary extensions of {ML} or Haskell, offering programmers a balanced compromise between expressive strength and existing well-understood technology. Typically they revolve around type- or kind-indexed types such as {GADTs}, supported by limited equality reasoning at the type-checking level, thus separating the dynamic behaviour of programs from the (simpler) static behaviour of indexing information occurring in their types.I want to argue in this talk for a more radical departure from such practice by examining full spectrum type dependency, lifting such restrictions on the data upon which types may depend. Conor {McBride} and I designed the language {EPIGRAM} for experiments in programming with inductive families of data (of which {GADTs} are a special case). Using it for illustration, I will explore some of the possibilities and challenges afforded by full spectrum type dependency at the static and dynamic level: types directly support modelling complex invariants in terms of other data (rather than their types), with a Curry-Howard flavour of data-as-evidence; such complexity is on a 'pay-as-you-go' basis, while keeping type annotations and other syntactic overheads to a minimum; data decomposition steps, e.g. case analysis, furnish more informative interactions between types and values during typechecking; such steps may moreover be abstractly specified by their types, and thus user definable; this supports a style of programming embracing 'learning by testing', views, and Burstall's 'hand simulation plus a little induction'; the absence of a rigid phase distinction need not lead to type-passing or excessive run-time overhead; effectful computation, in particular partiality, can be incorporated via variations on existing ideas such as monads.This talk is based on joint work with Conor {McBride}, Edwin Brady and Thorsten Altenkirch.},
	pages = {1--1},
	booktitle = {Conference Record of the 33rd {ACM} {SIGPLAN}-{SIGACT} Symposium on Principles of Programming Languages},
	publisher = {{ACM}},
	author = {{McKinna}, James},
	urldate = {2019-03-22},
	date = {2006},
	note = {event-place: Charleston, South Carolina, {USA}},
	file = {ACM Full Text PDF:/home/fordrl/Zotero/storage/IR878C3R/McKinna - 2006 - Why Dependent Types Matter.pdf:application/pdf},
}

@online{stewart_verified_nodate,
	title = {Verified Separate Compilation for C {\textbar} Computer Science Department at Princeton University},
	url = {https://www.cs.princeton.edu/research/techreps/TR-980-15},
	author = {Stewart, Gordon},
	urldate = {2019-03-03},
	file = {Verified Separate Compilation for C  Computer Sci.pdf:/home/fordrl/Zotero/storage/U6MLH23P/Verified Separate Compilation for C  Computer Sci.pdf:application/pdf;Verified Separate Compilation for C | Computer Science Department at Princeton University:/home/fordrl/Zotero/storage/S255C77P/TR-980-15.html:text/html},
}

@software{noauthor_formalization_2019,
	title = {Formalization of the Interaction Tree Datatype in Coq: {DeepSpec}/{InteractionTrees}},
	rights = {{MIT}},
	url = {https://github.com/DeepSpec/InteractionTrees},
	shorttitle = {Formalization of the Interaction Tree Datatype in Coq},
	publisher = {{DeepSpec}},
	urldate = {2019-02-28},
	date = {2019-02-27},
	note = {original-date: 2018-06-21T18:53:18Z},
}

@software{sewell_ott_2019,
	title = {The Ott tool for writing definitions of programming languages and calculi: ott-lang/ott},
	rights = {View license},
	url = {https://github.com/ott-lang/ott},
	shorttitle = {The Ott tool for writing definitions of programming languages and calculi},
	publisher = {ott-lang},
	author = {Sewell, Peter},
	urldate = {2019-02-28},
	date = {2019-01-17},
	note = {original-date: 2016-10-27T15:44:41Z},
}

@software{noauthor_lem_2019,
	title = {Lem semantic definition language.},
	url = {https://github.com/rems-project/lem},
	publisher = {{REMS}},
	urldate = {2019-02-28},
	date = {2019-02-11},
	note = {original-date: 2018-01-31T15:35:24Z},
}

@inproceedings{mulligan_lem:_2014,
	location = {New York, {NY}, {USA}},
	title = {Lem: Reusable Engineering of Real-world Semantics},
	isbn = {978-1-4503-2873-9},
	url = {http://doi.acm.org/10.1145/2628136.2628143},
	doi = {10.1145/2628136.2628143},
	series = {{ICFP} '14},
	shorttitle = {Lem},
	abstract = {Recent years have seen remarkable successes in rigorous engineering: using mathematically rigorous semantic models (not just idealised calculi) of real-world processors, programming languages, protocols, and security mechanisms, for testing, proof, analysis, and design. Building these models is challenging, requiring experimentation, dialogue with vendors or standards bodies, and validation; their scale adds engineering issues akin to those of programming to the task of writing clear and usable mathematics. But language and tool support for specification is lacking. Proof assistants can be used but bring their own difficulties, and a model produced in one, perhaps requiring many person-years effort and maintained over an extended period, cannot be used by those familiar with another. We introduce Lem, a language for engineering reusable large-scale semantic models. The Lem design takes inspiration both from functional programming languages and from proof assistants, and Lem definitions are translatable into {OCaml} for testing, Coq, {HOL}4, and Isabelle/{HOL} for proof, and {LaTeX} and {HTML} for presentation. This requires a delicate balance of expressiveness, careful library design, and implementation of transformations - akin to compilation, but subject to the constraint of producing usable and human-readable code for each target. Lem's effectiveness is demonstrated by its use in practice.},
	pages = {175--188},
	booktitle = {Proceedings of the 19th {ACM} {SIGPLAN} International Conference on Functional Programming},
	publisher = {{ACM}},
	author = {Mulligan, Dominic P. and Owens, Scott and Gray, Kathryn E. and Ridge, Tom and Sewell, Peter},
	urldate = {2019-02-28},
	date = {2014},
	note = {event-place: Gothenburg, Sweden},
	keywords = {proof assistants, lem, real-world semantics, specification languages},
	file = {ACM Full Text PDF:/home/fordrl/Zotero/storage/FAGX7FNA/Mulligan et al. - 2014 - Lem Reusable Engineering of Real-world Semantics.pdf:application/pdf},
}

@inproceedings{kell_missing_2016,
	location = {New York, {NY}, {USA}},
	title = {The Missing Link: Explaining {ELF} Static Linking, Semantically},
	isbn = {978-1-4503-4444-9},
	url = {http://doi.acm.org/10.1145/2983990.2983996},
	doi = {10.1145/2983990.2983996},
	series = {{OOPSLA} 2016},
	shorttitle = {The Missing Link},
	abstract = {Beneath the surface, software usually depends on complex linker behaviour to work as intended. Even linking {\textless}pre{\textgreater}hello\_world.c{\textless}/pre{\textgreater} is surprisingly involved, and systems software such as {\textless}pre{\textgreater}libc{\textless}/pre{\textgreater} and operating system kernels rely on a host of linker features. But linking is poorly understood by working programmers and has largely been neglected by language researchers.  In this paper we survey the many use-cases that linkers support and the poorly specified linker speak by which they are controlled: metadata in object files, command-line options, and linker-script language. We provide the first validated formalisation of a realistic executable and linkable format ({ELF}), and capture aspects of the Application Binary Interfaces for four mainstream platforms ({AArch}64, {AMD}64, Power64, and {IA}32). Using these, we develop an executable specification of static linking, covering (among other things) enough to link small C programs (we use the example of bzip2) into a correctly running executable. We provide our specification in Lem and Isabelle/{HOL} forms. This is the first formal specification of mainstream linking. We have used the Isabelle/{HOL} version to prove a sample correctness property for one case of {AMD}64 {ABI} relocation, demonstrating that the specification supports formal proof, and as a first step towards the much more ambitious goal of verified linking. Our work should enable several novel strands of research, including linker-aware verified compilation and program analysis, and better languages for controlling linking.},
	pages = {607--623},
	booktitle = {Proceedings of the 2016 {ACM} {SIGPLAN} International Conference on Object-Oriented Programming, Systems, Languages, and Applications},
	publisher = {{ACM}},
	author = {Kell, Stephen and Mulligan, Dominic P. and Sewell, Peter},
	urldate = {2019-02-28},
	date = {2016},
	note = {event-place: Amsterdam, Netherlands},
	keywords = {Executable and Linkable Format ({ELF}), formal specification, Linking, theorem-proving},
	file = {ACM Full Text PDF:/home/fordrl/Zotero/storage/GN92372Y/Kell et al. - 2016 - The Missing Link Explaining ELF Static Linking, S.pdf:application/pdf},
}

@inproceedings{nienhuis_operational_2016,
	location = {New York, {NY}, {USA}},
	title = {An Operational Semantics for C/C++11 Concurrency},
	isbn = {978-1-4503-4444-9},
	url = {http://doi.acm.org/10.1145/2983990.2983997},
	doi = {10.1145/2983990.2983997},
	series = {{OOPSLA} 2016},
	abstract = {The C/C++11 concurrency model balances two goals: it is relaxed enough to be efficiently implementable and (leaving aside the ``thin-air'' problem) it is strong enough to give useful guarantees to programmers. It is mathematically precise and has been used in verification research and compiler testing. However, the model is expressed in an axiomatic style, as predicates on complete candidate executions. This suffices for computing the set of allowed executions of a small litmus test, but it does not directly support the incremental construction of executions of larger programs. It is also at odds with conventional operational semantics, as used implicitly in the rest of the C/C++ standards.   Our main contribution is the development of an operational model for C/C++11 concurrency. This covers all the features of the previous formalised axiomatic model, and we have a mechanised proof that the two are equivalent, in Isabelle/{HOL}. We also integrate this semantics with an operational semantics for sequential C (described elsewhere); the combined semantics can incrementally execute programs in a small fragment of C.   Doing this uncovered several new aspects of the C/C++11 model: we show that one cannot build an equivalent operational model that simply follows program order, sequential consistent order, or the synchronises-with order. The first negative result is forced by hardware-observable behaviour, but the latter two are not, and so might be ameliorated by changing C/C++11. More generally, we hope that this work, with its focus on incremental construction of executions, will inform the future design of new concurrency models.},
	pages = {111--128},
	booktitle = {Proceedings of the 2016 {ACM} {SIGPLAN} International Conference on Object-Oriented Programming, Systems, Languages, and Applications},
	publisher = {{ACM}},
	author = {Nienhuis, Kyndylan and Memarian, Kayvan and Sewell, Peter},
	urldate = {2019-02-28},
	date = {2016},
	note = {event-place: Amsterdam, Netherlands},
	keywords = {C/C++, Concurrency},
	file = {ACM Full Text PDF:/home/fordrl/Zotero/storage/CHY6KVGP/Nienhuis et al. - 2016 - An Operational Semantics for CC++11 Concurrency.pdf:application/pdf},
}

@article{pulte_simplifying_2017,
	title = {Simplifying {ARM} Concurrency: Multicopy-atomic Axiomatic and Operational Models for {ARMv}8},
	volume = {2},
	issn = {2475-1421},
	url = {http://doi.acm.org/10.1145/3158107},
	doi = {10.1145/3158107},
	shorttitle = {Simplifying {ARM} Concurrency},
	abstract = {{ARM} has a relaxed memory model, previously specified in informal prose for {ARMv}7 and {ARMv}8. Over time, and partly due to work building formal semantics for {ARM} concurrency, it has become clear that some of the complexity of the model is not justified by the potential benefits. In particular, the model was originally non-multicopy-atomic: writes could become visible to some other threads before becoming visible to all — but this has not been exploited in production implementations, the corresponding potential hardware optimisations are thought to have insufficient benefits in the {ARM} context, and it gives rise to subtle complications when combined with other {ARMv}8 features. The {ARMv}8 architecture has therefore been revised: it now has a multicopy-atomic model. It has also been simplified in other respects, including more straightforward notions of dependency, and the architecture now includes a formal concurrency model.  In this paper we detail these changes and discuss their motivation. We define two formal concurrency models: an operational one, simplifying the Flowing model of Flur et al., and the axiomatic model of the revised {ARMv}8 specification. The models were developed by an academic group and by {ARM} staff, respectively, and this extended collaboration partly motivated the above changes. We prove the equivalence of the two models. The operational model is integrated into an executable exploration tool with new web interface, demonstrated by exhaustively checking the possible behaviours of a loop-unrolled version of a Linux kernel lock implementation, a previously known bug due to unprevented speculation, and a fixed version.},
	pages = {19:1--19:29},
	issue = {{POPL}},
	journaltitle = {Proc. {ACM} Program. Lang.},
	author = {Pulte, Christopher and Flur, Shaked and Deacon, Will and French, Jon and Sarkar, Susmit and Sewell, Peter},
	urldate = {2019-02-28},
	date = {2017-12},
	keywords = {Semantics, Axiomatic, Operational, Relaxed Memory Models},
	file = {ACM Full Text PDF:/home/fordrl/Zotero/storage/6BGU9SUM/Pulte et al. - 2017 - Simplifying ARM Concurrency Multicopy-atomic Axio.pdf:application/pdf},
}

@article{armstrong_isa_2019,
	title = {{ISA} Semantics for {ARMv}8-a, {RISC}-v, and {CHERI}-{MIPS}},
	volume = {3},
	issn = {2475-1421},
	url = {http://doi.acm.org/10.1145/3290384},
	doi = {10.1145/3290384},
	abstract = {Architecture specifications notionally define the fundamental interface between hardware and software: the envelope of allowed behaviour for processor implementations, and the basic assumptions for software development and verification. But in practice, they are typically prose and pseudocode documents, not rigorous or executable artifacts, leaving software and verification on shaky ground.   In this paper, we present rigorous semantic models for the sequential behaviour of large parts of the mainstream {ARMv}8-A, {RISC}-V, and {MIPS} architectures, and the research {CHERI}-{MIPS} architecture, that are complete enough to boot operating systems, variously Linux, {FreeBSD}, or {seL}4. Our {ARMv}8-A models are automatically translated from authoritative {ARM}-internal definitions, and (in one variant) tested against the {ARM} Architecture Validation Suite.   We do this using a custom language for {ISA} semantics, Sail, with a lightweight dependent type system, that supports automatic generation of emulator code in C and {OCaml}, and automatic generation of proof-assistant definitions for Isabelle, {HOL}4, and (currently only for {MIPS}) Coq. We use the former for validation, and to assess specification coverage. To demonstrate the usability of the latter, we prove (in Isabelle) correctness of a purely functional characterisation of {ARMv}8-A address translation. We moreover integrate the {RISC}-V model into the {RMEM} tool for (user-mode) relaxed-memory concurrency exploration. We prove (on paper) the soundness of the core Sail type system.   We thereby take a big step towards making the architectural abstraction actually well-defined, establishing foundations for verification and reasoning.},
	pages = {71:1--71:31},
	issue = {{POPL}},
	journaltitle = {Proc. {ACM} Program. Lang.},
	author = {Armstrong, Alasdair and Bauereiss, Thomas and Campbell, Brian and Reid, Alastair and Gray, Kathryn E. and Norton, Robert M. and Mundkur, Prashanth and Wassell, Mark and French, Jon and Pulte, Christopher and Flur, Shaked and Stark, Ian and Krishnaswami, Neel and Sewell, Peter},
	urldate = {2019-02-28},
	date = {2019-01},
	keywords = {Semantics, Instruction Set Architectures, Theorem Proving},
	file = {ACM Full Text PDF:/home/fordrl/Zotero/storage/E4ASQ97S/Armstrong et al. - 2019 - ISA Semantics for ARMv8-a, RISC-v, and CHERI-MIPS.pdf:application/pdf},
}

@article{memarian_exploring_2019,
	title = {Exploring C Semantics and Pointer Provenance},
	volume = {3},
	issn = {2475-1421},
	url = {http://doi.acm.org/10.1145/3290380},
	doi = {10.1145/3290380},
	abstract = {The semantics of pointers and memory objects in C has been a vexed question for many years. C values cannot be treated as either purely abstract or purely concrete entities: the language exposes their representations, but compiler optimisations rely on analyses that reason about provenance and initialisation status, not just runtime representations. The {ISO} {WG}14 standard leaves much of this unclear, and in some respects differs with de facto standard usage --- which itself is difficult to investigate.   In this paper we explore the possible source-language semantics for memory objects and pointers, in {ISO} C and in C as it is used and implemented in practice, focussing especially on pointer provenance. We aim to, as far as possible, reconcile the {ISO} C standard, mainstream compiler behaviour, and the semantics relied on by the corpus of existing C code. We present two coherent proposals, tracking provenance via integers and not; both address many design questions. We highlight some pros and cons and open questions, and illustrate the discussion with a library of test cases. We make our semantics executable as a test oracle, integrating it with the Cerberus semantics for much of the rest of C, which we have made substantially more complete and robust, and equipped with a web-interface {GUI}. This allows us to experimentally assess our proposals on those test cases. To assess their viability with respect to larger bodies of C code, we analyse the changes required and the resulting behaviour for a port of {FreeBSD} to {CHERI}, a research architecture supporting hardware capabilities, which (roughly speaking) traps on the memory safety violations which our proposals deem undefined behaviour. We also develop a new runtime instrumentation tool to detect possible provenance violations in normal C code, and apply it to some of the {SPEC} benchmarks. We compare our proposal with a source-language variant of the twin-allocation {LLVM} semantics proposal of Lee et al. Finally, we describe ongoing interactions with {WG}14, exploring how our proposals could be incorporated into the {ISO} standard.},
	pages = {67:1--67:32},
	issue = {{POPL}},
	journaltitle = {Proc. {ACM} Program. Lang.},
	author = {Memarian, Kayvan and Gomes, Victor B. F. and Davis, Brooks and Kell, Stephen and Richardson, Alexander and Watson, Robert N. M. and Sewell, Peter},
	urldate = {2019-02-28},
	date = {2019-01},
	keywords = {C},
	file = {ACM Full Text PDF:/home/fordrl/Zotero/storage/B37CZ7YU/Memarian et al. - 2019 - Exploring C Semantics and Pointer Provenance.pdf:application/pdf},
}

@article{bishop_engineering_2018,
	title = {Engineering with Logic: Rigorous Test-Oracle Specification and Validation for {TCP}/{IP} and the Sockets {API}},
	volume = {66},
	issn = {0004-5411},
	url = {http://doi.acm.org/10.1145/3243650},
	doi = {10.1145/3243650},
	shorttitle = {Engineering with Logic},
	abstract = {Conventional computer engineering relies on test-and-debug development processes, with the behavior of common interfaces described (at best) with prose specification documents. But prose specifications cannot be used in test-and-debug development in any automated way, and prose is a poor medium for expressing complex (and loose) specifications. The {TCP}/{IP} protocols and Sockets {API} are a good example of this: they play a vital role in modern communication and computation, and interoperability between implementations is essential. But what exactly they are is surprisingly obscure: their original development focused on “rough consensus and running code,” augmented by prose {RFC} specifications that do not precisely define what it means for an implementation to be correct. Ultimately, the actual standard is the de facto one of the common implementations, including, for example, the 15 000 to 20 000 lines of the {BSD} implementation—optimized and multithreaded C code, time dependent, with asynchronous event handlers, intertwined with the operating system, and security critical. This article reports on work done in the Netsem project to develop lightweight mathematically rigorous techniques that can be applied to such systems: to specify their behavior precisely (but loosely enough to permit the required implementation variation) and to test whether these specifications and the implementations correspond with specifications that are executable as test oracles. We developed post hoc specifications of {TCP}, {UDP}, and the Sockets {API}, both of the service that they provide to applications (in terms of {TCP} bidirectional stream connections) and of the internal operation of the protocol (in terms of {TCP} segments and {UDP} datagrams), together with a testable abstraction function relating the two. These specifications are rigorous, detailed, readable, with broad coverage, and rather accurate. Working within a general-purpose proof assistant ({HOL}4), we developed language idioms (within higher-order logic) in which to write the specifications: operational semantics with nondeterminism, time, system calls, monadic relational programming, and so forth. We followed an experimental semantics approach, validating the specifications against several thousand traces captured from three implementations ({FreeBSD}, Linux, and {WinXP}). Many differences between these were identified, as were a number of bugs. Validation was done using a special-purpose symbolic model checker programmed above {HOL}4. Having demonstrated that our logic-based engineering techniques suffice for handling real-world protocols, we argue that similar techniques could be applied to future critical software infrastructure at design time, leading to cleaner designs and (via specification-based testing) more robust and predictable implementations. In cases where specification looseness can be controlled, this should be possible with lightweight techniques, without the need for a general-purpose proof assistant, at relatively little cost.},
	pages = {1:1--1:77},
	number = {1},
	journaltitle = {J. {ACM}},
	author = {Bishop, Steve and Fairbairn, Matthew and Mehnert, Hannes and Norrish, Michael and Ridge, Tom and Sewell, Peter and Smith, Michael and Wansbrough, Keith},
	urldate = {2019-02-28},
	date = {2018-12},
	keywords = {network protocols, Rigorous engineering, specification},
	file = {ACM Full Text PDF:/home/fordrl/Zotero/storage/CSYHL8HP/Bishop et al. - 2018 - Engineering with Logic Rigorous Test-Oracle Speci.pdf:application/pdf},
}

@online{sewell_rems_nodate,
	title = {{REMS} - Rigorous Engineering of Mainstream Systems},
	url = {https://www.cl.cam.ac.uk/~pes20/rems/index.html},
	author = {Sewell, Peter},
	urldate = {2019-02-28},
	file = {report-2019-web.pdf:/home/fordrl/Zotero/storage/5EYFKN44/report-2019-web.pdf:application/pdf;REMS:/home/fordrl/Zotero/storage/RKHJKH69/index.html:text/html},
}

@article{lamport_if_2018,
	title = {If You’re Not Writing a Program, Don’t Use a Programming Language},
	volume = {2},
	rights = {Authors who publish with this journal agree to the following terms:    Authors retain copyright and grant the journal right of first publication with the work simultaneously licensed under a Creative Commons Attribution License that allows others to share the work with an acknowledgement of the work's authorship and initial publication in this journal.       Authors are able to enter into separate, additional contractual arrangements for the non-exclusive distribution of the journal's published version of the work (e.g., post it to an institutional repository or publish it in a book), with an acknowledgement of its initial publication in this journal.},
	url = {http://eatcs.org/beatcs/index.php/beatcs/article/view},
	abstract = {The need to handle large programs and to produce ecient compiled codeadds complexity to programming languages and limits their expressiveness.Algorithms are not programs, and they can be expressed in a simpler and more expressive language. That language is the one used by almost every branch of science and engineering to precisely describe and reason about the objects they study: the language of mathematics. Math is useful for describing a more general class of algorithms than are studied in algorithmcourses.},
	number = {125},
	journaltitle = {Bulletin of {EATCS}},
	author = {Lamport, Leslie and Distributed Computing {\textbackslash}\& Education Column by Juraj Hromkovic, Stefan Schmid},
	urldate = {2019-02-08},
	date = {2018-06-12},
	langid = {english},
	file = {Lamport and Distributed Computing & Education Column by Juraj Hromkovic - 2018 - If You’re Not Writing a Program, Don’t Use a Progr.pdf:/home/fordrl/Zotero/storage/VSCKQ5W2/Lamport and Distributed Computing & Education Column by Juraj Hromkovic - 2018 - If You’re Not Writing a Program, Don’t Use a Progr.pdf:application/pdf;Snapshot:/home/fordrl/Zotero/storage/XYAISFI9/539.html:text/html},
}

@software{herklotz_vericert_2021,
	title = {Vericert},
	rights = {View license         ,                 View license},
	url = {https://github.com/ymherklotz/vericert},
	abstract = {A formally verified high-level synthesis tool based on {CompCert} and written in Coq.},
	author = {Herklotz, Yann},
	urldate = {2021-01-20},
	date = {2021-01-20},
	note = {original-date: 2019-10-02T18:48:56Z},
	keywords = {verification, coq, c, compcert, high-level-synthesis, semantics, verilog},
}

@article{herklotz_formal_2017,
	title = {Formal Verification of High-Level Synthesis},
	abstract = {High-level synthesis ({HLS}), which refers to the automatic compilation of software into hardware, is rapidly gaining popularity. In a world increasingly reliant on applicationspecific hardware accelerators, {HLS} promises hardware designs of comparable performance and energy efficiency to those coded by hand in a hardware description language like Verilog, while maintaining the convenience and the rich ecosystem of software development. However, current {HLS} tools cannot always guarantee that the hardware designs they produce are equivalent to the software they were given, thus undermining any reasoning conducted at the software level. Worse, there is mounting evidence that existing {HLS} tools are quite unreliable, sometimes generating wrong hardware or crashing when given valid inputs. To address this problem, we present the first {HLS} tool that is mechanically verified to preserve the behaviour of its input software. Our tool, called Vericert, extends the {CompCert} verified C compiler with a new hardware-oriented intermediate language and a Verilog back end, and has been proven correct in Coq. Vericert supports all C constructs except for case statements, function pointers, recursive function calls, integers larger than 32 bits, floats, and global variables. An evaluation on the {PolyBench}/C benchmark suite indicates that Vericert generates hardware that is around an order of magnitude slower and larger than hardware generated by an existing, optimising (but unverified) {HLS} tool.},
	pages = {14},
	author = {Herklotz, Yann and Pollard, James and Ramanathan, Nadesh and Wickerson, John},
	date = {2017},
	langid = {english},
	file = {Herklotz et al. - 2017 - Formal Verification of High-Level Synthesis.pdf:/home/fordrl/Zotero/storage/CNADNJP5/Herklotz et al. - 2017 - Formal Verification of High-Level Synthesis.pdf:application/pdf},
}

@inproceedings{swamy_dependent_2016,
	location = {New York, {NY}, {USA}},
	title = {Dependent Types and Multi-monadic Effects in Fstar},
	isbn = {978-1-4503-3549-2},
	url = {http://doi.acm.org/10.1145/2837614.2837655},
	doi = {10.1145/2837614.2837655},
	series = {{POPL} '16},
	abstract = {We present a new, completely redesigned, version of F*, a language that works both as a proof assistant as well as a general-purpose, verification-oriented, effectful programming language. In support of these complementary roles, F* is a dependently typed, higher-order, call-by-value language with \_primitive\_ effects including state, exceptions, divergence and {IO}. Although primitive, programmers choose the granularity at which to specify effects by equipping each effect with a monadic, predicate transformer semantics. F* uses this to efficiently compute weakest preconditions and discharges the resulting proof obligations using a combination of {SMT} solving and manual proofs. Isolated from the effects, the core of F* is a language of pure functions used to write specifications and proof terms---its consistency is maintained by a semantic termination check based on a well-founded order. We evaluate our design on more than 55,000 lines of F* we have authored in the last year, focusing on three main case studies. Showcasing its use as a general-purpose programming language, F* is programmed (but not verified) in F*, and bootstraps in both {OCaml} and F\#. Our experience confirms F*'s pay-as-you-go cost model: writing idiomatic {ML}-like code with no finer specifications imposes no user burden. As a verification-oriented language, our most significant evaluation of F* is in verifying several key modules in an implementation of the {TLS}-1.2 protocol standard. For the modules we considered, we are able to prove more properties, with fewer annotations using F* than in a prior verified implementation of {TLS}-1.2. Finally, as a proof assistant, we discuss our use of F* in mechanizing the metatheory of a range of lambda calculi, starting from the simply typed lambda calculus to System F-omega and even micro-F*, a sizeable fragment of F* itself---these proofs make essential use of F*'s flexible combination of {SMT} automation and constructive proofs, enabling a tactic-free style of programming and proving at a relatively large scale.},
	pages = {256--270},
	booktitle = {Proceedings of the 43rd Annual {ACM} {SIGPLAN}-{SIGACT} Symposium on Principles of Programming Languages},
	publisher = {{ACM}},
	author = {Swamy, Nikhil and Hriţcu, Cătălin and Keller, Chantal and Rastogi, Aseem and Delignat-Lavaud, Antoine and Forest, Simon and Bhargavan, Karthikeyan and Fournet, Cédric and Strub, Pierre-Yves and Kohlweiss, Markulf and Zinzindohoue, Jean-Karim and Zanella-Béguelin, Santiago},
	urldate = {2019-02-01},
	date = {2016},
	keywords = {proof assistants, verification, effectful programming},
	file = {ACM Full Text PDF:/home/fordrl/Zotero/storage/X6CZXAKM/Swamy et al. - 2016 - Dependent Types and Multi-monadic Effects in F.pdf:application/pdf},
}

@article{protzenko_verified_2017,
	title = {Verified Low-level Programming Embedded in Fstar},
	volume = {1},
	issn = {2475-1421},
	url = {http://doi.acm.org/10.1145/3110261},
	doi = {10.1145/3110261},
	abstract = {We present Low*, a language for low-level programming and verification, and its application to high-assurance optimized cryptographic libraries. Low* is a shallow embedding of a small, sequential, well-behaved subset of C in F*, a dependently- typed variant of {ML} aimed at program verification. Departing from {ML}, Low* does not involve any garbage collection or implicit heap allocation; instead, it has a structured memory model à la {CompCert}, and it provides the control required for writing efficient low-level security-critical code.   By virtue of typing, any Low* program is memory safe. In addition, the programmer can make full use of the verification power of F* to write high-level specifications and verify the functional correctness of Low* code using a combination of {SMT} automation and sophisticated manual proofs. At extraction time, specifications and proofs are erased, and the remaining code enjoys a predictable translation to C. We prove that this translation preserves semantics and side-channel resistance.   We provide a new compiler back-end from Low* to C and, to evaluate our approach, we implement and verify various cryptographic algorithms, constructions, and tools for a total of about 28,000 lines of code. We show that our Low* code delivers performance competitive with existing (unverified) C cryptographic libraries, suggesting our approach may be applicable to larger-scale low-level software.},
	pages = {17:1--17:29},
	issue = {{ICFP}},
	journaltitle = {Proc. {ACM} Program. Lang.},
	author = {Protzenko, Jonathan and Zinzindohoué, Jean-Karim and Rastogi, Aseem and Ramananandro, Tahina and Wang, Peng and Zanella-Béguelin, Santiago and Delignat-Lavaud, Antoine and Hriţcu, Cătălin and Bhargavan, Karthikeyan and Fournet, Cédric and Swamy, Nikhil},
	urldate = {2019-02-01},
	date = {2017-08},
	keywords = {Compilers, Semantics, Functional languages, Software verifcation, Source code generation, Type theory, źSoftware and its engineering ź Correctness, źTheory of computation ź Hoare logic},
	file = {ACM Full Text PDF:/home/fordrl/Zotero/storage/BG9T92IN/Protzenko et al. - 2017 - Verified Low-level Programming Embedded in F.pdf:application/pdf},
}

@article{martinez_meta-fstar:_2018,
	title = {Meta-Fstar: Proof Automation with {SMT}, Tactics, and Metaprograms},
	url = {http://arxiv.org/abs/1803.06547},
	shorttitle = {Meta-F*},
	abstract = {We introduce Meta-F*, a tactics and metaprogramming framework for the F* program verifier. The main novelty of Meta-F* is allowing to use tactics and metaprogramming to discharge assertions not solvable by {SMT}, or to just simplify them into well-behaved {SMT} fragments. Plus, Meta-F* can be used to generate verified code automatically. Meta-F* is implemented as an F* effect, which, given the powerful effect system of F*, heavily increases code reuse and even enables the lightweight verification of metaprograms. Metaprograms can be either interpreted, or compiled to efficient native code that can be dynamically loaded into the F* type-checker and can interoperate with interpreted code. Evaluation on realistic case studies shows that Meta-F* provides substantial gains in proof development, efficiency, and robustness.},
	journaltitle = {{arXiv}:1803.06547 [cs]},
	author = {Martínez, Guido and Ahman, Danel and Dumitrescu, Victor and Giannarakis, Nick and Hawblitzel, Chris and Hritcu, Catalin and Narasimhamurthy, Monal and Paraskevopoulou, Zoe and Pit-Claudel, Clément and Protzenko, Jonathan and Ramananandro, Tahina and Rastogi, Aseem and Swamy, Nikhil},
	urldate = {2019-02-01},
	date = {2018-03-17},
	eprinttype = {arxiv},
	eprint = {1803.06547},
	keywords = {Computer Science - Programming Languages, Computer Science - Logic in Computer Science},
	file = {arXiv.org Snapshot:/home/fordrl/Zotero/storage/4UGPV8V2/1803.html:text/html;arXiv\:1803.06547 PDF:/home/fordrl/Zotero/storage/D6VDW32P/Martínez et al. - 2018 - Meta-F Proof Automation with SMT, Tactics, and M.pdf:application/pdf},
}

@online{fstar-team_fstar_2021,
	title = {Fstar: A Higher-Order Effectful Language Designed for Program Verification},
	url = {https://www.fstar-lang.org/},
	author = {fstar-team},
	urldate = {2021-01-20},
	date = {2021-01-20},
	file = {Fstar\: A Higher-Order Effectful Language Designed for Program Verification:/home/fordrl/Zotero/storage/UGC9JDZY/www.fstar-lang.org.html:text/html},
}

@article{cousot_a2i:_2019,
	title = {A2I: Abstract2 Interpretation},
	volume = {3},
	issn = {2475-1421},
	url = {http://doi.acm.org/10.1145/3290355},
	doi = {10.1145/3290355},
	shorttitle = {A\${\textasciicircum}2\$I},
	abstract = {The fundamental idea of Abstract2 Interpretation (A2I), also called meta-abstract interpretation, is to apply abstract interpretation to abstract interpretation-based static program analyses. A2I is generally meant to use abstract interpretation to analyse properties of program analysers. A2I can be either offline or online. Offline A2I is performed either before the program analysis, such as variable packing used by the Astrée program analyser, or after the program analysis, such as in alarm diagnosis. Online A2I is performed during the program analysis, such as Venet’s cofibred domains or Halbwachs et al.’s and Singh et al.’s variable partitioning techniques for fast polyhedra/numerical abstract domains. We formalize offline and online meta-abstract interpretation and illustrate this notion with the design of widenings and the decomposition of relational abstract domains to speed-up program analyses. This shows how novel static analyses can be extracted as meta-abstract interpretations to design efficient and precise program analysis algorithms.},
	pages = {42:1--42:31},
	issue = {{POPL}},
	journaltitle = {Proc. {ACM} Program. Lang.},
	author = {Cousot, Patrick and Giacobazzi, Roberto and Ranzato, Francesco},
	urldate = {2019-01-31},
	date = {2019-01},
	keywords = {program analysis, Abstract interpretation, meta-abstract interpretation},
	file = {ACM Full Text PDF:/home/fordrl/Zotero/storage/ZVG3RMZK/Cousot et al. - 2019 - A\$^2\$I Abstract\$^2\$ Interpretation.pdf:application/pdf},
}

@article{hellerstein_keeping_2020,
	title = {Keeping {CALM}: when distributed consistency is easy},
	volume = {63},
	issn = {0001-0782, 1557-7317},
	url = {https://dl.acm.org/doi/10.1145/3369736},
	doi = {10.1145/3369736},
	shorttitle = {Keeping {CALM}},
	pages = {72--81},
	number = {9},
	journaltitle = {Communications of the {ACM}},
	shortjournal = {Commun. {ACM}},
	author = {Hellerstein, Joseph M. and Alvaro, Peter},
	urldate = {2021-01-18},
	date = {2020-08-21},
	langid = {english},
	file = {Hellerstein and Alvaro - 2020 - Keeping CALM when distributed consistency is easy.pdf:/home/fordrl/Zotero/storage/V6QQTWY3/Hellerstein and Alvaro - 2020 - Keeping CALM when distributed consistency is easy.pdf:application/pdf},
}

@article{delignat-lavaud_security_nodate,
	title = {A Security Model and Fully Veriﬁed Implementation for the {IETF} {QUIC} Record Layer},
	abstract = {Drawing on earlier protocol-veriﬁcation work, we investigate the security of the {QUIC} record layer, as standardized by the {IETF} in draft version 30. This version features major differences compared to Google’s original protocol and early {IETF} drafts. It serves as a useful test case for our veriﬁcation methodology and toolchain, while also, hopefully, drawing attention to a little studied yet crucially important emerging standard. We model {QUIC} packet and header encryption, which uses a custom construction for privacy. To capture its goals, we propose a security deﬁnition for authenticated encryption with semi-implicit nonces. We show that {QUIC} uses an instance of a generic construction parameterized by a standard {AEAD}-secure scheme and a {PRF}-secure cipher. We formalize and verify the security of this construction in F . The proof uncovers interesting limitations of nonce conﬁdentiality, due to the malleability of short headers and the ability to choose the number of least signiﬁcant bits included in the packet counter. We propose improvements that simplify the proof and increase robustness against strong attacker models. In addition to the veriﬁed security model, we also give a concrete functional speciﬁcation for the record layer, and prove that it satisﬁes important functionality properties (such as the correct successful decryption of encrypted packets) after ﬁxing more errors in the draft. We then provide a highperformance implementation of the record layer that we prove to be memory safe, correct with respect to our concrete speciﬁcation (inheriting its functional correctness properties), and secure with respect to our veriﬁed model. To evaluate this component, we develop a provably-safe implementation of the rest of the {QUIC} protocol. Our record layer achieves nearly 2 {GB}/s throughput, and our {QUIC} implementation’s performance is within 21\% of an unveriﬁed baseline.},
	pages = {17},
	author = {Delignat-Lavaud, Antoine and Fournet, Cédric and Parno, Bryan and Protzenko, Jonathan and Ramananandro, Tahina and Bosamiya, Jay and Lallemand, Joseph and Rakotonirina, Itsaka and Zhou, Yi},
	langid = {english},
	file = {Delignat-Lavaud et al. - A Security Model and Fully Veriﬁed Implementation .pdf:/home/fordrl/Zotero/storage/MHIE7CYS/Delignat-Lavaud et al. - A Security Model and Fully Veriﬁed Implementation .pdf:application/pdf},
}

@book{arya_blockchain_2021,
	title = {{BLOCKCHAIN}: {BASICS}, {APPLICATIONS}, {CHALLENGES} {AND} {OPPORTUNITIES}},
	shorttitle = {{BLOCKCHAIN}},
	author = {Arya, Jaswant and Kumar, Arun and Singh, Akhilendra and Mishra, Tapas and Chong, Peter},
	date = {2021-01-07},
	doi = {10.13140/RG.2.2.33899.16160},
}

@article{begay_developing_2021,
	title = {Developing and Certifying Datalog Optimizations in Coq/{MathComp}},
	abstract = {We introduce a static analysis and two program transformations for Datalog to circumvent performance issues that arise with the implementation of primitive predicates, notably in the framework of a large scale telecommunication application. To this effect, we introduce a new trace semantics for Datalog with a verified mechanization. This work can be seen as both a first step and a proof of concept for the creation of a full-blown library of verified Datalog optimizations, on top of an existing Coq/{MathComp} formalization of Datalog[5, 14] towards the development of a realistic environment for certified data-centric applications.},
	pages = {15},
	author = {Bégay, Pierre-Léo and Crégut, Pierre and Monin, Jean-François},
	date = {2021},
	langid = {english},
	file = {Bégay et al. - 2021 - Developing and Certifying Datalog Optimizations in.pdf:/home/fordrl/Zotero/storage/URQW5TTF/Bégay et al. - 2021 - Developing and Certifying Datalog Optimizations in.pdf:application/pdf},
}

@article{mahboubi_machine-checked_nodate,
	title = {Machine-checked computer-aided mathematics},
	pages = {110},
	author = {Mahboubi, Assia},
	langid = {english},
	file = {Mahboubi - Machine-checked computer-aided mathematics.pdf:/home/fordrl/Zotero/storage/UEUL4Y29/Mahboubi - Machine-checked computer-aided mathematics.pdf:application/pdf},
}

@inproceedings{le_compositional_2021,
	location = {Cham},
	title = {Compositional Satisfiability Solving in Separation Logic},
	isbn = {978-3-030-67067-2},
	doi = {10.1007/978-3-030-67067-2_26},
	series = {Lecture Notes in Computer Science},
	abstract = {We introduce a novel decision procedure to the satisfiability problem in array separation logic combined with general inductively defined predicates and arithmetic. Our proposal differentiates itself from existing works by solving satisfiability through compositional reasoning. First, following Fermat’s method of infinite descent, it infers for every inductive definition a “base” that precisely characterises the satisfiability. It then utilises the base to derive such a base for any formula where these inductive predicates reside in. Especially, we identify an expressive decidable fragment for the compositionality. We have implemented the proposal in a tool and evaluated it over challenging problems. The experimental results show that the compositional satisfiability solving is efficient and our tool is effective and efficient when compared with existing solvers.},
	pages = {578--602},
	booktitle = {Verification, Model Checking, and Abstract Interpretation},
	publisher = {Springer International Publishing},
	author = {Le, Quang Loc},
	editor = {Henglein, Fritz and Shoham, Sharon and Vizel, Yakir},
	date = {2021},
	langid = {english},
	keywords = {Separation logic, Regular proofs, Satisfiability},
}

@inproceedings{namjoshi_self-certifying_2021,
	location = {Cham},
	title = {A Self-certifying Compilation Framework for {WebAssembly}},
	isbn = {978-3-030-67067-2},
	doi = {10.1007/978-3-030-67067-2_7},
	series = {Lecture Notes in Computer Science},
	abstract = {A self-certifying compiler is designed to generate a correctness proof for each optimization performed during compilation. The generated proofs are checked automatically by an independent proof validator. The outcome is formally verified compilation, achieved without formally verifying the compiler. This paper describes the design and implementation of a self-certifying compilation framework for {WebAssembly}, a new intermediate language supported by all major browsers.},
	pages = {127--148},
	booktitle = {Verification, Model Checking, and Abstract Interpretation},
	publisher = {Springer International Publishing},
	author = {Namjoshi, Kedar S. and Xue, Anton},
	editor = {Henglein, Fritz and Shoham, Sharon and Vizel, Yakir},
	date = {2021},
	langid = {english},
}

@inproceedings{goudsmid_compositional_2021,
	location = {Cham},
	title = {Compositional Model Checking for Multi-properties},
	isbn = {978-3-030-67067-2},
	doi = {10.1007/978-3-030-67067-2_4},
	series = {Lecture Notes in Computer Science},
	abstract = {Hyperproperties lift conventional trace properties in a way that describes how a system behaves in its entirety, and not just based on its individual traces. We generalize this notion to multi-properties, which describe the behavior of not just a single system, but of a set of systems, which we call a multi-model. We demonstrate the usefulness of our setting with practical examples. We show that model-checking multi-properties is equivalent to model-checking hyperproperties. However, our framework has the immediate advantage of being compositional. We introduce sound and complete compositional proof rules for model-checking multi-properties, based on over- and under-approximations of the systems in the multi-model. We then describe methods of computing such approximations. The first is abstraction-refinement based, in which a coarse initial abstraction is continuously refined using counterexamples, until a suitable approximation is found. The second, tailored for models with finite traces, finds suitable approximations via the {\textbackslash}(L{\textasciicircum}*{\textbackslash}) learning algorithm. Our methods can produce much smaller models than the original ones, and can therefore be used for accelerating model-checking for both multi-properties and hyperproperties.},
	pages = {55--80},
	booktitle = {Verification, Model Checking, and Abstract Interpretation},
	publisher = {Springer International Publishing},
	author = {Goudsmid, Ohad and Grumberg, Orna and Sheinvald, Sarai},
	editor = {Henglein, Fritz and Shoham, Sharon and Vizel, Yakir},
	date = {2021},
	langid = {english},
}

@inproceedings{dietsch_verification_2021,
	location = {Cham},
	title = {Verification of Concurrent Programs Using Petri Net Unfoldings},
	isbn = {978-3-030-67067-2},
	doi = {10.1007/978-3-030-67067-2_9},
	series = {Lecture Notes in Computer Science},
	abstract = {Given a verification problem for a concurrent program (with a fixed number of threads) over infinite data domains, we can construct a model checking problem for an abstraction of the concurrent program through a Petri net (a problem which can be solved using {McMillan}’s unfoldings technique). We present a method of abstraction refinement which translates Floyd/Hoare-style proofs for sample traces into additional synchronization constraints for the Petri net.},
	pages = {174--195},
	booktitle = {Verification, Model Checking, and Abstract Interpretation},
	publisher = {Springer International Publishing},
	author = {Dietsch, Daniel and Heizmann, Matthias and Klumpp, Dominik and Naouar, Mehdi and Podelski, Andreas and Schätzle, Claus},
	editor = {Henglein, Fritz and Shoham, Sharon and Vizel, Yakir},
	date = {2021},
	langid = {english},
	keywords = {Verification, Concurrency, Petri nets, Unfoldings},
}

@inproceedings{vedrine_runtime_2021,
	location = {Cham},
	title = {Runtime Abstract Interpretation for Numerical Accuracy and Robustness},
	isbn = {978-3-030-67067-2},
	doi = {10.1007/978-3-030-67067-2_12},
	series = {Lecture Notes in Computer Science},
	abstract = {Verification of numerical accuracy properties in modern software remains an important and challenging task. One of its difficulties is related to unstable tests, where the execution can take different branches for real and floating-point numbers. This paper presents a new verification technique for numerical properties, named Runtime Abstract Interpretation ({RAI}), that, given an annotated source code, embeds into it an abstract analyzer in order to analyze the program behavior at runtime. {RAI} is a hybrid technique combining abstract interpretation and runtime verification that aims at being sound as the former while taking benefit from the concrete run to gain greater precision from the latter when necessary. It solves the problem of unstable tests by surrounding an unstable test by two carefully defined program points, forming a so-called split-merge section, for which it separately analyzes different executions and merges the computed domains at the end of the section. Our implementation of this technique in a toolchain called {FLDBox} relies on two basic tools, {FLDCompiler}, that performs a source-to-source transformation of the given program and defines the split-merge sections, and an instrumentation library {FLDLib} that provides necessary primitives to explore relevant (partial) executions of each section and propagate accuracy properties. Initial experiments show that the proposed technique can efficiently and soundly analyze numerical accuracy for industrial programs on thin numerical scenarios.},
	pages = {243--266},
	booktitle = {Verification, Model Checking, and Abstract Interpretation},
	publisher = {Springer International Publishing},
	author = {Védrine, Franck and Jacquemin, Maxime and Kosmatov, Nikolai and Signoles, Julien},
	editor = {Henglein, Fritz and Shoham, Sharon and Vizel, Yakir},
	date = {2021},
	langid = {english},
}

@inproceedings{zhang_netter_2021,
	location = {Cham},
	title = {Netter: Probabilistic, Stateful Network Models},
	isbn = {978-3-030-67067-2},
	doi = {10.1007/978-3-030-67067-2_22},
	series = {Lecture Notes in Computer Science},
	shorttitle = {Netter},
	abstract = {We study the problem of using probabilistic network models to formally analyze their quantitative properties, such as the effect of different load-balancing strategies on the long-term traffic on a server farm. Compared to prior work, we explore a different design space in terms of tradeoffs between model expressiveness and analysis scalability, which we realize in a language we call Netter. Netter code is compiled to probabilistic automata, undergoing optimization passes to reduce the state space of the generated models, thus helping verification scale. We evaluate Netter on several case studies, including a probabilistic load balancer, a routing scheme reminiscent of {MPLS}, and a network defense mechanism against link-flooding attacks. Our results show that Netter can analyze quantitative properties of interesting routing schemes that prior work hadn’t addressed, for networks of small size (4–9 nodes and a few different types of flows). Moreover, when specialized to simpler, stateless networks, Netter can parallel the performance of previous state-of-the-art tools, scaling up to millions of nodes.},
	pages = {486--508},
	booktitle = {Verification, Model Checking, and Abstract Interpretation},
	publisher = {Springer International Publishing},
	author = {Zhang, Han and Zhang, Chi and Azevedo de Amorim, Arthur and Agarwal, Yuvraj and Fredrikson, Matt and Jia, Limin},
	editor = {Henglein, Fritz and Shoham, Sharon and Vizel, Yakir},
	date = {2021},
	langid = {english},
	keywords = {Discrete-time Markov chains, Probabilistic model checking, Stateful networks},
}

@incollection{maillardspan_dijkstra_2019,
	title = {Dijkstra Monads for All},
	url = {https://arxiv.org/abs/1903.01237},
	booktitle = {24th {ACM} {SIGPLAN} International Conference on Functional Programming ({ICFP})},
	author = {Maillard\{{\textbackslash}textless\}/span\{{\textbackslash}textgreater\}, \{{\textbackslash}textless\}span itemprop="author" itemtype="http://schema org/Person"\{{\textbackslash}textgreater\}Kenji and Ahman\{{\textbackslash}textless\}/span\{{\textbackslash}textgreater\}, \{{\textbackslash}textless\}span itemprop="author" itemtype="http://schema org/Person"\{{\textbackslash}textgreater\}Danel and Atkey\{{\textbackslash}textless\}/span\{{\textbackslash}textgreater\}, \{{\textbackslash}textless\}span itemprop="author" itemtype="http://schema org/Person"\{{\textbackslash}textgreater\}Robert and Martínez\{{\textbackslash}textless\}/span\{{\textbackslash}textgreater\}, \{{\textbackslash}textless\}span itemprop="author" itemtype="http://schema org/Person"\{{\textbackslash}textgreater\}Guido and Hritcu\{{\textbackslash}textless\}/span\{{\textbackslash}textgreater\}, \{{\textbackslash}textless\}span itemprop="author" itemtype="http://schema org/Person"\{{\textbackslash}textgreater\}Catalin and Rivas\{{\textbackslash}textless\}/span\{{\textbackslash}textgreater\}, \{{\textbackslash}textless\}span itemprop="author" itemtype="http://schema org/Person"\{{\textbackslash}textgreater\}Exequiel and Tanter\{{\textbackslash}textless\}/span\{{\textbackslash}textgreater\}, \{{\textbackslash}textless\}span itemprop="author" itemtype="http://schema org/Person"\{{\textbackslash}textgreater\}Éric},
	date = {2019},
	file = {Papers:/home/fordrl/Zotero/storage/2FQXALJK/papers.html:text/html},
}

@article{swamy_steelcore_2020,
	title = {{SteelCore}: an extensible concurrent separation logic for effectful dependently typed programs},
	volume = {4},
	url = {https://doi.org/10.1145/3409003},
	doi = {10.1145/3409003},
	shorttitle = {{SteelCore}},
	abstract = {Much recent research has been devoted to modeling effects within type theory. Building on this work, we observe that effectful type theories can provide a foundation on which to build semantics for more complex programming constructs and program logics, extending the reasoning principles that apply within the host effectful type theory itself. Concretely, our main contribution is a semantics for concurrent separation logic ({CSL}) within the F⋆ proof assistant in a manner that enables dependently typed, effectful F⋆ programs to make use of concurrency and to be specified and verified using a full-featured, extensible {CSL}. In contrast to prior approaches, we directly derive the partial-correctness Hoare rules for {CSL} from the denotation of computations in the effectful semantics of non-deterministically interleaved atomic actions. Demonstrating the flexibility of our semantics, we build generic, verified libraries that support various concurrency constructs, ranging from dynamically allocated, storable spin locks, to protocol-indexed channels. We conclude that our effectful semantics provides a simple yet expressive basis on which to layer domain-specific languages and logics for verified, concurrent programming.},
	pages = {121:1--121:30},
	issue = {{ICFP}},
	journaltitle = {Proceedings of the {ACM} on Programming Languages},
	shortjournal = {Proc. {ACM} Program. Lang.},
	author = {Swamy, Nikhil and Rastogi, Aseem and Fromherz, Aymeric and Merigoux, Denis and Ahman, Danel and Martínez, Guido},
	urldate = {2021-01-15},
	date = {2020-08-02},
	keywords = {Separation Logic, Concurrency, Program Proofs},
	file = {Full Text PDF:/home/fordrl/Zotero/storage/SUDXPIZE/Swamy et al. - 2020 - SteelCore an extensible concurrent separation log.pdf:application/pdf},
}

@inproceedings{almeida_last_2020,
	location = {San Francisco, {CA}, {USA}},
	title = {The Last Mile: High-Assurance and High-Speed Cryptographic Implementations},
	isbn = {978-1-72813-497-0},
	url = {https://ieeexplore.ieee.org/document/9152665/},
	doi = {10.1109/SP40000.2020.00028},
	shorttitle = {The Last Mile},
	abstract = {We develop a new approach for building cryptographic implementations. Our approach goes the last mile and delivers assembly code that is provably functionally correct, protected against side-channels, and as efﬁcient as handwritten assembly. We illustrate our approach using {ChaCha}20Poly1305, one of the two ciphersuites recommended in {TLS} 1.3, and deliver formally veriﬁed vectorized implementations which outperform the fastest non-veriﬁed code.},
	eventtitle = {2020 {IEEE} Symposium on Security and Privacy ({SP})},
	pages = {965--982},
	booktitle = {2020 {IEEE} Symposium on Security and Privacy ({SP})},
	publisher = {{IEEE}},
	author = {Almeida, Jose Bacelar and Barbosa, Manuel and Barthe, Gilles and Gregoire, Benjamin and Koutsos, Adrien and Laporte, Vincent and Oliveira, Tiago and Strub, Pierre-Yves},
	urldate = {2021-01-14},
	date = {2020-05},
	langid = {english},
	file = {Almeida et al. - 2020 - The Last Mile High-Assurance and High-Speed Crypt.pdf:/home/fordrl/Zotero/storage/6KSYXHM5/Almeida et al. - 2020 - The Last Mile High-Assurance and High-Speed Crypt.pdf:application/pdf},
}

@article{ferles_verifying_2021,
	title = {Verifying correct usage of context-free {API} protocols},
	volume = {5},
	url = {https://doi.org/10.1145/3434298},
	doi = {10.1145/3434298},
	abstract = {Several real-world libraries (e.g., reentrant locks, {GUI} frameworks, serialization libraries) require their clients to use the provided {API} in a manner that conforms to a context-free specification. Motivated by this observation, this paper describes a new technique for verifying the correct usage of context-free {API} protocols. The key idea underlying our technique is to over-approximate the program’s feasible {API} call sequences using a context-free grammar ({CFG}) and then check language inclusion between this grammar and the specification. However, since this inclusion check may fail due to imprecision in the program’s {CFG} abstraction, we propose a novel refinement technique to progressively improve the {CFG}. In particular, our method obtains counterexamples from {CFG} inclusion queries and uses them to introduce new non-terminals and productions to the grammar while still over-approximating the program’s relevant behavior. We have implemented the proposed algorithm in a tool called {CFPChecker} and evaluate it on 10 popular Java applications that use at least one {API} with a context-free specification. Our evaluation shows that {CFPChecker} is able to verify correct usage of the {API} in clients that use it correctly and produces counterexamples for those that do not. We also compare our method against three relevant baselines and demonstrate that {CFPChecker} enables verification of safety properties that are beyond the reach of existing tools.},
	pages = {17:1--17:30},
	issue = {{POPL}},
	journaltitle = {Proceedings of the {ACM} on Programming Languages},
	shortjournal = {Proc. {ACM} Program. Lang.},
	author = {Ferles, Kostas and Stephens, Jon and Dillig, Isil},
	urldate = {2021-01-14},
	date = {2021-01-04},
	keywords = {Program Verification, Abstraction Refinement, Context-Free {API} Protocols},
	file = {Full Text PDF:/home/fordrl/Zotero/storage/73V7VR5H/Ferles et al. - 2021 - Verifying correct usage of context-free API protoc.pdf:application/pdf},
}

@article{watertor_assessing_nodate,
	title = {Assessing the standard-compliance for multi-threading primitives in C compilers},
	pages = {58},
	author = {Watertor, Rick},
	langid = {english},
	file = {Watertor - Assessing the standard-compliance for multi-thread.pdf:/home/fordrl/Zotero/storage/C8Y6Q2GJ/Watertor - Assessing the standard-compliance for multi-thread.pdf:application/pdf},
}

@article{backes_one-click_2019,
	title = {One-Click Formal Methods},
	volume = {36},
	issn = {0740-7459, 1937-4194},
	url = {https://ieeexplore.ieee.org/document/8880058/},
	doi = {10.1109/MS.2019.2930609},
	pages = {61--65},
	number = {6},
	journaltitle = {{IEEE} Software},
	author = {Backes, John and Varming, Carsten and Whalen, Michael and Bolignano, Pauline and Cook, Byron and Gacek, Andrew and Luckow, Kasper Soe and Rungta, Neha and Schaef, Martin and Schlesinger, Cole and Tanash, Rima},
	urldate = {2021-01-12},
	date = {2019-11},
	langid = {english},
	file = {Backes et al. - 2019 - One-Click Formal Methods.pdf:/home/fordrl/Zotero/storage/Y9ZE6M6U/Backes et al. - 2019 - One-Click Formal Methods.pdf:application/pdf},
}

@inproceedings{liu_p4v_2018,
	location = {Budapest Hungary},
	title = {p4v: practical verification for programmable data planes},
	isbn = {978-1-4503-5567-4},
	url = {https://dl.acm.org/doi/10.1145/3230543.3230582},
	doi = {10.1145/3230543.3230582},
	shorttitle = {p4v},
	abstract = {We present the design and implementation of p4v, a practical tool for verifying data planes described using the P4 programming language. The design of p4v is based on classic verification techniques but adds several key innovations including a novel mechanism for incorporating assumptions about the control plane and domain-specific optimizations which are needed to scale to large programs. We present case studies showing that p4v verifies important properties and finds bugs in real-world programs. We conduct experiments to quantify the scalability of p4v on a wide range of additional examples. We show that with just a few hundred lines of control-plane annotations, p4v is able to verify critical safety properties for switch.p4, a program that implements the functionality of on a modern data center switch, in under three minutes.},
	eventtitle = {{SIGCOMM} '18: {ACM} {SIGCOMM} 2018 Conference},
	pages = {490--503},
	booktitle = {Proceedings of the 2018 Conference of the {ACM} Special Interest Group on Data Communication},
	publisher = {{ACM}},
	author = {Liu, Jed and Hallahan, William and Schlesinger, Cole and Sharif, Milad and Lee, Jeongkeun and Soulé, Robert and Wang, Han and Caşcaval, Călin and {McKeown}, Nick and Foster, Nate},
	urldate = {2021-01-10},
	date = {2018-08-07},
	langid = {english},
	file = {Liu et al. - 2018 - p4v practical verification for programmable data .pdf:/home/fordrl/Zotero/storage/5MKBLF7T/Liu et al. - 2018 - p4v practical verification for programmable data .pdf:application/pdf},
}

@article{foster_using_2020,
	title = {Using deep programmability to put network owners in control},
	volume = {50},
	issn = {0146-4833},
	url = {https://doi.org/10.1145/3431832.3431842},
	doi = {10.1145/3431832.3431842},
	abstract = {Controlling an opaque system by reading some "dials" and setting some "knobs," without really knowing what they do, is a hazardous and fruitless endeavor, particularly at scale. What we need are transparent networks, that start at the top with a high-level intent and map all the way down, through the control plane to the data plane. If we can specify the behavior we want in software, then we can check that the system behaves as we expect. This is impossible if the implementation is opaque. We therefore need to use open-source software or write it ourselves (or both), and have mechanisms for checking actual behavior against the specified intent. With fine-grain checking (e.g., every packet, every state variable), we can build networks that are more reliable, secure, and performant. In the limit, we can build networks that run autonomously under verifiable, closed-loop control. We believe this vision, while ambitious, is finally within our reach, due to deep programmability across the stack, both vertically (control and data plane) and horizontally (end to end). It will emerge naturally in some networks, as network owners take control of their software and engage in open-source efforts; whereas in enterprise networks it may take longer. In 5G access networks, there is a pressing need for our community to engage, so these networks, too, can operate autonomously under verifiable, closed-loop control.},
	pages = {82--88},
	number = {4},
	journaltitle = {{ACM} {SIGCOMM} Computer Communication Review},
	shortjournal = {{SIGCOMM} Comput. Commun. Rev.},
	author = {Foster, Nate and {McKeown}, Nick and Rexford, Jennifer and Parulkar, Guru and Peterson, Larry and Sunay, Oguz},
	urldate = {2021-01-10},
	date = {2020-10-26},
	keywords = {network verification, programmable networks, software defined networks ({SDN}), telemetry},
	file = {Full Text PDF:/home/fordrl/Zotero/storage/286YIG6A/Foster et al. - 2020 - Using deep programmability to put network owners i.pdf:application/pdf},
}

@article{benzaken_coq_2021,
	title = {A Coq Formalization of Data Provenance},
	abstract = {{CCS} Concepts: • Software and its engineering → Formal software verification; Correctness; Software verification; • Theory of computation → Logic and verification; Type theory; Program verification; Program semantics; Data provenance.},
	pages = {18},
	author = {Benzaken, Véronique and Cohen-Boulakia, Sarah and Contejean, Évelyne and Keller, Chantal and Zucchini, Rébecca},
	date = {2021},
	langid = {english},
	file = {Benzaken et al. - 2021 - A Coq Formalization of Data Provenance.pdf:/home/fordrl/Zotero/storage/SNE5BLUL/Benzaken et al. - 2021 - A Coq Formalization of Data Provenance.pdf:application/pdf},
}

@article{meseguer_symbolic_nodate,
	title = {Symbolic Computation in Maude: Some Tapas},
	abstract = {Programming in Maude is executable mathematical modeling. Your mathematical model is the code you execute. Both deterministic systems, specified equationally as so-called functional modules and concurrent ones, specified in rewriting logic as system modules, are mathematically modeled and programmed this way. But rewriting logic is also a logical framework in which many different logics can be naturally represented. And one would like not only to execute these models, but to reason about them at a high level. For this, symbolic methods that can automate much of the reasoning are crucial. Many of them are actually supported by Maude itself or by some of its tools. These methods are very general: they apply not just to Maude, but to many other logics, languages and tools. This paper presents some tapas about these Maude-based symbolic methods in an informal way to make it easy for many other people to learn about, and benefit from, them.},
	pages = {26},
	author = {Meseguer, Jose},
	langid = {english},
	file = {Meseguer - Symbolic Computation in Maude Some Tapas.pdf:/home/fordrl/Zotero/storage/QHR37R2G/Meseguer - Symbolic Computation in Maude Some Tapas.pdf:application/pdf},
}

@article{chiplunkar_automated_nodate,
	title = {Automated Synthesis of Verified Firewalls},
	abstract = {We demonstrate correct-by-construction firewalls—stateful packet filters for {TCP}/{IP} packets—using the Fiat synthesis library [3]. We present a general {DSL} for specifying their behavior independent of algorithmic implementation. We outline the design of a verified compiler in Coq, detail a few verified efficiency optimizations, and show how the compiler can easily be extended to support custom optimizations for user-defined policies.},
	pages = {3},
	author = {Chiplunkar, Shardul and Pit-Claudel, Clément and Chlipala, Adam},
	langid = {english},
	file = {Chiplunkar et al. - Automated Synthesis of Verified Firewalls.pdf:/home/fordrl/Zotero/storage/Y4ABWKKA/Chiplunkar et al. - Automated Synthesis of Verified Firewalls.pdf:application/pdf},
}

@article{bosshart_programming_2014,
	title = {Programming Protocol-Independent Packet Processors},
	url = {http://arxiv.org/abs/1312.1719},
	abstract = {P4 is a high-level language for programming protocol-independent packet processors. P4 works in conjunction with {SDN} control protocols like {OpenFlow}. In its current form, {OpenFlow} explicitly specifies protocol headers on which it operates. This set has grown from 12 to 41 fields in a few years, increasing the complexity of the specification while still not providing the flexibility to add new headers. In this paper we propose P4 as a strawman proposal for how {OpenFlow} should evolve in the future. We have three goals: (1) Reconfigurability in the field: Programmers should be able to change the way switches process packets once they are deployed. (2) Protocol independence: Switches should not be tied to any specific network protocols. (3) Target independence: Programmers should be able to describe packet-processing functionality independently of the specifics of the underlying hardware. As an example, we describe how to use P4 to configure a switch to add a new hierarchical label.},
	journaltitle = {{arXiv}:1312.1719 [cs]},
	author = {Bosshart, Pat and Daly, Dan and Izzard, Martin and {McKeown}, Nick and Rexford, Jennifer and Schlesinger, Cole and Talayco, Dan and Vahdat, Amin and Varghese, George and Walker, David},
	urldate = {2021-01-05},
	date = {2014-05-15},
	eprinttype = {arxiv},
	eprint = {1312.1719},
	keywords = {Computer Science - Networking and Internet Architecture},
	file = {arXiv.org Snapshot:/home/fordrl/Zotero/storage/TBFDVBAK/1312.html:text/html;arXiv Fulltext PDF:/home/fordrl/Zotero/storage/XTUGDPN7/Bosshart et al. - 2014 - Programming Protocol-Independent Packet Processors.pdf:application/pdf},
}

@inproceedings{leijen_mimalloc_2019,
	location = {Cham},
	title = {Mimalloc: Free List Sharding in Action},
	isbn = {978-3-030-34175-6},
	doi = {10.1007/978-3-030-34175-6_13},
	series = {Lecture Notes in Computer Science},
	shorttitle = {Mimalloc},
	abstract = {Modern memory allocators have to balance many simultaneous demands, including performance, security, the presence of concurrency, and application-specific demands depending on the context of their use. One increasing use-case for allocators is as back-end implementations of languages, such as Swift and Python, that use reference counting to automatically deallocate objects. We present mimalloc, a memory allocator that effectively balances these demands, shows significant performance advantages over existing allocators, and is tailored to support languages that rely on the memory allocator as a backend for reference counting. Mimalloc combines several innovations to achieve this result. First, it uses three page-local sharded free lists to increase locality, avoid contention, and support a highly-tuned allocate and free fast path. These free lists also support temporal cadence, which allows the allocator to predictably leave the fast path for regular maintenance tasks such as supporting deferred freeing, handling frees from non-local threads, etc. While influenced by the allocation workload of the reference-counted Lean and Koka programming language, we show that mimalloc has superior performance to modern commercial memory allocators, including tcmalloc and jemalloc, with speed improvements of 7\% and 14\%, respectively, on redis, and consistently out performs over a wide range of sequential and concurrent benchmarks. Allocators tailored to provide an efficient runtime for reference-counting languages reduce the implementation burden on developers and encourage the creation of innovative new language designs.},
	pages = {244--265},
	booktitle = {Programming Languages and Systems},
	publisher = {Springer International Publishing},
	author = {Leijen, Daan and Zorn, Benjamin and de Moura, Leonardo},
	editor = {Lin, Anthony Widjaja},
	date = {2019},
	langid = {english},
}

@article{selsam_tabled_2020,
	title = {Tabled Typeclass Resolution},
	url = {http://arxiv.org/abs/2001.04301},
	abstract = {Typeclasses provide an elegant and effective way of managing ad-hoc polymorphism in both programming languages and interactive proof assistants. However, the increasingly sophisticated uses of typeclasses within proof assistants, especially within Lean's burgeoning mathematics library, mathlib, have elevated once-theoretical limitations of existing typeclass resolution procedures into major impediments to ongoing progress. The two most devastating limitations of existing procedures are exponential running times in the presence of diamonds and divergence in the presence of cycles. We present a new procedure, tabled typeclass resolution, that solves both problems by tabling, which is a generalization of memoizing originally introduced to address similar limitations of early logic programming systems. We have implemented our procedure for the upcoming version (v4) of Lean, and have confirmed empirically that our implementation is exponentially faster than existing systems in the presence of diamonds. Although tabling is notoriously difficult to implement, our procedure is notably lightweight and could easily be implemented in other systems. We hope our new procedure facilitates even more sophisticated uses of typeclasses in both software development and interactive theorem proving.},
	journaltitle = {{arXiv}:2001.04301 [cs]},
	author = {Selsam, Daniel and Ullrich, Sebastian and de Moura, Leonardo},
	urldate = {2021-01-05},
	date = {2020-01-21},
	eprinttype = {arxiv},
	eprint = {2001.04301},
	keywords = {Computer Science - Programming Languages, Computer Science - Logic in Computer Science},
	file = {arXiv.org Snapshot:/home/fordrl/Zotero/storage/ZJEFBKCJ/2001.html:text/html;arXiv Fulltext PDF:/home/fordrl/Zotero/storage/2UD23YW9/Selsam et al. - 2020 - Tabled Typeclass Resolution.pdf:application/pdf},
}

@inproceedings{carneiro_metamath_2020,
	location = {Cham},
	title = {Metamath Zero: Designing a Theorem Prover Prover},
	isbn = {978-3-030-53518-6},
	doi = {10.1007/978-3-030-53518-6_5},
	series = {Lecture Notes in Computer Science},
	shorttitle = {Metamath Zero},
	abstract = {As the usage of theorem prover technology expands, so too does the reliance on correctness of the tools. Metamath Zero is a verification system that aims for simplicity of logic and implementation, without compromising on efficiency of verification. It is formally specified in its own language, and supports a number of translations to and from other proof languages. This paper describes the abstract logic of Metamath Zero, essentially a multi-sorted first order logic, as well as the binary proof format and the way in which it can ensure essentially linear time verification while still being concise and efficient at scale. Metamath Zero currently holds the record for fastest verification of the set.mm Metamath library of proofs in {ZFC} (including 71 of Wiedijk’s 100 formalization targets), at less than 200 ms. Ultimately, we intend to use it to verify the correctness of the implementation of the verifier down to binary executable, so it can be used as a root of trust for more complex proof systems.},
	pages = {71--88},
	booktitle = {Intelligent Computer Mathematics},
	publisher = {Springer International Publishing},
	author = {Carneiro, Mario},
	editor = {Benzmüller, Christoph and Miller, Bruce},
	date = {2020},
	langid = {english},
	keywords = {Verification, Formal proof, Mathematics, Metamath zero, Metamathematics},
	file = {Carneiro - 2020 - Metamath Zero Designing a Theorem Prover Prover.pdf:/home/fordrl/Zotero/storage/642A4BN2/Carneiro - 2020 - Metamath Zero Designing a Theorem Prover Prover.pdf:application/pdf},
}

@article{wang_formalization_2018,
	title = {Formalization and Verification of the {OpenFlow} Bundle Mechanism Using {CSP}},
	volume = {28},
	issn = {0218-1940},
	url = {https://www.worldscientific.com/doi/abs/10.1142/S0218194018400223},
	doi = {10.1142/S0218194018400223},
	abstract = {Software-Defined Networking ({SDN}) is an emerging architecture of computer networking. {OpenFlow} is considered as the first and currently most popular standard southbound interface of {SDN}. It is a communication protocol which enables the {SDN} controller to directly interact with the forwarding plane, which makes the network more flexible and programmable. The promising and widespread use makes the reliability of {OpenFlow} important. The {OpenFlow} bundle mechanism is a new mechanism proposed by {OpenFlow} protocol to guarantee the completeness and consistency of the messages transmitted between {SDN} devices like switches and controllers. In this paper, we use Communication Sequential Processes ({CSP}) to formally model the {OpenFlow} bundle mechanism. By adopting the models into the model checker Process Analysis Toolkit ({PAT}), we verify the relevant properties of the mechanism, including deadlock freeness, parallelism, atomicity, order property and schedulability. Our formalization and verification show that the mechanism can satisfy these properties, from which we can conclude that the mechanism offers a better way to guarantee the completeness and consistency.},
	pages = {1657--1677},
	number = {11},
	journaltitle = {International Journal of Software Engineering and Knowledge Engineering},
	shortjournal = {Int. J. Soft. Eng. Knowl. Eng.},
	author = {Wang, Huiwen and Zhu, Huibiao and Xiao, Lili and Fei, Yuan},
	urldate = {2021-01-05},
	date = {2018-11-01},
	note = {Publisher: World Scientific Publishing Co.},
	file = {Snapshot:/home/fordrl/Zotero/storage/RR5GN5BU/S0218194018400223.html:text/html},
}

@book{kang_formal_2013,
	title = {Formal Modeling and Verification of {SDN}-{OpenFlow}},
	isbn = {978-1-4673-5961-0},
	abstract = {Software-Defined Networking ({SDN}) is a network architecture where a controller manages flow control to enable intelligent networking. Currently, a popular specification for creating an {SDN} is an open standard called {OpenFlow}. The behavior of the {SDN} {OpenFlow} ({SDN}-{OF}) is critical to the safety of the network system and its correctness must be proven so as to avoid system failures. In this paper, we report our experience in applying formal techniques for modeling and analysis of {SDN}-{OF}. The formal model of {SDN}-{OF} is described in detail and its correctness is formalized in logical formulas based on the informal specification. The desired properties are verified over the model using {VERSA} and {UPPAAL}. Our work-in-progressinvolves the development of a model translation tool that facilitates automatic conversion of the verified model to Python for modular code synthesis on the application platform},
	pagetotal = {481},
	author = {Kang, Miyoung and Kang, Eun-Young and Hwang, Dae-Yon and Kim, Beom-Jin and Nam, Ki-Hyuk and Shin, Myung-Ki and Choi, Jin-Young},
	date = {2013-03-01},
	doi = {10.1109/ICST.2013.69},
	note = {Pages: 482},
	file = {Full Text PDF:/home/fordrl/Zotero/storage/2F9G8P8Z/Kang et al. - 2013 - Formal Modeling and Verification of SDN-OpenFlow.pdf:application/pdf},
}

@article{bordg_certified_2020,
	title = {Certified Quantum Computation in Isabelle/{HOL}},
	doi = {10.1007/s10817-020-09584-7},
	abstract = {In this article we present an ongoing effort to formalise quantum algorithms and results in quantum information theory using the proof assistant Isabelle/{HOL}. Formal methods being critical for the safety and security of algorithms and protocols, we foresee their widespread use for quantum computing in the future. We have developed a large library for quantum computing in Isabelle based on a matrix representation for quantum circuits, successfully formalising the no-cloning theorem, quantum teleportation, Deutsch’s algorithm, the Deutsch–Jozsa algorithm and the quantum Prisoner’s Dilemma. We discuss the design choices made and report on an outcome of our work in the field of quantum game theory.},
	pages = {1--19},
	journaltitle = {Journal of Automated Reasoning},
	shortjournal = {Journal of Automated Reasoning},
	author = {Bordg, Anthony and Lachnitt, Hanna and He, Yijun},
	date = {2020-12-24},
	file = {Full Text PDF:/home/fordrl/Zotero/storage/DYIJZQEV/Bordg et al. - 2020 - Certified Quantum Computation in IsabelleHOL.pdf:application/pdf},
}

@article{silver_dijkstra_nodate,
	title = {Dijkstra Monads Forever: Termination-Sensitive Specifications for Interaction Trees},
	volume = {5},
	abstract = {{STEVE} {ZDANCEWIC}, University of Pennsylvania, {USA} This paper extends the Dijkstra monad framework, designed for writing specifications over effectful programs using monadic effects, to handle termination sensitive specifications over interactive programs. We achieve this by introducing base specification monads for non-terminating programs with uninterpreted events. We model such programs using interaction trees, a coinductive datatype for representing programs with algebraic effects in Coq, which we further develop by adding trace semantics. We show that this approach subsumes typical, simple proof principles. The framework is implemented as an extension of the Interaction Trees Coq library. {CCS} Concepts: • Theory of computation → Logic and verification; Programming logic; Hoare logic; Program specifications; Pre- and post-conditions; Program verification; Invariants.},
	pages = {28},
	author = {Silver, Lucas and Zdancewic, Steve},
	langid = {english},
	file = {Silver and Zdancewic - Dijkstra Monads Forever Termination-Sensitive Spe.pdf:/home/fordrl/Zotero/storage/XDSHWEWD/Silver and Zdancewic - Dijkstra Monads Forever Termination-Sensitive Spe.pdf:application/pdf},
}

@article{myreen_minimalistic_2021,
	title = {A Minimalistic Verified Bootstrapped Compiler (Proof Pearl)},
	abstract = {This paper shows how a small verified bootstrapped compiler can be developed inside an interactive theorem prover ({ITP}). Throughout, emphasis is put on clarity and minimalism.},
	pages = {14},
	author = {Myreen, Magnus O},
	date = {2021},
	langid = {english},
	file = {Myreen - 2021 - A Minimalistic Verified Bootstrapped Compiler (Pro.pdf:/home/fordrl/Zotero/storage/W86LYDH6/Myreen - 2021 - A Minimalistic Verified Bootstrapped Compiler (Pro.pdf:application/pdf},
}

@article{astrauskas_leveraging_2019,
	title = {Leveraging rust types for modular specification and verification},
	volume = {3},
	url = {https://doi.org/10.1145/3360573},
	doi = {10.1145/3360573},
	abstract = {Rust's type system ensures memory safety: well-typed Rust programs are guaranteed to not exhibit problems such as dangling pointers, data races, and unexpected side effects through aliased references. Ensuring correctness properties beyond memory safety, for instance, the guaranteed absence of assertion failures or more-general functional correctness, requires static program verification. For traditional system programming languages, formal verification is notoriously difficult and requires complex specifications and logics to reason about pointers, aliasing, and side effects on mutable state. This complexity is a major obstacle to the more-widespread verification of system software. In this paper, we present a novel verification technique that leverages Rust's type system to greatly simplify the specification and verification of system software written in Rust. We analyse information from the Rust compiler and synthesise a corresponding core proof for the program in a flavour of separation logic tailored to automation. To verify correctness properties beyond memory safety, users can annotate Rust programs with specifications at the abstraction level of Rust expressions; our technique weaves them into the core proof to verify modularly whether these specifications hold. Crucially, our proofs are constructed and checked automatically without exposing the underlying formal logic, allowing users to work exclusively at the level of abstraction of the programming language. As such, our work enables a new kind of verification tool, with the potential to impact a wide audience and allow the Rust community to benefit from state-of-the-art verification techniques. We have implemented our techniques for a subset of Rust; our evaluation on several thousand functions from widely-used Rust crates demonstrates its effectiveness.},
	pages = {147:1--147:30},
	issue = {{OOPSLA}},
	journaltitle = {Proceedings of the {ACM} on Programming Languages},
	shortjournal = {Proc. {ACM} Program. Lang.},
	author = {Astrauskas, Vytautas and Müller, Peter and Poli, Federico and Summers, Alexander J.},
	urldate = {2020-03-16},
	date = {2019-10-10},
	keywords = {concurrency, heap-manipulating programs, Rust, type systems},
	file = {Full Text PDF:/home/fordrl/Zotero/storage/L2NTGNPA/Astrauskas et al. - 2019 - Leveraging rust types for modular specification an.pdf:application/pdf},
}

@inproceedings{cousot_automatic_2013,
	location = {Berlin, Heidelberg},
	title = {Automatic Inference of Necessary Preconditions},
	isbn = {978-3-642-35873-9},
	doi = {10.1007/978-3-642-35873-9_10},
	series = {Lecture Notes in Computer Science},
	abstract = {We consider the problem of automatic precondition inference. We argue that the common notion of sufficient precondition inference (i.e., under which precondition is the program correct?) imposes too large a burden on callers, and hence it is unfit for automatic program analysis. Therefore, we define the problem of necessary precondition inference (i.e., under which precondition, if violated, will the program always be incorrect?). We designed and implemented several new abstract interpretation-based analyses to infer atomic, disjunctive, universally and existentially quantified necessary preconditions.We experimentally validated the analyses on large scale industrial code. For unannotated code, the inference algorithms find necessary preconditions for almost 64\% of methods which contained warnings. In 27\% of these cases the inferred preconditions were also sufficient, meaning all warnings within the method body disappeared. For annotated code, the inference algorithms find necessary preconditions for over 68\% of methods with warnings. In almost 50\% of these cases the preconditions were also sufficient. Overall, the precision improvement obtained by precondition inference (counted as the additional number of methods with no warnings) ranged between 9\% and 21\%.},
	pages = {128--148},
	booktitle = {Verification, Model Checking, and Abstract Interpretation},
	publisher = {Springer},
	author = {Cousot, Patrick and Cousot, Radhia and Fähndrich, Manuel and Logozzo, Francesco},
	editor = {Giacobazzi, Roberto and Berdine, Josh and Mastroeni, Isabella},
	date = {2013},
	langid = {english},
	keywords = {Abstract Interpretation, Abstract Domain, Inference Algorithm, Predicate Abstraction, Proof Obligation},
	file = {Cousot et al. - 2013 - Automatic Inference of Necessary Preconditions.pdf:/home/fordrl/Zotero/storage/PUMBQR6I/Cousot et al. - 2013 - Automatic Inference of Necessary Preconditions.pdf:application/pdf},
}

@article{andronick_formal_2018,
	title = {Formal Model of a Multi-Core Kernel-based System},
	pages = {33},
	author = {Andronick, June and Klein, Gerwin and Lewis, Corey},
	date = {2018-10-10},
	langid = {english},
	file = {Andronick et al. - Formal Model of a Multi-Core Kernel-based System.pdf:/home/fordrl/Zotero/storage/4J3RV6NZ/Andronick et al. - Formal Model of a Multi-Core Kernel-based System.pdf:application/pdf},
}

@inproceedings{hur_power_2013,
	location = {Rome, Italy},
	title = {The power of parameterization in coinductive proof},
	isbn = {978-1-4503-1832-7},
	url = {https://doi.org/10.1145/2429069.2429093},
	doi = {10.1145/2429069.2429093},
	series = {{POPL} '13},
	abstract = {Coinduction is one of the most basic concepts in computer science. It is therefore surprising that the commonly-known lattice-theoretic accounts of the principles underlying coinductive proofs are lacking in two key respects: they do not support compositional reasoning (i.e. breaking proofs into separate pieces that can be developed in isolation), and they do not support incremental reasoning (i.e. developing proofs interactively by starting from the goal and generalizing the coinduction hypothesis repeatedly as necessary). In this paper, we show how to support coinductive proofs that are both compositional and incremental, using a dead simple construction we call the parameterized greatest fixed point. The basic idea is to parameterize the greatest fixed point of interest over the accumulated knowledge of "the proof so far". While this idea has been proposed before, by Winskel in 1989 and by Moss in 2001, neither of the previous accounts suggests its general applicability to improving the state of the art in interactive coinductive proof. In addition to presenting the lattice-theoretic foundations of parameterized coinduction, demonstrating its utility on representative examples, and studying its composition with "up-to" techniques, we also explore its mechanization in proof assistants like Coq and Isabelle. Unlike traditional approaches to mechanizing coinduction (e.g. Coq's cofix), which employ syntactic "guardedness checking", parameterized coinduction offers a semantic account of guardedness. This leads to faster and more robust proof development, as we demonstrate using our new Coq library, Paco.},
	pages = {193--206},
	booktitle = {Proceedings of the 40th annual {ACM} {SIGPLAN}-{SIGACT} symposium on Principles of programming languages},
	publisher = {Association for Computing Machinery},
	author = {Hur, Chung-Kil and Neis, Georg and Dreyer, Derek and Vafeiadis, Viktor},
	urldate = {2020-03-02},
	date = {2013-01-23},
	keywords = {interactive theorem proving, coinduction, compositionality, lattice theory, parameterized greatest fixed point, simulation},
	file = {Full Text PDF:/home/fordrl/Zotero/storage/2C6GE35D/Hur et al. - 2013 - The power of parameterization in coinductive proof.pdf:application/pdf},
}

@article{lin_symbolic_2020,
	title = {Symbolic Execution Game Semantics},
	url = {http://arxiv.org/abs/2002.09115},
	abstract = {We present a framework for symbolically executing and model checking higher-order programs with external (open) methods. We focus on the client-library paradigm and in particular we aim to check libraries with respect to any definable client. We combine traditional symbolic execution techniques with operational game semantics to build a symbolic execution semantics that captures arbitrary external behaviour. We prove the symbolic semantics to be sound and complete. This yields a bounded technique by imposing bounds on the depth of recursion and callbacks. We provide an implementation of our technique in the K framework and showcase its performance on a custom benchmark based on higher-order coding errors such as reentrancy bugs.},
	journaltitle = {{arXiv}:2002.09115 [cs]},
	author = {Lin, Yu-Yang and Tzevelekos, Nikos},
	urldate = {2020-02-28},
	date = {2020-02-20},
	eprinttype = {arxiv},
	eprint = {2002.09115},
	keywords = {Computer Science - Programming Languages},
	file = {arXiv Fulltext PDF:/home/fordrl/Zotero/storage/M4LTSXQN/Lin and Tzevelekos - 2020 - Symbolic Execution Game Semantics.pdf:application/pdf;arXiv.org Snapshot:/home/fordrl/Zotero/storage/JFXL2FJJ/2002.html:text/html},
}

@article{matsushita_rusthorn_2020,
	title = {{RustHorn}: {CHC}-based Verification for Rust Programs (full version)},
	url = {http://arxiv.org/abs/2002.09002},
	shorttitle = {{RustHorn}},
	abstract = {Reduction to the satisfiablility problem for constrained Horn clauses ({CHCs}) is a widely studied approach to automated program verification. The current {CHC}-based methods for pointer-manipulating programs, however, are not very scalable. This paper proposes a novel translation of pointer-manipulating Rust programs into {CHCs}, which clears away pointers and heaps by leveraging ownership. We formalize the translation for a simplified core of Rust and prove its correctness. We have implemented a prototype verifier for a subset of Rust and confirmed the effectiveness of our method.},
	journaltitle = {{arXiv}:2002.09002 [cs]},
	author = {Matsushita, Yusuke and Tsukada, Takeshi and Kobayashi, Naoki},
	urldate = {2020-02-28},
	date = {2020-02-20},
	eprinttype = {arxiv},
	eprint = {2002.09002},
	keywords = {Computer Science - Programming Languages},
	file = {arXiv.org Snapshot:/home/fordrl/Zotero/storage/QWQII4N9/2002.html:text/html;arXiv Fulltext PDF:/home/fordrl/Zotero/storage/NA5J7Z6V/Matsushita et al. - 2020 - RustHorn CHC-based Verification for Rust Programs.pdf:application/pdf},
}

@article{bao_unifying_2018,
	title = {Unifying separation logic and region logic to allow interoperability},
	volume = {30},
	issn = {1433-299X},
	url = {https://doi.org/10.1007/s00165-018-0455-5},
	doi = {10.1007/s00165-018-0455-5},
	abstract = {Framing is important for specification and verification, especially in programs that mutate data structures with shared data, such as {DAGs}. Both separation logic and region logic are successful approaches to framing, with separation logic providing a concise way to reason about data structures that are disjoint, and region logic providing the ability to reason about framing for shared mutable data. In order to obtain the benefits of both logics for programs with shared mutable data, this paper unifies them into a single logic, which can encode both of them and allows them to interoperate. The new logic thus provides a way to reason about program modules specified in a mix of styles.},
	pages = {381--441},
	number = {3},
	journaltitle = {Formal Aspects of Computing},
	shortjournal = {Form Asp Comp},
	author = {Bao, Yuyan and Leavens, Gary T. and Ernst, Gidon},
	urldate = {2020-02-07},
	date = {2018-08-01},
	langid = {english},
}

@article{polikarpova_fully_2018,
	title = {A fully verified container library},
	volume = {30},
	issn = {1433-299X},
	url = {https://doi.org/10.1007/s00165-017-0435-1},
	doi = {10.1007/s00165-017-0435-1},
	abstract = {The comprehensive functionality and nontrivial design of realistic general-purpose container libraries pose challenges to formal verification that go beyond those of individual benchmark problems mainly targeted by the state of the art. We present our experience verifying the full functional correctness of {EiffelBase}2: a container library offering all the features customary in modern language frameworks, such as external iterators, and hash tables with generic mutable keys and load balancing. Verification uses the automated deductive verifier {AutoProof}, which we extended as part of the present work. Our results indicate that verification of a realistic container library (135 public methods, 8400 {LOC}) is possible with moderate annotation overhead (1.4 lines of specification per {LOC}) and good performance (0.2 s per method on average).},
	pages = {495--523},
	number = {5},
	journaltitle = {Formal Aspects of Computing},
	shortjournal = {Form Asp Comp},
	author = {Polikarpova, Nadia and Tschannen, Julian and Furia, Carlo A.},
	urldate = {2020-02-07},
	date = {2018-09-01},
	langid = {english},
	file = {Springer Full Text PDF:/home/fordrl/Zotero/storage/RDFUD4HN/Polikarpova et al. - 2018 - A fully verified container library.pdf:application/pdf},
}

@article{sitaraman_building_2011,
	title = {Building a push-button {RESOLVE} verifier: Progress and challenges},
	volume = {23},
	issn = {0934-5043, 1433-299X},
	url = {http://link.springer.com/10.1007/s00165-010-0154-3},
	doi = {10.1007/s00165-010-0154-3},
	shorttitle = {Building a push-button {RESOLVE} verifier},
	pages = {607--626},
	number = {5},
	journaltitle = {Formal Aspects of Computing},
	author = {Sitaraman, Murali and Adcock, Bruce and Avigad, Jeremy and Bronish, Derek and Bucci, Paolo and Frazier, David and Friedman, Harvey M. and Harton, Heather and Heym, Wayne and Kirschenbaum, Jason and Krone, Joan and Smith, Hampton and Weide, Bruce W.},
	urldate = {2020-02-07},
	date = {2011-09},
	langid = {english},
	file = {Full Text:/home/fordrl/Zotero/storage/T96IBWVZ/Sitaraman et al. - 2011 - Building a push-button RESOLVE verifier Progress .pdf:application/pdf},
}

@inproceedings{kirschenbaum_verifying_2009,
	location = {Berlin, Heidelberg},
	title = {Verifying Component-Based Software: Deep Mathematics or Simple Bookkeeping?},
	isbn = {978-3-642-04211-9},
	doi = {10.1007/978-3-642-04211-9_4},
	series = {Lecture Notes in Computer Science},
	shorttitle = {Verifying Component-Based Software},
	abstract = {Anecdotal experience constructing proofs of correctness of code built from reusable software components reveals that they tend to be relatively trivial bookkeeping exercises: they rarely require a substantive mathematical deduction. A careful empirical analysis of hundreds of verification conditions ({VCs}) for a library of component-client code shows the level of sophistication each proof requires, and suggests how to use the results to characterize a notion of mathematical “obviousness.”},
	pages = {31--40},
	booktitle = {Formal Foundations of Reuse and Domain Engineering},
	publisher = {Springer},
	author = {Kirschenbaum, Jason and Adcock, Bruce and Bronish, Derek and Smith, Hampton and Harton, Heather and Sitaraman, Murali and Weide, Bruce W.},
	editor = {Edwards, Stephen H. and Kulczycki, Gregory},
	date = {2009},
	langid = {english},
	keywords = {Proof Rule, Client Code, Grand Challenge, Loop Invariant, Proof System},
	file = {Submitted Version:/home/fordrl/Zotero/storage/5U4UEMUD/Kirschenbaum et al. - 2009 - Verifying Component-Based Software Deep Mathemati.pdf:application/pdf},
}

@inproceedings{welch_scaling_2017,
	location = {Seattle, Washington, {USA}},
	title = {Scaling Up Automated Verification: A Case Study and Formal-{IDE} for the Construction of High Integrity Software},
	isbn = {978-1-4503-4698-6},
	url = {https://doi.org/10.1145/3017680.3022456},
	doi = {10.1145/3017680.3022456},
	series = {{SIGCSE} '17},
	shorttitle = {Scaling Up Automated Verification},
	abstract = {This work aims to show through a detailed case study that scaling up automated verification to larger non-trivial data structures is not only possible, but when combined with appropriate tool support, can be made more comprehensible and practicable to users in a variety of settings, including the undergraduate curriculum. The study involves an interplay of multiple components annotated with formal interface contracts and the components are all designed to be modular, reusable, and amenable to automated verification and analysis. The components are built using a formal integrated development environment (F-{IDE}). The plan is to evaluate the F-{IDE} in an upper-level undergraduate software engineering course in the Spring semester at Clemson University.},
	pages = {785--786},
	booktitle = {Proceedings of the 2017 {ACM} {SIGCSE} Technical Symposium on Computer Science Education},
	publisher = {Association for Computing Machinery},
	author = {Welch, Daniel},
	urldate = {2020-02-07},
	date = {2017-03-08},
	keywords = {verification, formal methods, contracts, {IDE}, software components},
	file = {Full Text PDF:/home/fordrl/Zotero/storage/MMF5M94G/Welch - 2017 - Scaling Up Automated Verification A Case Study an.pdf:application/pdf},
}

@article{filliatre_toolchain_nodate,
	title = {A Toolchain to Produce Verified {OCaml} Libraries},
	abstract = {In this paper, we present a methodology to produce veri ed {OCaml} libraries, using the {GOSPEL} speci cation language and the Why3 program veri cation tool. First, a formal behavioral speci cation of the library is written in {OCaml}/{GOSPEL}, in the form of an {OCaml} module signature extended with type invariants and function contracts. Second, an implementation is written in {WhyML}, the programming language of Why3, and then veri ed with respect to the {GOSPEL} speci cation. Finally, {WhyML} code is automatically translated into {OCaml} source code by Why3. Our methodology is illustrated with two examples:  rst, a small binary search function; then, a union- nd data structure that is part of a larger {OCaml} veri ed library.},
	pages = {13},
	author = {Filliâtre, Jean-Christophe and Gondelman, Léon and Lourenço, Cláudio and Paskevich, Andrei and Pereira, Mário},
	langid = {english},
	file = {Filliâtre et al. - A Toolchain to Produce Verified OCaml Libraries.pdf:/home/fordrl/Zotero/storage/FZ3LXAKN/Filliâtre et al. - A Toolchain to Produce Verified OCaml Libraries.pdf:application/pdf},
}

@book{jacobs_introduction_2017,
	location = {Cambridge},
	title = {Introduction to Coalgebra: Towards Mathematics of States and Observation},
	isbn = {978-1-316-82318-7},
	url = {http://ebooks.cambridge.org/ref/id/CBO9781316823187},
	shorttitle = {Introduction to Coalgebra},
	publisher = {Cambridge University Press},
	author = {Jacobs, Bart},
	urldate = {2020-02-02},
	date = {2017},
	doi = {10.1017/CBO9781316823187},
	file = {Submitted Version:/home/fordrl/Zotero/storage/A5K4D7IJ/Jacobs - 2017 - Introduction to Coalgebra Towards Mathematics of .pdf:application/pdf},
}

@inproceedings{celik_mutation_2019,
	location = {San Diego, {CA}, {USA}},
	title = {Mutation Analysis for Coq},
	isbn = {978-1-72812-508-4},
	url = {https://ieeexplore.ieee.org/document/8952421/},
	doi = {10.1109/ASE.2019.00057},
	abstract = {Mutation analysis, which introduces artiﬁcial defects into software systems, is the basis of mutation testing, a technique widely applied to evaluate and enhance the quality of test suites. However, despite the deep analogy between tests and formal proofs, mutation analysis has seldom been considered in the context of deductive veriﬁcation. We propose mutation proving, a technique for analyzing veriﬁcation projects that use proof assistants. We implemented our technique for the Coq proof assistant in a tool dubbed {MCOQ}. {MCOQ} applies a set of mutation operators to Coq deﬁnitions of functions and datatypes, inspired by operators previously proposed for functional programming languages. {MCOQ} then checks proofs of lemmas affected by operator application. To make our technique feasible in practice, we implemented several optimizations in {MCOQ} such as parallel proof checking. We applied {MCOQ} to several medium and large scale Coq projects, and recorded whether proofs passed or failed when applying different mutation operators. We then qualitatively analyzed the mutants, ﬁnding many instances of incomplete speciﬁcations. For our evaluation, we made several improvements to serialization of Coq ﬁles and even discovered a notable bug in Coq itself, all acknowledged by developers. We believe {MCOQ} can be useful both to proof engineers for improving the quality of their veriﬁcation projects and to researchers for evaluating proof engineering techniques.},
	eventtitle = {2019 34th {IEEE}/{ACM} International Conference on Automated Software Engineering ({ASE})},
	pages = {539--551},
	booktitle = {2019 34th {IEEE}/{ACM} International Conference on Automated Software Engineering ({ASE})},
	publisher = {{IEEE}},
	author = {Celik, Ahmet and Palmskog, Karl and Parovic, Marinela and Jesus Gallego Arias, Emilio and Gligoric, Milos},
	urldate = {2020-01-20},
	date = {2019-11},
	langid = {english},
	file = {Celik et al. - 2019 - Mutation Analysis for Coq.pdf:/home/fordrl/Zotero/storage/MUVES2QN/Celik et al. - 2019 - Mutation Analysis for Coq.pdf:application/pdf},
}

@book{epstein_computability_1989,
	location = {Pacific Grove, Calif},
	edition = {1 edition},
	title = {Computability: Computable Functions Logic and the Foundations of Math},
	isbn = {978-0-534-10356-9},
	shorttitle = {Computability},
	abstract = {This book should be of interest to intermediate mathematics undergraduates; postgraduates in theoretical computer science/philosophy of mathematics.},
	pagetotal = {320},
	publisher = {Chapman and Hall/{CRC}},
	author = {Epstein, Richard L. and Carnielli, Walter Alexandr},
	date = {1989-11-09},
}

@incollection{hutchison_modular_2013,
	location = {Berlin, Heidelberg},
	title = {Modular Reasoning about Separation of Concurrent Data Structures},
	volume = {7792},
	isbn = {978-3-642-37035-9 978-3-642-37036-6},
	url = {http://link.springer.com/10.1007/978-3-642-37036-6_11},
	abstract = {In a concurrent setting, the usage protocol of standard separation logic speciﬁcations are not reﬁnable by clients, because standard speciﬁcations abstract all information about potential interleavings. This breaks modularity, as libraries cannot be veriﬁed in isolation, since the appropriate speciﬁcation depends on how clients intend to use the library. In this paper we propose a new logic and a new style of speciﬁcation for thread-safe concurrent data structures. Our speciﬁcations allow clients to reﬁne usage protocols and associate ownership of additional resources with instances of these data structures.},
	pages = {169--188},
	booktitle = {Programming Languages and Systems},
	publisher = {Springer Berlin Heidelberg},
	author = {Svendsen, Kasper and Birkedal, Lars and Parkinson, Matthew},
	editor = {Felleisen, Matthias and Gardner, Philippa},
	editorb = {Hutchison, David and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M. and Mattern, Friedemann and Mitchell, John C. and Naor, Moni and Nierstrasz, Oscar and Pandu Rangan, C. and Steffen, Bernhard and Sudan, Madhu and Terzopoulos, Demetri and Tygar, Doug and Vardi, Moshe Y. and Weikum, Gerhard},
	editorbtype = {redactor},
	urldate = {2020-01-15},
	date = {2013},
	langid = {english},
	doi = {10.1007/978-3-642-37036-6_11},
	file = {Svendsen et al. - 2013 - Modular Reasoning about Separation of Concurrent D.pdf:/home/fordrl/Zotero/storage/Q4D8UYKL/Svendsen et al. - 2013 - Modular Reasoning about Separation of Concurrent D.pdf:application/pdf},
}

@incollection{hutchison_impredicative_2014,
	location = {Berlin, Heidelberg},
	title = {Impredicative Concurrent Abstract Predicates},
	volume = {8410},
	isbn = {978-3-642-54832-1 978-3-642-54833-8},
	url = {http://link.springer.com/10.1007/978-3-642-54833-8_9},
	abstract = {We present impredicative concurrent abstract predicates –{iCAP} – a program logic for modular reasoning about concurrent, higherorder, reentrant, imperative code. Building on earlier work, {iCAP} uses protocols to reason about shared mutable state. A key novel feature of {iCAP} is the ability to deﬁne impredicative protocols; protocols that are parameterized on arbitrary predicates, including predicates that themselves refer to protocols. We demonstrate the utility of impredicative protocols through a series of examples, including the speciﬁcation and veriﬁcation, in the logic, of a spin-lock, a reentrant event loop, and a concurrent bag implemented using cooperation, against modular speciﬁcations.},
	pages = {149--168},
	booktitle = {Programming Languages and Systems},
	publisher = {Springer Berlin Heidelberg},
	author = {Svendsen, Kasper and Birkedal, Lars},
	editor = {Shao, Zhong},
	editorb = {Hutchison, David and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M. and Mattern, Friedemann and Mitchell, John C. and Naor, Moni and Nierstrasz, Oscar and Pandu Rangan, C. and Steffen, Bernhard and Sudan, Madhu and Terzopoulos, Demetri and Tygar, Doug and Vardi, Moshe Y. and Weikum, Gerhard},
	editorbtype = {redactor},
	urldate = {2020-01-15},
	date = {2014},
	langid = {english},
	doi = {10.1007/978-3-642-54833-8_9},
	file = {Svendsen and Birkedal - 2014 - Impredicative Concurrent Abstract Predicates.pdf:/home/fordrl/Zotero/storage/Q8CWH7QI/Svendsen and Birkedal - 2014 - Impredicative Concurrent Abstract Predicates.pdf:application/pdf},
}

@article{friedman_elementary_2016,
	title = {An elementary illustrated introduction to simplicial sets},
	url = {http://arxiv.org/abs/0809.4221},
	abstract = {This is an expository introduction to simplicial sets and simplicial homotopy theory with particular focus on relating the combinatorial aspects of the theory to their geometric/topological origins. It is intended to be accessible to students familiar with just the fundamentals of algebraic topology.},
	journaltitle = {{arXiv}:0809.4221 [math]},
	author = {Friedman, Greg},
	urldate = {2020-01-15},
	date = {2016-10-03},
	eprinttype = {arxiv},
	eprint = {0809.4221},
	keywords = {18G30, 55U10, Mathematics - Algebraic Topology, Mathematics - Category Theory, Mathematics - Geometric Topology},
	file = {arXiv.org Snapshot:/home/fordrl/Zotero/storage/IRT624MN/0809.html:text/html;arXiv Fulltext PDF:/home/fordrl/Zotero/storage/V7AHEHJZ/Friedman - 2016 - An elementary illustrated introduction to simplici.pdf:application/pdf},
}

@article{leinster_higher_2003,
	title = {Higher Operads, Higher Categories},
	url = {http://arxiv.org/abs/math/0305049},
	abstract = {Higher-dimensional category theory is the study of n-categories, operads, braided monoidal categories, and other such exotic structures. It draws its inspiration from areas as diverse as topology, quantum algebra, mathematical physics, logic, and theoretical computer science. This is the first book on the subject and lays its foundations. Many examples are given throughout. There is also an introductory chapter motivating the subject for topologists.},
	journaltitle = {{arXiv}:math/0305049},
	author = {Leinster, Tom},
	urldate = {2020-01-15},
	date = {2003-05-02},
	eprinttype = {arxiv},
	eprint = {math/0305049},
	keywords = {Mathematics - Algebraic Topology, Mathematics - Category Theory, Mathematics - Algebraic Geometry, Mathematics - Quantum Algebra},
	file = {arXiv.org Snapshot:/home/fordrl/Zotero/storage/AYETAAVU/0305049.html:text/html;arXiv Fulltext PDF:/home/fordrl/Zotero/storage/QS8ULIWD/Leinster - 2003 - Higher Operads, Higher Categories.pdf:application/pdf},
}

@book{appel_program_2014,
	edition = {1 edition},
	title = {Program Logics for Certified Compilers},
	abstract = {Separation logic is the twenty-first-century variant of Hoare logic that permits verification of pointer-manipulating programs. This book covers practical and theoretical aspects of separation logic at a level accessible to beginning graduate students interested in software verification. On the practical side it offers an introduction to verification in Hoare and separation logics, simple case studies for toy languages, and the Verifiable C program logic for the C programming language. On the theoretical side it presents separation algebras as models of separation logics; step-indexed models of higher-order logical features for higher-order programs; indirection theory for constructing step-indexed separation algebras; tree-shares as models for shared ownership; and the semantic construction (and soundness proof) of Verifiable C. In addition, the book covers several aspects of the {CompCert} verified C compiler, and its connection to foundationally verified software analysis tools. All constructions and proofs are made rigorous and accessible in the Coq developments of the open-source Verified Software Toolchain.},
	pagetotal = {472},
	publisher = {Cambridge University Press},
	author = {Appel, Andrew W. and Dockins, Robert and Hobor, Aquinas and Beringer, Lennart and Dodds, Josiah and Stewart, Gordon and Blazy, Sandrine and Leroy, Xavier},
	date = {2014-04-21},
}

@book{riehl_category_2017,
	title = {Category Theory in Context},
	abstract = {Category theory has provided the foundations for many of the twentieth century's greatest advances in pure mathematics. This concise, original text for a one-semester course on the subject is derived from courses that author Emily Riehl taught at Harvard and Johns Hopkins Universities. The treatment introduces the essential concepts of category theory: categories, functors, natural transformations, the Yoneda lemma, limits and colimits, adjunctions, monads, and other topics. Suitable for advanced undergraduates and graduate students in mathematics, the text provides tools for understanding and attacking difficult problems in algebra, number theory, algebraic geometry, and algebraic topology. Drawing upon a broad range of mathematical examples from the categorical perspective, the author illustrates how the concepts and constructions of category theory arise from and illuminate more basic mathematical ideas. Prerequisites are limited to familiarity with some basic set theory and logic.},
	pagetotal = {272},
	publisher = {Dover Publications},
	author = {Riehl, Emily},
	date = {2017-03-09},
}

@article{adamek_abstract_2004,
	title = {Abstract and Concrete Categories - The Joy of Cats},
	url = {http://katmat.math.uni-bremen.de/acc/acc.pdf},
	abstract = {Abstract and Concrete Categories was published by John Wiley and Sons, Inc, in 1990, and after several reprints, the book has been sold out and unavailable for several years. We now present an improved and corrected version as an open access file. This was made possible due to the return of copyright to the authors, and due to many hours of hard work and the exceptional skill of Christoph Schubert, to whom we wish to express our profound gratitude. The illustrations of Edward Gorey are unfortunately missing in the current version (for copyright reasons), but fortunately additional original illustrations by Marcel Erné, to whom additional special thanks of the authors belong, counterbalance the loss.
Open access includes the right of any reader to copy, store or distribute the book or parts of it freely. (See the {GNU} Free Documentation License at the end of the text.) Besides the acknowledgements appearing at the end of the original preface (below), we wish to thank all those who have helped to eliminate mistakes that survived the first printing of the text, particularly H. Bargenda, J. Jürjens W. Meyer, L. Schröder A. M. Torkabud, and O. Wyler.
January 12, 2004},
	pages = {524},
	author = {Adamek, Jiri and Herrlich, Horst and Strecker, George E and Schubert, Christoph},
	date = {2004-01-12},
	langid = {english},
	file = {Schubert - Abstract and Concrete Categories - The Joy of Cats.pdf:/home/fordrl/Zotero/storage/QQ75DYII/Schubert - Abstract and Concrete Categories - The Joy of Cats.pdf:application/pdf},
}

@online{noauthor_alloy_nodate,
	title = {Alloy - software modeling},
	url = {http://alloytools.org/},
	abstract = {Alloy is an open source language and analyzer for software modeling. It has been used in a wide range of applications, from finding holes in security mechanisms to designing telephone switching networks. This site provides language documentation, tool downloads, and a repository of links to case studies and applications. As the open source community grows, this site will also provide access to extensions of the Alloy Analyzer, and tools built on top of it and on top of Kodkod, its model finding engine.},
	urldate = {2020-01-15},
	file = {:/home/fordrl/Zotero/storage/P6XWRH3W/alloytools.org.html:text/html},
}

@online{noauthor_iron_nodate,
	title = {Iron: Managing Obligations in Higher-Order Concurrent Separation Logic ({POPL} 2019)},
	url = {https://iris-project.org/iron/},
	urldate = {2020-01-14},
	file = {Iron\: Managing Obligations in Higher-Order Concurrent Separation Logic (POPL 2019):/home/fordrl/Zotero/storage/LCDYTTVM/iron.html:text/html},
}

@article{bizjak_iron_2019,
	title = {Iron: managing obligations in higher-order concurrent separation logic},
	volume = {3},
	issn = {24751421},
	url = {http://dl.acm.org/citation.cfm?doid=3302515.3290378},
	doi = {10.1145/3290378},
	shorttitle = {Iron},
	pages = {1--30},
	issue = {{POPL}},
	journaltitle = {Proceedings of the {ACM} on Programming Languages},
	author = {Bizjak, Aleš and Gratzer, Daniel and Krebbers, Robbert and Birkedal, Lars},
	urldate = {2020-01-14},
	date = {2019-01-02},
	langid = {english},
	file = {Bizjak et al. - 2019 - Iron managing obligations in higher-order concurr.pdf:/home/fordrl/Zotero/storage/VKCEUYVS/Bizjak et al. - 2019 - Iron managing obligations in higher-order concurr.pdf:application/pdf},
}

@article{birkedal_lecture_nodate,
	title = {Lecture Notes on Iris: Higher-Order Concurrent Separation Logic},
	pages = {138},
	author = {Birkedal, Lars and Bizjak, Aleš},
	langid = {english},
	file = {Birkedal and Bizjak - Lecture Notes on Iris Higher-Order Concurrent Sep.pdf:/home/fordrl/Zotero/storage/G2TQDRZA/Birkedal and Bizjak - Lecture Notes on Iris Higher-Order Concurrent Sep.pdf:application/pdf},
}

@online{noauthor_formal_nodate,
	title = {Formal Versus Agile: Survival of the Fittest},
	url = {https://www.researchgate.net/publication/224587383_Formal_Versus_Agile_Survival_of_the_Fittest},
	shorttitle = {(17) ({PDF}) Formal Versus Agile},
	abstract = {{ResearchGate} is a network dedicated to science and research. Connect, collaborate and discover scientific publications, jobs and conferences. All for free.},
	titleaddon = {{ResearchGate}},
	urldate = {2020-01-14},
	langid = {english},
	file = {Formal Versus Agile Survival of the Fittest.pdf:/home/fordrl/Zotero/storage/T7SMMH8N/Formal Versus Agile Survival of the Fittest.pdf:application/pdf;Snapshot:/home/fordrl/Zotero/storage/MEGWY5FF/224587383_Formal_Versus_Agile_Survival_of_the_Fittest.html:text/html},
}

@incollection{girard_linear_1995,
	location = {Cambridge},
	title = {Linear Logic: its syntax and semantics},
	isbn = {978-0-511-62915-0},
	url = {https://www.cambridge.org/core/product/identifier/CBO9780511629150A008/type/book_part},
	shorttitle = {Linear Logic},
	pages = {1--42},
	booktitle = {Advances in Linear Logic},
	publisher = {Cambridge University Press},
	author = {Girard, J.-Y.},
	editor = {Girard, Jean-Yves and Lafont, Yves and Regnier, Laurent},
	urldate = {2020-01-13},
	date = {1995},
	langid = {english},
	doi = {10.1017/CBO9780511629150.002},
	file = {Girard - 1995 - Linear Logic its syntax and semantics.pdf:/home/fordrl/Zotero/storage/AYG62SL5/Girard - 1995 - Linear Logic its syntax and semantics.pdf:application/pdf},
}

@incollection{di_cosmo_linear_2019,
	edition = {Summer 2019},
	title = {Linear Logic},
	url = {https://plato.stanford.edu/archives/sum2019/entries/logic-linear/},
	abstract = {Linear logic is a refinement of classical and intuitionistic logic.Instead of emphasizing truth, as in classical logic, orproof, as in intuitionistic logic, linear logic emphasizes therole of formulas as resources. To achieve this focus, linearlogic does not allow the usual structural rules of contraction andweakening to apply to all formulas but only those formulas marked withcertain modals. Linear logic contains a fully involutive negation whilemaintaining a strong constructive interpretation. Linear logic alsoprovides new insights into the nature of proofs in both classical andintuitionistic logic. Given its focus on resources, linear logic hasfound many applications in Computer Science.},
	booktitle = {The Stanford Encyclopedia of Philosophy},
	publisher = {Metaphysics Research Lab, Stanford University},
	author = {Di Cosmo, Roberto and Miller, Dale},
	editor = {Zalta, Edward N.},
	urldate = {2020-01-13},
	date = {2019},
	keywords = {logic: and games, logic: classical, logic: dialogical, logic: intuitionistic, logic: substructural, proof theory},
	file = {SEP - Snapshot:/home/fordrl/Zotero/storage/F2F4YKGP/logic-linear.html:text/html},
}

@online{noauthor_introduction_nodate,
	title = {Introduction to Domain Theory},
	url = {http://www.cs.nott.ac.uk/~pszgmh/domains.html},
	urldate = {2020-01-13},
	file = {Introduction to Domain Theory:/home/fordrl/Zotero/storage/2TARLBQN/domains.html:text/html},
}

@incollection{hutchison_embedding_2007,
	location = {Berlin, Heidelberg},
	title = {Embedding Pure Type Systems in the Lambda-Pi-Calculus Modulo},
	volume = {4583},
	isbn = {978-3-540-73227-3 978-3-540-73228-0},
	url = {http://link.springer.com/10.1007/978-3-540-73228-0_9},
	abstract = {The lambda-Pi-calculus allows to express proofs of minimal predicate logic. It can be extended, in a very simple way, by adding computation rules. This leads to the lambda-Pi-calculus modulo. We show in this paper that this simple extension is surprisingly expressive and, in particular, that all functional Pure Type Systems, such as the system F, or the Calculus of Constructions, can be embedded in it. And, moreover, that this embedding is conservative under termination hypothesis.},
	pages = {102--117},
	booktitle = {Typed Lambda Calculi and Applications},
	publisher = {Springer Berlin Heidelberg},
	author = {Cousineau, Denis and Dowek, Gilles},
	editor = {Della Rocca, Simona Ronchi},
	editorb = {Hutchison, David and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M. and Mattern, Friedemann and Mitchell, John C. and Naor, Moni and Nierstrasz, Oscar and Rangan, C. Pandu and Steffen, Bernhard and Sudan, Madhu and Terzopoulos, Demetri and Tygar, Doug and Vardi, Moshe Y. and Weikum, Gerhard},
	editorbtype = {redactor},
	urldate = {2020-01-13},
	date = {2007},
	langid = {english},
	doi = {10.1007/978-3-540-73228-0_9},
	file = {Cousineau and Dowek - 2007 - Embedding Pure Type Systems in the Lambda-Pi-Calcu.pdf:/home/fordrl/Zotero/storage/X92R9WSL/Cousineau and Dowek - 2007 - Embedding Pure Type Systems in the Lambda-Pi-Calcu.pdf:application/pdf},
}

@article{krebbers_mosel_2018,
	title = {{MoSeL}: a general, extensible modal framework for interactive proofs in separation logic},
	volume = {2},
	issn = {24751421},
	url = {http://dl.acm.org/citation.cfm?doid=3243631.3236772},
	doi = {10.1145/3236772},
	shorttitle = {{MoSeL}},
	pages = {1--30},
	issue = {{ICFP}},
	journaltitle = {Proceedings of the {ACM} on Programming Languages},
	author = {Krebbers, Robbert and Jourdan, Jacques-Henri and Jung, Ralf and Tassarotti, Joseph and Kaiser, Jan-Oliver and Timany, Amin and Charguéraud, Arthur and Dreyer, Derek},
	urldate = {2020-01-13},
	date = {2018-07-30},
	langid = {english},
	file = {Krebbers et al. - 2018 - MoSeL a general, extensible modal framework for i.pdf:/home/fordrl/Zotero/storage/YAMP778J/Krebbers et al. - 2018 - MoSeL a general, extensible modal framework for i.pdf:application/pdf},
}

@thesis{saillard_typechecking_2015,
	title = {Typechecking in the lambda-Pi-Calculus Modulo : Theory and Practice},
	url = {https://pastel.archives-ouvertes.fr/tel-01299180},
	shorttitle = {Typechecking in the lambda-Pi-Calculus Modulo},
	abstract = {Automatic proof checking is about using a computer to check the validity of proofs of mathematical statements. Since this verification is purely computational, it offers a high degree of confidence. Therefore, it is particularly useful for checking that a critical software, i.e., a software that when malfunctioning may result in death or serious injury to people, loss or severe damage to equipment or environmental harm, corresponds to its specification. {DEDUKTI} is such a proof checker. It implements a type system, the lambda-Pi-Calculus Modulo, that is an extension of the dependently-typed lambda-calculus with first-order rewrite rules. Through the Curry-Howard correspondence, {DEDUKTI} implements both a powerful programming language and an expressive logical system. Furthermore, this language is particularly well suited for encoding other proof systems. For instance, we can import in {DEDUKTI} theorems proved using other tools such as {COQ}, {HOL} or {ZENON}, a first step towards creating interoperability between these systems.The lambda-Pi-Calculus Modulo is a very expressive language. On the other hand, some fundamental properties such as subject reduction (i.e., the stability of typing by reduction) and uniqueness of types are not guaranteed in general and depend on the rewrite rules considered. Yet, these properties are necessary for guaranteeing the coherence of the proof system, but also for provingthe soundness and completeness of the type-checking algorithms implemented in {DEDUKTI}. Unfortunately, these properties are undecidable. In this thesis, we design new criteria for subject reduction and uniqueness of types that are decidable in order to be implemented in {DEDUKTI}.For this purpose, we give a new definition of the lambda-Pi-Calculus Modulo that takes into account the iterative aspect of the addition of rewrite rules in the typing context. A detailed study of this new system shows that the problems of subject reduction and uniqueness of types can be reduced to two simpler properties that we call product compatibility and well-typedness of rewrite rules.Hence, we study these two properties separately and give effective sufficient conditions for them to hold.These ideas have been implemented in {DEDUKTI}, increasing its generality and reliability.},
	institution = {Ecole Nationale Supérieure des Mines de Paris},
	type = {phdthesis},
	author = {Saillard, Ronan},
	urldate = {2020-01-13},
	date = {2015-09-25},
	langid = {english},
	file = {Snapshot:/home/fordrl/Zotero/storage/CKUULC6W/tel-01299180.html:text/html;Full Text PDF:/home/fordrl/Zotero/storage/2HPMRHNE/Saillard - 2015 - Typechecking in the lambda-Pi-Calculus Modulo  Th.pdf:application/pdf},
}

@online{noauthor_cerco_nodate,
	title = {{CerCo} - Certified Complexity},
	url = {http://cerco.cs.unibo.it/},
	abstract = {{CerCo} (Certified Complexity) is a European research project in the ​7th Research Framework Programme ({FP}7) of the ​European Commission (project number 243381). The project is situated in the {FP}7 theme ​Information \& Communication Technologies ({ICT}) in the topic Future and Emerging Technologies ({FET} Open). The project has started February 1st, 2010, and will have a duration of 3 years.

The project aims to the construction of a formally verified complexity preserving compiler from a large subset of C to some typical microcontroller assembly, of the kind traditionally used in embedded systems. The work comprise the definition of cost models for the input and target languages, and the machine-checked proof of preservation of complexity (concrete, not asymptotic) along compilation. The compiler will also return tight and certified cost annotations for the source program, providing a reliable infrastructure to draw temporal assertions on the executable code while reasoning on the source. The compiler will be open source, and all proofs will be public domain.},
	urldate = {2020-01-13},
	file = {CerCo:/home/fordrl/Zotero/storage/FVM747ZK/cerco.cs.unibo.it.html:text/html},
}

@online{noauthor_matita_nodate,
	title = {Matita - Interactive Theorem Prover},
	url = {http://matita.cs.unibo.it/},
	abstract = {Matita (that means pencil in italian) is an experimental, interactive theorem prover under development at the Computer Science Department of the University of Bologna.},
	urldate = {2020-01-13},
	file = {Matita - Home Page:/home/fordrl/Zotero/storage/7U4SV46Z/matita.cs.unibo.it.html:text/html},
}

@software{noauthor_lambdapi_2020,
	title = {Lambdapi, a proof assistant based on the λΠ-calculus modulo rewriting},
	url = {https://github.com/Deducteam/lambdapi},
	abstract = {Proof assistant based on the λΠ-calculus modulo rewriting},
	publisher = {Deducteam},
	urldate = {2020-01-13},
	date = {2020-01-10},
	note = {original-date: 2017-09-10T20:32:16Z},
	keywords = {dependent-types, logical-framework, proof-assistant, proof-checker, rewriting},
}

@article{birkedal_taste_nodate,
	title = {A Taste of Categorical Logic — Tutorial Notes},
	pages = {41},
	author = {Birkedal, Lars},
	langid = {english},
	file = {Birkedal - A Taste of Categorical Logic — Tutorial Notes.pdf:/home/fordrl/Zotero/storage/Q7H9YWPZ/Birkedal - A Taste of Categorical Logic — Tutorial Notes.pdf:application/pdf},
}

@article{gross_experience_2014,
	title = {Experience Implementing a Performant Category-Theory Library in Coq},
	url = {http://arxiv.org/abs/1401.7694},
	abstract = {We describe our experience implementing a broad categorytheory library in Coq. Category theory and computational performance are not usually mentioned in the same breath, but we have needed substantial engineering effort to teach Coq to cope with large categorical constructions without slowing proof script processing unacceptably. In this paper, we share the lessons we have learned about how to represent very abstract mathematical objects and arguments in Coq and how future proof assistants might be designed to better support such reasoning. One particular encoding trick to which we draw attention allows category-theoretic arguments involving duality to be internalized in Coq’s logic with definitional equality. Ours may be the largest Coq development to date that uses the relatively new Coq version developed by homotopy type theorists, and we reflect on which new features were especially helpful.},
	journaltitle = {{arXiv}:1401.7694 [cs, math]},
	author = {Gross, Jason and Chlipala, Adam and Spivak, David I.},
	urldate = {2020-01-13},
	date = {2014-04-17},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {1401.7694},
	keywords = {Computer Science - Logic in Computer Science, Mathematics - Category Theory},
	file = {Gross et al. - 2014 - Experience Implementing a Performant Category-Theo.pdf:/home/fordrl/Zotero/storage/LERST232/Gross et al. - 2014 - Experience Implementing a Performant Category-Theo.pdf:application/pdf},
}

@article{aydemir_engineering_nodate,
	title = {Engineering Formal Metatheory},
	abstract = {Machine-checked proofs of properties of programming languages have become a critical need, both for increased conﬁdence in large and complex designs and as a foundation for technologies such as proof-carrying code. However, constructing these proofs remains a black art, involving many choices in the formulation of deﬁnitions and theorems that make a huge cumulative difference in the difﬁculty of carrying out large formal developments. The representation and manipulation of terms with variable binding is a key issue.},
	pages = {13},
	author = {Aydemir, Brian and Chargueraud, Arthur and Pierce, Benjamin C and Pollack, Randy and Weirich, Stephanie},
	langid = {english},
	file = {Aydemir et al. - Engineering Formal Metatheory.pdf:/home/fordrl/Zotero/storage/94I3EC6C/Aydemir et al. - Engineering Formal Metatheory.pdf:application/pdf},
}

@online{scott_continuous_nodate,
	title = {Continuous lattices},
	url = {https://www.researchgate.net/publication/251394986_Continuous_lattices},
	abstract = {Starting from the topological point of view a certain wide class of To-spaces is introduced having a very strong extension property for continuous functions with values in these spaces. It is then shown that all such spaces are complete lattices whose lattice structure determines the topology — these are the continuous lattices — and every such lattice has the extension property. With this foundation the lattices are studied in detail with respect to projections, subspaces, embeddings, and constructions such as products, sums, function spaces, and inverse limits. The main result of the paper is a proof that every topological space can be embedded in a continuous lattice which is homeomorphic (and isomorphic) to its own function space. The function algebra of such spaces provides mathematical models for the Church-Curry λ-calculus.},
	titleaddon = {{ResearchGate}},
	author = {Scott, Dana},
	urldate = {2020-01-12},
	langid = {english},
	file = {Scott - Continuous lattices.pdf:/home/fordrl/Zotero/storage/DF7MHLVE/Scott - Continuous lattices.pdf:application/pdf;Snapshot:/home/fordrl/Zotero/storage/8EFC6RBA/251394986_Continuous_lattices.html:text/html},
}

@article{assaf_dedukti_nodate,
	title = {Dedukti: a Logical Framework based on the λΠ-Calculus Modulo Theory},
	abstract = {Dedukti is a Logical Framework based on the λΠ-Calculus Modulo Theory. We show that many theories can be expressed in Dedukti: constructive and classical predicate logic, Simple type theory, programming languages, Pure type systems, the Calculus of inductive constructions with universes, etc. and that permits to used it to check large libraries of proofs developed in other proof systems: Zenon, {iProver}, {FoCaLiZe}, {HOL} Light, and Matita.},
	pages = {36},
	author = {Assaf, Ali and Burel, Guillaume and Cauderlier, Raphaël and Dowek, Gilles and Dubois, Catherine and Gilbert, Frédéric and Halmagrand, Pierre and Hermant, Olivier and Saillard, Ronan},
	langid = {english},
	file = {Assaf et al. - Dedukti a Logical Framework based on the λΠ-Calcu.pdf:/home/fordrl/Zotero/storage/6MS7VU63/Assaf et al. - Dedukti a Logical Framework based on the λΠ-Calcu.pdf:application/pdf},
}

@online{noauthor_dedukti_nodate,
	title = {Dedukti - a Logical Framework},
	url = {https://deducteam.github.io/},
	urldate = {2020-01-10},
	file = {Dedukti - a Logical Framework:/home/fordrl/Zotero/storage/6C4KAPKJ/deducteam.github.io.html:text/html},
}

@software{noauthor_deducteamdedukti_2019,
	title = {Deducteam/Dedukti},
	url = {https://github.com/Deducteam/Dedukti},
	abstract = {Implementation of the λΠ-calculus modulo rewriting},
	publisher = {Deducteam},
	urldate = {2020-01-10},
	date = {2019-12-22},
	note = {original-date: 2017-11-16T15:34:07Z},
}

@software{noauthor_deducteamholide_2019,
	title = {Deducteam/Holide},
	url = {https://github.com/Deducteam/Holide},
	abstract = {A translator from {OpenTheory} to Dedukti. Contribute to Deducteam/Holide development by creating an account on {GitHub}.},
	publisher = {Deducteam},
	urldate = {2020-01-10},
	date = {2019-11-05},
	note = {original-date: 2018-02-08T13:18:34Z},
}

@article{xi_introduction_nodate,
	title = {Introduction to Programming in {ATS}},
	pages = {252},
	author = {Xi, Hongwei},
	langid = {english},
	file = {Xi - Introduction to Programming in ATS.pdf:/home/fordrl/Zotero/storage/RHKEDKY6/Xi - Introduction to Programming in ATS.pdf:application/pdf},
}

@article{xi_applied_2017,
	title = {Applied Type System: An Approach to Practical Programming with Theorem-Proving},
	url = {http://arxiv.org/abs/1703.08683},
	shorttitle = {Applied Type System},
	abstract = {The framework Pure Type System ({PTS}) offers a simple and general approach to designing and formalizing type systems. However, in the presence of dependent types, there often exist certain acute problems that make it difficult for {PTS} to directly accommodate many common realistic programming features such as general recursion, recursive types, effects (e.g., exceptions, references, input/output), etc. In this paper, Applied Type System ({ATS}) is presented as a framework for designing and formalizing type systems in support of practical programming with advanced types (including dependent types). In particular, it is demonstrated that {ATS} can readily accommodate a paradigm referred to as programming with theorem-proving ({PwTP}) in which programs and proofs are constructed in a syntactically intertwined manner, yielding a practical approach to internalizing constraint-solving needed during type-checking. The key salient feature of {ATS} lies in a complete separation between statics, where types are formed and reasoned about, and dynamics, where programs are constructed and evaluated. With this separation, it is no longer possible for a program to occur in a type as is otherwise allowed in {PTS}. The paper contains not only a formal development of {ATS} but also some examples taken from ats-lang.org, a programming language with a type system rooted in {ATS}, in support of employing {ATS} as a framework to formulate advanced type systems for practical programming.},
	journaltitle = {{arXiv}:1703.08683 [cs]},
	author = {Xi, Hongwei},
	urldate = {2020-01-10},
	date = {2017-03-25},
	eprinttype = {arxiv},
	eprint = {1703.08683},
	keywords = {Computer Science - Programming Languages, Computer Science - Logic in Computer Science},
	file = {arXiv.org Snapshot:/home/fordrl/Zotero/storage/SVKPK6CW/1703.html:text/html;arXiv Fulltext PDF:/home/fordrl/Zotero/storage/65F5XPI9/Xi - 2017 - Applied Type System An Approach to Practical Prog.pdf:application/pdf},
}

@online{noauthor_ats_nodate,
	title = {The {ATS} Programming Language},
	url = {http://www.ats-lang.org/},
	urldate = {2020-01-10},
	file = {ATS-PL-SYS:/home/fordrl/Zotero/storage/UWKPQ2PR/www.ats-lang.org.html:text/html},
}

@online{joe_leslie-hurd_slowest_2015,
	title = {The Slowest Software Development Methodology in the World},
	url = {https://gilith.wordpress.com/2015/07/19/the-slowest-software-development-methodology-in-the-world/},
	abstract = {For some time now I’ve been practicing what can only be described as the slowest software development methodology in the world: a three step waltz of Prototyping, Verification and Export. Pro…},
	titleaddon = {The Robot Mathematician},
	author = {{Joe Leslie-Hurd}},
	urldate = {2020-01-10},
	date = {2015-07-19},
	langid = {english},
	file = {Snapshot:/home/fordrl/Zotero/storage/WPXZIPZ3/the-slowest-software-development-methodology-in-the-world.html:text/html},
}

@online{noauthor_proofpower_nodate,
	title = {The {ProofPower} Web Pages},
	url = {http://www.lemma-one.com/ProofPower/index/},
	urldate = {2020-01-10},
	file = {The ProofPower Web Pages:/home/fordrl/Zotero/storage/NJ5Q9DBQ/index.html:text/html},
}

@incollection{bobaru_opentheory_2011,
	location = {Berlin, Heidelberg},
	title = {The {OpenTheory} Standard Theory Library},
	volume = {6617},
	isbn = {978-3-642-20397-8 978-3-642-20398-5},
	url = {http://link.springer.com/10.1007/978-3-642-20398-5_14},
	abstract = {Interactive theorem proving is tackling ever larger formalization and veriﬁcation projects, and there is a critical need for theory engineering techniques to support these eﬀorts. One such technique is cross-prover package management, which has the potential to simplify the development of logical theories and eﬀectively share theories between diﬀerent theorem prover implementations. The {OpenTheory} project has developed standards for packaging theories of the higher order logic implemented by the {HOL} family of theorem provers. What is currently missing is a standard theory library that can serve as a published contract of interoperability and contain proofs of basic properties that would otherwise appear in many theory packages. The core contribution of this paper is the presentation of a standard theory library for higher order logic represented as an {OpenTheory} package. We identify the core theory set of the {HOL} family of theorem provers, and describe the process of instrumenting the {HOL} Light theorem prover to extract a standardized version of its core theory development. We proﬁle the axioms and theorems of our standard theory library and investigate the performance cost of separating the standard theory library into coherent hierarchical theory packages.},
	pages = {177--191},
	booktitle = {{NASA} Formal Methods},
	publisher = {Springer Berlin Heidelberg},
	author = {Hurd, Joe},
	editor = {Bobaru, Mihaela and Havelund, Klaus and Holzmann, Gerard J. and Joshi, Rajeev},
	urldate = {2020-01-10},
	date = {2011},
	langid = {english},
	doi = {10.1007/978-3-642-20398-5_14},
	file = {Hurd - 2011 - The OpenTheory Standard Theory Library.pdf:/home/fordrl/Zotero/storage/IWLYWVQY/Hurd - 2011 - The OpenTheory Standard Theory Library.pdf:application/pdf},
}

@online{noauthor_metis_nodate,
	title = {Metis Theorem Prover - Gilith},
	url = {http://www.gilith.com/metis/},
	urldate = {2020-01-10},
	file = {Metis Theorem Prover - Gilith:/home/fordrl/Zotero/storage/QTVYNGV4/metis.html:text/html},
}

@online{noauthor_opentheory_nodate,
	title = {{OpenTheory} Project - Gilith},
	url = {http://www.gilith.com/opentheory/},
	urldate = {2020-01-10},
	file = {OpenTheory Project - Gilith:/home/fordrl/Zotero/storage/DUMQW9F5/opentheory.html:text/html},
}

@article{lombardi_commutative_2015,
	title = {Commutative algebra: Constructive methods. Finite projective modules},
	volume = {20},
	url = {http://arxiv.org/abs/1605.04832},
	doi = {10.1007/978-94-017-9944-7},
	shorttitle = {Commutative algebra},
	abstract = {This book is an introductory course to basic commutative algebra with a particular emphasis on finitely generated projective modules. We adopt the constructive point of view, with which all existence theorems have an explicit algorithmic content content. In particular, when a theorem affirms the existence of an object -- the solution of a problem -- a construction algorithm of the object can always be extracted from the given proof. We revisit with a new and often simplifying eye several abstract classical theories. In particular, we review theories which did not have any algorithmic content in their general natural framework, such as Galois theory, the Dedekind domains, the finitely generated projective modules or the Krull dimension.},
	journaltitle = {{arXiv}:1605.04832 [math]},
	author = {Lombardi, Henri and Quitté, Claude},
	urldate = {2020-01-10},
	date = {2015},
	eprinttype = {arxiv},
	eprint = {1605.04832},
	keywords = {13-02 (13C10), Mathematics - Commutative Algebra},
	file = {arXiv.org Snapshot:/home/fordrl/Zotero/storage/JGCJRI88/1605.html:text/html;arXiv Fulltext PDF:/home/fordrl/Zotero/storage/ZM8CL6MF/Lombardi and Quitté - 2015 - Commutative algebra Constructive methods. Finite .pdf:application/pdf},
}

@inproceedings{devai_embedding_2009,
	title = {Embedding a Proof System in Haskell},
	url = {http://link.springer.com/chapter/10.1007/978-3-642-17685-2_10},
	doi = {10.1007/978-3-642-17685-2_10},
	abstract = {This article reports about a work-in-progress project that aims at embedding a proof system [4] in the Haskellprogramming language. The goal of the system is to create formally verified software...},
	eventtitle = {Central European Functional Programming School},
	pages = {354--371},
	booktitle = {Central European Functional Programming School},
	publisher = {Springer, Berlin, Heidelberg},
	author = {Dévai, Gergely},
	urldate = {2020-01-10},
	date = {2009-05-21},
	langid = {english},
	file = {Dévai - 2009 - Embedding a Proof System in Haskell.pdf:/home/fordrl/Zotero/storage/CFRETGP9/Dévai - 2009 - Embedding a Proof System in Haskell.pdf:application/pdf},
}

@video{noauthor_galois_nodate,
	title = {Galois, Inc. Tech Talk: {JaVerT}: a {JavaScript} Verification Toolchain (Dr. Philippa Gardner)},
	url = {https://www.youtube.com/watch?v=uNVAmCYL1Jo},
	shorttitle = {Galois, Inc. Tech Talk},
	abstract = {Abstract:

The dynamic nature of {JavaScript} and its complex semantics make it a difficult target for logic-based verification. In this talk, I will describe {JaVerT}, a semi-automatic {JavaScript} Verification Toolchain
based on separation logic. {JaVerT} is aimed at the specialist developer wanting rich, mechanically verified specifications of critical {JavaScript} code. The specification challenge is to design specifications that are readable by developers. The verification challenge is to handle the complex, dynamic nature of {JavaScript}
without simplification. The validation challenge is to understand what it means for the verification to be trusted.

Bio:

Philippa Gardner is a professor in the Department of Computing at Imperial College London and leader of the research group working on Verified Trustworthy Software Specification. Her current research focusses on reasoning about web programs ({JavaScript} and {DOM}); and reasoning about concurrent programs. 
She completed her {PhD} thesis, supervised by Professor Gordon Plotkin {FRS} at Edinburgh in 1992. She moved to Cambridge in 1998 on an {EPSRC} Advanced Fellowship, hosted by Professor Robin Milner {FRS}. She obtained a lectureship at Imperial in 2001, and became professor in 2009. She held a Microsoft Research Cambridge/Royal Academy of Engineering Senior Fellowship from 2005 to 2010 at Imperial.

Philippa directs the Research Institute on Verified Trustworthy Software Systems ({VeTSS}), funded by {EPSRC}, from 2017 to 2022. She also chairs the {BCS} awards committee, which decides the Lovelace medal (senior) and Roger Needham award (mid-career) for computer science and engineering.},
	urldate = {2020-01-10},
}

@article{carneiro_specifying_2019,
	title = {Specifying verified x86 software from scratch},
	url = {http://arxiv.org/abs/1907.01283},
	abstract = {We present a simple framework for specifying and proving facts about the input/output behavior of {ELF} binary files on the x86-64 architecture. A strong emphasis has been placed on simplicity at all levels: the specification says only what it needs to about the target executable, the specification is performed inside a simple logic (equivalent to first-order Peano Arithmetic), and the verification language and proof checker are custom-designed to have only what is necessary to perform efficient general purpose verification. This forms a part of the Metamath Zero project, to build a minimal verifier that is capable of verifying its own binary. In this paper, we will present the specification of the dynamic semantics of x86 machine code, together with enough information about Linux system calls to perform simple {IO}.},
	journaltitle = {{arXiv}:1907.01283 [cs]},
	author = {Carneiro, Mario},
	urldate = {2020-01-10},
	date = {2019-07-02},
	eprinttype = {arxiv},
	eprint = {1907.01283},
	keywords = {Computer Science - Logic in Computer Science, 68Q60 (Primary) 68N30 (Secondary)},
	file = {arXiv.org Snapshot:/home/fordrl/Zotero/storage/9X7GGN9W/1907.html:text/html;arXiv Fulltext PDF:/home/fordrl/Zotero/storage/2MU53N8P/Carneiro - 2019 - Specifying verified x86 software from scratch.pdf:application/pdf},
}

@article{carneiro_type_2019,
	title = {The Type Theory of Lean},
	url = {https://github.com/digama0/lean-type-theory/releases/download/v1.0/main.pdf},
	author = {Carneiro, Mario},
	date = {2019-04-16},
	file = {Carneiro - 2019 - The Type Theory of Lean.pdf:/home/fordrl/Zotero/storage/3KWG8UY5/Carneiro - 2019 - The Type Theory of Lean.pdf:application/pdf},
}

@software{carneiro_metamath_2020-1,
	title = {Metamath Zero},
	rights = {{CC}0-1.0},
	url = {https://github.com/digama0/mm0},
	abstract = {Metamath Zero specification language. Contribute to digama0/mm0 development by creating an account on {GitHub}.},
	author = {Carneiro, Mario},
	urldate = {2020-01-10},
	date = {2020-01-10},
	note = {original-date: 2019-02-25T07:34:19Z},
}

@article{ullrich_counting_2019,
	title = {Counting Immutable Beans: Reference Counting Optimized for Purely Functional Programming},
	url = {http://arxiv.org/abs/1908.05647},
	shorttitle = {Counting Immutable Beans},
	abstract = {Most functional languages rely on some garbage collection for automatic memory management. They usually eschew reference counting in favor of a tracing garbage collector, which has less bookkeeping overhead at runtime. On the other hand, having an exact reference count of each value can enable optimizations, such as destructive updates. We explore these optimization opportunities in the context of an eager, purely functional programming language. We propose a new mechanism for efficiently reclaiming memory used by nonshared values, reducing stress on the global memory allocator. We describe an approach for minimizing the number of reference counts updates using borrowed references and a heuristic for automatically inferring borrow annotations. We implemented all these techniques in a new compiler for an eager and purely functional programming language with support for multi-threading. Our preliminary experimental results demonstrate our approach is competitive and often outperforms state-of-the-art compilers.},
	journaltitle = {{arXiv}:1908.05647 [cs]},
	author = {Ullrich, Sebastian and de Moura, Leonardo},
	urldate = {2020-01-10},
	date = {2019-09-03},
	eprinttype = {arxiv},
	eprint = {1908.05647},
	keywords = {Computer Science - Programming Languages},
	file = {arXiv.org Snapshot:/home/fordrl/Zotero/storage/7MNP545U/1908.html:text/html;arXiv Fulltext PDF:/home/fordrl/Zotero/storage/7DG57YQ9/Ullrich and de Moura - 2019 - Counting Immutable Beans Reference Counting Optim.pdf:application/pdf},
}

@article{shafiq_integrating_2014,
	title = {Integrating Formal Methods in {XP}—A Conceptual Solution},
	volume = {07},
	issn = {1945-3116, 1945-3124},
	url = {http://www.scirp.org/journal/doi.aspx?DOI=10.4236/jsea.2014.74029},
	doi = {10.4236/jsea.2014.74029},
	pages = {299--310},
	number = {4},
	journaltitle = {Journal of Software Engineering and Applications},
	author = {Shafiq, Shagufta and Minhas, Nasir Mehmood},
	urldate = {2020-01-10},
	date = {2014},
	file = {Full Text:/home/fordrl/Zotero/storage/IPQVKICE/Shafiq and Minhas - 2014 - Integrating Formal Methods in XP—A Conceptual Solu.pdf:application/pdf},
}

@online{noauthor_theorem_nodate,
	title = {Theorem Proving in Lean — Theorem Proving in Lean 3.4.0 documentation},
	url = {https://leanprover.github.io/theorem_proving_in_lean/index.html},
	urldate = {2020-01-10},
	file = {Theorem Proving in Lean — Theorem Proving in Lean .pdf:/home/fordrl/Zotero/storage/CZUXXKHS/Theorem Proving in Lean — Theorem Proving in Lean .pdf:application/pdf;Theorem Proving in Lean — Theorem Proving in Lean 3.4.0 documentation:/home/fordrl/Zotero/storage/MK7SN4IG/index.html:text/html},
}

@online{noauthor_event-b_nodate,
	title = {Event-B and the Rodin Platform},
	url = {http://www.event-b.org/},
	urldate = {2020-01-10},
	file = {Event-B.org:/home/fordrl/Zotero/storage/3FA6KM7N/www.event-b.org.html:text/html},
}

@software{noauthor_coqeal_2020,
	title = {{CoqEAL}},
	url = {https://github.com/CoqEAL/CoqEAL},
	abstract = {{CoqEAL} -- The Coq Effective Algebra Library. Contribute to {CoqEAL}/{CoqEAL} development by creating an account on {GitHub}.},
	publisher = {{CoqEAL}},
	urldate = {2020-01-10},
	date = {2020-01-08},
	note = {original-date: 2014-02-10T12:35:29Z},
}

@online{noauthor_iris_nodate,
	title = {Iris / stdpp},
	url = {https://gitlab.mpi-sws.org/iris/stdpp},
	abstract = {An extended "Standard Library" for Coq. [[coqdoc]](https://plv.mpi-sws.org/coqdoc/stdpp/)},
	titleaddon = {{GitLab}},
	urldate = {2020-01-10},
	langid = {english},
	file = {Snapshot:/home/fordrl/Zotero/storage/9RJK2RNR/stdpp.html:text/html},
}

@online{noauthor_acsl_nodate,
	title = {{ACSL} by Example},
	url = {https://github.com/fraunhoferfokus/acsl-by-example},
	abstract = {Public snapshots of "{ACSL} by Example". Contribute to fraunhoferfokus/acsl-by-example development by creating an account on {GitHub}.},
	titleaddon = {{GitHub}},
	urldate = {2020-01-10},
	langid = {english},
	file = {Snapshot:/home/fordrl/Zotero/storage/XJL9QPWX/ACSL-by-Example.html:text/html},
}

@incollection{kennedy_types_2010,
	location = {Berlin, Heidelberg},
	title = {Types for Units-of-Measure: Theory and Practice},
	isbn = {978-3-642-17685-2},
	url = {https://doi.org/10.1007/978-3-642-17685-2_8},
	series = {Lecture Notes in Computer Science},
	shorttitle = {Types for Units-of-Measure},
	abstract = {Units-of-measure are to science what types are to programming. In science and engineering, dimensional and unit consistency provides a first check on the correctness of an equation or formula, just as in programming the validation of a program by the type-checker eliminates one possible reason for failure.},
	pages = {268--305},
	booktitle = {Central European Functional Programming School: Third Summer School, {CEFP} 2009, Budapest, Hungary, May 21-23, 2009 and Komárno, Slovakia, May 25-30, 2009, Revised Selected Lectures},
	publisher = {Springer},
	author = {Kennedy, Andrew},
	editor = {Horváth, Zoltán and Plasmeijer, Rinus and Zsók, Viktória},
	urldate = {2020-01-01},
	date = {2010},
	langid = {english},
	doi = {10.1007/978-3-642-17685-2_8},
	keywords = {Inference Algorithm, Equational Theory, Type Inference, Type Scheme, Type System},
	file = {Kennedy - 2010 - Types for Units-of-Measure Theory and Practice.pdf:/home/fordrl/Zotero/storage/MDYN5WIW/Kennedy - 2010 - Types for Units-of-Measure Theory and Practice.pdf:application/pdf},
}

@inproceedings{shin_wormspace:_2019,
	location = {Santa Cruz, {CA}, {USA}},
	title = {{WormSpace}: A Modular Foundation for Simple, Verifiable Distributed Systems},
	isbn = {978-1-4503-6973-2},
	url = {http://dl.acm.org/citation.cfm?doid=3357223.3362739},
	doi = {10.1145/3357223.3362739},
	shorttitle = {{WormSpace}},
	abstract = {We propose the Write-Once Register ({WOR}) as an abstraction for building and verifying distributed systems. A {WOR} exposes a simple, data-centric {API}: clients can capture, write, and read it. Applications can use a sequence or a set of {WORs} to obtain properties such as durability, concurrency control, and failure atomicity. By hiding the logic for distributed coordination underneath a data-centric {API}, the {WOR} abstraction enables easy, incremental, and extensible implementation and verification of applications built above it. We present the design, implementation, and verification of a system called {WormSpace} that provides developers with an address space of {WORs}, implementing each {WOR} via a Paxos instance. We describe three applications built over {WormSpace}: a flexible, efficient Multi-Paxos implementation; a shared log implementation with lower append latency than the state-of-the-art; and a faulttolerant transaction coordinator that uses an optimal number of round-trips. We show that these applications are simple, easy to verify, and match the performance of unverified monolithic implementations. We use a modular layered verification approach to link the proofs for {WormSpace}, its applications, and a verified operating system to produce the first verified distributed system stack from the application to the operating system.},
	eventtitle = {the {ACM} Symposium},
	pages = {299--311},
	booktitle = {Proceedings of the {ACM} Symposium on Cloud Computing  - {SoCC} '19},
	publisher = {{ACM} Press},
	author = {Shin, Ji-Yong and Kim, Jieung and Honoré, Wolf and Vanzetto, Hernán and Radhakrishnan, Srihari and Balakrishnan, Mahesh and Shao, Zhong},
	urldate = {2019-12-31},
	date = {2019},
	langid = {english},
	file = {Shin et al. - 2019 - WormSpace A Modular Foundation for Simple, Verifi.pdf:/home/fordrl/Zotero/storage/KPL5EXSL/Shin et al. - 2019 - WormSpace A Modular Foundation for Simple, Verifi.pdf:application/pdf},
}

@article{liu_virtual_2019,
	title = {Virtual timeline: a formal abstraction for verifying preemptive schedulers with temporal isolation},
	volume = {4},
	issn = {24751421},
	url = {http://dl.acm.org/citation.cfm?doid=3377388.3371088},
	doi = {10.1145/3371088},
	shorttitle = {Virtual timeline},
	pages = {1--31},
	issue = {{POPL}},
	journaltitle = {Proceedings of the {ACM} on Programming Languages},
	author = {Liu, Mengqi and Rieg, Lionel and Shao, Zhong and Gu, Ronghui and Costanzo, David and Kim, Jung-Eun and Yoon, Man-Ki},
	urldate = {2019-12-31},
	date = {2019-12-20},
	langid = {english},
	file = {Liu et al. - 2019 - Virtual timeline a formal abstraction for verifyi.pdf:/home/fordrl/Zotero/storage/FLN4HKK6/Liu et al. - 2019 - Virtual timeline a formal abstraction for verifyi.pdf:application/pdf},
}

@online{lamport_pretending_2005,
	title = {Pretending Atomicity, Digital Systems Research Center: Report 44},
	url = {https://web.archive.org/web/20051227134748/http://gatekeeper.research.compaq.com/pub/DEC/SRC/research-reports/abstracts/src-rr-044.html},
	shorttitle = {Pretending Atomicity},
	abstract = {We present a theorem for deriving properties of a concurrent program by reasoning about a simpler, coarser-grained version. The theorem generalizes a result that Lipton proved for partial correctness and deadlock-freedom. Our theorem applies to all safety properties.},
	author = {Lamport, Leslie and Schneider, Fred B},
	urldate = {2019-12-30},
	date = {2005-12-27},
	file = {Pretending Atomicity:/home/fordrl/Zotero/storage/D58RFPMM/pretending.pdf:application/pdf;Snapshot:/home/fordrl/Zotero/storage/HZ5GATYJ/src-rr-044.html:text/html},
}

@inproceedings{ford_specification-based_1997,
	title = {The specification-based testing of a trusted kernel: {MK}++},
	doi = {10.1109/ICFEM.1997.630422},
	shorttitle = {The specification-based testing of a trusted kernel},
	abstract = {The {MK}++ kernel, a descendant of Mach, was designed and implemented at the Open Group Research Institute. Independently, Computational Logic Inc. had developed a formal specification for the Mach kernel interface. We report on the adaptation of this specification to {MK}++, and its use in the derivation of a testing strategy for the {MK}++ implementation. The results and utility of the tests are discussed.},
	eventtitle = {First {IEEE} International Conference on Formal Engineering Methods},
	pages = {151--160},
	booktitle = {First {IEEE} International Conference on Formal Engineering Methods},
	author = {Ford, R.L. and Simon, R.T. and Bevier, W.R. and Smith, L.M.},
	date = {1997-11},
	note = {{ISSN}: null},
	keywords = {Kernel, program testing, Computer bugs, Logic, formal specification, Atomic layer deposition, Formal specifications, Law, Legal factors, Mach kernel interface, {MK}++ implementation, {MK}++ kernel, operating system kernels, Performance evaluation, software reliability, specification based testing, System testing, testing strategy, trusted kernel, Yarn},
	file = {Ford et al. - 1997 - The specification-based testing of a trusted kerne.pdf:/home/fordrl/Zotero/storage/TM9VUD7S/Ford et al. - 1997 - The specification-based testing of a trusted kerne.pdf:application/pdf;IEEE Xplore Abstract Record:/home/fordrl/Zotero/storage/KASH6I92/630422.html:text/html},
}

@online{noauthor_rems:_nodate,
	title = {{REMS}: Rigorous Engineering of Mainsteam Systems, Papers},
	url = {https://www.cl.cam.ac.uk/~pes20/rems/rems-all.html},
	urldate = {2019-12-27},
	file = {rems-all:/home/fordrl/Zotero/storage/TZ3CQF6C/rems-all.html:text/html},
}

@book{bourque_guide_2014,
	title = {Guide to the software engineering body of knowledge},
	isbn = {978-0-7695-5166-1},
	author = {{IEEE Computer Society}},
	editor = {Bourque, Pierre and Fairley, R. E},
	date = {2014},
	langid = {english},
	note = {{OCLC}: 973217192},
	file = {Bourque et al. - 2014 - Guide to the software engineering body of knowledg.pdf:/home/fordrl/Zotero/storage/43FIHMET/Bourque et al. - 2014 - Guide to the software engineering body of knowledg.pdf:application/pdf},
}

@article{giuffrida_safe_2013,
	title = {Safe and automatic live update for operating systems},
	volume = {41},
	issn = {0163-5964, 0362-1340},
	url = {http://dl.acm.org/citation.cfm?id=2451116.2451147},
	doi = {10.1145/2451116.2451147},
	pages = {279--292},
	number = {1},
	journaltitle = {{ACM} {SIGARCH} Computer Architecture News},
	author = {Giuffrida, Cristiano and Kuijsten, Anton and Tanenbaum, Andrew S. and Giuffrida, Cristiano and Kuijsten, Anton and Tanenbaum, Andrew S. and Giuffrida, Cristiano and Kuijsten, Anton and Tanenbaum, Andrew S.},
	urldate = {2019-12-04},
	date = {2013-03-16},
	file = {Snapshot:/home/fordrl/Zotero/storage/D4ZCW5XH/citation.html:text/html;Full Text PDF:/home/fordrl/Zotero/storage/IJHI7NRV/Giuffrida et al. - 2013 - Safe and automatic live update for operating syste.pdf:application/pdf},
}

@thesis{giuffrida_safe_2014,
	title = {Safe and automatic live update},
	type = {phdthesis},
	author = {Giuffrida, C},
	date = {2014},
	langid = {english},
	note = {{OCLC}: 876276706},
	file = {Giuffrida - 2014 - Safe and automatic live update.pdf:/home/fordrl/Zotero/storage/XDPPCG4E/Giuffrida - 2014 - Safe and automatic live update.pdf:application/pdf},
}

@article{dang_rustbelt_nodate,
	title = {{RustBelt} Meets Relaxed Memory},
	volume = {4},
	abstract = {The Rust programming language supports safe systems programming by means of a strong ownership-tracking type system. In their prior work on {RustBelt}, Jung et al. began the task of setting Rust’s safety claims on a more rigorous formal foundation. Specifically, they used Iris, a Coq-based separation logic framework, to build a machine-checked proof of semantic soundness for a λ-calculus model of Rust, as well as for a number of widely-used Rust libraries that internally employ unsafe language features. However, they also made the significant simplifying assumption that the language is sequentially consistent. In this paper, we adapt {RustBelt} to account for the relaxed-memory operations that concurrent Rust libraries actually use, in the process uncovering a data race in the Arc library. We focus on the most interesting technical problem: how to reason about resource reclamation under relaxed memory, using a logical construction we call synchronized ghost state. {CCS} Concepts: • Theory of computation → Separation logic; Operational semantics; Programming logic.},
	pages = {29},
	author = {Dang, Hoang-Hai and Jourdan, Jacques-Henri and Kaiser, Jan-Oliver and Dreyer, Derek},
	langid = {english},
	file = {Dang et al. - RustBelt Meets Relaxed Memory.pdf:/home/fordrl/Zotero/storage/9BZCWM3G/Dang et al. - RustBelt Meets Relaxed Memory.pdf:application/pdf},
}

@article{jones_function_2013,
	title = {Function Points As a Universal Software Metric},
	volume = {38},
	issn = {0163-5948},
	url = {http://doi.acm.org/10.1145/2492248.2492268},
	doi = {10.1145/2492248.2492268},
	abstract = {Function point metrics are the most accurate and effective metrics yet developed for software sizing and also for studying software productivity, quality, costs, risks, and economic value. Unlike the older "lines of code" metric function points can be used to study requirements, design, and in fact all software activities from development through maintenance. In the future function point metrics can easily become a universal metric used for all software applications and for all software contracts in all countries. The government of Brazil already requires function points for all software contracts, and South Korea and Italy may soon follow. However, there are some logistical problems with function point metrics that need to be understood and overcome in order for function point metrics to become the primary metric for software economic analysis. Manual function point counting is too slow and costly to be used on large software projects above 10,000 function points in size. Also, application size is not constant but grows at about 2\% per calendar month during development and 8\% or more per calendar year for as long as software is in active use. This paper discusses a method of high-speed function point counting that can size any application in less than two minutes, and which can predict application growth during development and for five years after release. This new method is based on pattern matching and is covered by U.S. utility patent application and hence is patent pending.},
	pages = {1--27},
	number = {4},
	journaltitle = {{SIGSOFT} Softw. Eng. Notes},
	author = {Jones, Capers},
	urldate = {2019-11-27},
	date = {2013-07},
	file = {ACM Full Text PDF:/home/fordrl/Zotero/storage/7JSFC92I/Jones - 2013 - Function Points As a Universal Software Metric.pdf:application/pdf},
}

@article{clark_instructors_2019,
	title = {The Instructor’s Guide to Real Induction},
	volume = {92},
	issn = {0025-570X, 1930-0980},
	url = {https://www.tandfonline.com/doi/full/10.1080/0025570X.2019.1549902},
	doi = {10.1080/0025570X.2019.1549902},
	pages = {136--150},
	number = {2},
	journaltitle = {Mathematics Magazine},
	shortjournal = {Mathematics Magazine},
	author = {Clark, Pete L.},
	urldate = {2019-11-27},
	date = {2019-03-15},
	langid = {english},
	file = {Clark - 2019 - The Instructor’s Guide to Real Induction.pdf:/home/fordrl/Zotero/storage/F4QAXND8/Clark - 2019 - The Instructor’s Guide to Real Induction.pdf:application/pdf},
}

@inproceedings{malecha_towards_2016,
	title = {Towards foundational verification of cyber-physical systems},
	doi = {10.1109/SOSCYPS.2016.7580000},
	abstract = {The safety-critical aspects of cyber-physical systems motivate the need for rigorous analysis of these systems. In the literature this work is often done using idealized models of systems where the analysis can be carried out using high-level reasoning techniques such as Lyapunov functions and model checking. In this paper we present {VERIDRONE}, a foundational framework for reasoning about cyber-physical systems at all levels from high-level models to C code that implements the system. {VERIDRONE} is a library within the Coq proof assistant enabling us to build on its foundational implementation, its interactive development environments, and its wealth of libraries capturing interesting theories ranging from real numbers and differential equations to verified compilers and floating point numbers. These features make proof assistants in general, and Coq in particular, a powerful platform for unifying foundational results about safety-critical systems and ensuring interesting properties at all levels of the stack.},
	eventtitle = {2016 Science of Security for Cyber-Physical Systems Workshop ({SOSCYPS})},
	pages = {1--5},
	booktitle = {2016 Science of Security for Cyber-Physical Systems Workshop ({SOSCYPS})},
	author = {Malecha, Gregory and Ricketts, Daniel and Alvarez, Mario M. and Lerner, Sorin},
	date = {2016-04},
	note = {{ISSN}: null},
	keywords = {formal verification, model checking, verified compilers, Monitoring, Coq proof assistant, program compilers, Biomedical monitoring, Cognition, cyber-physical systems, Cyber-physical systems, differential equations, floating point numbers, foundational framework, high-level models, idealized models, interactive development environments, Lyapunov functions, Robustness, safety-critical aspects, safety-critical software, Software, Stability analysis, towards foundational verification},
}

@inproceedings{protzenko_formally_2019,
	location = {San Francisco, {CA}, {USA}},
	title = {Formally Verified Cryptographic Web Applications in {WebAssembly}},
	isbn = {978-1-5386-6660-9},
	url = {https://ieeexplore.ieee.org/document/8835291/},
	doi = {10.1109/SP.2019.00064},
	abstract = {After suffering decades of high-proﬁle attacks, the need for formal veriﬁcation of security-critical software has never been clearer. Veriﬁcation-oriented programming languages like F∗ are now being used to build high-assurance cryptographic libraries and implementations of standard protocols like {TLS}. In this paper, we seek to apply these veriﬁcation techniques to modern Web applications, like {WhatsApp}, that embed sophisticated custom cryptographic components. The problem is that these components are often implemented in {JavaScript}, a language that is both hostile to cryptographic code and hard to reason about. So we instead target {WebAssembly}, a new instruction set that is supported by all major {JavaScript} runtimes.},
	eventtitle = {2019 {IEEE} Symposium on Security and Privacy ({SP})},
	pages = {1256--1274},
	booktitle = {2019 {IEEE} Symposium on Security and Privacy ({SP})},
	publisher = {{IEEE}},
	author = {Protzenko, Jonathan and Beurdouche, Benjamin and Merigoux, Denis and Bhargavan, Karthikeyan},
	urldate = {2019-11-26},
	date = {2019-05},
	langid = {english},
	file = {Protzenko et al. - 2019 - Formally Verified Cryptographic Web Applications i.pdf:/home/fordrl/Zotero/storage/KL7T699C/Protzenko et al. - 2019 - Formally Verified Cryptographic Web Applications i.pdf:application/pdf},
}

@collection{cooper_incomputable_2017,
	location = {Cham},
	title = {The Incomputable},
	isbn = {978-3-319-43667-8 978-3-319-43669-2},
	url = {http://link.springer.com/10.1007/978-3-319-43669-2},
	series = {Theory and Applications of Computability},
	publisher = {Springer International Publishing},
	editor = {Cooper, S. Barry and Soskova, Mariya I.},
	urldate = {2019-11-15},
	date = {2017},
	doi = {10.1007/978-3-319-43669-2},
	file = {Cooper and Soskova - 2017 - The Incomputable.pdf:/home/fordrl/Zotero/storage/ZJSEKPHJ/Cooper and Soskova - 2017 - The Incomputable.pdf:application/pdf},
}

@book{soare_turing_2016,
	location = {Berlin, Heidelberg},
	title = {Turing Computability},
	isbn = {978-3-642-31932-7 978-3-642-31933-4},
	url = {http://link.springer.com/10.1007/978-3-642-31933-4},
	series = {Theory and Applications of Computability},
	publisher = {Springer Berlin Heidelberg},
	author = {Soare, Robert I.},
	urldate = {2019-11-15},
	date = {2016},
	doi = {10.1007/978-3-642-31933-4},
	file = {Soare - 2016 - Turing Computability.pdf:/home/fordrl/Zotero/storage/YRCUVKEF/Soare - 2016 - Turing Computability.pdf:application/pdf},
}

@book{longley_higher-order_2015,
	location = {Berlin, Heidelberg},
	title = {Higher-Order Computability},
	isbn = {978-3-662-47991-9 978-3-662-47992-6},
	url = {http://link.springer.com/10.1007/978-3-662-47992-6},
	series = {Theory and Applications of Computability},
	publisher = {Springer Berlin Heidelberg},
	author = {Longley, John and Normann, Dag},
	urldate = {2019-11-15},
	date = {2015},
	doi = {10.1007/978-3-662-47992-6},
	file = {Longley and Normann - 2015 - Higher-Order Computability.pdf:/home/fordrl/Zotero/storage/UES9V7IJ/Longley and Normann - 2015 - Higher-Order Computability.pdf:application/pdf},
}

@book{downey_algorithmic_2010,
	location = {New York, {NY}},
	title = {Algorithmic Randomness and Complexity},
	isbn = {978-0-387-95567-4 978-0-387-68441-3},
	url = {http://link.springer.com/10.1007/978-0-387-68441-3},
	series = {Theory and Applications of Computability},
	publisher = {Springer New York},
	author = {Downey, Rodney G. and Hirschfeldt, Denis R.},
	urldate = {2019-11-15},
	date = {2010},
	doi = {10.1007/978-0-387-68441-3},
	file = {Downey and Hirschfeldt - 2010 - Algorithmic Randomness and Complexity.pdf:/home/fordrl/Zotero/storage/K4LMHPLX/Downey and Hirschfeldt - 2010 - Algorithmic Randomness and Complexity.pdf:application/pdf},
}

@book{bridges_apartness_2011,
	location = {Berlin, Heidelberg},
	title = {Apartness and Uniformity},
	isbn = {978-3-642-22414-0 978-3-642-22415-7},
	url = {http://link.springer.com/10.1007/978-3-642-22415-7},
	series = {Theory and Applications of Computability},
	publisher = {Springer Berlin Heidelberg},
	author = {Bridges, Douglas S. and Vîţă, Luminiţa Simona},
	urldate = {2019-11-15},
	date = {2011},
	doi = {10.1007/978-3-642-22415-7},
	file = {Bridges and Vîţă - 2011 - Apartness and Uniformity.pdf:/home/fordrl/Zotero/storage/HU52C494/Bridges and Vîţă - 2011 - Apartness and Uniformity.pdf:application/pdf},
}

@article{oconnor_computer-verified_2010,
	title = {A computer-verified monadic functional implementation of the integral},
	volume = {411},
	issn = {0304-3975},
	url = {http://www.sciencedirect.com/science/article/pii/S0304397510003233},
	doi = {10.1016/j.tcs.2010.05.031},
	abstract = {We provide a computer-verified exact monadic functional implementation of the Riemann integral in type theory. Together with previous work by O’Connor, this may be seen as the beginning of the realization of Bishop’s vision to use constructive mathematics as a programming language for exact analysis.},
	pages = {3386--3402},
	number = {37},
	journaltitle = {Theoretical Computer Science},
	shortjournal = {Theoretical Computer Science},
	author = {O’Connor, Russell and Spitters, Bas},
	urldate = {2019-11-06},
	date = {2010-08-07},
	langid = {english},
	keywords = {Type theory, Exact real analysis, Functional programming, Monads},
	file = {ScienceDirect Full Text PDF:/home/fordrl/Zotero/storage/9CBAVCVC/O’Connor and Spitters - 2010 - A computer-verified monadic functional implementat.pdf:application/pdf;ScienceDirect Snapshot:/home/fordrl/Zotero/storage/EH5KVJ6P/S0304397510003233.html:text/html},
}

@online{noauthor_coquelicot.coquelicot_nodate,
	title = {Coquelicot.Coquelicot},
	url = {http://coquelicot.saclay.inria.fr/html/Coquelicot.Coquelicot.html},
	urldate = {2019-11-03},
	file = {Coquelicot.Coquelicot:/home/fordrl/Zotero/storage/VLB33M7N/Coquelicot.Coquelicot.html:text/html},
}

@incollection{hutchison_pragmatic_2013,
	location = {Berlin, Heidelberg},
	title = {Pragmatic Quotient Types in Coq},
	volume = {7998},
	isbn = {978-3-642-39633-5 978-3-642-39634-2},
	url = {http://link.springer.com/10.1007/978-3-642-39634-2_17},
	abstract = {In intensional type theory, it is not always possible to form the quotient of a type by an equivalence relation. However, quotients are extremely useful when formalizing mathematics, especially in algebra. We provide a Coq library with a pragmatic approach in two complementary components. First, we provide a framework to work with quotient types in an axiomatic manner. Second, we program construction mechanisms for some speciﬁc cases where it is possible to build a quotient type. This library was helpful in implementing the types of rational fractions, multivariate polynomials, ﬁeld extensions and real algebraic numbers.},
	pages = {213--228},
	booktitle = {Interactive Theorem Proving},
	publisher = {Springer Berlin Heidelberg},
	author = {Cohen, Cyril},
	editor = {Blazy, Sandrine and Paulin-Mohring, Christine and Pichardie, David},
	editorb = {Hutchison, David and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M. and Mattern, Friedemann and Mitchell, John C. and Naor, Moni and Nierstrasz, Oscar and Pandu Rangan, C. and Steffen, Bernhard and Sudan, Madhu and Terzopoulos, Demetri and Tygar, Doug and Vardi, Moshe Y. and Weikum, Gerhard},
	editorbtype = {redactor},
	urldate = {2019-10-18},
	date = {2013},
	langid = {english},
	doi = {10.1007/978-3-642-39634-2_17},
	file = {Cohen2013_Chapter_PragmaticQuotientTypesInCoq.pdf:/home/fordrl/Zotero/storage/SY5Z6DX3/Cohen2013_Chapter_PragmaticQuotientTypesInCoq.pdf:application/pdf},
}

@inproceedings{garillot_packaging_2009,
	title = {Packaging Mathematical Structures},
	isbn = {978-3-642-03359-9},
	series = {Lecture Notes in Computer Science},
	abstract = {This paper proposes generic design patterns to define and combine algebraic structures, using dependent records, coercions and type inference, inside the Coq system. This alternative to telescopes in particular supports multiple inheritance, maximal sharing of notations and theories, and automated structure inference. Our methodology is robust enough to handle a hierarchy comprising a broad variety of algebraic structures, from types with a choice operator to algebraically closed fields. Interfaces for the structures enjoy the convenience of a classical setting, without requiring any axiom. Finally, we present two applications of our proof techniques: a key lemma for characterising the discrete logarithm, and a matrix decomposition problem.},
	pages = {327--342},
	booktitle = {Theorem Proving in Higher Order Logics},
	publisher = {Springer Berlin Heidelberg},
	author = {Garillot, François and Gonthier, Georges and Mahboubi, Assia and Rideau, Laurence},
	editor = {Berghofer, Stefan and Nipkow, Tobias and Urban, Christian and Wenzel, Makarius},
	date = {2009},
	langid = {english},
	keywords = {Coq, Coercive subtyping, Formalization of Algebra, {SSReflect}, Type inference},
	file = {Garillot et al. - 2009 - Packaging Mathematical Structures.pdf:/home/fordrl/Zotero/storage/PFXDE3SD/Garillot et al. - 2009 - Packaging Mathematical Structures.pdf:application/pdf},
}

@online{noauthor_fm_nodate,
	title = {{FM} folks - richardlford@gmail.com - Gmail},
	url = {https://mail.google.com/mail/u/0/#inbox/FMfcgxwDrlVnZmDccTxHFBnzPRMfbmpn?projector=1&messagePartId=0.1},
	urldate = {2019-10-14},
	file = {FM folks - richardlford@gmail.com - Gmail:/home/fordrl/Zotero/storage/BJ2KFM5C/0.html:text/html},
}

@inproceedings{moscato_provably_2019,
	title = {Provably Correct Floating-Point Implementation of a Point-in-Polygon Algorithm},
	isbn = {978-3-030-30942-8},
	series = {Lecture Notes in Computer Science},
	abstract = {The problem of determining whether or not a point lies inside a given polygon occurs in many applications. In air traffic management concepts, a correct solution to the point-in-polygon problem is critical to geofencing systems for Unmanned Aerial Vehicles and in weather avoidance applications. Many mathematical methods can be used to solve the point-in-polygon problem. Unfortunately, a straightforward floating-point implementation of these methods can lead to incorrect results due to round-off errors. In particular, these errors may cause the control flow of the program to diverge with respect to the ideal real-number algorithm. This divergence potentially results in an incorrect point-in-polygon determination even when the point is far from the edges of the polygon. This paper presents a provably correct implementation of a point-in-polygon method that is based on the computation of the winding number. This implementation is mechanically generated from a source-to-source transformation of the ideal real-number specification of the algorithm. The correctness of this implementation is formally verified within the Frama-C analyzer, where the proof obligations are discharged using the Prototype Verification System ({PVS}).},
	pages = {21--37},
	booktitle = {Formal Methods – The Next 30 Years},
	publisher = {Springer International Publishing},
	author = {Moscato, Mariano M. and Titolo, Laura and Feliú, Marco A. and Muñoz, César A.},
	editor = {ter Beek, Maurice H. and {McIver}, Annabelle and Oliveira, José N.},
	date = {2019},
	langid = {english},
}

@article{klein_formally_2018,
	title = {Formally verified software in the real world},
	volume = {61},
	issn = {00010782},
	url = {http://dl.acm.org/citation.cfm?doid=3281635.3230627},
	doi = {10.1145/3230627},
	pages = {68--77},
	number = {10},
	journaltitle = {Communications of the {ACM}},
	shortjournal = {Commun. {ACM}},
	author = {Klein, Gerwin and Andronick, June and Fernandez, Matthew and Kuz, Ihor and Murray, Toby and Heiser, Gernot},
	urldate = {2019-10-14},
	date = {2018-09-26},
	langid = {english},
	file = {Klein et al. - 2018 - Formally verified software in the real world.pdf:/home/fordrl/Zotero/storage/U4UV5PRH/Klein et al. - 2018 - Formally verified software in the real world.pdf:application/pdf},
}

@incollection{ter_beek_gospelproviding_2019,
	location = {Cham},
	title = {{GOSPEL}—Providing {OCaml} with a Formal Specification Language},
	volume = {11800},
	isbn = {978-3-030-30941-1 978-3-030-30942-8},
	url = {http://link.springer.com/10.1007/978-3-030-30942-8_29},
	abstract = {This paper introduces {GOSPEL}, a behavioral speciﬁcation language for {OCaml}. It is designed to enable modular veriﬁcation of data structures and algorithms. {GOSPEL} is a contract-based, strongly typed language, with a formal semantics deﬁned by means of translation into Separation Logic. Compared with writing speciﬁcations directly in Separation Logic, {GOSPEL} provides a high-level syntax that greatly improves conciseness and makes it accessible to programmers with no familiarity with Separation Logic. Although {GOSPEL} has been developed for specifying {OCaml} code, we believe that many aspects of its design could apply to other programming languages. This paper presents the design and semantics of {GOSPEL}, and reports on its application for the development of a formally veriﬁed library of general-purpose {OCaml} data structures.},
	pages = {484--501},
	booktitle = {Formal Methods – The Next 30 Years},
	publisher = {Springer International Publishing},
	author = {Charguéraud, Arthur and Filliâtre, Jean-Christophe and Lourenço, Cláudio and Pereira, Mário},
	editor = {ter Beek, Maurice H. and {McIver}, Annabelle and Oliveira, José N.},
	urldate = {2019-10-14},
	date = {2019},
	langid = {english},
	doi = {10.1007/978-3-030-30942-8_29},
	file = {Charguéraud et al. - 2019 - GOSPEL—Providing OCaml with a Formal Specification.pdf:/home/fordrl/Zotero/storage/P9ICM9G6/Charguéraud et al. - 2019 - GOSPEL—Providing OCaml with a Formal Specification.pdf:application/pdf},
}

@article{easterbrook_formal_nodate,
	title = {Formal Methods for V\&V of partial specifications: An experience report},
	abstract = {This paper describes our work exploring the suitability of formal specification methods f o r independ e n t verification and validation ({IVi}3V) of software specifications for large, safety critical systems. An {IV}\&V contractor often has to perform rapid analysis on incomplete specifications, with no control over how those {speciJcations} are represented. Lightweight formal methods show significant promise in this context, as they offer a way of uncovering major errors, without the burden of full proofs of correctness. We describe an experiment in the application of the method {SCR} to testing for consistency properties of a partial model of th,e requirements for Fault Detection Isolation and Recovery o n th,e space station. We conclude that the insights gained from formalizing a specification is valuable, and it is the process of formalization, rather than the end product that is important. It was only necessary to build enough of the formal model to test the properties in which we were interested. Maintenance of fidelity between multiple representations of the same requirements (as they evolve) is still a problem,, and deserves further study.},
	pages = {9},
	author = {Easterbrook, Steve and Callahan, John},
	langid = {english},
	file = {Easterbrook and Callahan - Formal Methods for V&V of partial specifications .pdf:/home/fordrl/Zotero/storage/2NY7449P/Easterbrook and Callahan - Formal Methods for V&V of partial specifications .pdf:application/pdf},
}

@inproceedings{easterbrook_formal_1997,
	title = {Formal methods for V \& V of partial specifications: an experience report},
	doi = {10.1109/ISRE.1997.566865},
	shorttitle = {Formal methods for V amp;V of partial specifications},
	abstract = {This paper describes our work exploring the suitability of formal specification methods for independent verification and validation ({IV}\&V) of software specifications for large, safety critical systems. An {IV}\&V contractor often has to perform rapid analysis on incomplete specifications, with no control over how those specifications are represented. Lightweight formal methods show significant promise in this context, as they offer a way of uncovering major errors, without the burden of full proofs of correctness. We describe an experiment in the application of the method {SCR} to testing for consistency properties of a partial model of the requirements for fault detection isolation and recovery on the space station. We conclude that the insights gained from formalizing a specification is valuable, and it is the process of formalization, rather than the end product that is important. It was only necessary to build enough of the formal model to test the properties in which we were interested. Maintenance of fidelity between multiple representations of the same requirements (as they evolve) is still a problem, and deserves further study.},
	eventtitle = {Proceedings of {ISRE} '97: 3rd {IEEE} International Symposium on Requirements Engineering},
	pages = {160--168},
	booktitle = {Proceedings of {ISRE} '97: 3rd {IEEE} International Symposium on Requirements Engineering},
	author = {Easterbrook, S. and Callahan, J.},
	date = {1997-01},
	keywords = {program testing, program verification, formal methods, Performance analysis, testing, formal specification, Formal specifications, safety-critical software, aerospace computing, Aerospace safety, artificial satellites, consistency properties, Error correction, errors, fault detection isolation, fault diagnosis, fault recovery, formal specification methods, incomplete specifications, independent verification, International Space Station, large safety critical systems, {NASA}, partial specification verification, {SCR}, Software safety, space station, Space stations, Testing, Thyristors},
}

@article{chihani_certication_nodate,
	title = {Certiﬁcation of First-order proofs in classical and intuitionistic logics},
	pages = {167},
	author = {Chihani, Zakaria},
	langid = {english},
	file = {Chihani - Certiﬁcation of First-order proofs in classical an.pdf:/home/fordrl/Zotero/storage/VQJPPM4J/Chihani - Certiﬁcation of First-order proofs in classical an.pdf:application/pdf},
}

@article{gonthier_how_2013,
	title = {How to make ad hoc proof automation less ad hoc},
	volume = {23},
	issn = {0956-7968, 1469-7653},
	url = {https://www.cambridge.org/core/product/identifier/S0956796813000051/type/journal_article},
	doi = {10.1017/S0956796813000051},
	abstract = {Most interactive theorem provers provide support for some form of user-customizable proof automation. In a number of popular systems, such as Coq and Isabelle, this automation is achieved primarily through tactics, which are programmed in a separate language from that of the prover’s base logic. While tactics are clearly useful in practice, they can be difﬁcult to maintain and compose because, unlike lemmas, their behavior cannot be speciﬁed within the expressive type system of the prover itself.},
	pages = {357--401},
	number = {4},
	journaltitle = {Journal of Functional Programming},
	shortjournal = {J. Funct. Prog.},
	author = {Gonthier, Georges and Ziliani, Beta and Nanevski, Aleksandar and Dreyer, Derek},
	urldate = {2019-10-13},
	date = {2013-07},
	langid = {english},
	file = {Gonthier et al. - 2013 - How to make ad hoc proof automation less ad hoc.pdf:/home/fordrl/Zotero/storage/927PW954/Gonthier et al. - 2013 - How to make ad hoc proof automation less ad hoc.pdf:application/pdf},
}

@article{farrell_robotics_2018,
	title = {Robotics and Integrated Formal Methods: Necessity meets Opportunity},
	volume = {11023},
	url = {http://arxiv.org/abs/1805.11996},
	doi = {10.1007/978-3-319-98938-9_10},
	shorttitle = {Robotics and Integrated Formal Methods},
	abstract = {Robotic systems are multi-dimensional entities, combining both hardware and software, that are heavily dependent on, and influenced by, interactions with the real world. They can be variously categorised as embedded, cyberphysical, real-time, hybrid, adaptive and even autonomous systems, with a typical robotic system being likely to contain all of these aspects. The techniques for developing and verifying each of these system varieties are often quite distinct. This, together with the sheer complexity of robotic systems, leads us to argue that diverse formal techniques must be integrated in order to develop, verify, and provide certification evidence for, robotic systems. Furthermore, we propose the fast evolving field of robotics as an ideal catalyst for the advancement of integrated formal methods research, helping to drive the field in new and exciting directions and shedding light on the development of large-scale, dynamic, complex systems.},
	pages = {161--171},
	journaltitle = {{arXiv}:1805.11996 [cs]},
	author = {Farrell, Marie and Luckcuck, Matt and Fisher, Michael},
	urldate = {2019-10-05},
	date = {2018},
	eprinttype = {arxiv},
	eprint = {1805.11996},
	keywords = {Computer Science - Software Engineering, Computer Science - Robotics},
	file = {arXiv.org Snapshot:/home/fordrl/Zotero/storage/UHPEFVBL/1805.html:text/html;arXiv\:1805.11996 PDF:/home/fordrl/Zotero/storage/PPGSYFJR/Farrell et al. - 2018 - Robotics and Integrated Formal Methods Necessity .pdf:application/pdf},
}

@article{cofer_formal_nodate,
	title = {Formal Methods Case Studies for {DO}-333},
	pages = {203},
	author = {Cofer, Darren and Miller, Steven P and Collins, Rockwell},
	langid = {english},
	file = {Cofer et al. - Formal Methods Case Studies for DO-333.pdf:/home/fordrl/Zotero/storage/VSAYJK4A/Cofer et al. - Formal Methods Case Studies for DO-333.pdf:application/pdf},
}

@incollection{hutchison_formal_2009,
	location = {Berlin, Heidelberg},
	title = {Formal Methods for Privacy},
	volume = {5850},
	isbn = {978-3-642-05088-6 978-3-642-05089-3},
	url = {http://link.springer.com/10.1007/978-3-642-05089-3_1},
	pages = {1--15},
	booktitle = {{FM} 2009: Formal Methods},
	publisher = {Springer Berlin Heidelberg},
	author = {Tschantz, Michael Carl and Wing, Jeannette M.},
	editor = {Cavalcanti, Ana and Dams, Dennis R.},
	editorb = {Hutchison, David and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M. and Mattern, Friedemann and Mitchell, John C. and Naor, Moni and Nierstrasz, Oscar and Pandu Rangan, C. and Steffen, Bernhard and Sudan, Madhu and Terzopoulos, Demetri and Tygar, Doug and Vardi, Moshe Y. and Weikum, Gerhard},
	editorbtype = {redactor},
	urldate = {2019-10-04},
	date = {2009},
	langid = {english},
	doi = {10.1007/978-3-642-05089-3_1},
	file = {Tschantz and Wing - 2009 - Formal Methods for Privacy.pdf:/home/fordrl/Zotero/storage/ZJ5VILLY/Tschantz and Wing - 2009 - Formal Methods for Privacy.pdf:application/pdf},
}

@article{collins_secure_nodate,
	title = {{SECURE} {MATHEMATICALLY}- {ASSURED} {COMPOSITION} {OF} {CONTROL} {MODELS}},
	pages = {134},
	author = {Collins, Rockwell},
	langid = {english},
	file = {Collins - SECURE MATHEMATICALLY- ASSURED COMPOSITION OF CONT.pdf:/home/fordrl/Zotero/storage/GMUEMDAE/Collins - SECURE MATHEMATICALLY- ASSURED COMPOSITION OF CONT.pdf:application/pdf},
}

@book{ringer_qed_2019-1,
	title = {{QED} at Large: A Survey of Engineering of Formally Verified Software},
	url = {http://ieeexplore.ieee.org/document/8824174},
	shorttitle = {{QED} at Large},
	abstract = {Development of formal proofs of correctness of programs can increase actual and perceived reliability and facilitate better understanding of program specifications and their underlying assumptions. Tools supporting such development have been available for over 40 years but have only recently seen wide practical use. Projects based on construction of machine-checked formal proofs are now reaching an unprecedented scale, comparable to large software projects, which leads to new challenges in proof development and maintenance. Despite its increasing importance, the field of proof engineering is seldom considered in its own right; related theories, techniques, and tools span many fields and venues. {QED} at Large covers the timeline and research literature concerning proof development for program verification, including theories, languages, and tools. It emphasizes challenges and breakthroughs at each stage in history and highlights challenges that are currently present due to the increasing scale of proof developments. This monograph is intended for use by researchers and students who are new to the field. It provides the reader with an insightful overview of the work that has led to modern-day techniques for formally verifying software. In times of increasing automation, this underpins many software systems so future trends are also highlighted.},
	publisher = {now},
	author = {Ringer, T. and Palmskog, K. and Sergey, I. and Gligoric, M. and Tatlock, Z.},
	urldate = {2019-09-26},
	date = {2019},
}

@inproceedings{tuch_types_2007,
	location = {New York, {NY}, {USA}},
	title = {Types, Bytes, and Separation Logic},
	isbn = {978-1-59593-575-5},
	url = {http://doi.acm.org/10.1145/1190216.1190234},
	doi = {10.1145/1190216.1190234},
	series = {{POPL} '07},
	abstract = {We present a formal model of memory that both captures the low-level features of C's pointers and memory, and that forms the basis for an expressive implementation of separation logic. At the low level, we do not commit common oversimplifications, but correctly deal with C's model of programming language values and the heap. At the level of separation logic, we are still able to reason abstractly and efficiently. We implement this framework in the theorem prover Isabelle/{HOL} and demonstrate it on two case studies. We show that the divide between detailed and abstract does not impose undue verification overhead, and that simple programs remain easy to verify. We also show that the framework is applicable to real, security- and safety-critical code by formally verifying the memory allocator of the L4 microkernel.},
	pages = {97--108},
	booktitle = {Proceedings of the 34th Annual {ACM} {SIGPLAN}-{SIGACT} Symposium on Principles of Programming Languages},
	publisher = {{ACM}},
	author = {Tuch, Harvey and Klein, Gerwin and Norrish, Michael},
	urldate = {2019-09-26},
	date = {2007},
	note = {event-place: Nice, France},
	keywords = {C, separation logic, interactive theorem proving},
	file = {ACM Full Text PDF:/home/fordrl/Zotero/storage/LM5767HX/Tuch et al. - 2007 - Types, Bytes, and Separation Logic.pdf:application/pdf},
}

@article{ross_exterminators_2005-1,
	title = {The exterminators [software bugs},
	volume = {42},
	issn = {0018-9235},
	url = {http://ieeexplore.ieee.org/document/1502527/},
	doi = {10.1109/MSPEC.2005.1502527},
	pages = {36--41},
	number = {9},
	journaltitle = {{IEEE} Spectrum},
	shortjournal = {{IEEE} Spectr.},
	author = {Ross, P.E.},
	urldate = {2019-09-24},
	date = {2005-09},
	langid = {english},
	file = {Ross - 2005 - The exterminators [software bugs.pdf:/home/fordrl/Zotero/storage/J92P78QP/Ross - 2005 - The exterminators [software bugs.pdf:application/pdf},
}

@article{zhang_decision_nodate,
	title = {Decision Trees for Tactic Prediction in Coq},
	pages = {3},
	author = {Zhang, Liao and Blaauwbroek, Lasse and Piotrowski, Bartosz and Kaliszyk, Cezary and Urban, Josef},
	langid = {english},
	file = {Zhang et al. - Decision Trees for Tactic Prediction in Coq.pdf:/home/fordrl/Zotero/storage/JTFPGUFY/Zhang et al. - Decision Trees for Tactic Prediction in Coq.pdf:application/pdf},
}

@article{yuan_verified_nodate,
	title = {Verified functional programming of an {IoT} operating system's bootloader},
	abstract = {The fault of one device on a grid may incur severe economical or physical damages. Among the many critical components in such {IoT} devices, the operating system’s bootloader comes ﬁrst to initiate the trusted function of the device on the network. However, a bootloader uses hardware-dependent features that make its functional correctness proof difﬁcult. This paper uses veriﬁed programming to automate the veriﬁcation of both the C libraries and assembly boot-sequence of such a, real-world, bootloader in an operating system for {ARM}-based {IoT} devices: {RIOT}. We ﬁrst deﬁne the {ARM} {ISA} speciﬁcation, semantics and properties in F to model its critical assembly code boot sequence. We then use Low , a {DSL} rendering a Clike memory model in F , to implement the complete bootloader library and verify its functional correctness and memory safety. Other than ﬁxing potential faults and vulnerabilities in the source C and {ASM} bootloader, our evaluation provides an optimized and formally documented code structure, a reasonable speciﬁcation/implementation ratio, a high degree of proof automation and an equally efﬁcient generated code.},
	pages = {17},
	author = {Yuan, Shenghao and Talpin, Jean-Pierre},
	langid = {english},
	file = {Yuan and Talpin - Verified functional programming of an IoT operatin.pdf:/home/fordrl/Zotero/storage/63HVAKDA/Yuan and Talpin - Verified functional programming of an IoT operatin.pdf:application/pdf},
}

@inproceedings{danvy_abstracting_1990,
	location = {New York, {NY}, {USA}},
	title = {Abstracting control},
	isbn = {978-0-89791-368-3},
	url = {https://doi.org/10.1145/91556.91622},
	doi = {10.1145/91556.91622},
	series = {{LFP} '90},
	abstract = {The last few years have seen a renewed interest in continuations for expressing advanced control structures in programming languages, and new models such as Abstract Continuations have been proposed to capture these dimensions. This article investigates an alternative formulation, exploiting the latent expressive power of the standard continuation-passing style ({CPS}) instead of introducing yet other new concepts. We build on a single foundation: abstracting control as a hierarchy of continuations, each one modeling a specific language feature as acting on nested evaluation contexts. We show how iterating the continuation-passing conversion allows us to specify a wide range of control behavior. For example, two conversions yield an abstraction of Prolog-style backtracking. A number of other constructs can likewise be expressed in this framework; each is defined independently of the others, but all are arranged in a hierarchy making any interactions between them explicit. This approach preserves all the traditional results about {CPS}, e.g., its evaluation order independence. Accordingly, our semantics is directly implementable in a call-by-value language such as Scheme or {ML}. Furthermore, because the control operators denote simple, typable lambda-terms in {CPS}, they themselves can be statically typed. Contrary to intuition, the iterated {CPS} transformation does not yield huge results: except where explicitly needed, all continuations beyond the first one disappear due to the extensionality principle (η-reduction). Besides presenting a new motivation for control operators, this paper also describes an improved conversion into applicative-order {CPS}. The conversion operates in one pass by performing all administrative reductions at translation time; interestingly, it can be expressed very concisely using the new control operators. The paper also presents some examples of nondeterministic programming in direct style.},
	pages = {151--160},
	booktitle = {Proceedings of the 1990 {ACM} conference on {LISP} and functional programming},
	publisher = {Association for Computing Machinery},
	author = {Danvy, Olivier and Filinski, Andrzej},
	urldate = {2021-09-14},
	date = {1990-05-01},
	file = {Full Text PDF:/home/fordrl/Zotero/storage/I5TKIMG6/Danvy and Filinski - 1990 - Abstracting control.pdf:application/pdf},
}

@incollection{sivaramakrishnan_retrofitting_2021,
	location = {New York, {NY}, {USA}},
	title = {Retrofitting effect handlers onto {OCaml}},
	isbn = {978-1-4503-8391-2},
	url = {https://doi.org/10.1145/3453483.3454039},
	abstract = {Effect handlers have been gathering momentum as a mechanism for modular programming with user-defined effects. Effect handlers allow for non-local control flow mechanisms such as generators, async/await, lightweight threads and coroutines to be composably expressed. We present a design and evaluate a full-fledged efficient implementation of effect handlers for {OCaml}, an industrial-strength multi-paradigm programming language. Our implementation strives to maintain the backwards compatibility and performance profile of existing {OCaml} code. Retrofitting effect handlers onto {OCaml} is challenging since {OCaml} does not currently have any non-local control flow mechanisms other than exceptions. Our implementation of effect handlers for {OCaml}: (i) imposes a mean 1\% overhead on a comprehensive macro benchmark suite that does not use effect handlers; (ii) remains compatible with program analysis tools that inspect the stack; and (iii) is efficient for new code that makes use of effect handlers.},
	pages = {206--221},
	booktitle = {Proceedings of the 42nd {ACM} {SIGPLAN} International Conference on Programming Language Design and Implementation},
	publisher = {Association for Computing Machinery},
	author = {Sivaramakrishnan, {KC} and Dolan, Stephen and White, Leo and Kelly, Tom and Jaffer, Sadiq and Madhavapeddy, Anil},
	urldate = {2021-09-14},
	date = {2021-06-19},
	keywords = {Backtraces, Backwards compatibility, Continuations, Effect handlers, Fibers},
	file = {Full Text PDF:/home/fordrl/Zotero/storage/FE5TB3DP/Sivaramakrishnan et al. - 2021 - Retrofitting effect handlers onto OCaml.pdf:application/pdf},
}

@article{kulik_survey_2021,
	title = {A Survey of Practical Formal Methods for Security},
	url = {http://arxiv.org/abs/2109.01362},
	abstract = {In today's world, critical infrastructure is often controlled by computing systems. This introduces new risks for cyber attacks, which can compromise the security and disrupt the functionality of these systems. It is therefore necessary to build such systems with strong guarantees of resiliency against cyber attacks. One way to achieve this level of assurance is using formal verification, which provides proofs of system compliance with desired cyber security properties. The use of Formal Methods ({FM}) in aspects of cyber security and safety-critical systems are reviewed in this article. We split {FM} into the three main classes: theorem proving, model checking and lightweight {FM}. To allow the different uses of {FM} to be compared, we define a common set of terms. We further develop categories based on the type of computing system {FM} are applied in. Solutions in each class and category are presented, discussed, compared and summarised. We describe historical highlights and developments and present a state-of-the-art review in the area of {FM} in cyber security. This review is presented from the point of view of {FM} practitioners and researchers, commenting on the trends in each of the classes and categories. This is achieved by considering all types of {FM}, several types of security and safety critical systems and by structuring the taxonomy accordingly. The article hence provides a comprehensive overview of {FM} and techniques available to system designers of security-critical systems, simplifying the process of choosing the right tool for the task. The article concludes by summarising the discussion of the review, focusing on best practices, challenges, general future trends and directions of research within this field.},
	journaltitle = {{arXiv}:2109.01362 [cs]},
	author = {Kulik, Tomas and Dongol, Brijesh and Larsen, Peter Gorm and Macedo, Hugo Daniel and Schneider, Steve and Tran-Jørgensen, Peter Würtz Vinther and Woodcock, Jim},
	urldate = {2021-09-13},
	date = {2021-09-03},
	eprinttype = {arxiv},
	eprint = {2109.01362},
	keywords = {Computer Science - Cryptography and Security, Computer Science - Formal Languages and Automata Theory},
	file = {arXiv.org Snapshot:/home/fordrl/Zotero/storage/CBYN5J8D/2109.html:text/html;arXiv Fulltext PDF:/home/fordrl/Zotero/storage/MKQ3RHV5/Kulik et al. - 2021 - A Survey of Practical Formal Methods for Security.pdf:application/pdf},
}

@article{de_boer_formal_nodate,
	title = {Formal analysis of the Java Collections framework},
	pages = {108},
	author = {de Boer},
	langid = {english},
	file = {de Boer - Formal analysis of the Java Collections framework.pdf:/home/fordrl/Zotero/storage/CKM5QQUB/de Boer - Formal analysis of the Java Collections framework.pdf:application/pdf},
}

@article{mine_octagon_2007,
	title = {The Octagon Abstract Domain},
	url = {http://arxiv.org/abs/cs/0703084},
	abstract = {This article presents a new numerical abstract domain for static analysis by abstract interpretation. It extends a former numerical abstract domain based on Difference-Bound Matrices and allows us to represent invariants of the form (+/-x+/-y{\textless}=c), where x and y are program variables and c is a real constant. We focus on giving an efficient representation based on Difference-Bound Matrices - O(n2) memory cost, where n is the number of variables - and graph-based algorithms for all common abstract operators - O(n3) time cost. This includes a normal form algorithm to test equivalence of representation and a widening operator to compute least fixpoint approximations.},
	journaltitle = {{arXiv}:cs/0703084},
	author = {Miné, Antoine},
	urldate = {2021-09-08},
	date = {2007-03-16},
	eprinttype = {arxiv},
	eprint = {cs/0703084},
	keywords = {Computer Science - Programming Languages},
	file = {arXiv.org Snapshot:/home/fordrl/Zotero/storage/V69YF5B7/0703084.html:text/html;arXiv Fulltext PDF:/home/fordrl/Zotero/storage/U3Z2IVHR/Miné - 2007 - The Octagon Abstract Domain.pdf:application/pdf},
}

@article{watt_two_nodate,
	title = {Two Mechanisations of {WebAssembly} 1.0},
	abstract = {{WebAssembly} (Wasm) is a new bytecode language supported by all major Web browsers, designed primarily to be an eﬃcient compilation target for low-level languages such as C/C++ and Rust. It is unusual in that it is oﬃcially speciﬁed through a formal semantics. An initial draft speciﬁcation was published in 2017 [14], with an associated mechanised speciﬁcation in Isabelle/{HOL} published by Watt that found bugs in the original speciﬁcation, ﬁxed before its publication [37].},
	pages = {19},
	author = {Watt, Conrad and Rao, Xiaojia and Pichon-Pharabod, Jean and Bodin, Martin and Gardner, Philippa},
	langid = {english},
	file = {Watt et al. - Two Mechanisations of WebAssembly 1.0.pdf:/home/fordrl/Zotero/storage/RQGFAZMZ/Watt et al. - Two Mechanisations of WebAssembly 1.0.pdf:application/pdf},
}

@article{wang_concurrent_2021,
	title = {Concurrent matching logic},
	url = {http://arxiv.org/abs/2109.00319},
	abstract = {Abstract. Matching logic cannot handle concurrency. We introduce concurrent matching logic ({CML}) to reason about fault-free partial correctness of shared-memory concurrent programs. We also present a soundness proof for concurrent matching logic ({CML}) in terms of operational semantics. Under certain assumptions, the assertion of {CSL} can be transformed into the assertion of {CML}. Hence, {CSL} can be seen as an instance of {CML}.},
	journaltitle = {{arXiv}:2109.00319 [cs]},
	author = {Wang, Shangbei},
	urldate = {2021-09-08},
	date = {2021-09-01},
	eprinttype = {arxiv},
	eprint = {2109.00319},
	keywords = {Computer Science - Logic in Computer Science, Computer Science - Computer Science and Game Theory},
	file = {arXiv.org Snapshot:/home/fordrl/Zotero/storage/VVYV6EJS/2109.html:text/html;arXiv Fulltext PDF:/home/fordrl/Zotero/storage/TRABMLZ9/Wang - 2021 - Concurrent matching logic.pdf:application/pdf},
}

@article{raad_local_nodate,
	title = {Local Reasoning about the Presence of Bugs: Incorrectness Separation Logic},
	abstract = {There has been a large body of work on local reasoning for proving the absence of bugs, but none for proving their presence. We present a new formal framework for local reasoning about the presence of bugs, building on two complementary foundations: 1) separation logic and 2) incorrectness logic. We explore the theory of this new incorrectness separation logic ({ISL}), and use it to derive a begin-anywhere, intraprocedural symbolic execution analysis that has no false positives by construction. In so doing, we take a step towards transferring modular, scalable techniques from the world of program veriﬁcation to bug catching.},
	pages = {41},
	author = {Raad, Azalea and Berdine, Josh and Dang, Hoang-Hai and Dreyer, Derek and O’Hearn, Peter and Villard, Jules},
	langid = {english},
	note = {This is the full paper with appendix.},
	file = {Raad et al. - Local Reasoning about the Presence of Bugs Incorr.pdf:/home/fordrl/Zotero/storage/LWBIKJTB/Raad et al. - Local Reasoning about the Presence of Bugs Incorr.pdf:application/pdf},
}

@online{noauthor_local_nodate,
	title = {Local Reasoning About the Presence of Bugs: Incorrectness Separation Logic},
	url = {http://plv.mpi-sws.org/ISL/},
	urldate = {2021-09-08},
	file = {Local Reasoning About the Presence of Bugs\: Incorrectness Separation Logic:/home/fordrl/Zotero/storage/F93S8HY3/ISL.html:text/html},
}

@article{ohearn_separation_2019,
	title = {Separation logic},
	volume = {62},
	issn = {0001-0782},
	url = {https://doi.org/10.1145/3211968},
	doi = {10.1145/3211968},
	abstract = {Separation logic is a key development in formal reasoning about programs, opening up new lines of attack on longstanding problems.},
	pages = {86--95},
	number = {2},
	journaltitle = {Communications of the {ACM}},
	shortjournal = {Commun. {ACM}},
	author = {O'Hearn, Peter},
	urldate = {2021-09-08},
	date = {2019-01-28},
	file = {Full Text PDF:/home/fordrl/Zotero/storage/CLH9YBFR/O'Hearn - 2019 - Separation logic.pdf:application/pdf},
}

@article{ohearn_incorrectness_2019,
	title = {Incorrectness logic},
	volume = {4},
	url = {https://doi.org/10.1145/3371078},
	doi = {10.1145/3371078},
	abstract = {Program correctness and incorrectness are two sides of the same coin. As a programmer, even if you would like to have correctness, you might find yourself spending most of your time reasoning about incorrectness. This includes informal reasoning that people do while looking at or thinking about their code, as well as that supported by automated testing and static analysis tools. This paper describes a simple logic for program incorrectness which is, in a sense, the other side of the coin to Hoare's logic of correctness.},
	pages = {10:1--10:32},
	issue = {{POPL}},
	journaltitle = {Proceedings of the {ACM} on Programming Languages},
	shortjournal = {Proc. {ACM} Program. Lang.},
	author = {O'Hearn, Peter W.},
	urldate = {2021-09-07},
	date = {2019-12-20},
	keywords = {none},
	file = {Full Text PDF:/home/fordrl/Zotero/storage/SVSCWW8H/O'Hearn - 2019 - Incorrectness logic.pdf:application/pdf},
}

@article{le_finding_nodate,
	title = {Finding Real Bugs in Big Programs with Incorrectness Logic},
	volume = {1},
	pages = {31},
	number = {1},
	author = {Le, Quang Loc and Raad, Azalea and Villard, Jules and Berdine, Josh and Dreyer, Derek and O'Hearn, Peter W},
	langid = {english},
	file = {Le et al. - Finding Real Bugs in Big Programs with Incorrectne.pdf:/home/fordrl/Zotero/storage/DQZED98E/Le et al. - Finding Real Bugs in Big Programs with Incorrectne.pdf:application/pdf},
}

@thesis{boulme_formally_nodate,
	title = {Formally Veriﬁed Defensive Programming},
	pagetotal = {144},
	type = {phdthesis},
	author = {Boulmé, Sylvain},
	langid = {english},
	file = {Boulmé - Formally Veriﬁed Defensive Programming.pdf:/home/fordrl/Zotero/storage/P4BLMFRR/Boulmé - Formally Veriﬁed Defensive Programming.pdf:application/pdf},
}

@thesis{six_compilation_2021,
	title = {Compilation optimisante et formellement prouvée pour un processeur {VLIW}},
	url = {https://hal.archives-ouvertes.fr/tel-03326923},
	pagetotal = {258},
	institution = {Université Grenoble Alpes},
	type = {Theses},
	author = {Six, Cyril},
	urldate = {2021-09-07},
	date = {2021-07},
	keywords = {Optimization, Formal Verification, Compilation, Embarqué, Embedded, Optimisations, Vérification Formelle, {VLIW}},
	file = {HAL PDF Full Text:/home/fordrl/Zotero/storage/9NCN5BU6/Six - 2021 - Compilation optimisante et formellement prouvée po.pdf:application/pdf},
}

@article{devkota_cfgconf_2021,
	title = {{CFGConf}: Supporting high level requirements for visualizing Control Flow Graphs},
	url = {http://arxiv.org/abs/2108.03047},
	shorttitle = {{CFGConf}},
	abstract = {Control Flow Graphs ({CFGs}) are directed graphs that represent all possible walks a program can take during its execution. {CFGs} are used to analyze computer programs for purposes such as compilation, performance, and security. They are commonly drawn using hierarchical layouts. However, the general nature of such layouts may not capture {CFG}-specific structures, making it more difficult to match the drawing to the domain. Domain-specific drawings often require the help of a graph drawing expert, despite the computing expertise of the target audience. To alleviate these issues, we conduct a survey of drawing conventions and needs for {CFGs}. We then, through an iterative design process, design a flexible set of representations based on these findings and develop {CFGConf}, a {JSON} specification for specifying and drawing these higher-level drawing requirements, thereby allowing users to generate and integrate their own {CFG}-aware graph drawings. The {CFGConf} language enables the creation of domain-aware graph drawings of {CFGs} by increasing the notational efficiency of specifying the requirements while also retaining the expressiveness found in commonly used systems such as dot/graphviz. We evaluate {CFGConf} in terms of notational efficiency, expressiveness, and accessibility through user study and illustrative examples.},
	journaltitle = {{arXiv}:2108.03047 [cs]},
	author = {Devkota, Sabin and Legendre, Matthew and Kunen, Adam and Aschwanden, Pascal and Isaacs, Katherine E.},
	urldate = {2021-09-07},
	date = {2021-08-06},
	eprinttype = {arxiv},
	eprint = {2108.03047},
	keywords = {Computer Science - Human-Computer Interaction},
	file = {arXiv.org Snapshot:/home/fordrl/Zotero/storage/X82AIA98/2108.html:text/html;arXiv Fulltext PDF:/home/fordrl/Zotero/storage/4I22GWA8/Devkota et al. - 2021 - CFGConf Supporting high level requirements for vi.pdf:application/pdf},
}

@thesis{ringer_proof_nodate,
	title = {Proof Repair - Talia Ringer Thesis},
	pagetotal = {158},
	type = {phdthesis},
	author = {Ringer, Talia},
	langid = {english},
	file = {Proof Repair.pdf:/home/fordrl/Zotero/storage/9DCW8GXE/Proof Repair.pdf:application/pdf},
}

@article{lin_trustworthy_nodate,
	title = {Trustworthy Program Veriﬁcation via Proof Generation},
	abstract = {In an ideal language framework, language designers only need to deﬁne the formal semantics of their languages. Deductive program veriﬁers and other language tools are automatically generated by the framework. In this paper, we propose a novel approach to establishing the correctness of these autogenerated veriﬁers via proof generation. Our approach is based on the K language framework and its logical foundation, matching logic. Given a formal language semantics in K, we translate it into a corresponding matching logic theory. Then, we encode formal veriﬁcation tasks as reachability formulas in matching logic. The correctness of one veriﬁcation task is then established, on a case-by-case basis, by automatically generating a rigorous, machine-checkable mathematical proof of the associated reachability formula. Experiments with our proof generation prototype on various veriﬁcation tasks in diﬀerent programming languages show promising performance and attest to the feasibility of the proposed approach.},
	pages = {43},
	author = {Lin, Zhengyao and Chen, Xiaohong and Trinh, Minh-Thai and Wang, John and Roşu, Grigore},
	langid = {english},
	file = {Lin et al. - Trustworthy Program Veriﬁcation via Proof Generati.pdf:/home/fordrl/Zotero/storage/CXCCQHGK/Lin et al. - Trustworthy Program Veriﬁcation via Proof Generati.pdf:application/pdf},
}

@inproceedings{bakhirkin_combining_2017,
	location = {New York City, United States},
	title = {Combining Forward and Backward Abstract Interpretation of Horn Clauses},
	url = {https://hal.archives-ouvertes.fr/hal-01551447},
	series = {Static Analysis},
	abstract = {Alternation of forward and backward analyses is a standard technique in abstract interpretation of programs, which is in particular useful when we wish to prove unreachability of some undesired program states. The current state-of-the-art technique for combining forward (bottom-up, in logic programming terms) and backward (top-down) abstract interpretation of Horn clauses is query-answer transformation. It transforms a system of Horn clauses, such that standard forward analysis can propagate constraints both forward, and backward from a goal. Query-answer transformation is effective, but has issues that we wish to address. For that, we introduce a new backward collecting semantics, which is suitable for alternating forward and backward abstract interpretation of Horn clauses. We show how the alternation can be used to prove unreachability of the goal and how every subsequent run of an analysis yields a refined model of the system. Experimentally, we observe that combining forward and backward analyses is important for analysing systems that encode questions about reachability in C programs. In particular, the combination that follows our new semantics improves the precision of our own abstract interpreter, including when compared to a forward analysis of a query-answer-transformed system.},
	booktitle = {24th International Static Analysis Symposium ({SAS})},
	publisher = {Springer},
	author = {Bakhirkin, Alexey and Monniaux, David},
	editor = {Ranzato, Francesco},
	urldate = {2021-09-07},
	date = {2017-08},
	note = {Backup Publisher: Francesco Ranzato and Patrick Cousot},
	keywords = {Horn clauses, Static analysis of programs},
	file = {HAL PDF Full Text:/home/fordrl/Zotero/storage/K2FSDDRC/Bakhirkin and Monniaux - 2017 - Combining Forward and Backward Abstract Interpreta.pdf:application/pdf},
}

@article{pickard_calculating_2021,
	title = {Calculating dependently-typed compilers (functional pearl)},
	volume = {5},
	issn = {2475-1421},
	url = {https://dl.acm.org/doi/10.1145/3473587},
	doi = {10.1145/3473587},
	abstract = {{GRAHAM} {HUTTON}, University of Nottingham, {UK} Compilers are difficult to write, and difficult to get right. Bahr and Hutton recently developed a new technique for calculating compilers directly from specifications of their correctness, which ensures that the resulting compilers are correct-by-construction. To date, however, this technique has only been applicable to source languages that are untyped. In this article, we show that moving to a dependently-typed setting allows us to naturally support typed source languages, ensure that all compilation components are type-safe, and make the resulting calculations easier to mechanically check using a proof assistant. {CCS} Concepts: • Software and its engineering → Compilers; • Theory of computation → Type theory; Logic and verification.},
	pages = {1--27},
	issue = {{ICFP}},
	journaltitle = {Proceedings of the {ACM} on Programming Languages},
	shortjournal = {Proc. {ACM} Program. Lang.},
	author = {Pickard, Mitchell and Hutton, Graham},
	urldate = {2021-08-26},
	date = {2021-08-22},
	langid = {english},
	file = {Pickard and Hutton - 2021 - Calculating dependently-typed compilers (functiona.pdf:/home/fordrl/Zotero/storage/7Z4LQ7ZD/Pickard and Hutton - 2021 - Calculating dependently-typed compilers (functiona.pdf:application/pdf},
}

@article{baudin_dogged_2021,
	title = {The dogged pursuit of bug-free C programs: the Frama-C software analysis platform},
	volume = {64},
	issn = {0001-0782},
	url = {https://doi.org/10.1145/3470569},
	doi = {10.1145/3470569},
	shorttitle = {The dogged pursuit of bug-free C programs},
	abstract = {A panoramic view of a popular platform for C program analysis and verification.},
	pages = {56--68},
	number = {8},
	journaltitle = {Communications of the {ACM}},
	shortjournal = {Commun. {ACM}},
	author = {Baudin, Patrick and Bobot, François and Bühler, David and Correnson, Loïc and Kirchner, Florent and Kosmatov, Nikolai and Maroneze, André and Perrelle, Valentin and Prevosto, Virgile and Signoles, Julien and Williams, Nicky},
	urldate = {2021-08-26},
	date = {2021-07-26},
	file = {Full Text PDF:/home/fordrl/Zotero/storage/SI8BPHRG/Baudin et al. - 2021 - The dogged pursuit of bug-free C programs the Fra.pdf:application/pdf},
}

@article{scharager_verified_2021,
	title = {Verified Quadratic Virtual Substitution for Real Arithmetic},
	url = {http://arxiv.org/abs/2105.14183},
	abstract = {This paper presents a formally verified quantifier elimination ({QE}) algorithm for first-order real arithmetic by linear and quadratic virtual substitution ({VS}) in Isabelle/{HOL}. The Tarski-Seidenberg theorem established that the first-order logic of real arithmetic is decidable by {QE}. However, in practice, {QE} algorithms are highly complicated and often combine multiple methods for performance. {VS} is a practically successful method for {QE} that targets formulas with low-degree polynomials. To our knowledge, this is the first work to formalize {VS} for quadratic real arithmetic including inequalities. The proofs necessitate various contributions to the existing multivariate polynomial libraries in Isabelle/{HOL}, including a method for re-indexing variables in a polynomial. Our framework is modularized and easily expandable (to facilitate integrating future optimizations), and could serve as a basis for developing a general-purpose {QE} algorithm. Further, as our formalization is designed with practicality in mind, we export our development to {SML} and test the resulting code on 378 benchmarks from the literature, comparing to Redlog, Z3, Mathematica, and {SMT}-{RAT}.},
	journaltitle = {{arXiv}:2105.14183 [cs]},
	author = {Scharager, Matias and Cordwell, Katherine and Mitsch, Stefan and Platzer, André},
	urldate = {2021-08-26},
	date = {2021-05-28},
	eprinttype = {arxiv},
	eprint = {2105.14183},
	keywords = {Computer Science - Logic in Computer Science, F.3.1, F.4.1, 03B35, 03C10, 68V20},
	file = {arXiv.org Snapshot:/home/fordrl/Zotero/storage/Y33ATKPW/2105.html:text/html;arXiv Fulltext PDF:/home/fordrl/Zotero/storage/IHM9N48G/Scharager et al. - 2021 - Verified Quadratic Virtual Substitution for Real A.pdf:application/pdf},
}

@thesis{mine_static_nodate,
	title = {Static analysis by abstract interpretation of concurrent programs},
	pagetotal = {94},
	institution = {{ENS}},
	type = {Habilitation Thesis},
	author = {Miné, Antoine},
	langid = {english},
	file = {Mine - Static analysis by abstract interpretation of conc.pdf:/home/fordrl/Zotero/storage/GKPU3FJS/Mine - Static analysis by abstract interpretation of conc.pdf:application/pdf},
}

@article{dawes_specifying_nodate,
	title = {Specifying Properties over Inter-Procedural, Source Code Level Behaviour of Programs},
	abstract = {The problem of verifying a program at runtime with respect to some formal speciﬁcation has led to the development of a rich collection of speciﬁcation languages. These languages often have a high level of abstraction and provide sophisticated modal operators, giving a high level of expressiveness. In particular, this makes it possible to express properties concerning the source code level behaviour of programs. However, for many languages, the correspondence between events generated at the source code level and parts of the speciﬁcation in question would have to be carefully deﬁned.},
	pages = {20},
	author = {Dawes, Joshua Heneage},
	langid = {english},
	file = {Dawes - Specifying Properties over Inter-Procedural, Sourc.pdf:/home/fordrl/Zotero/storage/2UTHXLFJ/Dawes - Specifying Properties over Inter-Procedural, Sourc.pdf:application/pdf},
}

@inproceedings{chen_boosting_2021,
	location = {New York, {NY}, {USA}},
	title = {Boosting static analysis accuracy with instrumented test executions},
	isbn = {978-1-4503-8562-6},
	url = {https://doi.org/10.1145/3468264.3468626},
	doi = {10.1145/3468264.3468626},
	series = {{ESEC}/{FSE} 2021},
	abstract = {The two broad approaches to discover properties of programs---static and dynamic analyses---have complementary strengths: static techniques perform exhaustive exploration and prove upper bounds on program behaviors, while the dynamic analysis of test cases provides concrete evidence of these behaviors and promise low false alarm rates. In this paper, we present {DynaBoost}, a system which uses information obtained from test executions to prioritize the alarms of a static analyzer. We instrument the program to dynamically look for dataflow behaviors predicted by the static analyzer, and use these results to bootstrap a probabilistic alarm ranking system, where the user repeatedly inspects the alarm judged most likely to be a real bug, and where the system re-ranks the remaining alarms in response to user feedback. The combined system is able to exploit information that cannot be easily provided by users, and provides significant improvements in the human alarm inspection burden: by 35\% compared to the baseline ranking system, and by 89\% compared to an unaided programmer triaging alarm reports.},
	pages = {1154--1165},
	booktitle = {Proceedings of the 29th {ACM} Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
	publisher = {Association for Computing Machinery},
	author = {Chen, Tianyi and Heo, Kihong and Raghothaman, Mukund},
	urldate = {2021-08-26},
	date = {2021-08-20},
	keywords = {Static analysis, alarm ranking, Bayesian inference, belief networks, dynamic analysis},
	file = {Full Text PDF:/home/fordrl/Zotero/storage/SNST7W42/Chen et al. - 2021 - Boosting static analysis accuracy with instrumente.pdf:application/pdf},
}

@inproceedings{pizzuti_generating_2021,
	location = {New York, {NY}, {USA}},
	title = {Generating high performance code for irregular data structures using dependent types},
	isbn = {978-1-4503-8614-2},
	url = {https://doi.org/10.1145/3471873.3472977},
	doi = {10.1145/3471873.3472977},
	series = {{FHPNC} 2021},
	abstract = {Parallel architectures offer high performance but are challenging to program. Data parallel functional languages offer a solution by providing a high-level programming model to work with accelerators such as {GPUs}. Existing languages are designed to work with dense arrays, limiting their usefulness in expressing irregular data structures, such as graphs and sparse matrices important in many application domains. This paper addresses this limitation by extending a data-parallel language with limited dependent types, including position dependent arrays and dependent pairs to model irregular data structures. The approach is demonstrated through three case studies: dense to sparse matrix conversion, sparse matrix-vector multiplication, and parallel breadth-first search. Experimental results show that this approach outperforms state-of-the-art implementations on {GPUs}. Compared to Nvidia’s {cuSparse}, our automatically generated code achieves an average speedup of 1.2× for dense to sparse matrix conversion and 1.3× for sparse matrix-vector multiplication.},
	pages = {37--49},
	booktitle = {Proceedings of the 9th {ACM} {SIGPLAN} International Workshop on Functional High-Performance and Numerical Computing},
	publisher = {Association for Computing Machinery},
	author = {Pizzuti, Federico and Steuwer, Michel and Dubach, Christophe},
	urldate = {2021-08-26},
	date = {2021-08-22},
	keywords = {Dependent Types, Irregular Data Structures},
	file = {Full Text PDF:/home/fordrl/Zotero/storage/HTBXMEKV/Pizzuti et al. - 2021 - Generating high performance code for irregular dat.pdf:application/pdf},
}

@inproceedings{punchihewa_safe_2021,
	location = {Virtual Republic of Korea},
	title = {Safe mutation with algebraic effects},
	isbn = {978-1-4503-8615-9},
	url = {https://dl.acm.org/doi/10.1145/3471874.3472988},
	doi = {10.1145/3471874.3472988},
	abstract = {It can be difficult to write safe concurrent programs which use shared mutable state. Subtle mistakes can lead to data races that manifest as unexpected program behaviour. The prevailing approaches to solving this dilemma are to either eschew mutable state altogether, or design bespoke languages that prevent data races by design. This article introduces a third approach by showing how safe mutation can be integrated into a mainstream functional programming language with algebraic effects. This article produces a framework that tracks the use of mutable state and guarantees data race freedom at compile time.},
	eventtitle = {{ICFP} '21: 26th {ACM} {SIGPLAN} International Conference on Functional Programming},
	pages = {122--135},
	booktitle = {Proceedings of the 14th {ACM} {SIGPLAN} International Symposium on Haskell},
	publisher = {{ACM}},
	author = {Punchihewa, Hashan and Wu, Nicolas},
	urldate = {2021-08-26},
	date = {2021-08-18},
	langid = {english},
	file = {Punchihewa and Wu - 2021 - Safe mutation with algebraic effects.pdf:/home/fordrl/Zotero/storage/RRT3M3LV/Punchihewa and Wu - 2021 - Safe mutation with algebraic effects.pdf:application/pdf},
}

@article{eisenberg_existential_2021,
	title = {An existential crisis resolved: type inference for first-class existential types},
	volume = {5},
	url = {https://doi.org/10.1145/3473569},
	doi = {10.1145/3473569},
	shorttitle = {An existential crisis resolved},
	abstract = {Despite the great success of inferring and programming with universal types, their dual—existential types—are much harder to work with. Existential types are useful in building abstract types, working with indexed types, and providing first-class support for refinement types. This paper, set in the context of Haskell, presents a bidirectional type-inference algorithm that infers where to introduce and eliminate existentials without any annotations in terms, along with an explicitly typed, type-safe core language usable as a compilation target. This approach is backward compatible. The key ingredient is to use strong existentials, which support (lazily) projecting out the encapsulated data, not weak existentials accessible only by pattern-matching.},
	pages = {64:1--64:29},
	issue = {{ICFP}},
	journaltitle = {Proceedings of the {ACM} on Programming Languages},
	shortjournal = {Proc. {ACM} Program. Lang.},
	author = {Eisenberg, Richard A. and Duboc, Guillaume and Weirich, Stephanie and Lee, Daniel},
	urldate = {2021-08-26},
	date = {2021-08-18},
	keywords = {Haskell, existential types, type inference},
	file = {Full Text PDF:/home/fordrl/Zotero/storage/HCLF6VIC/Eisenberg et al. - 2021 - An existential crisis resolved type inference for.pdf:application/pdf},
}

@article{zakowski_modular_2021,
	title = {Modular, compositional, and executable formal semantics for {LLVM} {IR}},
	volume = {5},
	url = {https://doi.org/10.1145/3473572},
	doi = {10.1145/3473572},
	abstract = {This paper presents a novel formal semantics, mechanized in Coq, for a large, sequential subset of the {LLVM} {IR}. In contrast to previous approaches, which use relationally-specified operational semantics, this new semantics is based on monadic interpretation of interaction trees, a structure that provides a more compositional approach to defining language semantics while retaining the ability to extract an executable interpreter. Our semantics handles many of the {LLVM} {IR}'s non-trivial language features and is constructed modularly in terms of event handlers, including those that deal with nondeterminism in the specification. We show how this semantics admits compositional reasoning principles derived from the interaction trees equational theory of weak bisimulation, which we extend here to better deal with nondeterminism, and we use them to prove that the extracted reference interpreter faithfully refines the semantic model. We validate the correctness of the semantics by evaluating it on unit tests and {LLVM} {IR} programs generated by {HELIX}.},
	pages = {67:1--67:30},
	issue = {{ICFP}},
	journaltitle = {Proceedings of the {ACM} on Programming Languages},
	shortjournal = {Proc. {ACM} Program. Lang.},
	author = {Zakowski, Yannick and Beck, Calvin and Yoon, Irene and Zaichuk, Ilia and Zaliva, Vadim and Zdancewic, Steve},
	urldate = {2021-08-26},
	date = {2021-08-18},
	keywords = {{LLVM}, Coq, Semantics, Monads, Verified Compilation},
	file = {Full Text PDF:/home/fordrl/Zotero/storage/LMFV6MGJ/Zakowski et al. - 2021 - Modular, compositional, and executable formal sema.pdf:application/pdf},
}

@inproceedings{su_conditional_2021,
	location = {Athens Greece},
	title = {Conditional interpolation: making concurrent program verification more effective},
	isbn = {978-1-4503-8562-6},
	url = {https://dl.acm.org/doi/10.1145/3468264.3468602},
	doi = {10.1145/3468264.3468602},
	shorttitle = {Conditional interpolation},
	abstract = {Due to the state-space explosion problem, efficient verification of real-world programs in large scale is still a big challenge. Particularly, thread alternation makes the verification of concurrent programs much more difficult since it aggravates this problem. In this paper, an application of Craig interpolation, namely conditional interpolation, is proposed to work together with {CEGAR}-based approach to reduce the state-space of concurrent tasks. Specifically, conditional interpolation is formalized to confine the reachable region of states so that infeasible conditional branches could be pruned. Furthermore, the generated conditional interpolants are utilized to shorten the interpolation paths, which makes the time consumed for verification significantly reduced. We have implemented the proposed approach on top of an open-source software model checker. Empirical results show that the conditional interpolation is effective in improving the verification efficiency of concurrent tasks.},
	eventtitle = {{ESEC}/{FSE} '21: 29th {ACM} Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
	pages = {144--154},
	booktitle = {Proceedings of the 29th {ACM} Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
	publisher = {{ACM}},
	author = {Su, Jie and Tian, Cong and Duan, Zhenhua},
	urldate = {2021-08-26},
	date = {2021-08-20},
	langid = {english},
	file = {Su et al. - 2021 - Conditional interpolation making concurrent progr.pdf:/home/fordrl/Zotero/storage/X3DY5PKG/Su et al. - 2021 - Conditional interpolation making concurrent progr.pdf:application/pdf},
}

@article{chlipala_skipping_nodate,
	title = {Skipping the Binder Bureaucracy with Mixed Embeddings in a Semantics Course (Functional Pearl)},
	volume = {5},
	abstract = {{ADAM} {CHLIPALA}, {MIT}, {USA} Rigorous reasoning about programs calls for some amount of bureaucracy in managing details like variable binding, but, in guiding students through big ideas in semantics, we might hope to minimize the overhead. We describe our experiment introducing a range of such ideas, using the Coq proof assistant, without any explicit representation of variables, instead using a higher-order syntax encoding that we dub łmixed embeddingž: it is neither the fully explicit syntax of deep embeddings nor the syntax-free programming of shallow embeddings. Marquee examples include different takes on concurrency reasoning, including in the traditions of model checking (partial-order reduction), program logics (concurrent separation logic), and type checking (session types) ś all presented without any side conditions on variables. {CCS} Concepts: • Theory of computation → Program semantics; Program reasoning.},
	pages = {28},
	author = {Chlipala, Adam},
	langid = {english},
	file = {Chlipala - Skipping the Binder Bureaucracy with Mixed Embeddi.pdf:/home/fordrl/Zotero/storage/QP3BBMR9/Chlipala - Skipping the Binder Bureaucracy with Mixed Embeddi.pdf:application/pdf},
}

@article{mcbride_applicative_2008,
	title = {Applicative programming with effects},
	volume = {18},
	issn = {0956-7968, 1469-7653},
	url = {http://www.journals.cambridge.org/abstract_S0956796807006326},
	doi = {10.1017/S0956796807006326},
	abstract = {In this paper, we introduce Applicative functors—an abstract characterisation of an applicative style of eﬀectful programming, weaker than Monads and hence more widespread. Indeed, it is the ubiquity of this programming pattern that drew us to the abstraction. We retrace our steps in this paper, introducing the applicative pattern by diverse examples, then abstracting it to deﬁne the Applicative type class and introducing a bracket notation which interprets the normal application syntax in the idiom of an Applicative functor. Further, we develop the properties of applicative functors and the generic operations they support. We close by identifying the categorical structure of applicative functors and examining their relationship both with Monads and with Arrows.},
	number = {1},
	journaltitle = {Journal of Functional Programming},
	shortjournal = {J. Funct. Prog.},
	author = {Mcbride, Conor and Paterson, Ross},
	urldate = {2021-08-09},
	date = {2008-01},
	langid = {english},
	file = {Mcbride and Paterson - 2008 - Applicative programming with effects.pdf:/home/fordrl/Zotero/storage/IQUTB7AB/Mcbride and Paterson - 2008 - Applicative programming with effects.pdf:application/pdf},
}

@article{gratzer_multimodal_2021,
	title = {Multimodal Dependent Type Theory},
	volume = {Volume 17, Issue 3},
	issn = {1860-5974},
	url = {https://lmcs.episciences.org/7571},
	doi = {10.46298/lmcs-17(3:11)2021},
	abstract = {We introduce {MTT}, a dependent type theory which supports multiple modalities. {MTT} is parametrized by a mode theory which speciﬁes a collection of modes, modalities, and transformations between them. We show that diﬀerent choices of mode theory allow us to use the same type theory to compute and reason in many modal situations, including guarded recursion, axiomatic cohesion, and parametric quantiﬁcation. We reproduce examples from prior work in guarded recursion and axiomatic cohesion, thereby demonstrating that {MTT} constitutes a simple and usable syntax whose instantiations intuitively correspond to previous handcrafted modal type theories. In some cases, instantiating {MTT} to a particular situation unearths a previously unknown type theory that improves upon prior systems. Finally, we investigate the metatheory of {MTT}. We prove the consistency of {MTT} and establish canonicity through an extension of recent type-theoretic gluing techniques. These results hold irrespective of the choice of mode theory, and thus apply to a wide variety of modal situations.},
	pages = {7571},
	journaltitle = {Logical Methods in Computer Science},
	author = {Gratzer, Daniel and Kavvos, G. A. and Nuyts, Andreas and Birkedal, Lars},
	urldate = {2021-08-04},
	date = {2021-07-28},
	langid = {english},
	file = {Gratzer et al. - 2021 - Multimodal Dependent Type Theory.pdf:/home/fordrl/Zotero/storage/V5MYXX3L/Gratzer et al. - 2021 - Multimodal Dependent Type Theory.pdf:application/pdf},
}

@article{tarski_lattice-theoretical_1955,
	title = {A lattice-theoretical fixpoint theorem and its applications.},
	volume = {5},
	issn = {0030-8730},
	url = {https://www.projecteuclid.org/journals/pacific-journal-of-mathematics/volume-5/issue-2/A-lattice-theoretical-fixpoint-theorem-and-its-applications/pjm/1103044538.full},
	abstract = {Pacific Journal of Mathematics},
	pages = {285--309},
	number = {2},
	journaltitle = {Pacific Journal of Mathematics},
	author = {Tarski, Alfred},
	urldate = {2021-08-03},
	date = {1955-01},
	note = {Publisher: Pacific Journal of Mathematics, A Non-profit Corporation},
	keywords = {06.0X},
	file = {Snapshot:/home/fordrl/Zotero/storage/WE3V7Y52/1103044538.html:text/html;Full Text PDF:/home/fordrl/Zotero/storage/JNSL6DFD/Tarski - 1955 - A lattice-theoretical fixpoint theorem and its app.pdf:application/pdf},
}

@article{maillard_multiverse_nodate,
	title = {The Multiverse: Logical Modularity for Proof Assistants},
	pages = {28},
	author = {Maillard, Kenji and Margulies, Nicolas and Sozeau, Matthieu and Tabareau, Nicolas and Tanter, Éric},
	langid = {english},
	file = {Maillard et al. - The Multiverse Logical Modularity for Proof Assis.pdf:/home/fordrl/Zotero/storage/VTYIEKMW/Maillard et al. - The Multiverse Logical Modularity for Proof Assis.pdf:application/pdf},
}

@article{mosses_fundamental_2021,
	title = {Fundamental Constructs in Programming Languages},
	url = {http://arxiv.org/abs/2107.10545},
	abstract = {Specifying the semantics of a programming language formally can have many benefits. However, it can also require a huge effort. The effort can be significantly reduced by translating language syntax to so-called fundamental constructs (funcons). A translation to funcons is easy to update when the language evolves, and it exposes relationships between individual language constructs. The {PLanCompS} project has developed an initial collection of funcons (primarily for translation of functional and imperative languages). The behaviour of each funcon is defined, once and for all, using a modular variant of structural operational semantics. The definitions are available online. This paper introduces and motivates funcons. It illustrates translation of language constructs to funcons, and how funcons are defined. It also relates funcons to notation used in previous frameworks, including monadic semantics and action semantics.},
	journaltitle = {{arXiv}:2107.10545 [cs]},
	author = {Mosses, Peter D.},
	urldate = {2021-07-27},
	date = {2021-07-22},
	eprinttype = {arxiv},
	eprint = {2107.10545},
	keywords = {Computer Science - Programming Languages, D.3.3, F.3.2, D.3.1},
	file = {arXiv.org Snapshot:/home/fordrl/Zotero/storage/QBLZUANJ/2107.html:text/html;arXiv Fulltext PDF:/home/fordrl/Zotero/storage/69RG46MH/Mosses - 2021 - Fundamental Constructs in Programming Languages.pdf:application/pdf},
}

@article{chang_shape_2020,
	title = {Shape Analysis},
	volume = {6},
	issn = {2325-1107, 2325-1131},
	url = {http://www.nowpublishers.com/article/Details/PGL-037},
	doi = {10.1561/2500000037},
	pages = {1--158},
	number = {1},
	journaltitle = {Foundations and Trends® in Programming Languages},
	shortjournal = {{FNT} in Programming Languages},
	author = {Chang, Bor-Yuh Evan and Drăgoi, Cezara and Manevich, Roman and Rinetzky, Noam and Rival, Xavier},
	urldate = {2021-07-27},
	date = {2020},
	langid = {english},
	file = {Full Text:/home/fordrl/Zotero/storage/XKYJNYTM/Chang et al. - 2020 - Shape Analysis.pdf:application/pdf},
}

@article{chajed_gojournal_nodate,
	title = {{GoJournal}: a verified, concurrent, crash-safe journaling system},
	abstract = {The main contribution of this paper is {GoJournal}, a verified, concurrent journaling system that provides atomicity for storage applications, together with Perennial 2.0, a framework for formally specifying and verifying concurrent crash-safe systems. {GoJournal}’s goal is to bring the advantages of journaling for code to specs and proofs. Perennial 2.0 makes this possible by introducing several techniques to formalize {GoJournal}’s specification and to manage the complexity in the proof of {GoJournal}’s implementation. Lifting predicates and crash framing make the specification easy to use for developers, and logically atomic crash specifications allow for modular reasoning in {GoJournal}, making the proof tractable despite complex concurrency and crash interleavings.},
	pages = {17},
	author = {Chajed, Tej and Tassarotti, Joseph and Kaashoek, M Frans and Theng, Mark and Jung, Ralf and Zeldovich, Nickolai},
	langid = {english},
	file = {Chajed et al. - GoJournal a verified, concurrent, crash-safe jour.pdf:/home/fordrl/Zotero/storage/VWY8UZWX/Chajed et al. - GoJournal a verified, concurrent, crash-safe jour.pdf:application/pdf},
}

@inproceedings{moskal_programming_2009,
	location = {New York, {NY}, {USA}},
	title = {Programming with triggers},
	isbn = {978-1-60558-484-3},
	url = {https://doi.org/10.1145/1670412.1670416},
	doi = {10.1145/1670412.1670416},
	series = {{SMT} '09},
	abstract = {We give a case study for a Satisfiability Modulo Theories ({SMT}) solver usage in functional verification of a real world operating system. In particular, we present a view of the E-matching pattern annotations on quantified formulas as a kind of logic programming language, used to encode semantics of the programming language undergoing verification. We postulate a few encoding patterns to be benchmark problems for a possible E-matching alternative. We also describe features required from the {SMT} solver in deductive software verification scenarios.},
	pages = {20--29},
	booktitle = {Proceedings of the 7th International Workshop on Satisfiability Modulo Theories},
	publisher = {Association for Computing Machinery},
	author = {Moskal, Michał},
	urldate = {2021-07-27},
	date = {2009-08-02},
	keywords = {program verification, {SMT}, axiomatizations, e-matching, triggers},
	file = {Full Text PDF:/home/fordrl/Zotero/storage/E94JZXY9/Moskal - 2009 - Programming with triggers.pdf:application/pdf},
}

@article{parkinson_relationship_2012,
	title = {{THE} {RELATIONSHIP} {BETWEEN} {SEPARATION} {LOGIC} {AND} {IMPLICIT} {DYNAMIC} {FRAMES}},
	volume = {802},
	url = {https://lmcs.episciences.org/802},
	doi = {https://doi.org/10.2168/LMCS-8(3:1)2012},
	abstract = {Separation logic is a concise method for specifying programs that manipulate dynamically allocated storage. Partially inspired by separation logic, Implicit Dynamic Frames has recently been proposed, aiming at ﬁrst-order tool support. In this paper, we precisely connect the semantics of these two logics. We deﬁne a logic whose syntax subsumes both that of a standard separation logic, and that of implicit dynamic frames as sub-syntaxes. We deﬁne a total heap semantics for our logic, and, for the separation logic subsyntax, prove it equivalent the standard partial heaps model. In order to deﬁne a semantics which works uniformly for both subsyntaxes, we deﬁne the novel concept of a minimal state extension, which provides a diﬀerent (but equivalent) deﬁnition of the semantics of separation logic implication and magic wand connectives, while also giving a suitable semantics for these connectives in implicit dynamic frames. We show that our resulting semantics agrees with the existing deﬁnition of weakest pre-condition semantics for the implicit dynamic frames fragment. Finally, we show that we can encode the separation logic fragment of our logic into the implicit dynamic frames fragment, preserving semantics. For the connectives typically supported by tools, this shows that separation logic can be faithfully encoded in a ﬁrst-order automatic veriﬁcation tool (Chalice).},
	pages = {54},
	number = {3},
	journaltitle = {Logic Methods in Computer Science},
	shortjournal = {lmcs},
	author = {Parkinson, Matthew J and Summers, Alexander J},
	date = {2012-07-31},
	langid = {english},
	file = {Parkinson and Summers - THE RELATIONSHIP BETWEEN SEPARATION LOGIC AND IMPL.pdf:/home/fordrl/Zotero/storage/PN5WMPJ3/Parkinson and Summers - THE RELATIONSHIP BETWEEN SEPARATION LOGIC AND IMPL.pdf:application/pdf},
}

@article{bahr_monadic_nodate,
	title = {Monadic Compiler Calculation},
	pages = {27},
	author = {Bahr, Patrick and Hutton, Graham},
	langid = {english},
	file = {Bahr and Hutton - Monadic Compiler Calculation.pdf:/home/fordrl/Zotero/storage/U27NHT7K/Bahr and Hutton - Monadic Compiler Calculation.pdf:application/pdf},
}

@article{el-beheiry_smltocoq_2021,
	title = {{SMLtoCoq}: Automated Generation of Coq Specifications and Proof Obligations from {SML} Programs with Contracts},
	volume = {337},
	issn = {2075-2180},
	url = {http://arxiv.org/abs/2107.07664},
	doi = {10.4204/EPTCS.337.6},
	shorttitle = {{SMLtoCoq}},
	abstract = {Formally reasoning about functional programs is supposed to be straightforward and elegant, however, it is not typically done as a matter of course. Reasoning in a proof assistant requires "reimplementing" the code in those tools, which is far from trivial. {SMLtoCoq} provides an automatic translation of {SML} programs and function contracts into Coq. Programs are translated into Coq specifications, and function contracts into theorems, which can then be formally proved. Using the Equations plugin and other well established Coq libraries, {SMLtoCoq} is able to translate {SML} programs without side-effects containing partial functions, structures, functors, records, among others. Additionally, we provide a Coq version of many parts of {SML}'s basis library, so that calls to these libraries are kept almost as is.},
	pages = {71--87},
	journaltitle = {Electronic Proceedings in Theoretical Computer Science},
	shortjournal = {Electron. Proc. Theor. Comput. Sci.},
	author = {El-Beheiry, Laila and Reis, Giselle and Karkour, Ammar},
	urldate = {2021-07-26},
	date = {2021-07-14},
	eprinttype = {arxiv},
	eprint = {2107.07664},
	keywords = {Computer Science - Programming Languages, Computer Science - Logic in Computer Science, F.3.1},
	file = {arXiv.org Snapshot:/home/fordrl/Zotero/storage/2KDB3V9G/2107.html:text/html;arXiv Fulltext PDF:/home/fordrl/Zotero/storage/BBM8BEB7/El-Beheiry et al. - 2021 - SMLtoCoq Automated Generation of Coq Specificatio.pdf:application/pdf},
}

@article{franceschino_verified_2021,
	title = {Verified Functional Programming of an Abstract Interpreter},
	url = {http://arxiv.org/abs/2107.09472},
	abstract = {Abstract interpreters are complex pieces of software: even if the abstract interpretation theory and companion algorithms are well understood, their implementations are subject to bugs, that might question the soundness of their computations. While some formally verified abstract interpreters have been written in the past, writing and understanding them requires expertise in the use of proof assistants, and requires a non-trivial amount of interactive proofs. This paper presents a formally verified abstract interpreter fully programmed and proved correct in the F* verified programming environment. Thanks to F* refinement types and {SMT} prover capabilities we demonstrate a substantial saving in proof effort compared to previous works based on interactive proof assistants. Almost all the code of our implementation, proofs included, written in a functional style, are presented directly in the paper.},
	journaltitle = {{arXiv}:2107.09472 [cs]},
	author = {Franceschino, Lucas and Pichardie, David and Talpin, Jean-Pierre},
	urldate = {2021-07-26},
	date = {2021-07-20},
	eprinttype = {arxiv},
	eprint = {2107.09472},
	keywords = {Computer Science - Programming Languages},
	file = {arXiv.org Snapshot:/home/fordrl/Zotero/storage/H7YEDGBR/2107.html:text/html;arXiv Fulltext PDF:/home/fordrl/Zotero/storage/W94XPHVB/Franceschino et al. - 2021 - Verified Functional Programming of an Abstract Int.pdf:application/pdf},
}

@article{sozeau_touring_2021,
	title = {Touring the {MetaCoq} Project (Invited Paper)},
	volume = {337},
	issn = {2075-2180},
	url = {http://arxiv.org/abs/2107.07670},
	doi = {10.4204/EPTCS.337.2},
	abstract = {Proof assistants are getting more widespread use in research and industry to provide certified and independently checkable guarantees about theories, designs, systems and implementations. However, proof assistant implementations themselves are seldom verified, although they take a major share of the trusted code base in any such certification effort. In this area, proof assistants based on Higher-Order Logic enjoy stronger guarantees, as self-certified implementations have been available for some years. One cause of this difference is the inherent complexity of dependent type theories together with their extensions with inductive types, universe polymorphism and complex sort systems, and the gap between theory on paper and practical implementations in efficient programming languages. {MetaCoq} is a collaborative project that aims to tackle these difficulties to provide the first fully-certified realistic implementation of a type checker for the full calculus underlying the Coq proof assistant. To achieve this, we refined the sometimes blurry, if not incorrect, specification and implementation of the system. We show how theoretical tools from this community such as bidirectional type-checking, Tait-Martin-L{\textbackslash}"of/Takahashi's confluence proof technique and monadic and dependently-typed programming can help construct the following artefacts: a specification of Coq's syntax and type theory, the Polymorphic Cumulative Calculus of (Co)-Inductive Constructions ({PCUIC}); a monad for the manipulation of raw syntax and interaction with the Coq system; a verification of {PCUIC}'s metatheory, whose main results are the confluence of reduction, type preservation and principality of typing; a realistic, correct and complete type-checker for {PCUIC}; a sound type and proof erasure procedure from {PCUIC} to untyped lambda-calculus, i.e., the core of the extraction mechanism of Coq.},
	pages = {13--29},
	journaltitle = {Electronic Proceedings in Theoretical Computer Science},
	shortjournal = {Electron. Proc. Theor. Comput. Sci.},
	author = {Sozeau, Matthieu},
	urldate = {2021-07-26},
	date = {2021-07-14},
	eprinttype = {arxiv},
	eprint = {2107.07670},
	keywords = {Computer Science - Programming Languages, Computer Science - Logic in Computer Science},
	file = {arXiv.org Snapshot:/home/fordrl/Zotero/storage/K82JJZQX/2107.html:text/html;arXiv Fulltext PDF:/home/fordrl/Zotero/storage/N3S8GWUM/Sozeau - 2021 - Touring the MetaCoq Project (Invited Paper).pdf:application/pdf},
}

@article{bhargavan_dy_nodate,
	title = {{DY}* : A Modular Symbolic Veriﬁcation Framework for Executable Cryptographic Protocol Code},
	abstract = {We present {DY} , a new formal veriﬁcation framework for the symbolic security analysis of cryptographic protocol code written in the F programming language. Unlike automated symbolic provers, our framework accounts for advanced protocol features like unbounded loops and mutable recursive data structures, as well as low-level implementation details like protocol state machines and message formats, which are often at the root of real-world attacks. Our work extends a long line of research on using dependent type systems for this task, but takes a fundamentally new approach by explicitly modeling the global trace-based semantics within the framework, hence bridging the gap between trace-based and type-based protocol analyses. This approach enables us to uniformly, precisely, and soundly model, for the ﬁrst time using dependent types, long-lived mutable protocol state, equational theories, ﬁne-grained dynamic corruption, and trace-based security properties like forward secrecy and post-compromise security. {DY} is built as a library of F modules that includes a model of low-level protocol execution, a Dolev-Yao symbolic attacker, and generic security abstractions and lemmas, all veriﬁed using F . The library exposes a high-level {API} that facilitates succinct security proofs for protocol code. We demonstrate the effectiveness of this approach through a detailed symbolic security analysis of the Signal protocol that is based on an interoperable implementation of the protocol from prior work, and is the ﬁrst mechanized proof of Signal to account for forward and post-compromise security over an unbounded number of protocol rounds.},
	pages = {20},
	author = {Bhargavan, Karthikeyan and Bichhawat, Abhishek and Do, Quoc Huy and Hosseyni, Pedram and Küsters, Ralf and Schmitz, Guido and Würtele, Tim},
	langid = {english},
	file = {Bhargavan et al. - DY  A Modular Symbolic Veriﬁcation Framework for .pdf:/home/fordrl/Zotero/storage/8PRHW6YP/Bhargavan et al. - DY  A Modular Symbolic Veriﬁcation Framework for .pdf:application/pdf},
}

@article{rastogi_programming_nodate,
	title = {Programming and Proving with Indexed Effects},
	pages = {28},
	author = {Rastogi, Aseem},
	langid = {english},
	file = {Rastogi - Programming and Proving with Indexed Effects.pdf:/home/fordrl/Zotero/storage/AHEKEVVG/Rastogi - Programming and Proving with Indexed Effects.pdf:application/pdf},
}

@inproceedings{zhao_formal_2013,
	location = {New York, {NY}, {USA}},
	title = {Formal verification of {SSA}-based optimizations for {LLVM}},
	isbn = {978-1-4503-2014-6},
	url = {https://doi.org/10.1145/2491956.2462164},
	doi = {10.1145/2491956.2462164},
	series = {{PLDI} '13},
	abstract = {Modern compilers, such as {LLVM} and {GCC}, use a static single assignment({SSA}) intermediate representation ({IR}) to simplify and enable many advanced optimizations. However, formally verifying the correctness of {SSA}-based optimizations is challenging because {SSA} properties depend on a function's entire control-flow graph. This paper addresses this challenge by developing a proof technique for proving {SSA}-based program invariants and compiler optimizations. We use this technique in the Coq proof assistant to create mechanized correctness proofs of several "micro" transformations that form the building blocks for larger {SSA} optimizations. To demonstrate the utility of this approach, we formally verify a variant of {LLVM}'s mem2reg transformation in Vellvm, a Coq-based formal semantics of the {LLVM} {IR}. The extracted implementation generates code with performance comparable to that of {LLVM}'s unverified implementation.},
	pages = {175--186},
	booktitle = {Proceedings of the 34th {ACM} {SIGPLAN} Conference on Programming Language Design and Implementation},
	publisher = {Association for Computing Machinery},
	author = {Zhao, Jianzhou and Nagarakatte, Santosh and Martin, Milo M.K. and Zdancewic, Steve},
	urldate = {2021-07-21},
	date = {2013-06-16},
	keywords = {coq, llvm, single static assignment},
	file = {Full Text PDF:/home/fordrl/Zotero/storage/627G8XIV/Zhao et al. - 2013 - Formal verification of SSA-based optimizations for.pdf:application/pdf},
}

@article{jaiswal_unified_2021,
	title = {A Unified Model for Context-Sensitive Program Analyses: The Blind Men and the Elephant},
	volume = {54},
	issn = {0360-0300},
	url = {https://doi.org/10.1145/3456563},
	doi = {10.1145/3456563},
	shorttitle = {A Unified Model for Context-Sensitive Program Analyses},
	abstract = {Context-sensitive methods of program analysis increase the precision of interprocedural analysis by achieving the effect of call inlining. These methods have been defined using different formalisms and hence appear as algorithms that are very different from each other. Some methods traverse a call graph top-down, whereas some others traverse it bottom-up first and then top-down. Some define contexts explicitly, whereas some do not. Some of them directly compute data flow values, while some first compute summary functions and then use them to compute data flow values. Further, different methods place different kinds of restrictions on the data flow frameworks supported by them. As a consequence, it is difficult to compare the ideas behind these methods in spite of the fact that they solve essentially the same problem. We argue that these incomparable views are similar to those of blind men describing an elephant, called context sensitivity, and make it difficult for a non-expert reader to form a coherent picture of context-sensitive data flow analysis. We bring out this whole-elephant view of context sensitivity in program analysis by proposing a unified model of context sensitivity that provides a clean separation between computation of contexts and computation of data flow values. Our model captures the essence of context sensitivity and defines simple soundness and precision criteria for context-sensitive methods. It facilitates declarative specifications of context-sensitive methods, insightful comparisons between them, and reasoning about their soundness and precision. We demonstrate this by instantiating our model to many known context-sensitive methods.},
	pages = {114:1--114:37},
	number = {6},
	journaltitle = {{ACM} Computing Surveys},
	shortjournal = {{ACM} Comput. Surv.},
	author = {Jaiswal, Swati and Khedker, Uday P. and Mycroft, Alan},
	urldate = {2021-07-20},
	date = {2021-07-13},
	keywords = {context sensitivity, flow sensitivity, Interprocedural data flow analysis, interprocedurally valid paths},
	file = {Full Text PDF:/home/fordrl/Zotero/storage/GEPECFW6/Jaiswal et al. - 2021 - A Unified Model for Context-Sensitive Program Anal.pdf:application/pdf},
}

@article{loring_practical_nodate,
	title = {Practical Dynamic Symbolic Execution for {JavaScript}},
	pages = {222},
	author = {Loring, Blake William},
	langid = {english},
	file = {Loring - Practical Dynamic Symbolic Execution for JavaScrip.pdf:/home/fordrl/Zotero/storage/EELNACQK/Loring - Practical Dynamic Symbolic Execution for JavaScrip.pdf:application/pdf},
}

@article{saborido_verification_nodate,
	title = {Verification of linked data structures in Dafny},
	abstract = {Formal veri cation is gaining adoption in the parts of the software industry where full correctness of a system is needed. Dafny is a programming language with veri cation capabilities that allows the programmer to formally specify their code and have it veri ed by an underlying theorem prover. Veri cation in Dafny, however, is not always an easy task. The programmer must give a detailed description of the behavior of the program.},
	pages = {68},
	author = {Saborido, Jorge Blázquez},
	langid = {english},
	file = {Saborido - Verification of linked data structures in Dafny.pdf:/home/fordrl/Zotero/storage/EXD9U8UB/Saborido - Verification of linked data structures in Dafny.pdf:application/pdf},
}

@article{li_deriving_nodate,
	title = {Deriving Efficient Program Transformations from Rewrite Rules},
	volume = {5},
	pages = {29},
	author = {Li, John M and Appel, Andrew W},
	langid = {english},
	file = {Li and Appel - Deriving Efficient Program Transformations from Re.pdf:/home/fordrl/Zotero/storage/7G676C8Q/Li and Appel - Deriving Efficient Program Transformations from Re.pdf:application/pdf},
}

@article{paraskevopoulou_compositional_nodate,
	title = {Compositional Optimizations for {CertiCoq}},
	volume = {5},
	pages = {30},
	author = {Paraskevopoulou, Zoe and Li, John M and Appel, Andrew W},
	langid = {english},
	file = {Paraskevopoulou et al. - Compositional Optimizations for CertiCoq.pdf:/home/fordrl/Zotero/storage/BXUT6QY9/Paraskevopoulou et al. - Compositional Optimizations for CertiCoq.pdf:application/pdf},
}

@online{noauthor_ieee_nodate-3,
	title = {{IEEE} Xplore Full-Text {PDF}:},
	url = {https://ieeexplore-ieee-org.rsic.army.mil:3443/stamp/stamp.jsp?tp=&arnumber=9470541&tag=1},
	urldate = {2021-07-16},
	file = {IEEE Xplore Full-Text PDF\::/home/fordrl/Zotero/storage/HFNMMUXC/stamp.html:text/html},
}

@article{monteiro_model_2021,
	title = {Model Checking C++ Programs},
	url = {http://arxiv.org/abs/2107.01093},
	abstract = {In the last three decades, memory safety issues in system programming languages such as C or C++ have been one of the significant sources of security vulnerabilities. However, there exist only a few attempts with limited success to cope with the complexity of C++ program verification. Here we describe and evaluate a novel verification approach based on bounded model checking ({BMC}) and satisfiability modulo theories ({SMT}) to verify C++ programs formally. Our verification approach analyzes bounded C++ programs by encoding into {SMT} various sophisticated features that the C++ programming language offers, such as templates, inheritance, polymorphism, exception handling, and the Standard C++ Libraries. We formalize these features within our formal verification framework using a decidable fragment of first-order logic and then show how state-of-the-art {SMT} solvers can efficiently handle that. We implemented our verification approach on top of {ESBMC}. We compare {ESBMC} to {LLBMC} and {DIVINE}, which are state-of-the-art verifiers to check C++ programs directly from the {LLVM} bitcode. Experimental results show that {ESBMC} can handle a wide range of C++ programs, presenting a higher number of correct verification results. At the same time, it reduces the verification time if compared to {LLBMC} and {DIVINE} tools. Additionally, {ESBMC} has been applied to a commercial C++ application in the telecommunication domain and successfully detected arithmetic overflow errors, potentially leading to security vulnerabilities.},
	journaltitle = {{arXiv}:2107.01093 [cs]},
	author = {Monteiro, Felipe R. and Gadelha, Mikhail R. and Cordeiro, Lucas C.},
	urldate = {2021-07-09},
	date = {2021-07-02},
	eprinttype = {arxiv},
	eprint = {2107.01093},
	keywords = {Computer Science - Software Engineering},
	file = {arXiv.org Snapshot:/home/fordrl/Zotero/storage/BMV6H375/2107.html:text/html;arXiv Fulltext PDF:/home/fordrl/Zotero/storage/VS78XNAC/Monteiro et al. - 2021 - Model Checking C++ Programs.pdf:application/pdf},
}

@article{watanabe_certifying_nodate,
	title = {Certifying the Synthesis of Heap-Manipulating Programs},
	volume = {5},
	pages = {29},
	author = {Watanabe, Yasunari and College, Yale-{NUS} and Gopinathan, Kiran and Pîrlea, George and Polikarpova, Nadia and Sergey, Ilya and College, Yale-{NUS}},
	langid = {english},
	file = {Watanabe et al. - Certifying the Synthesis of Heap-Manipulating Prog.pdf:/home/fordrl/Zotero/storage/AWHTXGKD/Watanabe et al. - Certifying the Synthesis of Heap-Manipulating Prog.pdf:application/pdf},
}

@article{tondwalkar_refinements_2021,
	title = {Refinements of Futures Past: Higher-Order Specification with Implicit Refinement Types (Extended Version)},
	url = {http://arxiv.org/abs/2105.01954},
	shorttitle = {Refinements of Futures Past},
	abstract = {Refinement types decorate types with assertions that enable automatic verification. Like assertions, refinements are limited to binders that are in scope, and hence, cannot express higher-order specifications. Ghost variables circumvent this limitation but are prohibitively tedious to use as the programmer must divine and explicate their values at all call-sites. We introduce Implicit Refinement Types which turn ghost variables into implicit pair and function types, in a way that lets the refinement typechecker automatically synthesize their values at compile time. Implicit Refinement Types further take advantage of refinement type information, allowing them to be used as a lightweight verification tool, rather than merely as a technique to automate programming tasks. We evaluate the utility of Implicit Refinement Types by showing how they enable the modular specification and automatic verification of various higher-order examples including stateful protocols, access control, and resource usage.},
	journaltitle = {{arXiv}:2105.01954 [cs]},
	author = {Tondwalkar, Anish and Kolosick, Matthew and Jhala, Ranjit},
	urldate = {2021-07-09},
	date = {2021-05-05},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {2105.01954},
	keywords = {Computer Science - Programming Languages, F.3.1, F.3.3},
	file = {Tondwalkar et al. - 2021 - Refinements of Futures Past Higher-Order Specific.pdf:/home/fordrl/Zotero/storage/UFZHNKFJ/Tondwalkar et al. - 2021 - Refinements of Futures Past Higher-Order Specific.pdf:application/pdf},
}

@inproceedings{knuppel_how_2021,
	title = {How much Specification is Enough? Mutation Analysis for Software Contracts},
	doi = {10.1109/FormaliSE52586.2021.00011},
	shorttitle = {How much Specification is Enough?},
	abstract = {Design-by-contract is a light-weight formal development paradigm, in which object-oriented software is specified with so-called software contracts. Contracts are annotations in the source code that explicitly document intended functional behavior and can be used for verifying correctness of a particular implementation or as test oracles during automatic test case generation. As writing strong specifications is an expensive and error-prone activity due to lack of expertise and tool support, developers are often only willing to write simpler specifications, covering only a fraction of all functional properties. As a consequence, software quality is lowered, or even worse, potential bugs remain undetected during software verification. To give developers a sense of specification coverage, we propose a methodology that considers the degree of incomplete specifications by means of mutation analysis. We consider Java programs annotated with {JML} and employ the deductive program verifier {KEY}-2.6.3 to show that this approach is applicable to numerous open-source {JML} projects from the literature.},
	eventtitle = {2021 {IEEE}/{ACM} 9th International Conference on Formal Methods in Software Engineering ({FormaliSE})},
	pages = {42--53},
	booktitle = {2021 {IEEE}/{ACM} 9th International Conference on Formal Methods in Software Engineering ({FormaliSE})},
	author = {Knüppel, Alexander and Schaer, Leon and Schaefer, Ina},
	date = {2021-05},
	note = {{ISSN}: 2575-5099},
	keywords = {Writing, Java, Tools, Software quality, Computer bugs, Annotations, Design by Contract, Measurement, Mutation Analysis, Software Quality Metrics},
	file = {Knüppel et al. - 2021 - How much Specification is Enough Mutation Analysi.pdf:/home/fordrl/Zotero/storage/FSWUXF39/Knüppel et al. - 2021 - How much Specification is Enough Mutation Analysi.pdf:application/pdf;IEEE Xplore Abstract Record:/home/fordrl/Zotero/storage/C59UREBH/9460939.html:text/html},
}

@article{wolff_modular_nodate,
	title = {Modular Specification and Verification of Closures in Rust},
	abstract = {Closures are a language feature supported by many mainstream languages, combining the ability to package up references to code blocks with the possibility of capturing state from the environment of the closure’s declaration. Closures are powerful, but complicate understanding and formal reasoning, especially when closure invocations may mutate objects reachable from the captured state or from closure arguments. This paper presents a novel technique for the modular specification and verification of closure-manipulating code in Rust. Our technique combines Rust’s type system guarantees and novel specification features to enable formal verification of rich functional properties. It encodes higher-order concerns into a first-order logic, which enables automation via {SMT} solvers. Our technique is implemented as an extension of the deductive verifier Prusti, with which we have successfully verified many common idioms of closure usage.},
	pages = {27},
	author = {Wolff, Fabian},
	langid = {english},
	file = {Wolff - Modular Specification and Verification of Closures.pdf:/home/fordrl/Zotero/storage/7VBKU6MP/Wolff - Modular Specification and Verification of Closures.pdf:application/pdf},
}

@article{myreen_cakeml_2021,
	title = {The {CakeML} Project's Quest for Ever Stronger Correctness Theorems},
	abstract = {The {CakeML} project has developed a proof-producing code generation mechanism for the {HOL}4 theorem prover, a verified compiler for {ML} and, using these, a number of verified application programs that are proved correct down to the machine code that runs them (in some cases, even down to the underlying hardware). The purpose of this extended abstract is to tell the story of the project and to point curious readers to publications where they can read more about specific contributions.},
	pages = {10},
	author = {Myreen, Magnus O},
	date = {2021},
	langid = {english},
	file = {Myreen - 2021 - The CakeML Project's Quest for Ever Stronger Corre.pdf:/home/fordrl/Zotero/storage/J4EMXKX2/Myreen - 2021 - The CakeML Project's Quest for Ever Stronger Corre.pdf:application/pdf},
}

@article{zhang_verifying_2021,
	title = {Verifying an {HTTP} Key-Value Server with Interaction Trees and {VST}},
	abstract = {We present a networked key-value server, implemented in C and formally verified in Coq. The server interacts with clients using a subset of the {HTTP}/1.1 protocol and is specified and verified using interaction trees and the Verified Software Toolchain. The codebase includes a reusable and fully verified C string library that provides 17 standard {POSIX} string functions and 17 general purpose non-{POSIX} string functions. For the {KVServer} socket system calls, we establish a refinement relation between specifications at user-space level and at {CertiKOS} kernel-space level.},
	pages = {19},
	author = {Zhang, Hengchu and Koh, Nicolas and Li, Yishuai and Beringer, Lennart and Pierce, Benjamin and Honoré, Wolf and Li, Yao and Xia, Li-Yao and Mansky, William and Zdancewic, Steve},
	date = {2021},
	langid = {english},
	file = {Zhang et al. - 2021 - Verifying an HTTP Key-Value Server with Interactio.pdf:/home/fordrl/Zotero/storage/VV4U8EBP/Zhang et al. - 2021 - Verifying an HTTP Key-Value Server with Interactio.pdf:application/pdf},
}

@inproceedings{polikarpova_synthesis_2021,
	location = {Dagstuhl, Germany},
	title = {Synthesis of Safe Pointer-Manipulating Programs},
	volume = {193},
	isbn = {978-3-95977-188-7},
	url = {https://drops.dagstuhl.de/opus/volltexte/2021/13897},
	doi = {10.4230/LIPIcs.ITP.2021.2},
	series = {Leibniz International Proceedings in Informatics ({LIPIcs})},
	pages = {2:1--2:1},
	booktitle = {12th International Conference on Interactive Theorem Proving ({ITP} 2021)},
	publisher = {Schloss Dagstuhl – Leibniz-Zentrum für Informatik},
	author = {Polikarpova, Nadia},
	editor = {Cohen, Liron and Kaliszyk, Cezary},
	urldate = {2021-06-22},
	date = {2021},
	note = {{ISSN}: 1868-8969},
	keywords = {Program Synthesis, Separation Logic, Proof Search},
	file = {Snapshot:/home/fordrl/Zotero/storage/YAVMKSIS/13897.html:text/html;Full Text PDF:/home/fordrl/Zotero/storage/YVZBZ7TA/Polikarpova - 2021 - Synthesis of Safe Pointer-Manipulating Programs.pdf:application/pdf},
}

@article{barras_sets_2010,
	title = {Sets in Coq, Coq in Sets},
	volume = {3},
	rights = {Copyright (c) 2010 Bruno Barras},
	issn = {1972-5787},
	url = {https://jfr.unibo.it/article/view/1695},
	doi = {10.6092/issn.1972-5787/1695},
	pages = {29--48},
	number = {1},
	journaltitle = {Journal of Formalized Reasoning},
	shortjournal = {{JFR}},
	author = {Barras, Bruno},
	urldate = {2021-06-22},
	date = {2010-10-06},
	langid = {english},
	note = {Number: 1},
	file = {Snapshot:/home/fordrl/Zotero/storage/IHM39V8J/1695.html:text/html;Full Text PDF:/home/fordrl/Zotero/storage/NKEN4W26/Barras - 2010 - Sets in Coq, Coq in Sets.pdf:application/pdf},
}

@article{haslbeck_for_nodate,
	title = {For a Few Dollars More: Verified Fine-Grained Algorithm Analysis Down to {LLVM}},
	volume = {37},
	abstract = {{MAXIMILIAN} P. L. {HASLBECK}, Technische Universität München, Germany {PETER} {LAMMICH}, University of Twente, Netherlands We present a framework to verify both, functional correctness and (amortized) worst-case complexity of practically efficient algorithms. We implemented a stepwise refinement approach, using the novel concept of resource currencies to naturally structure the resource analysis along the refinement chain, and allow a fine-grained analysis of operation counts. Our framework targets the {LLVM} intermediate representation. We extend its semantics from earlier work with a cost model. As case studies, we verify the amortized constant time push operation on dynamic arrays and the O(n log n) introsort algorithm, and refine them down to efficient {LLVM} implementations. Our sorting algorithm performs on par with the state-of-the-art implementation found in the {GNU} C++ Library, and provably satisfies the complexity required by the C++ standard. {CCS} Concepts: • Theory of computation → Logic and verification; Separation logic; Program semantics; Program verification.},
	pages = {35},
	number = {4},
	journaltitle = {J. {ACM}},
	author = {Haslbeck, Maximilian P L and Lammich, Peter},
	langid = {english},
	file = {Haslbeck and Lammich - For a Few Dollars More Verified Fine-Grained Algo.pdf:/home/fordrl/Zotero/storage/GPBKKLCX/Haslbeck and Lammich - For a Few Dollars More Verified Fine-Grained Algo.pdf:application/pdf},
}

@article{chen_homotopy_2021,
	title = {Homotopy Type Theory in Isabelle},
	url = {http://arxiv.org/abs/2002.09282},
	abstract = {This paper introduces Isabelle/{HoTT}, the first development of homotopy type theory in the Isabelle proof assistant. Building on earlier work by Paulson, I use Isabelle's existing logical framework infrastructure to implement essential automation, such as type checking and term elaboration, that is usually handled on the source code level of dependently typed systems. I also integrate the propositions-as-types paradigm with the declarative Isar proof language, providing an alternative to the tactic-based proofs of Coq and the proof terms of Agda. The infrastructure developed is then used to formalize foundational results from the Homotopy Type Theory book.},
	journaltitle = {{arXiv}:2002.09282 [cs]},
	author = {Chen, Joshua},
	urldate = {2021-04-25},
	date = {2021-04-19},
	eprinttype = {arxiv},
	eprint = {2002.09282},
	keywords = {Computer Science - Logic in Computer Science},
	file = {arXiv.org Snapshot:/home/fordrl/Zotero/storage/9RE5MCN8/2002.html:text/html;arXiv Fulltext PDF:/home/fordrl/Zotero/storage/BTM8LQJ7/Chen - 2021 - Homotopy Type Theory in Isabelle.pdf:application/pdf},
}

@article{smolka_modeling_nodate,
	title = {Modeling and Proving in Computational Type Theory Using the Coq Proof Assistant},
	pages = {338},
	author = {Smolka, Gert},
	langid = {english},
	file = {Smolka - Modeling and Proving in Computational Type Theory .pdf:/home/fordrl/Zotero/storage/S4XAJ3EM/Smolka - Modeling and Proving in Computational Type Theory .pdf:application/pdf},
}

@article{koenig_compcerto_2021,
	title = {{CompCertO}: Compiling Certified Open C Components},
	abstract = {Since the introduction of {CompCert}, researchers have been refining its language semantics and correctness theorem, and used them as components in software verification efforts. Meanwhile, artifacts ranging from {CPU} designs to network protocols have been successfully verified, and there is interest in making them interoperable to tackle end-to-end verification at an even larger scale. Recent work shows that a synthesis of game semantics, refinement-based methods, and abstraction layers has the potential to serve as a common theory of certified components. Integrating certified compilers to such a theory is a critical goal. However, none of the existing variants of {CompCert} meets the requirements we have identified for this task.},
	pages = {15},
	author = {Koenig, Jérémie and Shao, Zhong},
	date = {2021},
	langid = {english},
	file = {Koenig and Shao - 2021 - CompCertO Compiling Certified Open C Components.pdf:/home/fordrl/Zotero/storage/RE2MH5SM/Koenig and Shao - 2021 - CompCertO Compiling Certified Open C Components.pdf:application/pdf},
}

@article{arasu_fastver_nodate,
	title = {{FastVer}: Making Data Integrity a Commodity},
	abstract = {We present {FastVer}, a high-performance key-value store with strong data integrity guarantees. {FastVer} is built as an extension of {FASTER}, an open-source, high-performance key-value store. It offers the same key-value {API} as {FASTER} plus an additional verify() method that detects if an unauthorized attacker tampered with the database and checks whether results of all read operations are consistent with historical updates. {FastVer} is based on a novel approach that combines the advantages of Merkle trees and deferred memory verification. We show that this approach achieves one to two orders of magnitudes higher throughputs than traditional approaches based on either Merkle trees or memory verification. We have formally proven the correctness of our approach in a proof assistant, ensuring that verify() detects any inconsistencies, except if a collision can be found on a cryptographic hash.},
	pages = {13},
	author = {Arasu, Arvind and Chandramouli, Badrish and Gehrke, Johannes and Ghosh, Esha and Kossmann, Donald and Protzenko, Jonathan and Ramamurthy, Ravi and Ramananandro, Tahina and Rastogi, Aseem and Setty, Srinath and Swamy, Nikhil},
	langid = {english},
	file = {Arasu et al. - FastVer Making Data Integrity a Commodity.pdf:/home/fordrl/Zotero/storage/LG5QJZFN/Arasu et al. - FastVer Making Data Integrity a Commodity.pdf:application/pdf},
}

@article{li_secure_nodate,
	title = {A Secure and Formally Verified Linux {KVM} Hypervisor},
	abstract = {Commodity hypervisors are widely deployed to support virtual machines ({VMs}) on multiprocessor hardware. Their growing complexity poses a security risk. To enable formal verification over such a large codebase, we introduce microverification, a new approach that decomposes a commodity hypervisor into a small core and a set of untrusted services so that we can prove security properties of the entire hypervisor by verifying the core alone. To verify the multiprocessor hypervisor core, we introduce security-preserving layers to modularize the proof without hiding information leakage so we can prove each layer of the implementation refines its specification, and the top layer specification is refined by all layers of the core implementation. To verify commodity hypervisor features that require dynamically changing information flow, we introduce data oracles to mask intentional information flow. We can then prove noninterference at the top layer specification and guarantee the resulting security properties hold for the entire hypervisor implementation. Using microverification, we retrofitted the Linux {KVM} hypervisor with only modest modifications to its codebase. Using Coq, we proved that the hypervisor protects the confidentiality and integrity of {VM} data, while retaining {KVM}’s functionality and performance. Our work is the first machinechecked security proof for a commodity multiprocessor hypervisor.},
	pages = {18},
	author = {Li, Shih-Wei and Li, Xupeng and Gu, Ronghui and Nieh, Jason and Hui, John Zhuang},
	langid = {english},
	file = {Li et al. - A Secure and Formally Verified Linux KVM Hyperviso.pdf:/home/fordrl/Zotero/storage/2QDS98L2/Li et al. - A Secure and Formally Verified Linux KVM Hyperviso.pdf:application/pdf},
}

@article{fromherz_steel_nodate,
	title = {Steel: Proof-oriented Programming in a Dependently Typed Concurrent Separation Logic},
	volume = {1},
	pages = {27},
	number = {1},
	author = {Fromherz, Aymeric and Rastogi, Aseem and Swamy, Nikhil and Gibson, Sydney and Martínez, Guido and Merigoux, Denis and Ramananandro, Tahina},
	langid = {english},
	file = {Fromherz et al. - Steel Proof-oriented Programming in a Dependently.pdf:/home/fordrl/Zotero/storage/4S2FBGIH/Fromherz et al. - Steel Proof-oriented Programming in a Dependently.pdf:application/pdf},
}

@article{bourgeat_multipurpose_2021,
	title = {A Multipurpose Formal {RISC}-V Specification},
	url = {http://arxiv.org/abs/2104.00762},
	abstract = {{RISC}-V is a relatively new, open instruction set architecture with a mature ecosystem and an official formal machine-readable specification. It is therefore a promising playground for formal-methods research. However, we observe that different formal-methods research projects are interested in different aspects of {RISC}-V and want to simplify, abstract, approximate, or ignore the other aspects. Often, they also require different encoding styles, resulting in each project starting a new formalization from-scratch. We set out to identify the commonalities between projects and to represent the {RISC}-V specification as a program with holes that can be instantiated differently by different projects. Our formalization of the {RISC}-V specification is written in Haskell and leverages existing tools rather than requiring new domain-specific tools, contrary to other approaches. To our knowledge, it is the first {RISC}-V specification able to serve as the interface between a processor-correctness proof and a compiler-correctness proof, while supporting several other projects with diverging requirements as well.},
	journaltitle = {{arXiv}:2104.00762 [cs]},
	author = {Bourgeat, Thomas and Clester, Ian and Erbsen, Andres and Gruetter, Samuel and Wright, Andrew and Chlipala, Adam},
	urldate = {2021-04-11},
	date = {2021-04-01},
	eprinttype = {arxiv},
	eprint = {2104.00762},
	keywords = {Computer Science - Logic in Computer Science},
	file = {arXiv.org Snapshot:/home/fordrl/Zotero/storage/YCN9GPRK/2104.html:text/html;arXiv Fulltext PDF:/home/fordrl/Zotero/storage/U45ME8BC/Bourgeat et al. - 2021 - A Multipurpose Formal RISC-V Specification.pdf:application/pdf},
}

@article{bhargavan_dy_nodate-1,
	title = {{DY}*: A Modular Symbolic Verification Framework for Executable Cryptographic Protocol Code},
	abstract = {We present {DY} , a new formal veriﬁcation framework for the symbolic security analysis of cryptographic protocol code written in the F programming language. Unlike automated symbolic provers, our framework accounts for advanced protocol features like unbounded loops and mutable recursive data structures, as well as low-level implementation details like protocol state machines and message formats, which are often at the root of real-world attacks. Our work extends a long line of research on using dependent type systems for this task, but takes a fundamentally new approach by explicitly modeling the global trace-based semantics within the framework, hence bridging the gap between trace-based and type-based protocol analyses. This approach enables us to uniformly, precisely, and soundly model, for the ﬁrst time using dependent types, long-lived mutable protocol state, equational theories, ﬁne-grained dynamic corruption, and trace-based security properties like forward secrecy and post-compromise security. {DY} is built as a library of F modules that includes a model of low-level protocol execution, a Dolev-Yao symbolic attacker, and generic security abstractions and lemmas, all veriﬁed using F . The library exposes a high-level {API} that facilitates succinct security proofs for protocol code. We demonstrate the effectiveness of this approach through a detailed symbolic security analysis of the Signal protocol that is based on an interoperable implementation of the protocol from prior work, and is the ﬁrst mechanized proof of Signal to account for forward and post-compromise security over an unbounded number of protocol rounds.},
	pages = {21},
	author = {Bhargavan, Karthikeyan and Bichhawat, Abhishek and Do, Quoc and Hosseyni, Pedram and Küsters, Ralf and Schmitz, Guido and Würtele, Tim},
	langid = {english},
	file = {Bhargavan et al. - DY A Modular Symbolic Verification Framework for.pdf:/home/fordrl/Zotero/storage/RITHPHJ2/Bhargavan et al. - DY A Modular Symbolic Verification Framework for.pdf:application/pdf},
}

@article{jung_safe_2021,
	title = {Safe systems programming in Rust},
	volume = {64},
	issn = {0001-0782, 1557-7317},
	url = {https://dl.acm.org/doi/10.1145/3418295},
	doi = {10.1145/3418295},
	abstract = {In order to obtain safety, the Rust type system enforces the discipline that a reference is never both aliased and mutable. Having a value of type T means you “own” it fully. The value of type T can be “borrowed” using a mutable reference (\&mut T) or shared reference (\&T).},
	pages = {144--152},
	number = {4},
	journaltitle = {Communications of the {ACM}},
	shortjournal = {Commun. {ACM}},
	author = {Jung, Ralf and Jourdan, Jacques-Henri and Krebbers, Robbert and Dreyer, Derek},
	urldate = {2021-03-31},
	date = {2021-04},
	langid = {english},
	file = {Jung et al. - 2021 - Safe systems programming in Rust.pdf:/home/fordrl/Zotero/storage/JFXMTZFP/Jung et al. - 2021 - Safe systems programming in Rust.pdf:application/pdf},
}

@article{merigoux_hacspec_nodate,
	title = {Hacspec: succinct, executable, verifiable specifications for high-assurance cryptography embedded in Rust},
	abstract = {Despite signiﬁcant progress in the formal veriﬁcation of security-critical components like cryptographic libraries and protocols, the secure integration of these components into larger unveriﬁed applications remains an open challenge. The ﬁrst problem is that any memory safety bug or side-channel leak in the unveriﬁed code can nullify the security guarantees of the veriﬁed code. A second issue is that application developers may misunderstand the speciﬁcation and assumptions of the veriﬁed code and so use it incorrectly. In this paper, we propose a novel veriﬁcation framework that seeks to close these gaps for applications written in Rust. At the heart of this framework is hacspec, a new language for writing succinct, executable, formal speciﬁcations for cryptographic components. Syntactically, hacspec is a purely functional subset of Rust that aims to be readable by developers, cryptographers, and veriﬁcation experts. An application developer can use hacspec to specify and prototype cryptographic components in Rust, and then replace this speciﬁcation with a veriﬁed implementation before deployment. We present the hacspec language, its formal semantics and type system, and describe a translation from hacspec to F . We evaluate the language and its toolchain on a library of popular cryptographic algorithms.},
	pages = {17},
	author = {Merigoux, Denis and Kiefer, Franziskus and Bhargavan, Karthikeyan},
	langid = {english},
	file = {Merigoux et al. - Hacspec succinct, executable, verifiable specific.pdf:/home/fordrl/Zotero/storage/7YH2MZMV/Merigoux et al. - Hacspec succinct, executable, verifiable specific.pdf:application/pdf},
}

@article{derakhshan_session_nodate,
	title = {Session Logical Relations for Noninterference},
	abstract = {Information ﬂow control type systems statically restrict the propagation of sensitive data to ensure end-toend conﬁdentiality. The property to be shown in particular is noninterference, asserting that an attacker cannot infer any secrets from made observations. Session types delimit the kinds of observations that can be made along a communication channel by imposing a protocol of message exchange. These protocols govern the exchange along a single channel and thus leave unconstrained the propagation along adjacent channels. This paper contributes an information ﬂow control type system for linear session types. The type system stands in close correspondence with intuitionistic linear logic. Intuitionistic linear logic typing not only ensures that process conﬁgurations are acyclic but also form a tree such that client processes are parent nodes and provider processes child nodes. To control the propagation of secret messages, the type system is enriched with secrecy levels and arranges these levels to be aligned with the conﬁguration tree. Two levels are associated with every process: the maximal secrecy denoting the process’ security clearance and the running secrecy denoting the highest level of secret information obtained so far. The computational semantics naturally stratiﬁes process conﬁgurations such that higher-secrecy processes are parents of lower-secrecy ones. This invariant is enforced by conﬁguration typing. Noninterference is then stated in terms of a logical relation that is indexed by the secrecy-level-enriched session types. The logical relation contributes a novel development of logical relations for session typed languages as it considers open conﬁgurations, allowing for any closing substitutions as long as they are related by the logical relation.},
	pages = {31},
	author = {Derakhshan, Farzaneh and Balzer, Stephanie and Jia, Limin},
	langid = {english},
	file = {Derakhshan et al. - Session Logical Relations for Noninterference.pdf:/home/fordrl/Zotero/storage/8WJK7CTU/Derakhshan et al. - Session Logical Relations for Noninterference.pdf:application/pdf},
}

@article{hance_finding_nodate,
	title = {Finding Invariants of Distributed Systems: It’s a Small (Enough) World After All},
	abstract = {Today’s distributed systems are increasingly complex, leading to subtle bugs that are difﬁcult to detect with standard testing methods. Formal veriﬁcation can provably rule out such bugs, but historically it has been excessively labor intensive. For distributed systems, recent work shows that, given a correct inductive invariant, nearly all other proof work can be automated; however, the construction of such invariants is still a difﬁcult manual task. In this paper, we demonstrate a new methodology for automating the construction of inductive invariants, given as input a (formal) description of the distributed system and a desired safety condition. Our system performs an exhaustive search within a given space of candidate invariants in order to ﬁnd and verify inductive invariants which sufﬁce to prove the safety condition. Central to our ability to search efﬁciently is our algorithm’s ability to learn from counterexamples whenever a candidate fails to be invariant, allowing us to check the remaining candidates more efﬁciently. We hypothesize that many distributed systems, even complex ones, may have concise invariants that make this approach practical, and in support of this, we show that our system is able to identify and verify inductive invariants for the Paxos protocol, which proved too complex for previous work.},
	pages = {17},
	author = {Hance, Travis and Heule, Marijn and Martins, Ruben and Parno, Bryan},
	langid = {english},
	file = {Hance et al. - Finding Invariants of Distributed Systems It’s a .pdf:/home/fordrl/Zotero/storage/BRXWJT5N/Hance et al. - Finding Invariants of Distributed Systems It’s a .pdf:application/pdf},
}

@article{gauhar_formal_2021,
	title = {Formal verification of Matrix based {MATLAB} models using interactive theorem proving},
	volume = {7},
	issn = {2376-5992},
	url = {https://peerj.com/articles/cs-440},
	doi = {10.7717/peerj-cs.440},
	abstract = {{MATLAB} is a software based analysis environment that supports a high-level programing language and is widely used to model and analyze systems in various domains of engineering and sciences. Traditionally, the analysis of {MATLAB} models is done using simulation and debugging/testing frameworks. These methods provide limited coverage due to their inherent incompleteness. Formal verification can overcome these limitations, but developing the formal models of the underlying {MATLAB} models is a very challenging and time-consuming task, especially in the case of higher-order-logic models. To facilitate this process, we present a library of higher-order-logic functions corresponding to the commonly used matrix functions of {MATLAB} as well as a translator that allows automatic conversion of {MATLAB} models to higher-order logic. The formal models can then be formally verified in an interactive theorem prover. For illustrating the usefulness of the proposed library and approach, we present the formal analysis of a Finite Impulse Response ({FIR}) filter, which is quite commonly used in digital signal processing applications, within the sound core of the {HOL} Light theorem prover.},
	pages = {e440},
	journaltitle = {{PeerJ} Computer Science},
	shortjournal = {{PeerJ} Comput. Sci.},
	author = {Gauhar, Ayesha and Rashid, Adnan and Hasan, Osman and Bispo, João and Cardoso, João M. P.},
	urldate = {2021-03-31},
	date = {2021-03-22},
	langid = {english},
	note = {Publisher: {PeerJ} Inc.},
	file = {Full Text PDF:/home/fordrl/Zotero/storage/RBKX395W/Gauhar et al. - 2021 - Formal verification of Matrix based MATLAB models .pdf:application/pdf},
}

@article{li_reasoning_2021,
	title = {Reasoning about the garden of forking paths},
	url = {http://arxiv.org/abs/2103.07543},
	abstract = {Lazy evaluation is a powerful tool for functional programmers. It enables the concise expression of on-demand computation and a form of compositionality not available under other evaluation strategies. However, the stateful nature of lazy evaluation makes it hard to analyze a program's computational cost, either informally or formally. In this work, we present a novel and simple framework for formally reasoning about lazy computation costs based on a recent model of lazy evaluation: clairvoyant call-by-value. The key feature of our framework is its simplicity, as expressed by our definition of the clairvoyance monad. This monad is both simple to define (around 20 lines of Coq) and simple to reason about. We show that this monad can be effectively used to mechanically reason about the computational cost of lazy functional programs written in Coq.},
	journaltitle = {{arXiv}:2103.07543 [cs]},
	author = {Li, Yao and Xia, Li-yao and Weirich, Stephanie},
	urldate = {2021-03-22},
	date = {2021-03-12},
	eprinttype = {arxiv},
	eprint = {2103.07543},
	keywords = {Computer Science - Programming Languages},
	file = {arXiv.org Snapshot:/home/fordrl/Zotero/storage/JYIN6H77/2103.html:text/html;arXiv Fulltext PDF:/home/fordrl/Zotero/storage/GTZV85IS/Li et al. - 2021 - Reasoning about the garden of forking paths.pdf:application/pdf},
}

@article{schmid_proving_2021,
	title = {Proving and Disproving Programs with Shared Mutable Data},
	url = {http://arxiv.org/abs/2103.07699},
	abstract = {We present a tool for verification of deterministic programs with shared mutable references against specifications such as assertions, preconditions, postconditions, and read/write effects. We implement our tool by encoding programs with mutable references into annotated purely functional recursive programs. We then rely on function unfolding and the {SMT} solver Z3 to prove or disprove safety and to establish program termination. Our tool uses a new translation of programs where frame conditions are encoded using quantifier-free formulas in first-order logic (instead of relying on quantifiers or separation logic). This quantifier-free encoding enables {SMT} solvers to prove safety or report counterexamples relative to the semantics of procedure specifications. Our encoding is possible thanks to the expressive power of the extended array theory of the Z3 {SMT} solver. In addition to the ability to report counterexamples, our tool retains efficiency of reasoning about purely functional layers of data structures, providing expressiveness for mutable data but also a significant level of automation for purely functional aspects of software. We illustrate our tool through examples manipulating mutable linked structures and arrays.},
	journaltitle = {{arXiv}:2103.07699 [cs]},
	author = {Schmid, Georg and Kunčak, Viktor},
	urldate = {2021-03-22},
	date = {2021-03-13},
	eprinttype = {arxiv},
	eprint = {2103.07699},
	keywords = {Computer Science - Logic in Computer Science},
	file = {arXiv.org Snapshot:/home/fordrl/Zotero/storage/IWRIND6M/2103.html:text/html;arXiv Fulltext PDF:/home/fordrl/Zotero/storage/6RN6SQ38/Schmid and Kunčak - 2021 - Proving and Disproving Programs with Shared Mutabl.pdf:application/pdf},
}

@article{demeo_agda_2021,
	title = {The Agda Universal Algebra Library, Part 2: Structure},
	url = {http://arxiv.org/abs/2103.09092},
	shorttitle = {The Agda Universal Algebra Library, Part 2},
	abstract = {The Agda Universal Algebra Library ({UALib}) is a library of types and programs (theorems and proofs) we developed to formalize the foundations of universal algebra in dependent type theory using the Agda programming language and proof assistant. The {UALib} includes a substantial collection of definitions, theorems, and proofs from universal algebra, equational logic, and model theory, and as such provides many examples that exhibit the power of inductive and dependent types for representing and reasoning about mathematical structures and equational theories. In this paper, we describe the the types and proofs of the {UALib} that concern homomorphisms, terms, and subalgebras.},
	journaltitle = {{arXiv}:2103.09092 [cs, math]},
	author = {{DeMeo}, William},
	urldate = {2021-03-22},
	date = {2021-03-16},
	eprinttype = {arxiv},
	eprint = {2103.09092},
	keywords = {Computer Science - Logic in Computer Science, F.4.1, Mathematics - Logic, 68V20 (Primary) 03C05 (Secondary)},
	file = {arXiv.org Snapshot:/home/fordrl/Zotero/storage/NNHGLAZT/2103.html:text/html;arXiv Fulltext PDF:/home/fordrl/Zotero/storage/N7WDY6IY/DeMeo - 2021 - The Agda Universal Algebra Library, Part 2 Struct.pdf:application/pdf},
}

@article{bauer_extensible_2021,
	title = {An extensible equality checking algorithm for dependent type theories},
	url = {http://arxiv.org/abs/2103.07397},
	abstract = {We present a general and user-extensible equality checking algorithm that is applicable to a large class of type theories. The algorithm has a type-directed phase for applying extensionality rules and a normalization phase based on computation rules, where both kinds of rules are defined using the type-theoretic concept of object-invertible rules. We also give sufficient syntactic criteria for recognizing such rules, as well as a simple pattern-matching algorithm for applying them. A third component of the algorithm is a suitable notion of principal arguments, which determines a notion of normal form. By varying these, we obtain known notions, such as weak head-normal and strong normal forms. We prove that our algorithm is sound. We implemented it in the Andromeda{\textasciitilde}2 proof assistant, which supports user-definable type theories. The user need only provide the equality rules they wish to use, which the algorithm automatically classifies as computation or extensionality rules, and select appropriate principal arguments.},
	journaltitle = {{arXiv}:2103.07397 [cs, math]},
	author = {Bauer, Andrej and Petković, Anja},
	urldate = {2021-03-22},
	date = {2021-03-12},
	eprinttype = {arxiv},
	eprint = {2103.07397},
	keywords = {Computer Science - Logic in Computer Science, F.4.1, Mathematics - Logic, 03B38 (Primary), 68Q42 (Secondary)},
	file = {arXiv.org Snapshot:/home/fordrl/Zotero/storage/7U6XHHWS/2103.html:text/html;arXiv Fulltext PDF:/home/fordrl/Zotero/storage/H5HKH6TR/Bauer and Petković - 2021 - An extensible equality checking algorithm for depe.pdf:application/pdf},
}

@inproceedings{zakowski_equational_2020,
	location = {New York, {NY}, {USA}},
	title = {An equational theory for weak bisimulation via generalized parameterized coinduction},
	isbn = {978-1-4503-7097-4},
	url = {https://doi.org/10.1145/3372885.3373813},
	doi = {10.1145/3372885.3373813},
	series = {{CPP} 2020},
	abstract = {Coinductive reasoning about infinitary structures such as streams is widely applicable. However, practical frameworks for developing coinductive proofs and finding reasoning principles that help structure such proofs remain a challenge, especially in the context of machine-checked formalization. This paper gives a novel presentation of an equational theory for reasoning about structures up to weak bisimulation. The theory is both compositional, making it suitable for defining general-purpose lemmas, and also incremental, meaning that the bisimulation can be created interactively. To prove the theory’s soundness, this paper also introduces generalized parameterized coinduction, which addresses expressivity problems of earlier works and provides a practical framework for coinductive reasoning. The paper presents the resulting equational theory for streams, but the technique applies to other structures too. All of the results in this paper have been proved in Coq, and the generalized parameterized coinduction framework is available as a Coq library.},
	pages = {71--84},
	booktitle = {Proceedings of the 9th {ACM} {SIGPLAN} International Conference on Certified Programs and Proofs},
	publisher = {Association for Computing Machinery},
	author = {Zakowski, Yannick and He, Paul and Hur, Chung-Kil and Zdancewic, Steve},
	urldate = {2021-03-15},
	date = {2020-01-20},
	keywords = {Coq, coinduction, equational theory, up-to techniques, weak bisimulation},
	file = {Full Text PDF:/home/fordrl/Zotero/storage/XQVHL9P8/Zakowski et al. - 2020 - An equational theory for weak bisimulation via gen.pdf:application/pdf},
}

@article{xia_interaction_2019,
	title = {Interaction trees: representing recursive and impure programs in Coq},
	volume = {4},
	url = {https://doi.org/10.1145/3371119},
	doi = {10.1145/3371119},
	shorttitle = {Interaction trees},
	abstract = {Interaction trees ({ITrees}) are a general-purpose data structure for representing the behaviors of recursive programs that interact with their environments. A coinductive variant of “free monads,” {ITrees} are built out of uninterpreted events and their continuations. They support compositional construction of interpreters from event handlers, which give meaning to events by defining their semantics as monadic actions. {ITrees} are expressive enough to represent impure and potentially nonterminating, mutually recursive computations, while admitting a rich equational theory of equivalence up to weak bisimulation. In contrast to other approaches such as relationally specified operational semantics, {ITrees} are executable via code extraction, making them suitable for debugging, testing, and implementing software artifacts that are amenable to formal verification. We have implemented {ITrees} and their associated theory as a Coq library, mechanizing classic domain- and category-theoretic results about program semantics, iteration, monadic structures, and equational reasoning. Although the internals of the library rely heavily on coinductive proofs, the interface hides these details so that clients can use and reason about {ITrees} without explicit use of Coq’s coinduction tactics. To showcase the utility of our theory, we prove the termination-sensitive correctness of a compiler from a simple imperative source language to an assembly-like target whose meanings are given in an {ITree}-based denotational semantics. Unlike previous results using operational techniques, our bisimulation proof follows straightforwardly by structural induction and elementary rewriting via an equational theory of combinators for control-flow graphs.},
	pages = {51:1--51:32},
	issue = {{POPL}},
	journaltitle = {Proceedings of the {ACM} on Programming Languages},
	shortjournal = {Proc. {ACM} Program. Lang.},
	author = {Xia, Li-yao and Zakowski, Yannick and He, Paul and Hur, Chung-Kil and Malecha, Gregory and Pierce, Benjamin C. and Zdancewic, Steve},
	urldate = {2021-03-15},
	date = {2019-12-20},
	keywords = {Coq, coinduction, compiler correctness, monads},
	file = {Full Text PDF:/home/fordrl/Zotero/storage/W9C2BMHJ/Xia et al. - 2019 - Interaction trees representing recursive and impu.pdf:application/pdf},
}

@article{demeo_agda_2021-1,
	title = {The Agda Universal Algebra Library, Part 1: Foundation},
	url = {http://arxiv.org/abs/2103.05581},
	shorttitle = {The Agda Universal Algebra Library, Part 1},
	abstract = {The Agda Universal Algebra Library ({UALib}) is a library of types and programs (theorems and proofs) we developed to formalize the foundations of universal algebra in dependent type theory using the Agda programming language and proof assistant. The {UALib} includes a substantial collection of definitions, theorems, and proofs from general algebra and equational logic, including many examples that exhibit the power of inductive and dependent types for representing and reasoning about relations, algebraic structures, and equational theories. In this paper we describe several important aspects of the logical foundations on which the library is built. We also discuss (though sometimes only briefly) all of the types defined in the first 13 modules of the library, with special attention given to those details that seem most interesting or challenging from a type theory or mathematical foundations perspective.},
	journaltitle = {{arXiv}:2103.05581 [cs, math]},
	author = {{DeMeo}, William},
	urldate = {2021-03-15},
	date = {2021-03-09},
	eprinttype = {arxiv},
	eprint = {2103.05581},
	keywords = {Computer Science - Logic in Computer Science, F.4.1, Mathematics - Logic, 68V20 (Primary) 03C05 (Secondary)},
	file = {arXiv.org Snapshot:/home/fordrl/Zotero/storage/NLZEGFD5/2103.html:text/html;arXiv Fulltext PDF:/home/fordrl/Zotero/storage/NU7AJV7D/DeMeo - 2021 - The Agda Universal Algebra Library, Part 1 Founda.pdf:application/pdf},
}

@article{russinovich_toward_2021,
	title = {Toward Confidential Cloud Computing: Extending hardware-enforced cryptographic protection to data while in use},
	volume = {19},
	issn = {1542-7730},
	url = {https://doi.org/10.1145/3454122.3456125},
	doi = {10.1145/3454122.3456125},
	shorttitle = {Toward Confidential Cloud Computing},
	abstract = {Although largely driven by economies of scale, the development of the modern cloud also enables increased security. Large data centers provide aggregate availability, reliability, and security assurances. The operational cost of ensuring that operating systems, databases, and other services have secure configurations can be amortized among all tenants, allowing the cloud provider to employ experts who are responsible for security; this is often unfeasible for smaller businesses, where the role of systems administrator is often conflated with many others.},
	pages = {Pages 20:49--Pages 20:76},
	number = {1},
	journaltitle = {Queue},
	shortjournal = {Queue},
	author = {Russinovich, Mark and Costa, Manuel and Fournet, Cédric and Chisnall, David and Delignat-Lavaud, Antoine and Clebsch, Sylvan and Vaswani, Kapil and Bhatia, Vikas},
	urldate = {2021-03-15},
	date = {2021-02-28},
	file = {Full Text PDF:/home/fordrl/Zotero/storage/4KYQDGWX/Russinovich et al. - 2021 - Toward Confidential Cloud Computing Extending har.pdf:application/pdf},
}

@thesis{li_verification_2020,
	title = {A {VERIFICATION} {FRAMEWORK} {SUITABLE} {FOR} {PROVING} {LARGE} {LANGUAGE} {TRANSLATIONS}},
	pagetotal = {191},
	institution = {University of Illinois at Urbana-Champaign},
	type = {phdthesis},
	author = {Li, Liyi},
	date = {2020},
	langid = {english},
	file = {Li - A VERIFICATION FRAMEWORK SUITABLE FOR PROVING LARG.pdf:/home/fordrl/Zotero/storage/Z8PYNIZS/Li - A VERIFICATION FRAMEWORK SUITABLE FOR PROVING LARG.pdf:application/pdf},
}

@article{gheorghiu_provability_2021,
	title = {Provability in {BI}'s Sequent Calculus is Decidable},
	url = {http://arxiv.org/abs/2103.02343},
	abstract = {The logic of Bunched Implications ({BI}) combines both additive and multiplicative connectives, which include two primitive intuitionistic implications. As a consequence, contexts in the sequent presentation are not lists, nor multisets, but rather tree-like structures called bunches. This additional complexity notwithstanding, the logic has a well-behaved metatheory admitting all the familiar forms of semantics and proof systems. However, the presentation of an effective proof-search procedure has been elusive since the logic's debut. We show that one can reduce the proof-search space for any given sequent to a primitive recursive set, the argument generalizing Gentzen's decidability argument for classical propositional logic and combining key features of Dyckhoff's contraction-elimination argument for intuitionistic logic. An effective proof-search procedure, and hence decidability of provability, follows as a corollary.},
	journaltitle = {{arXiv}:2103.02343 [cs, math]},
	author = {Gheorghiu, Alexander and Docherty, Simon and Pym, David},
	urldate = {2021-03-11},
	date = {2021-03-03},
	eprinttype = {arxiv},
	eprint = {2103.02343},
	keywords = {Computer Science - Logic in Computer Science, F.3, Mathematics - Logic, 03B25 (Primary) 03D99, 68W68, 68Q68 (Secondary), Computer Science - Symbolic Computation, F.0, I.1},
	file = {arXiv.org Snapshot:/home/fordrl/Zotero/storage/JRR6Y8EW/2103.html:text/html;arXiv Fulltext PDF:/home/fordrl/Zotero/storage/U65F23VH/Gheorghiu et al. - 2021 - Provability in BI's Sequent Calculus is Decidable.pdf:application/pdf},
}

@article{birkedal_guarded_2017,
	title = {Guarded Cubical Type Theory},
	url = {http://arxiv.org/abs/1611.09263},
	abstract = {This paper improves the treatment of equality in guarded dependent type theory ({GDTT}), by combining it with cubical type theory ({CTT}). {GDTT} is an extensional type theory with guarded recursive types, which are useful for building models of program logics, and for programming and reasoning with coinductive types. We wish to implement {GDTT} with decidable type checking, while still supporting non-trivial equality proofs that reason about the extensions of guarded recursive constructions. {CTT} is a variation of Martin-L{\textbackslash}"of type theory in which the identity type is replaced by abstract paths between terms. {CTT} provides a computational interpretation of functional extensionality, enjoys canonicity for the natural numbers type, and is conjectured to support decidable type-checking. Our new type theory, guarded cubical type theory ({GCTT}), provides a computational interpretation of extensionality for guarded recursive types. This further expands the foundations of {CTT} as a basis for formalisation in mathematics and computer science. We present examples to demonstrate the expressivity of our type theory, all of which have been checked using a prototype type-checker implementation. We show that {CTT} can be given semantics in presheaves on the product of the cube category and a small category with an initial object. We then show that the category of presheaves on the product of the cube category and omega provides semantics for {GCTT}.},
	journaltitle = {{arXiv}:1611.09263 [cs, math]},
	author = {Birkedal, Lars and Bizjak, Aleš and Clouston, Ranald and Grathwohl, Hans Bugge and Spitters, Bas and Vezzosi, Andrea},
	urldate = {2021-03-11},
	date = {2017-10-06},
	eprinttype = {arxiv},
	eprint = {1611.09263},
	keywords = {Computer Science - Logic in Computer Science, F.3.2, F.4.1, Mathematics - Logic, Mathematics - Category Theory, F.3.3, 03B70, 03B15, 55U35},
	file = {arXiv.org Snapshot:/home/fordrl/Zotero/storage/SSNPAAAZ/1611.html:text/html;arXiv Fulltext PDF:/home/fordrl/Zotero/storage/Z6EGAM2G/Birkedal et al. - 2017 - Guarded Cubical Type Theory.pdf:application/pdf},
}

@incollection{de_boer_finding_2020,
	location = {Cham},
	title = {Finding and Fixing a Mismatch Between the Go Memory Model and Data-Race Detector: A Story on Applied Formal Methods},
	volume = {12310},
	isbn = {978-3-030-58767-3 978-3-030-58768-0},
	url = {http://link.springer.com/10.1007/978-3-030-58768-0_2},
	shorttitle = {Finding and Fixing a Mismatch Between the Go Memory Model and Data-Race Detector},
	abstract = {Go is an open-source programming language developed at Google. In previous works, we presented formalizations for a weak memory model and a data-race detector inspired by the Go speciﬁcation. In this paper, we describe how our theoretical research guided us in the process of ﬁnding and ﬁxing a concrete bug in the language. Speciﬁcally, we discovered and ﬁxed a discrepancy between the Go memory model and the Go data-race detector implementation—the discrepancy led to the under-reporting of data races in Go programs. Here, we share our experience applying formal methods on software that powers infrastructure used by millions of people.},
	pages = {24--40},
	booktitle = {Software Engineering and Formal Methods},
	publisher = {Springer International Publishing},
	author = {Fava, Daniel Schnetzer},
	editor = {de Boer, Frank and Cerone, Antonio},
	urldate = {2021-03-11},
	date = {2020},
	langid = {english},
	doi = {10.1007/978-3-030-58768-0_2},
	note = {Series Title: Lecture Notes in Computer Science},
	file = {Fava - 2020 - Finding and Fixing a Mismatch Between the Go Memor.pdf:/home/fordrl/Zotero/storage/MDJD8SQE/Fava - 2020 - Finding and Fixing a Mismatch Between the Go Memor.pdf:application/pdf},
}

@article{nie_roosterize_2021,
	title = {Roosterize: Suggesting Lemma Names for Coq Verification Projects Using Deep Learning},
	url = {http://arxiv.org/abs/2103.01346},
	shorttitle = {Roosterize},
	abstract = {Naming conventions are an important concern in large verification projects using proof assistants, such as Coq. In particular, lemma names are used by proof engineers to effectively understand and modify Coq code. However, providing accurate and informative lemma names is a complex task, which is currently often carried out manually. Even when lemma naming is automated using rule-based tools, generated names may fail to adhere to important conventions not specified explicitly. We demonstrate a toolchain, dubbed Roosterize, which automatically suggests lemma names in Coq projects. Roosterize leverages a neural network model trained on existing Coq code, thus avoiding manual specification of naming conventions. To allow proof engineers to conveniently access suggestions from Roosterize during Coq project development, we integrated the toolchain into the popular Visual Studio Code editor. Our evaluation shows that Roosterize substantially outperforms strong baselines for suggesting lemma names and is useful in practice. The demo video for Roosterize can be viewed at: https://youtu.be/{HZ}5ac7Q14rc.},
	journaltitle = {{arXiv}:2103.01346 [cs]},
	author = {Nie, Pengyu and Palmskog, Karl and Li, Junyi Jessy and Gligoric, Milos},
	urldate = {2021-03-08},
	date = {2021-03-01},
	eprinttype = {arxiv},
	eprint = {2103.01346},
	keywords = {Computer Science - Programming Languages, Computer Science - Software Engineering, Computer Science - Computation and Language},
	file = {arXiv.org Snapshot:/home/fordrl/Zotero/storage/Y3TL4UJY/2103.html:text/html;arXiv Fulltext PDF:/home/fordrl/Zotero/storage/FCBCUDM7/Nie et al. - 2021 - Roosterize Suggesting Lemma Names for Coq Verific.pdf:application/pdf},
}

@article{cavallo_higher_2021,
	title = {Higher Inductive Types and Internal Parametricity for Cubical Type Theory},
	abstract = {Recent innovation in the design of type theories—foundational systems of mathematics with a focus on constructivity—has produced the concept of interval variable, which can be used to capture relations between objects that carry computational content. We examine two such relationships in type theory: equality, in particular quotients, and arbitrary relations as applied in parametricity interpretations.},
	pages = {322},
	author = {Cavallo, Evan},
	date = {2021},
	langid = {english},
	file = {Cavallo - Higher Inductive Types and Internal Parametricity .pdf:/home/fordrl/Zotero/storage/ZCJNK8X5/Cavallo - Higher Inductive Types and Internal Parametricity .pdf:application/pdf},
}

@article{molina_evospex_2021,
	title = {{EvoSpex}: An Evolutionary Algorithm for Learning Postconditions},
	url = {http://arxiv.org/abs/2102.13569},
	shorttitle = {{EvoSpex}},
	abstract = {Software reliability is a primary concern in the construction of software, and thus a fundamental component in the definition of software quality. Analyzing software reliability requires a specification of the intended behavior of the software under analysis, and at the source code level, such specifications typically take the form of assertions. Unfortunately, software many times lacks such specifications, or only provides them for scenario-specific behaviors, as assertions accompanying tests. This issue seriously diminishes the analyzability of software with respect to its reliability. In this paper, we tackle this problem by proposing a technique that, given a Java method, automatically produces a specification of the method's current behavior, in the form of postcondition assertions. This mechanism is based on generating executions of the method under analysis to obtain valid pre/post state pairs, mutating these pairs to obtain (allegedly) invalid ones, and then using a genetic algorithm to produce an assertion that is satisfied by the valid pre/post pairs, while leaving out the invalid ones. The technique, which targets in particular methods of reference-based class implementations, is assessed on a benchmark of open source Java projects, showing that our genetic algorithm is able to generate post-conditions that are stronger and more accurate, than those generated by related automated approaches, as evaluated by an automated oracle assessment tool. Moreover, our technique is also able to infer an important part of manually written rich postconditions in verified classes, and reproduce contracts for methods whose class implementations were automatically synthesized from specifications.},
	journaltitle = {{arXiv}:2102.13569 [cs]},
	author = {Molina, Facundo and Ponzio, Pablo and Aguirre, Nazareno and Frias, Marcelo},
	urldate = {2021-03-08},
	date = {2021-03-01},
	eprinttype = {arxiv},
	eprint = {2102.13569},
	keywords = {Computer Science - Software Engineering},
	file = {arXiv.org Snapshot:/home/fordrl/Zotero/storage/WP76E5G8/2102.html:text/html;arXiv Fulltext PDF:/home/fordrl/Zotero/storage/J8EZ7N3I/Molina et al. - 2021 - EvoSpex An Evolutionary Algorithm for Learning Po.pdf:application/pdf},
}

@article{majumder_hir_2021,
	title = {{HIR}: An {MLIR}-based Intermediate Representation for Hardware Accelerator Description},
	url = {http://arxiv.org/abs/2103.00194},
	shorttitle = {{HIR}},
	abstract = {The emergence of machine learning, image and audio processing on edge devices has motivated research towards power efficient custom hardware accelerators. Though {FPGAs} are an ideal target for energy efficient custom accelerators, the difficulty of hardware design and the lack of vendor agnostic, standardized hardware compilation infrastructure has hindered their adoption. This paper introduces {HIR}, an {MLIR}-based intermediate representation ({IR}) to describe hardware accelerator designs. {HIR} combines high level language features, such as loops and multi-dimensional tensors, with programmer defined explicit scheduling, to provide a high-level {IR} suitable for {DSL} compiler pipelines without compromising control over the micro-architecture of the accelerator. {HIR}'s explicit schedules allow it to express fine-grained, synchronization-free parallelism and optimizations such as retiming and pipelining. Built as a dialect in {MLIR}, it draws from best {IR} practices learnt from communities like those of {LLVM}. While offering rich optimization opportunities and a high level abstraction, {HIR} enables sharing of optimizations, utilities and passes with software compiler infrastructure. Our implementation shows that the code generation time of the {HIR} code generator is on average 1112x lower than that of Xilinx Vivado {HLS} on a range of kernels without a compromise on the quality of the generated hardware. We believe that these are significant steps forward in the design of {IRs} for hardware synthesis and in equipping domain-specific languages with a productive and performing compilation path to custom hardware acceleration.},
	journaltitle = {{arXiv}:2103.00194 [cs]},
	author = {Majumder, Kingshuk and Bondhugula, Uday},
	urldate = {2021-03-08},
	date = {2021-02-27},
	eprinttype = {arxiv},
	eprint = {2103.00194},
	keywords = {Computer Science - Programming Languages, Computer Science - Hardware Architecture},
	file = {arXiv.org Snapshot:/home/fordrl/Zotero/storage/A4B2MAUM/2103.html:text/html;arXiv Fulltext PDF:/home/fordrl/Zotero/storage/DCJYX4W2/Majumder and Bondhugula - 2021 - HIR An MLIR-based Intermediate Representation for.pdf:application/pdf},
}

@article{qian_client-server_nodate,
	title = {Client-Server Sessions in Linear Logic},
	volume = {1},
	pages = {28},
	number = {1},
	author = {Qian, Zesen and Kavvos, G A and Birkedal, Lars},
	langid = {english},
	file = {Qian et al. - Client-Server Sessions in Linear Logic.pdf:/home/fordrl/Zotero/storage/V4AUEI9H/Qian et al. - Client-Server Sessions in Linear Logic.pdf:application/pdf},
}

@article{birkedal_theorems_2021,
	title = {Theorems for Free from Separation Logic Specifications},
	volume = {1},
	pages = {28},
	number = {1},
	author = {Birkedal, Lars and Dinsdale-Young, Thomas and Guéneau, Armaël and Jaber, Guilhem and Svendsen, Kasper and Tzevelekos, Nikos},
	date = {2021},
	langid = {english},
	file = {Birkedal et al. - Theorems for Free from Separation Logic Specificat.pdf:/home/fordrl/Zotero/storage/9PNEAGGJ/Birkedal et al. - Theorems for Free from Separation Logic Specificat.pdf:application/pdf},
}

@article{marsik_introducing_2021,
	title = {Introducing ⦇ λ ⦈, a λ-calculus for Effectful Computation},
	issn = {0304-3975},
	url = {https://www.sciencedirect.com/science/article/pii/S0304397521001225},
	doi = {10.1016/j.tcs.2021.02.038},
	abstract = {We present ⦇λ⦈, a calculus with special constructions for dealing with effects and handlers. This is an extension of the simply-typed λ-calculus ({STLC}). We enrich {STLC} with a type for representing effectful computations alongside with operations to create and process values of this type. The calculus is motivated by natural language modelling, and especially semantic representation. Traditionally, the meaning of a sentence is calculated using λ-terms, but some semantic phenomena need more flexibility. In this article we introduce the calculus and show that the calculus respects the laws of algebraic structures and it enjoys strong normalisation. To do so, confluence is proven using the Combinatory Reduction Systems ({CRSs}) of Klop and termination using the Inductive Data Type Systems ({IDTSs}) of Blanqui.},
	journaltitle = {Theoretical Computer Science},
	shortjournal = {Theoretical Computer Science},
	author = {Maršík, Jirka and Amblard, Maxime and de Groote, Philippe},
	urldate = {2021-03-05},
	date = {2021-02-27},
	langid = {english},
	keywords = {monads, -calculus, {CRS}, handlers, {IDTS}, side effects},
	file = {ScienceDirect Snapshot:/home/fordrl/Zotero/storage/53D6X24U/S0304397521001225.html:text/html},
}

@article{hickman_certifying_2021,
	title = {Certifying Differential Equation Solutions from Computer Algebra Systems in Isabelle/{HOL}},
	url = {http://arxiv.org/abs/2102.02679},
	abstract = {The Isabelle/{HOL} proof assistant has a powerful library for continuous analysis, which provides the foundation for verification of hybrid systems. However, Isabelle lacks automated proof support for continuous artifacts, which means that verification is often manual. In contrast, Computer Algebra Systems ({CAS}), such as Mathematica and {SageMath}, contain a wealth of efficient algorithms for matrices, differential equations, and other related artifacts. Nevertheless, these algorithms are not verified, and thus their outputs cannot, of themselves, be trusted for use in a safety critical system. In this paper we integrate two {CAS} systems into Isabelle, with the aim of certifying symbolic solutions to ordinary differential equations. This supports a verification technique that is both automated and trustworthy.},
	journaltitle = {{arXiv}:2102.02679 [cs, math]},
	author = {Hickman, Thomas and Laursen, Christian Pardillo and Foster, Simon},
	urldate = {2021-03-01},
	date = {2021-02-04},
	eprinttype = {arxiv},
	eprint = {2102.02679},
	keywords = {Computer Science - Logic in Computer Science, Mathematics - Dynamical Systems},
	file = {arXiv.org Snapshot:/home/fordrl/Zotero/storage/XINZNDWR/2102.html:text/html;arXiv Fulltext PDF:/home/fordrl/Zotero/storage/BERU8LYB/Hickman et al. - 2021 - Certifying Differential Equation Solutions from Co.pdf:application/pdf},
}

@article{balabonski_strong_nodate,
	title = {A strong call-by-need calculus},
	pages = {22},
	author = {Balabonski, Thibaut and Lanco, Antoine and Melquiond, Guillaume},
	langid = {english},
	file = {Balabonski et al. - A strong call-by-need calculus.pdf:/home/fordrl/Zotero/storage/2ZJ6KJN3/Balabonski et al. - A strong call-by-need calculus.pdf:application/pdf},
}

@article{ongaro_search_2014,
	title = {In Search of an Understandable Consensus Algorithm},
	abstract = {Raft is a consensus algorithm for managing a replicated log. It produces a result equivalent to (multi-)Paxos, and it is as efﬁcient as Paxos, but its structure is different from Paxos; this makes Raft more understandable than Paxos and also provides a better foundation for building practical systems. In order to enhance understandability, Raft separates the key elements of consensus, such as leader election, log replication, and safety, and it enforces a stronger degree of coherency to reduce the number of states that must be considered. Results from a user study demonstrate that Raft is easier for students to learn than Paxos. Raft also includes a new mechanism for changing the cluster membership, which uses overlapping majorities to guarantee safety.},
	pages = {18},
	author = {Ongaro, Diego and Ousterhout, John},
	date = {2014-05-20},
	langid = {english},
	file = {Ongaro and Ousterhout - In Search of an Understandable Consensus Algorithm.pdf:/home/fordrl/Zotero/storage/EF32N8CF/Ongaro and Ousterhout - In Search of an Understandable Consensus Algorithm.pdf:application/pdf},
}

@inproceedings{woos_planning_2016,
	location = {New York, {NY}, {USA}},
	title = {Planning for change in a formal verification of the raft consensus protocol},
	isbn = {978-1-4503-4127-1},
	url = {https://doi.org/10.1145/2854065.2854081},
	doi = {10.1145/2854065.2854081},
	series = {{CPP} 2016},
	abstract = {We present the first formal verification of state machine safety for the Raft consensus protocol, a critical component of many distributed systems. We connected our proof to previous work to establish an end-to-end guarantee that our implementation provides linearizable state machine replication. This proof required iteratively discovering and proving 90 system invariants. Our verified implementation is extracted to {OCaml} and runs on real networks. The primary challenge we faced during the verification process was proof maintenance, since proving one invariant often required strengthening and updating other parts of our proof. To address this challenge, we propose a methodology of planning for change during verification. Our methodology adapts classical information hiding techniques to the context of proof assistants, factors out common invariant-strengthening patterns into custom induction principles, proves higher-order lemmas that show any property proved about a particular component implies analogous properties about related components, and makes proofs robust to change using structural tactics. We also discuss how our methodology may be applied to systems verification more broadly.},
	pages = {154--165},
	booktitle = {Proceedings of the 5th {ACM} {SIGPLAN} Conference on Certified Programs and Proofs},
	publisher = {Association for Computing Machinery},
	author = {Woos, Doug and Wilcox, James R. and Anton, Steve and Tatlock, Zachary and Ernst, Michael D. and Anderson, Thomas},
	urldate = {2021-03-01},
	date = {2016-01-18},
	keywords = {Coq, proof assistants, distributed systems, Formal verification, Raft, Verdi},
	file = {Full Text PDF:/home/fordrl/Zotero/storage/KWEMEJQ5/Woos et al. - 2016 - Planning for change in a formal verification of th.pdf:application/pdf},
}

@article{tusil_hyperproperties_2021,
	title = {Hyperproperties in Matching Logic},
	abstract = {Matching logic is a uniform logic to specify and reason about programming languages and program properties. Many important logics and/or formal systems have been shown to be deﬁnable in matching logic as logical theories. However, no research has been conducted to studying how hyperproperties can be treated in matching logic. In this paper, we give the ﬁrst theoretical result that shows that {HyperLTL} (hyper linear temporal logic), which is an important temporal logic designed for specifying and reasoning about hyperproperties, can be completely captured by matching logic. Our result demonstrates that matching logic oﬀers a uniform treatment to handling hyperproperties and to supporting their model checking problems.},
	pages = {70},
	author = {Tuˇsil, Jan and Chen, Xiaohong and Rosu, Grigore},
	date = {2021},
	langid = {english},
	file = {Tuˇsil et al. - Hyperproperties in Matching Logic.pdf:/home/fordrl/Zotero/storage/56XCKD5X/Tuˇsil et al. - Hyperproperties in Matching Logic.pdf:application/pdf},
}

@article{kachapova_formalizing_2021,
	title = {Formalizing relations in type theory},
	url = {http://arxiv.org/abs/2102.08595},
	abstract = {Type theory plays an important role in foundations of mathematics as a framework for formalizing mathematics and a base for proof assistants providing semi-automatic proof checking and construction. Derivation of each theorem in type theory results in a formal term encapsulating the whole proof process. In this paper we use a variant of type theory, namely the Calculus of Constructions with Definitions, to formalize the standard theory of binary relations. This includes basic operations on relations, criteria for special properties of relations, invariance of these properties under the basic operations, equivalence relation, well-ordering, and transfinite induction. Definitions and proofs are presented as flag-style derivations.},
	journaltitle = {{arXiv}:2102.08595 [cs, math]},
	author = {Kachapova, Farida},
	urldate = {2021-02-25},
	date = {2021-02-17},
	eprinttype = {arxiv},
	eprint = {2102.08595},
	keywords = {Computer Science - Logic in Computer Science, Mathematics - Logic, 03B30 (Primary) 03B38 (Secondary)},
	file = {arXiv.org Snapshot:/home/fordrl/Zotero/storage/RK9RRCRP/2102.html:text/html;arXiv Fulltext PDF:/home/fordrl/Zotero/storage/PU5WDBFJ/Kachapova - 2021 - Formalizing relations in type theory.pdf:application/pdf},
}

@article{chin_finding_2021,
	title = {Finding Bugs with Speciﬁcation-Based Testing is Easy!},
	abstract = {Automated speciﬁcation-based testing has a long history with several notable tools having emerged. For example, {QuickCheck} for Haskell focuses on testing against user-provided properties. Others, such as {JMLUnit}, use speciﬁcations in the form of pre- and post-conditions to drive testing. An interesting (and underexplored) question is how eﬀective this approach is at ﬁnding bugs in practice. In general, one would assume automated testing is less eﬀective at bug ﬁnding than static veriﬁcation. But, how much less eﬀective? To shed light on this question, we consider automated testing of programs written in Whiley — a language with ﬁrst-class support for speciﬁcations. Whilst originally designed with static veriﬁcation in mind, we have anecdotally found automated testing for Whiley surprisingly useful and cost-eﬀective. For example, when an error is detected with automated testing, a counterexample is always provided. This has motivated the more rigorous empirical examination presented in this paper. To that end, we provide a technical discussion of the implementation behind an automated testing tool for Whiley. Here, a key usability concern is the ability to parameterise the input space, and we present novel approaches for references and lambdas. We then report on several large experiments investigating the tool’s eﬀectiveness at bug ﬁnding using a range of benchmarks, including a suite of + mutants. The results indicate the automated testing is eﬀective in many cases, and that sampling oﬀers useful performance beneﬁts with only modest reductions in bug-ﬁnding capability. Finally, we report on some real-world uses of the tool where it has proved eﬀective at ﬁnding bugs (such as in the standard library).},
	pages = {35},
	author = {Chin, Janice and Pearce, David J},
	date = {2021},
	langid = {english},
	file = {Chin and Pearce - Finding Bugs with Speciﬁcation-Based Testing is Ea.pdf:/home/fordrl/Zotero/storage/P7P3ZA86/Chin and Pearce - Finding Bugs with Speciﬁcation-Based Testing is Ea.pdf:application/pdf},
}

@inproceedings{passmore_imandra_2020,
	location = {Cham},
	title = {The Imandra Automated Reasoning System (System Description)},
	isbn = {978-3-030-51054-1},
	doi = {10.1007/978-3-030-51054-1_30},
	series = {Lecture Notes in Computer Science},
	abstract = {We describe Imandra, a modern computational logic theorem prover designed to bridge the gap between decision procedures such as {SMT}, semi-automatic inductive provers of the Boyer-Moore family like {ACL}2, and interactive proof assistants for typed higher-order logics. Imandra’s logic is computational, based on a pure subset of {OCaml} in which all functions are terminating, with restrictions on types and higher-order functions that allow conjectures to be translated into multi-sorted first-order logic with theories, including arithmetic and datatypes. Imandra has novel features supporting large-scale industrial applications, including a seamless integration of bounded and unbounded verification, first-class computable counterexamples, efficiently executable models and a cloud-native architecture supporting live multiuser collaboration. The core reasoning mechanisms of Imandra are (i) a semi-complete procedure for finding models of formulas in the logic mentioned above, centered around the lazy expansion of recursive functions, (ii) an inductive waterfall and simplifier which “lifts” many Boyer-Moore ideas to our typed higher-order setting. These mechanisms are tightly integrated and subject to many forms of user control.},
	pages = {464--471},
	booktitle = {Automated Reasoning},
	publisher = {Springer International Publishing},
	author = {Passmore, Grant and Cruanes, Simon and Ignatovich, Denis and Aitken, Dave and Bray, Matt and Kagan, Elijah and Kanishev, Kostya and Maclean, Ewen and Mometto, Nicola},
	editor = {Peltier, Nicolas and Sofronie-Stokkermans, Viorica},
	date = {2020},
	langid = {english},
	file = {Springer Full Text PDF:/home/fordrl/Zotero/storage/UWNVZAQB/Passmore et al. - 2020 - The Imandra Automated Reasoning System (System Des.pdf:application/pdf},
}

@article{blom_correct_2021,
	title = {Correct program parallelisations},
	issn = {1433-2787},
	url = {https://doi.org/10.1007/s10009-020-00601-z},
	doi = {10.1007/s10009-020-00601-z},
	abstract = {A commonly used approach to develop deterministic parallel programs is to augment a sequential program with compiler directives that indicate which program blocks may potentially be executed in parallel. This paper develops a verification technique to reason about such compiler directives, in particular to show that they do not change the behaviour of the program. Moreover, the verification technique is tool-supported and can be combined with proving functional correctness of the program. To develop our verification technique, we propose a simple intermediate representation (syntax and semantics) that captures the main forms of deterministic parallel programs. This language distinguishes three kinds of basic blocks: parallel, vectorised and sequential blocks, which can be composed using three different composition operators: sequential, parallel and fusion composition. We show how a widely used subset of {OpenMP} can be encoded into this intermediate representation. Our verification technique builds on the notion of iteration contract to specify the behaviour of basic blocks; we show that if iteration contracts are manually specified for single blocks, then that is sufficient to automatically reason about data race freedom of the composed program. Moreover, we also show that it is sufficient to establish functional correctness on a linearised version of the original program to conclude functional correctness of the parallel program. Finally, we exemplify our approach on an example {OpenMP} program, and we discuss how tool support is provided.},
	journaltitle = {International Journal on Software Tools for Technology Transfer},
	shortjournal = {Int J Softw Tools Technol Transfer},
	author = {Blom, S. and Darabi, S. and Huisman, M. and Safari, M.},
	urldate = {2021-02-22},
	date = {2021-02-14},
	langid = {english},
}

@article{luo_c11tester_2021,
	title = {C11Tester: A Race Detector for C/C++ Atomics Technical Report},
	url = {http://arxiv.org/abs/2102.07901},
	shorttitle = {C11Tester},
	abstract = {Writing correct concurrent code that uses atomics under the C/C++ memory model is extremely difficult. We present C11Tester, a race detector for the C/C++ memory model that can explore executions in a larger fragment of the C/C++ memory model than previous race detector tools. Relative to previous work, C11Tester's larger fragment includes behaviors that are exhibited by {ARM} processors. C11Tester uses a new constraint-based algorithm to implement modification order that is optimized to allow C11Tester to make decisions in terms of application-visible behaviors. We evaluate C11Tester on several benchmark applications, and compare C11Tester's performance to both tsan11rec, the state of the art tool that controls scheduling for C/C++; and tsan11, the state of the art tool that does not control scheduling.},
	journaltitle = {{arXiv}:2102.07901 [cs]},
	author = {Luo, Weiyu and Demsky, Brian},
	urldate = {2021-02-22},
	date = {2021-02-15},
	eprinttype = {arxiv},
	eprint = {2102.07901},
	keywords = {Computer Science - Programming Languages},
	file = {arXiv.org Snapshot:/home/fordrl/Zotero/storage/9ZCHLCZA/2102.html:text/html;arXiv Fulltext PDF:/home/fordrl/Zotero/storage/HK4JS35H/Luo and Demsky - 2021 - C11Tester A Race Detector for CC++ Atomics Techn.pdf:application/pdf},
}

@article{dross_verifythis_2020,
	title = {{VerifyThis} 2019: A Program Verification Competition (Extended Report)},
	url = {http://arxiv.org/abs/2008.13610},
	shorttitle = {{VerifyThis} 2019},
	abstract = {{VerifyThis} is a series of program verification competitions that emphasize the human aspect: participants tackle the verification of detailed behavioral properties -- something that lies beyond the capabilities of fully automatic verification, and requires instead human expertise to suitably encode programs, specifications, and invariants. This paper describes the 8th edition of {VerifyThis}, which took place at {ETAPS} 2019 in Prague. Thirteen teams entered the competition, which consisted of three verification challenges and spanned two days of work. The report analyzes how the participating teams fared on these challenges, reflects on what makes a verification challenge more or less suitable for the typical {VerifyThis} participants, and outlines the difficulties of comparing the work of teams using wildly different verification approaches in a competition focused on the human aspect.},
	journaltitle = {{arXiv}:2008.13610 [cs]},
	author = {Dross, Claire and Furia, Carlo A. and Huisman, Marieke and Monahan, Rosemary and Müller, Peter},
	urldate = {2021-02-17},
	date = {2020-12-17},
	eprinttype = {arxiv},
	eprint = {2008.13610},
	keywords = {Computer Science - Logic in Computer Science},
	file = {arXiv.org Snapshot:/home/fordrl/Zotero/storage/YEXWQ2I9/2008.html:text/html;arXiv Fulltext PDF:/home/fordrl/Zotero/storage/H5NE2PWG/Dross et al. - 2020 - VerifyThis 2019 A Program Verification Competitio.pdf:application/pdf},
}

@article{gross_performance_2021,
	title = {Performance Engineering of Proof-Based Software Systems at Scale},
	abstract = {Formal verification is increasingly valuable as our world comes to rely more on software for critical infrastructure. A significant and understudied cost of developing mechanized proofs, especially at scale, is the computer performance of proof generation. This dissertation aims to be a partial guide to identifying and resolving performance bottlenecks in dependently typed tactic-driven proof assistants like Coq.},
	pages = {258},
	author = {Gross, Jason S},
	date = {2021-02},
	langid = {english},
	file = {Gross - Performance Engineering of Proof-Based Software Sy.pdf:/home/fordrl/Zotero/storage/JP5K2TCT/Gross - Performance Engineering of Proof-Based Software Sy.pdf:application/pdf},
}

@article{li_program_nodate,
	title = {Program Adverbs: Structures for Embedding Eﬀectful Programs},
	abstract = {We propose a new class of structures called program adverbs designed to abstractly represent eﬀectful programs in theorem provers like Coq. Program adverbs enable formal reasoning about general properties that hold for certain computation patterns regardless of the eﬀects that may occur during computation. Program adverbs are composable, allowing them to be used to model languages containing diﬀerent characteristics.},
	pages = {31},
	author = {Li, Yao and Weirich, Stephanie},
	langid = {english},
	file = {Li and Weirich - Structures for Embedding Eﬀectful Programs.pdf:/home/fordrl/Zotero/storage/H7HF4TYE/Li and Weirich - Structures for Embedding Eﬀectful Programs.pdf:application/pdf},
}

@article{li_mirchecker_nodate,
	title = {{MirChecker}: Detecting Bugs in Rust Programs via Static Analysis},
	abstract = {Safe system programming is often a crucial requirement due to its critical role in system software engineering. Conventional lowlevel programming languages such as C and assembly are efficient, but their inherent unsafe nature makes it undesirable for securitycritical scenarios. Recently, Rust has become a promising alternative for safe system-level programming. While giving programmers finegrained hardware control, its strong type system enforces many security properties including memory safety. However, Rust’s security guarantee is not a silver bullet. Runtime crashes and memory-safety errors still harass Rust developers, causing damaging exploitable vulnerabilities, as reported by numerous studies [29, 42, 47, 53, 54]. In this paper, we present and evaluate {MirChecker}, a fully automated bug detection framework for Rust programs by performing static analysis on Rust’s Mid-level Intermediate Representation ({MIR}). Based on the observation of existing bugs found in Rust codebases, our approach keeps track of both numerical and symbolic information, detects potential runtime crashes and memory-safety errors by using constraint solving techniques, and outputs informative diagnostics to users. We evaluate {MirChecker} on both buggy code snippets extracted from existing Common Vulnerabilities and Exposures ({CVE}) and real-world Rust codebases. Our experiments show that {MirChecker} can detect all the issues in our code snippets, and is capable of performing bug finding in realworld scenarios, where it detected a total of 33 previously unknown bugs including 16 memory-safety issues from 12 Rust packages (crates) with an acceptable false-positive rate.},
	pages = {14},
	author = {Li, Zhuohua and Wang, Jincheng and Sun, Mingshen and Lui, John C S},
	langid = {english},
	file = {Li et al. - MirChecker Detecting Bugs in Rust Programs via St.pdf:/home/fordrl/Zotero/storage/SDWQWDAP/Li et al. - MirChecker Detecting Bugs in Rust Programs via St.pdf:application/pdf},
}

@article{zhu_icallee_2021,
	title = {{iCallee}: Recovering Call Graphs for Binaries},
	url = {http://arxiv.org/abs/2111.01415},
	shorttitle = {{iCallee}},
	abstract = {Recovering programs' call graphs is crucial for inter-procedural analysis tasks and applications based on them. The core challenge is recognizing targets of indirect calls (i.e., indirect callees). It becomes more challenging if target programs are in binary forms, due to information loss in binaries. Existing indirect callee recognition solutions for binaries all have high false positives and negatives, making call graphs inaccurate. In this paper, we propose a new solution {iCallee} based on the Siamese Neural Network, inspired by the advances in question-answering applications. The key insight is that, neural networks can learn to answer whether a callee function is a potential target of an indirect callsite by comprehending their contexts, i.e., instructions nearby callsites and of callees. Following this insight, we first preprocess target binaries to extract contexts of callsites and callees. Then, we build a customized Natural Language Processing ({NLP}) model applicable to assembly language. Further, we collect abundant pairs of callsites and callees, and embed their contexts with the {NLP} model, then train a Siamese network and a classifier to answer the callsite-callee question. We have implemented a prototype of {iCallee} and evaluated it on several groups of targets. Evaluation results showed that, our solution could match callsites to callees with an F1-Measure of 93.7\%, recall of 93.8\%, and precision of 93.5\%, much better than state-of-the-art solutions. To show its usefulness, we apply {iCallee} to two specific applications - binary code similarity detection and binary program hardening, and found that it could greatly improve state-of-the-art solutions.},
	journaltitle = {{arXiv}:2111.01415 [cs]},
	author = {Zhu, Wenyu and Feng, Zhiyao and Zhang, Zihan and Ou, Zhijian and Yang, Min and Zhang, Chao},
	urldate = {2021-11-08},
	date = {2021-11-02},
	eprinttype = {arxiv},
	eprint = {2111.01415},
	keywords = {Computer Science - Cryptography and Security, Computer Science - Software Engineering, Computer Science - Artificial Intelligence},
	file = {arXiv.org Snapshot:/home/fordrl/Zotero/storage/FFW39KMQ/2111.html:text/html;arXiv Fulltext PDF:/home/fordrl/Zotero/storage/7NI2QSYL/Zhu et al. - 2021 - iCallee Recovering Call Graphs for Binaries.pdf:application/pdf},
}

@article{huyghebaert_semi-automatic_2021,
	title = {Semi-automatic verification of {ISA} security guarantees in the form of universal contracts},
	url = {https://silm-workshop-2021.inria.fr/wp-content/uploads/2021/09/ISAVerif.pdf},
	abstract = {Where {ISA} speciﬁcations used to be deﬁned in long prose documents, we have recently seen progress on formal and executable {ISA} speciﬁcations. However, for now, formal speciﬁcations provide only a functional speciﬁcation of the {ISA}, without specifying the {ISA}’s security guarantees. In this paper, we present a novel, general approach to specify an {ISA}’s security guarantee in a way that (1) can be semi-automatically validated against the {ISA} semantics, producing a mechanically veriﬁable proof, (2) supports informal and formal reasoning about security-critical software in the presence of adversarial code. Our approach is based on the use of universal contracts: software contracts that express bounds on the authority of arbitrary untrusted code on the {ISA}. We semi-automatically verify these contracts against existing {ISA} semantics implemented in Sail using our Katamaran tool: a veriﬁed, semi-automatic separation logic veriﬁer for Sail. For now, in this paper, we will illustrate our approach for {MinimalCaps}: a simpliﬁed custom-built capability machine {ISA}. However, we believe our approach has the potential to redeﬁne the formalization of {ISA} security guarantees and we will sketch our vision and plans.},
	pages = {6},
	journaltitle = {{SILM} Workshop 2021},
	author = {Huyghebaert, Sander and Keuchel, Steven and Devriese, Dominique},
	urldate = {2021-11-08},
	date = {2021-09},
	langid = {english},
	file = {Armstrong et al. - 2019 - ISA semantics for ARMv8-a, RISC-v, and CHERI-MIPS.pdf:/home/fordrl/Zotero/storage/E58AFJKZ/Armstrong et al. - 2019 - ISA semantics for ARMv8-a, RISC-v, and CHERI-MIPS.pdf:application/pdf},
}

@article{qu_relational_2021,
	title = {Relational cost analysis in a functional-imperative setting},
	volume = {31},
	issn = {0956-7968, 1469-7653},
	url = {https://www.cambridge.org/core/product/identifier/S0956796821000071/type/journal_article},
	doi = {10.1017/S0956796821000071},
	abstract = {Relational cost analysis aims at formally establishing bounds on the difference in the evaluation costs of two programs. As a particular case, one can also use relational cost analysis to establish bounds on the difference in the evaluation cost of the same program on two different inputs. One way to perform relational cost analysis is to use a relational type-and-effect system that supports reasoning about relations between two executions of two programs. Building on this basic idea, we present a type-and-effect system, called {ARel}, for reasoning about the relative cost (the difference in the evaluation cost) of array-manipulating, higher order functional-imperative programs. The key ingredient of our approach is a new lightweight type reﬁnement discipline that we use to track relations (differences) between two mutable arrays. This discipline combined with Hoare-style triples built into the types allows us to express and establish precise relative costs of several interesting programs that imperatively update their data. We have implemented {ARel} using ideas from bidirectional type checking.},
	pages = {e27},
	journaltitle = {Journal of Functional Programming},
	shortjournal = {J. Funct. Prog.},
	author = {Qu, Weihao and Gaboardi, Marco and Garg, Deepak},
	urldate = {2021-11-08},
	date = {2021},
	langid = {english},
	file = {Qu et al. - 2021 - Relational cost analysis in a functional-imperativ.pdf:/home/fordrl/Zotero/storage/J6DMWZR5/Qu et al. - 2021 - Relational cost analysis in a functional-imperativ.pdf:application/pdf},
}

@article{feldman_property-directed_2021,
	title = {Property-Directed Reachability as Abstract Interpretation in the Monotone Theory},
	url = {http://arxiv.org/abs/2111.00324},
	abstract = {Inferring inductive invariants is one of the main challenges of formal verification. The theory of abstract interpretation provides a rich framework to devise invariant inference algorithms. One of the latest breakthroughs in invariant inference is property-directed reachability ({PDR}), but the research community views {PDR} and abstract interpretation as mostly unrelated techniques. This paper shows that, surprisingly, propositional {PDR} can be formulated as an abstract interpretation algorithm in a logical domain. More precisely, we define a version of {PDR}, called \${\textbackslash}Lambda\$-{PDR}, in which all generalizations of counterexamples are used to strengthen a frame. In this way, there is no need to refine frames after their creation, because all the possible supporting facts are included in advance. We analyze this algorithm using notions from Bshouty's monotone theory, originally developed in the context of exact learning. We show that there is an inherent overapproximation between the algorithm's frames that is related to the monotone theory. We then define a new abstract domain in which the best abstract transformer performs this overapproximation, and show that it captures the invariant inference process, i.e., \${\textbackslash}Lambda\$-{PDR} corresponds to Kleene iterations with the best transformer in this abstract domain. We provide some sufficient conditions for when this process converges in a small number of iterations, with sometimes an exponential gap from the number of iterations required for naive exact forward reachability. These results provide a firm theoretical foundation for the benefits of how {PDR} tackles forward reachability.},
	journaltitle = {{arXiv}:2111.00324 [cs]},
	author = {Feldman, Yotam M. Y. and Sagiv, Mooly and Shoham, Sharon and Wilcox, James R.},
	urldate = {2021-11-08},
	date = {2021-10-30},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {2111.00324},
	keywords = {Computer Science - Programming Languages},
	file = {Feldman et al. - 2021 - Property-Directed Reachability as Abstract Interpr.pdf:/home/fordrl/Zotero/storage/I68HDRF8/Feldman et al. - 2021 - Property-Directed Reachability as Abstract Interpr.pdf:application/pdf},
}

@article{new_gradual_2021,
	title = {Gradual type theory},
	volume = {31},
	issn = {0956-7968, 1469-7653},
	url = {https://www.cambridge.org/core/product/identifier/S0956796821000125/type/journal_article},
	doi = {10.1017/S0956796821000125},
	abstract = {Gradually typed languages are designed to support both dynamically typed and statically typed programming styles while preserving the beneﬁts of each. Sound gradually typed languages dynamically check types at runtime at the boundary between statically typed and dynamically typed modules. However, there is much disagreement in the gradual typing literature over how to enforce complex types such as tuples, lists, functions and objects. In this paper, we propose a new perspective on the design of runtime gradual type enforcement: runtime type casts exist precisely to ensure the correctness of certain type-based refactorings and optimizations. For instance, for simple types, a language designer might desire that beta-eta equality is valid. We show that this perspective is useful by demonstrating that a cast semantics can be derived from beta-eta equality. We do this by providing an axiomatic account program equivalence in a gradual cast calculus in a logic we call gradual type theory ({GTT}). Based on Levy’s call-by-push-value, {GTT} allows us to axiomatize both call-byvalue and call-by-name gradual languages. We then show that we can derive the behavior of casts for simple types from the corresponding eta equality principle and the assumption that the language satisﬁes a property called graduality, also known as the dynamic gradual guarantee. Since we can derive the semantics from the assumption of eta equality, we also receive a useful contrapositive: any observably different cast semantics that satisﬁes graduality must violate the eta equality. We show the consistency and applicability of our axiomatic theory by proving that a contract-based implementation using the lazy cast semantics gives a logical relations model of our type theory, where equivalence in {GTT} implies contextual equivalence of the programs. Since {GTT} also axiomatizes the dynamic gradual guarantee, our model also establishes this central theorem of gradual typing. The model is parameterized by the implementation of the dynamic types, and so gives a family of implementations that validate type-based optimization and the gradual guarantee.},
	pages = {e21},
	journaltitle = {Journal of Functional Programming},
	shortjournal = {J. Funct. Prog.},
	author = {New, Max S. and Licata, Daniel R. and Ahmed, Amal},
	urldate = {2021-11-03},
	date = {2021},
	langid = {english},
	file = {New et al. - 2021 - Gradual type theory.pdf:/home/fordrl/Zotero/storage/QYE3GRSF/New et al. - 2021 - Gradual type theory.pdf:application/pdf},
}

@unpublished{casteran_hydras_2021,
	title = {Hydras \& Co.: Formalized mathematics in Coq for inspiration and entertainment},
	url = {https://hal.archives-ouvertes.fr/hal-03404668},
	shorttitle = {Hydras \& Co.},
	abstract = {Hydras \& Co. is a collaborative library of discrete mathematics for the Coq proof assistant, developed as part of the Coq-community organization on {GitHub}. The Coq code is accompanied by an electronic book, generated with the help of the Alectryon literate proving tool. We present the evolution of the mathematical contents of the library since former presentations at {JFLA} meetings. Then, we describe how the structure of the project is determined by two requirements which must be continuously satisfied. First, the Coq code needs to be compatible with its ever-evolving dependencies (the Coq proof assistant and several Coq packages both from inside and outside Coq-community) and reverse dependencies (Coq-community projects that depend on it). Second, the book needs to be consistent with the Coq code, which undergoes frequent changes to improve structure and include new material. We believe Hydras \& Co. demonstrates that books on formalized mathematics are not limited to providing exposition of theories and reasoning techniquesthey can also provide inspiration and entertainment that transcends educational goals.},
	author = {Castéran, Pierre and Damour, Jérémy and Palmskog, Karl and Pit-Claudel, Clément and Zimmermann, Théo},
	urldate = {2021-11-03},
	date = {2021-10},
	file = {HAL PDF Full Text:/home/fordrl/Zotero/storage/G5FHAM2D/Castéran et al. - 2021 - Hydras & Co. Formalized mathematics in Coq for in.pdf:application/pdf},
}

@article{bily_flexible_2021,
	title = {Flexible Refinement Proofs in Separation Logic},
	url = {http://arxiv.org/abs/2110.13559},
	abstract = {Refinement transforms an abstract system model into a concrete, executable program, such that properties established for the abstract model carry over to the concrete implementation. Refinement has been used successfully in the development of substantial verified systems. Nevertheless, existing refinement techniques have limitations that impede their practical usefulness. Some techniques generate executable code automatically, which generally leads to implementations with sub-optimal performance. Others employ bottom-up program verification to reason about efficient implementations, but impose strict requirements on the structure of the code, the structure of the refinement proofs, as well as the employed verification logic and tools. In this paper, we present a novel refinement technique that removes these limitations. Our technique uses separation logic to reason about efficient concurrent implementations. It prescribes only a loose coupling between an abstract model and the concrete implementation. It thereby supports a wide range of program structures, data representations, and proof structures. We make only minimal assumptions about the underlying program logic, which allows our technique to be used in combination with a wide range of logics and to be automated using off-the-shelf separation logic verifiers. We formalize the technique, prove the central trace inclusion property, and demonstrate its usefulness on several case studies.},
	journaltitle = {{arXiv}:2110.13559 [cs]},
	author = {Bílý, Aurel and Matheja, Christoph and Müller, Peter},
	urldate = {2021-11-01},
	date = {2021-10-26},
	eprinttype = {arxiv},
	eprint = {2110.13559},
	keywords = {Computer Science - Logic in Computer Science, F.3.1, 68Q60},
	file = {arXiv.org Snapshot:/home/fordrl/Zotero/storage/Z42KM2MC/2110.html:text/html;arXiv Fulltext PDF:/home/fordrl/Zotero/storage/K2ASRQQD/Bílý et al. - 2021 - Flexible Refinement Proofs in Separation Logic.pdf:application/pdf},
}

@article{oconnor_cogent_2021,
	title = {Cogent: uniqueness types and certifying compilation},
	volume = {31},
	issn = {0956-7968, 1469-7653},
	url = {https://www.cambridge.org/core/product/identifier/S095679682100023X/type/journal_article},
	doi = {10.1017/S095679682100023X},
	shorttitle = {Cogent},
	abstract = {Abstract
            This paper presents a framework aimed at significantly reducing the cost of proving functional correctness for low-level operating systems components. The framework is designed around a new functional programming language, Cogent. A central aspect of the language is its uniqueness type system, which eliminates the need for a trusted runtime or garbage collector while still guaranteeing memory safety, a crucial property for safety and security. Moreover, it allows us to assign two semantics to the language: The first semantics is imperative, suitable for efficient C code generation, and the second is purely functional, providing a user-friendly interface for equational reasoning and verification of higher-level correctness properties. The refinement theorem connecting the two semantics allows the compiler to produce a proof via translation validation certifying the correctness of the generated C code with respect to the semantics of the Cogent source program. We have demonstrated the effectiveness of our framework for implementation and for verification through two file system implementations.},
	pages = {e25},
	journaltitle = {Journal of Functional Programming},
	shortjournal = {J. Funct. Prog.},
	author = {O’Connor, Liam and Chen, Zilin and Rizkallah, Christine and Jackson, Vincent and Amani, Sidney and Klein, Gerwin and Murray, Toby and Sewell, Thomas and Keller, Gabriele},
	urldate = {2021-11-01},
	date = {2021},
	langid = {english},
	file = {O’Connor et al. - 2021 - Cogent uniqueness types and certifying compilatio.pdf:/home/fordrl/Zotero/storage/RSF9XQN7/O’Connor et al. - 2021 - Cogent uniqueness types and certifying compilatio.pdf:application/pdf},
}

@inproceedings{tao_formal_2021,
	location = {New York, {NY}, {USA}},
	title = {Formal Verification of a Multiprocessor Hypervisor on Arm Relaxed Memory Hardware},
	isbn = {978-1-4503-8709-5},
	url = {https://doi.org/10.1145/3477132.3483560},
	doi = {10.1145/3477132.3483560},
	series = {{SOSP} '21},
	abstract = {Concurrent systems software is widely-used, complex, and error-prone, posing a significant security risk. We introduce {VRM}, a new framework that makes it possible for the first time to verify concurrent systems software, such as operating systems and hypervisors, on Arm relaxed memory hardware. {VRM} defines a set of synchronization and memory access conditions such that a program that satisfies these conditions can be mostly verified on a sequentially consistent hardware model and the proofs will automatically hold on relaxed memory hardware. {VRM} can be used to verify concurrent kernel code that is not data race free, including code responsible for managing shared page tables in the presence of relaxed {MMU} hardware. Using {VRM}, we verify the security guarantees of a retrofitted implementation of the Linux {KVM} hypervisor on Arm. For multiple versions of {KVM}, we prove {KVM}'s security properties on a sequentially consistent model, then prove that {KVM} satisfies {VRM}'s required program conditions such that its security proofs hold on Arm relaxed memory hardware. Our experimental results show that the retrofit and {VRM} conditions do not adversely affect the scalability of verified {KVM}, as it performs similar to unmodified {KVM} when concurrently running many multiprocessor virtual machines with real application workloads on Arm multiprocessor server hardware. Our work is the first machine-checked proof for concurrent systems software on Arm relaxed memory hardware.},
	pages = {866--881},
	booktitle = {Proceedings of the {ACM} {SIGOPS} 28th Symposium on Operating Systems Principles},
	publisher = {Association for Computing Machinery},
	author = {Tao, Runzhou and Yao, Jianan and Li, Xupeng and Li, Shih-Wei and Nieh, Jason and Gu, Ronghui},
	urldate = {2021-11-01},
	date = {2021-10-26},
	keywords = {Formal methods, Arm, hypervisors, {KVM}, relaxed memory, systems verification},
	file = {Full Text PDF:/home/fordrl/Zotero/storage/IY4SDW7H/Tao et al. - 2021 - Formal Verification of a Multiprocessor Hypervisor.pdf:application/pdf},
}

@online{noauthor_theorem_nodate-1,
	title = {Theorem Proving and the Real Numbers: Overview Proving and the Real Numbers: Overview and Challenges Lawrence C. Paulson Computer Laboratory, University of Cambridge, England lp15@cl.cam.ac.uk - [Download {PDF}]},
	url = {https://vdocuments.mx/theorem-proving-and-the-real-numbers-overview-proving-and-the-real-numbers.html},
	shorttitle = {Theorem Proving and the Real Numbers},
	abstract = {Download theorem proving and the real numbers: overview proving and the real numbers: overview and challenges lawrence c. paulson computer laboratory, university of...},
	titleaddon = {vdocuments.mx},
	urldate = {2021-11-01},
	langid = {english},
	file = {Snapshot:/home/fordrl/Zotero/storage/7G5A9D8K/theorem-proving-and-the-real-numbers-overview-proving-and-the-real-numbers.html:text/html},
}

@article{frumin_reloc_2021,
	title = {{ReLoC} Reloaded: A Mechanized Relational Logic for Fine-Grained Concurrency and Logical Atomicity},
	volume = {Volume 17, Issue 3},
	issn = {1860-5974},
	url = {https://lmcs.episciences.org/6598},
	doi = {10.46298/lmcs-17(3:9)2021},
	shorttitle = {{ReLoC} Reloaded},
	abstract = {We present a new version of {ReLoC}: a relational separation logic for proving reﬁnements of programs with higher-order state, ﬁne-grained concurrency, polymorphism and recursive types. The core of {ReLoC} is its reﬁnement judgment e e : τ , which states that a program e reﬁnes a program e at type τ . {ReLoC} provides type-directed structural rules and symbolic execution rules in separation-logic style for manipulating the judgment, whereas in prior work on reﬁnements for languages with higher-order state and concurrency, such proofs were carried out by unfolding the judgment into its deﬁnition in the model. {ReLoC}’s abstract proof rules make it simpler to carry out reﬁnement proofs, and enable us to generalize the notion of logically atomic speciﬁcations to the relational case, which we call logically atomic relational speciﬁcations.},
	pages = {6598},
	journaltitle = {Logical Methods in Computer Science},
	author = {Frumin, Dan and Krebbers, Robbert and Birkedal, Lars},
	urldate = {2021-10-26},
	date = {2021-07-27},
	langid = {english},
	file = {Frumin et al. - 2021 - ReLoC Reloaded A Mechanized Relational Logic for .pdf:/home/fordrl/Zotero/storage/F2WR4824/Frumin et al. - 2021 - ReLoC Reloaded A Mechanized Relational Logic for .pdf:application/pdf},
}

@unpublished{mirliaz_flow-insensitive-complete_2021,
	title = {A Flow-Insensitive-Complete Program Representation},
	url = {https://hal.archives-ouvertes.fr/hal-03384612},
	abstract = {When designing a static analysis, choosing between a flowinsensitive or a flow-sensitive analysis often amounts to favor scalability over precision. It is well known than specific program representations can help to reconcile the two objectives at the same time. For example the {SSA} representation is used in modern compilers to perform a constant propagation analysis flow-insensitively without any loss of precision. This paper proposes a provably correct program transformation that reconciles them for any analysis. We formalize the notion of Flow-Insensitive-Completeness with two collecting semantics and provide a program transformation that permits to analyze a program in a flow insensitive manner without sacrificing the precision we could obtain with a flow sensitive approach.},
	author = {Mirliaz, Solène and Pichardie, David},
	urldate = {2021-10-26},
	date = {2021-10},
	file = {HAL PDF Full Text:/home/fordrl/Zotero/storage/ANEBAZF8/Mirliaz and Pichardie - 2021 - A Flow-Insensitive-Complete Program Representation.pdf:application/pdf},
}

@article{balajorshari_better_nodate,
	title = {Better Program Analysis for Security via Data Flow Tracking and Symbolic Execution},
	pages = {92},
	author = {Balajorshari, Navid Emamdoost and {McCamant}, Stephen},
	langid = {english},
	file = {Balajorshari and McCamant - Better Program Analysis for Security via Data Flow.pdf:/home/fordrl/Zotero/storage/76ZUIKDC/Balajorshari and McCamant - Better Program Analysis for Security via Data Flow.pdf:application/pdf},
}

@article{yao_program_2021,
	title = {Program analysis via efficient symbolic abstraction},
	volume = {5},
	url = {https://doi.org/10.1145/3485495},
	doi = {10.1145/3485495},
	abstract = {This paper concerns the scalability challenges of symbolic abstraction: given a formula ϕ in a logic L and an abstract domain A, find a most precise element in the abstract domain that over-approximates the meaning of ϕ. Symbolic abstraction is an important point in the space of abstract interpretation, as it allows for automatically synthesizing the best abstract transformers. However, current techniques for symbolic abstraction can have difficulty delivering on its practical strengths, due to performance issues. In this work, we introduce two algorithms for the symbolic abstraction of quantifier-free bit-vector formulas, which apply to the bit-vector interval domain and a certain kind of polyhedral domain, respectively. We implement and evaluate the proposed techniques on two machine code analysis clients, namely static memory corruption analysis and constrained random fuzzing. Using a suite of 57,933 queries from the clients, we compare our approach against a diverse group of state-of-the-art algorithms. The experiments show that our algorithms achieve a substantial speedup over existing techniques and illustrate significant precision advantages for the clients. Our work presents strong evidence that symbolic abstraction of numeric domains can be efficient and practical for large and realistic programs.},
	pages = {118:1--118:32},
	issue = {{OOPSLA}},
	journaltitle = {Proceedings of the {ACM} on Programming Languages},
	shortjournal = {Proc. {ACM} Program. Lang.},
	author = {Yao, Peisen and Shi, Qingkai and Huang, Heqing and Zhang, Charles},
	urldate = {2021-10-24},
	date = {2021-10-15},
	keywords = {optimization, Abstract interpretation, interval domain, polyhedral domain, symbolic abstraction},
	file = {Full Text PDF:/home/fordrl/Zotero/storage/4B6R8A9R/Yao et al. - 2021 - Program analysis via efficient symbolic abstractio.pdf:application/pdf},
}

@article{paraskevopoulou_compiling_2021,
	title = {Compiling with continuations, correctly},
	volume = {5},
	url = {https://doi.org/10.1145/3485491},
	doi = {10.1145/3485491},
	abstract = {In this paper we present a novel simulation relation for proving correctness of program transformations that combines syntactic simulations and logical relations. In particular, we establish a new kind of simulation diagram that uses a small-step or big-step semantics in the source language and an untyped, step-indexed logical relation in the target language. Our technique provides a practical solution for proving semantics preservation for transformations that do not preserve reductions in the source language. This is common when transformations generate new binder names, and hence α-conversion must be explicitly accounted for, or when transformations introduce administrative redexes. Our technique does not require reductions in the source language to correspond directly to reductions in the target language. Instead, we enforce a weaker notion of semantic preorder, which suffices to show that semantics are preserved for both whole-program and separate compilation. Because our logical relation is transitive, we can transition between intermediate program states in a small-step fashion and hence the shape of the proof resembles that of a simple small-step simulation. We use this technique to revisit the semantic correctness of a continuation-passing style ({CPS}) transformation and we demonstrate how it allows us to overcome well-known complications of this proof related to α-conversion and administrative reductions. In addition, by using a logical relation that is indexed by invariants that relate the resource consumption of two programs, we are able show that the transformation preserves diverging behaviors and that our {CPS} transformation asymptotically preserves the running time of the source program. Our results are formalized in the Coq proof assistant. Our continuation-passing style transformation is part of the {CertiCoq} compiler for Gallina, the specification language of Coq.},
	pages = {114:1--114:29},
	issue = {{OOPSLA}},
	journaltitle = {Proceedings of the {ACM} on Programming Languages},
	shortjournal = {Proc. {ACM} Program. Lang.},
	author = {Paraskevopoulou, Zoe and Grover, Anvay},
	urldate = {2021-10-24},
	date = {2021-10-15},
	keywords = {logical relations, compiler correctness, continuation-passing style, simulations},
	file = {Full Text PDF:/home/fordrl/Zotero/storage/B3FWY8BX/Paraskevopoulou and Grover - 2021 - Compiling with continuations, correctly.pdf:application/pdf},
}

@article{lanzinger_scalability_2021,
	title = {Scalability and precision by combining expressive type systems and deductive verification},
	volume = {5},
	url = {https://doi.org/10.1145/3485520},
	doi = {10.1145/3485520},
	abstract = {Type systems and modern type checkers can be used very successfully to obtain formal correctness guarantees with little specification overhead. However, type systems in practical scenarios have to trade precision for decidability and scalability. Tools for deductive verification, on the other hand, can prove general properties in more cases than a typical type checker can, but they do not scale well. We present a method to complement the scalability of expressive type systems with the precision of deductive program verification approaches. This is achieved by translating the type uses whose correctness the type checker cannot prove into assertions in a specification language, which can be dealt with by a deductive verification tool. Type uses whose correctness the type checker can prove are instead turned into assumptions to aid the verification tool in finding a proof.Our novel approach is introduced both conceptually for a simple imperative language, and practically by a concrete implementation for the Java programming language. The usefulness and power of our approach has been evaluated by discharging known false positives from a real-world program and by a small case study.},
	pages = {143:1--143:29},
	issue = {{OOPSLA}},
	journaltitle = {Proceedings of the {ACM} on Programming Languages},
	shortjournal = {Proc. {ACM} Program. Lang.},
	author = {Lanzinger, Florian and Weigl, Alexander and Ulbrich, Mattias and Dietl, Werner},
	urldate = {2021-10-24},
	date = {2021-10-15},
	keywords = {Deductive verification, Pluggable type systems, Refinement types},
	file = {Full Text PDF:/home/fordrl/Zotero/storage/V5DMU832/Lanzinger et al. - 2021 - Scalability and precision by combining expressive .pdf:application/pdf},
}

@article{lubin_how_2021,
	title = {How statically-typed functional programmers write code},
	volume = {5},
	url = {https://doi.org/10.1145/3485532},
	doi = {10.1145/3485532},
	abstract = {How working statically-typed functional programmers write code is largely understudied. And yet, a better understanding of developer practices could pave the way for the design of more useful and usable tooling, more ergonomic languages, and more effective on-ramps into programming communities. The goal of this work is to address this knowledge gap: to better understand the high-level authoring patterns that statically-typed functional programmers employ. We conducted a grounded theory analysis of 30 programming sessions of practicing statically-typed functional programmers, 15 of which also included a semi-structured interview. The theory we developed gives insight into how the specific affordances of statically-typed functional programming affect domain modeling, type construction, focusing techniques, exploratory and reasoning strategies, and expressions of intent. We conducted a set of quantitative lab experiments to validate our findings, including that statically-typed functional programmers often iterate between editing types and expressions, that they often run their compiler on code even when they know it will not successfully compile, and that they make textual program edits that reliably signal future edits that they intend to make. Lastly, we outline the implications of our findings for language and tool design. The success of this approach in revealing program authorship patterns suggests that the same methodology could be used to study other understudied programmer populations.},
	pages = {155:1--155:30},
	issue = {{OOPSLA}},
	journaltitle = {Proceedings of the {ACM} on Programming Languages},
	shortjournal = {Proc. {ACM} Program. Lang.},
	author = {Lubin, Justin and Chasins, Sarah E.},
	urldate = {2021-10-24},
	date = {2021-10-15},
	keywords = {functional programming, grounded theory, interviews, mixed methods, need-finding, qualitative, quantitative, randomized controlled trial, static types},
	file = {Full Text PDF:/home/fordrl/Zotero/storage/RLG4GDU8/Lubin and Chasins - 2021 - How statically-typed functional programmers write .pdf:application/pdf},
}

@article{sinkarovs_extracting_2021,
	title = {Extracting the Power of Dependent Types},
	abstract = {Most existing programming languages provide little support to formally state and prove properties about programs. Adding such capabilities is far from trivial, as it requires significant re-engineering of the existing compilers and tools. This paper proposes a novel technique to write correct-byconstruction programs in languages without built-in verification capabilities, while maintaining the ability to use existing tools. This is achieved in three steps. Firstly, we give a shallow embedding of the language (or a subset) into a dependently typed language. Secondly, we write a program in that embedding, and we use dependent types to guarantee correctness properties of interest within the embedding. Thirdly, we extract a program written in the original language, so it can be used with existing compilers and tools.},
	pages = {13},
	author = {Šinkarovs, Artjoms and Cockx, Jesper},
	date = {2021},
	langid = {english},
	file = {Šinkarovs and Cockx - 2021 - Extracting the Power of Dependent Types.pdf:/home/fordrl/Zotero/storage/UEUTB2HC/Šinkarovs and Cockx - 2021 - Extracting the Power of Dependent Types.pdf:application/pdf},
}

@article{fu_label_2021,
	title = {Label dependent lambda calculus and gradual typing},
	volume = {5},
	url = {https://doi.org/10.1145/3485485},
	doi = {10.1145/3485485},
	abstract = {Dependently-typed programming languages are gaining importance, because they can guarantee a wide range of properties at compile time. Their use in practice is often hampered because programmers have to provide very precise types. Gradual typing is a means to vary the level of typing precision between program fragments and to transition smoothly towards more precisely typed programs. The combination of gradual typing and dependent types seems promising to promote the widespread use of dependent types. We investigate a gradual version of a minimalist value-dependent lambda calculus. Compile-time calculations and thus dependencies are restricted to labels, drawn from a generic enumeration type. The calculus supports the usual Pi and Sigma types as well as singleton types and subtyping. It is sufficiently powerful to provide flexible encodings of variant and record types with first-class labels. We provide type checking algorithms for the underlying label-dependent lambda calculus and its gradual extension. The gradual type checker drives the translation into a cast calculus, which extends the original language. The cast calculus comes with several innovations: refined typing for casts in the presence of singletons, type reduction in casts, and fully dependent Sigma types. Besides standard metatheoretical results, we establish the gradual guarantee for the gradual language.},
	pages = {108:1--108:29},
	issue = {{OOPSLA}},
	journaltitle = {Proceedings of the {ACM} on Programming Languages},
	shortjournal = {Proc. {ACM} Program. Lang.},
	author = {Fu, Weili and Krause, Fabian and Thiemann, Peter},
	urldate = {2021-10-24},
	date = {2021-10-15},
	keywords = {dependent types, gradual type systems, subtyping},
	file = {Full Text PDF:/home/fordrl/Zotero/storage/LXXLQFLA/Fu et al. - 2021 - Label dependent lambda calculus and gradual typing.pdf:application/pdf},
}

@article{chaliasos_well-typed_2021,
	title = {Well-typed programs can go wrong: a study of typing-related bugs in {JVM} compilers},
	volume = {5},
	url = {https://doi.org/10.1145/3485500},
	doi = {10.1145/3485500},
	shorttitle = {Well-typed programs can go wrong},
	abstract = {Despite the substantial progress in compiler testing, research endeavors have mainly focused on detecting compiler crashes and subtle miscompilations caused by bugs in the implementation of compiler optimizations. Surprisingly, this growing body of work neglects other compiler components, most notably the front-end. In statically-typed programming languages with rich and expressive type systems and modern features, such as type inference or a mix of object-oriented with functional programming features, the process of static typing in compiler front-ends is complicated by a high-density of bugs. Such bugs can lead to the acceptance of incorrect programs (breaking code portability or the type system's soundness), the rejection of correct (e.g. well-typed) programs, and the reporting of misleading errors and warnings. We conduct, what is to the best of our knowledge, the first empirical study for understanding and characterizing typing-related compiler bugs. To do so, we manually study 320 typing-related bugs (along with their fixes and test cases) that are randomly sampled from four mainstream {JVM} languages, namely Java, Scala, Kotlin, and Groovy. We evaluate each bug in terms of several aspects, including their symptom, root cause, bug fix's size, and the characteristics of the bug-revealing test cases. Some representative observations indicate that: (1) more than half of the typing-related bugs manifest as unexpected compile-time errors: the buggy compiler wrongly rejects semantically correct programs, (2) the majority of typing-related bugs lie in the implementations of the underlying type systems and in other core components related to operations on types, (3) parametric polymorphism is the most pervasive feature in the corresponding test cases, (4) one third of typing-related bugs are triggered by non-compilable programs. We believe that our study opens up a new research direction by driving future researchers to build appropriate methods and techniques for a more holistic testing of compilers.},
	pages = {123:1--123:30},
	issue = {{OOPSLA}},
	journaltitle = {Proceedings of the {ACM} on Programming Languages},
	shortjournal = {Proc. {ACM} Program. Lang.},
	author = {Chaliasos, Stefanos and Sotiropoulos, Thodoris and Drosos, Georgios-Petros and Mitropoulos, Charalambos and Mitropoulos, Dimitris and Spinellis, Diomidis},
	urldate = {2021-10-24},
	date = {2021-10-15},
	keywords = {Java, compiler bugs, compiler testing, Groovy, Kotlin, Scala, static typing},
	file = {Full Text PDF:/home/fordrl/Zotero/storage/IRTUZNEC/Chaliasos et al. - 2021 - Well-typed programs can go wrong a study of typin.pdf:application/pdf},
}

@article{bao_reachability_2021,
	title = {Reachability types: tracking aliasing and separation in higher-order functional programs},
	volume = {5},
	url = {https://doi.org/10.1145/3485516},
	doi = {10.1145/3485516},
	shorttitle = {Reachability types},
	abstract = {Ownership type systems, based on the idea of enforcing unique access paths, have been primarily focused on objects and top-level classes. However, existing models do not as readily reflect the finer aspects of nested lexical scopes, capturing, or escaping closures in higher-order functional programming patterns, which are increasingly adopted even in mainstream object-oriented languages. We present a new type system, λ* , which enables expressive ownership-style reasoning across higher-order functions. It tracks sharing and separation through reachability sets, and layers additional mechanisms for selectively enforcing uniqueness on top of it. Based on reachability sets, we extend the type system with an expressive flow-sensitive effect system, which enables flavors of move semantics and ownership transfer. In addition, we present several case studies and extensions, including applications to capabilities for algebraic effects, one-shot continuations, and safe parallelization.},
	pages = {139:1--139:32},
	issue = {{OOPSLA}},
	journaltitle = {Proceedings of the {ACM} on Programming Languages},
	shortjournal = {Proc. {ACM} Program. Lang.},
	author = {Bao, Yuyan and Wei, Guannan and Bračevac, Oliver and Jiang, Yuxuan and He, Qiyang and Rompf, Tiark},
	urldate = {2021-10-24},
	date = {2021-10-15},
	keywords = {type systems, aliasing, effect systems, ownership types, reachability types},
	file = {Full Text PDF:/home/fordrl/Zotero/storage/BNVSKCUN/Bao et al. - 2021 - Reachability types tracking aliasing and separati.pdf:application/pdf},
}

@article{chaliasos_well-typed_2021-1,
	title = {Well-typed programs can go wrong: a study of typing-related bugs in {JVM} compilers},
	volume = {5},
	issn = {2475-1421},
	url = {https://dl.acm.org/doi/10.1145/3485500},
	doi = {10.1145/3485500},
	shorttitle = {Well-typed programs can go wrong},
	abstract = {{STEFANOS} {CHALIASOS}∗, Athens University of Economics and Business, Greece {THODORIS} {SOTIROPOULOS}∗, Athens University of Economics and Business, Greece {GEORGIOS}-{PETROS} {DROSOS}, Athens University of Economics and Business, Greece {CHARALAMBOS} {MITROPOULOS}, Technical University of Crete, Greece {DIMITRIS} {MITROPOULOS}, University of Athens, Greece {DIOMIDIS} {SPINELLIS}, Athens University of Economics and Business, Greece and Delft University of Technology, Netherlands Despite the substantial progress in compiler testing, research endeavors have mainly focused on detecting compiler crashes and subtle miscompilations caused by bugs in the implementation of compiler optimizations. Surprisingly, this growing body of work neglects other compiler components, most notably the front-end. In statically-typed programming languages with rich and expressive type systems and modern features, such as type inference or a mix of object-oriented with functional programming features, the process of static typing in compiler front-ends is complicated by a high-density of bugs. Such bugs can lead to the acceptance of incorrect programs (breaking code portability or the type system’s soundness), the rejection of correct (e.g. well-typed) programs, and the reporting of misleading errors and warnings. We conduct, what is to the best of our knowledge, the first empirical study for understanding and characterizing typing-related compiler bugs. To do so, we manually study 320 typing-related bugs (along with their fixes and test cases) that are randomly sampled from four mainstream {JVM} languages, namely Java, Scala, Kotlin, and Groovy. We evaluate each bug in terms of several aspects, including their symptom, root cause, bug fix’s size, and the characteristics of the bug-revealing test cases. Some representative observations indicate that: (1) more than half of the typing-related bugs manifest as unexpected compile-time errors: the buggy compiler wrongly rejects semantically correct programs, (2) the majority of typing-related bugs lie in the implementations of the underlying type systems and in other core components related to operations on types, (3) parametric polymorphism is the most pervasive feature in the corresponding test cases, (4) one third of typing-related bugs are triggered by non-compilable programs. We believe that our study opens up a new research direction by driving future researchers to build appropriate methods and techniques for a more holistic testing of compilers. {CCS} Concepts: • Software and its engineering → Compilers; Software testing and debugging.},
	pages = {1--30},
	issue = {{OOPSLA}},
	journaltitle = {Proceedings of the {ACM} on Programming Languages},
	shortjournal = {Proc. {ACM} Program. Lang.},
	author = {Chaliasos, Stefanos and Sotiropoulos, Thodoris and Drosos, Georgios-Petros and Mitropoulos, Charalambos and Mitropoulos, Dimitris and Spinellis, Diomidis},
	urldate = {2021-10-24},
	date = {2021-10-20},
	langid = {english},
	file = {Chaliasos et al. - 2021 - Well-typed programs can go wrong a study of typin.pdf:/home/fordrl/Zotero/storage/BP5S92KZ/Chaliasos et al. - 2021 - Well-typed programs can go wrong a study of typin.pdf:application/pdf},
}

@article{chaliasos_well-typed_2021-2,
	title = {Well-typed programs can go wrong: a study of typing-related bugs in {JVM} compilers},
	volume = {5},
	issn = {2475-1421},
	url = {https://dl.acm.org/doi/10.1145/3485500},
	doi = {10.1145/3485500},
	shorttitle = {Well-typed programs can go wrong},
	abstract = {{STEFANOS} {CHALIASOS}∗, Athens University of Economics and Business, Greece {THODORIS} {SOTIROPOULOS}∗, Athens University of Economics and Business, Greece {GEORGIOS}-{PETROS} {DROSOS}, Athens University of Economics and Business, Greece {CHARALAMBOS} {MITROPOULOS}, Technical University of Crete, Greece {DIMITRIS} {MITROPOULOS}, University of Athens, Greece {DIOMIDIS} {SPINELLIS}, Athens University of Economics and Business, Greece and Delft University of Technology, Netherlands Despite the substantial progress in compiler testing, research endeavors have mainly focused on detecting compiler crashes and subtle miscompilations caused by bugs in the implementation of compiler optimizations. Surprisingly, this growing body of work neglects other compiler components, most notably the front-end. In statically-typed programming languages with rich and expressive type systems and modern features, such as type inference or a mix of object-oriented with functional programming features, the process of static typing in compiler front-ends is complicated by a high-density of bugs. Such bugs can lead to the acceptance of incorrect programs (breaking code portability or the type system’s soundness), the rejection of correct (e.g. well-typed) programs, and the reporting of misleading errors and warnings. We conduct, what is to the best of our knowledge, the first empirical study for understanding and characterizing typing-related compiler bugs. To do so, we manually study 320 typing-related bugs (along with their fixes and test cases) that are randomly sampled from four mainstream {JVM} languages, namely Java, Scala, Kotlin, and Groovy. We evaluate each bug in terms of several aspects, including their symptom, root cause, bug fix’s size, and the characteristics of the bug-revealing test cases. Some representative observations indicate that: (1) more than half of the typing-related bugs manifest as unexpected compile-time errors: the buggy compiler wrongly rejects semantically correct programs, (2) the majority of typing-related bugs lie in the implementations of the underlying type systems and in other core components related to operations on types, (3) parametric polymorphism is the most pervasive feature in the corresponding test cases, (4) one third of typing-related bugs are triggered by non-compilable programs. We believe that our study opens up a new research direction by driving future researchers to build appropriate methods and techniques for a more holistic testing of compilers. {CCS} Concepts: • Software and its engineering → Compilers; Software testing and debugging.},
	pages = {1--30},
	issue = {{OOPSLA}},
	journaltitle = {Proceedings of the {ACM} on Programming Languages},
	shortjournal = {Proc. {ACM} Program. Lang.},
	author = {Chaliasos, Stefanos and Sotiropoulos, Thodoris and Drosos, Georgios-Petros and Mitropoulos, Charalambos and Mitropoulos, Dimitris and Spinellis, Diomidis},
	urldate = {2021-10-24},
	date = {2021-10-20},
	langid = {english},
	file = {Chaliasos et al. - 2021 - Well-typed programs can go wrong a study of typin.pdf:/home/fordrl/Zotero/storage/IWP45D43/Chaliasos et al. - 2021 - Well-typed programs can go wrong a study of typin.pdf:application/pdf},
}

@article{he_type_2021,
	title = {A type system for extracting functional specifications from memory-safe imperative programs},
	volume = {5},
	issn = {2475-1421},
	url = {https://dl.acm.org/doi/10.1145/3485512},
	doi = {10.1145/3485512},
	abstract = {{PAUL} {HE}, University of Pennsylvania, {USA} {EDDY} {WESTBROOK}, Galois, Inc., {USA} {BRENT} {CARMER}, Galois, Inc., {USA} {CHRIS} {PHIFER}, Galois, Inc., {USA} {VALENTIN} {ROBERT}, Galois, Inc., {USA} {KARL} {SMELTZER}, Galois, Inc., {USA} {ANDREI} Ş{TEFĂNESCU}, Galois, Inc., {USA} {AARON} {TOMB}, Galois, Inc., {USA} {ADAM} {WICK}, Galois, Inc., {USA} {MATTHEW} {YACAVONE}, Galois, Inc., {USA} {STEVE} {ZDANCEWIC}, University of Pennsylvania, {USA} Verifying imperative programs is hard. A key difficulty is that the specification of what an imperative program does is often intertwined with details about pointers and imperative state. Although there are a number of powerful separation logics that allow the details of imperative state to be captured and managed, these details are complicated and reasoning about them requires significant time and expertise. In this paper, we take a different approach: a memory-safe type system that, as part of type-checking, extracts functional specifications from imperative programs. This disentangles imperative state, which is handled by the type system, from functional specifications, which can be verified without reference to pointers. A key difficulty is that sometimes memory safety depends crucially on the functional specification of a program; e.g., an array index is only memory-safe if the index is in bounds. To handle this case, our specification extraction inserts dynamic checks into the specification. Verification then requires the additional proof that none of these checks fail. However, these checks are in a purely functional language, and so this proof also requires no reasoning about pointers. {CCS} Concepts: • Software and its engineering → Software verification; • Theory of computation → Program specifications; Type structures.},
	pages = {1--29},
	issue = {{OOPSLA}},
	journaltitle = {Proceedings of the {ACM} on Programming Languages},
	shortjournal = {Proc. {ACM} Program. Lang.},
	author = {He, Paul and Westbrook, Eddy and Carmer, Brent and Phifer, Chris and Robert, Valentin and Smeltzer, Karl and Ştefănescu, Andrei and Tomb, Aaron and Wick, Adam and Yacavone, Matthew and Zdancewic, Steve},
	urldate = {2021-10-18},
	date = {2021-10-20},
	langid = {english},
	file = {He et al. - 2021 - A type system for extracting functional specificat.pdf:/home/fordrl/Zotero/storage/GGISHZBP/He et al. - 2021 - A type system for extracting functional specificat.pdf:application/pdf},
}

@article{appel_efficient_2021,
	title = {Efficient Extensional Binary Tries},
	url = {http://arxiv.org/abs/2110.05063},
	abstract = {Lookup tables (finite maps) are a ubiquitous data structure. In pure functional languages they are best represented using trees instead of hash tables. In pure functional languages within constructive logic, without a primitive integer type, they are well represented using binary tries instead of search trees. In this work, we introduce canonical binary tries, an improved binary-trie data structure that enjoys a natural extensionality property, quite useful in proofs, and supports sparseness more efficiently. We provide full proofs of correctness in Coq. We provide microbenchmark measurements of canonical binary tries versus several other data structures for finite maps, in a variety of application contexts; as well as measurement of canonical versus original tries in a big, real system. The application context of data structures contained in theorem statements imposes unusual requirements for which canonical tries are particularly well suited.},
	journaltitle = {{arXiv}:2110.05063 [cs]},
	author = {Appel, Andrew and Leroy, Xavier},
	urldate = {2021-10-18},
	date = {2021-10-11},
	eprinttype = {arxiv},
	eprint = {2110.05063},
	keywords = {Computer Science - Programming Languages, Computer Science - Logic in Computer Science},
	file = {arXiv.org Snapshot:/home/fordrl/Zotero/storage/KEYJT8KJ/2110.html:text/html;arXiv Fulltext PDF:/home/fordrl/Zotero/storage/4KPHUSVJ/Appel and Leroy - 2021 - Efficient Extensional Binary Tries.pdf:application/pdf},
}

@article{yan_secrsl_nodate,
	title = {{SecRSL}: Security Separation Logic for C11 Release-Acquire Concurrency},
	volume = {5},
	pages = {26},
	author = {Yan, Pengbo and Murray, Toby},
	langid = {english},
	file = {Yan and Murray - SecRSL Security Separation Logic for C11 Release-.pdf:/home/fordrl/Zotero/storage/YMDTJSAK/Yan and Murray - SecRSL Security Separation Logic for C11 Release-.pdf:application/pdf},
}

@thesis{subramaniam_dependent_2021,
	title = {From dependent type theory to higher algebraic structures},
	url = {http://arxiv.org/abs/2110.02804},
	abstract = {The first part of this dissertation defines "dependently typed algebraic theories", which are a strict subclass of the generalised algebraic theories ({GATs}) of Cartmell. We characterise dependently typed algebraic theories as finitary monads on certain presheaf categories, generalising a well-known result due to Lawvere, B{\textbackslash}'enabou and Linton for ordinary multisorted algebraic theories. We use this to recognise dependently typed algebraic theories for a number of classes of algebraic structures, such as small categories, n-categories, strict and weak omega-categories, planar coloured operads and opetopic sets. We then show that every locally finitely presentable category is the category of models of some dependently typed algebraic theory. Thus, with respect to their Set-models, these theories are just as expressive as {GATs}, essentially algebraic theories and finite limit sketches. However, dependently typed algebraic theories admit a good definition of homotopy-models in spaces, via a left Bousfield localisation of a global model structure on simplicial presheaves. Some cases, such as certain "idempotent opetopic theories", have a rigidification theorem relating homotopy-models and (strict) simplicial models. The second part of this dissertation concerns localisations of presentable \$({\textbackslash}infty,1)\$-categories. We give a definition of "pre-modulator", and show that every accessible orthogonal factorisation system on a presentable \$({\textbackslash}infty,1)\$-category can be generated from a pre-modulator by iterating a plus-construction resembling that of sheafification. We give definitions of "modulator" and "left-exact modulator", and prove that they correspond to those factorisation systems that are modalities and left-exact modalities respectively. Thus every left-exact localisation of an \${\textbackslash}infty\$-topos is obtained by iterating the plus-construction associated to a left-exact modulator.},
	pagetotal = {155},
	type = {phdthesis},
	author = {Subramaniam, Chaitanya Leena},
	urldate = {2021-10-13},
	date = {2021-10-06},
	eprinttype = {arxiv},
	eprint = {2110.02804},
	keywords = {Mathematics - Category Theory, 18C10, 18C35, 18N40, 18N60},
	file = {arXiv.org Snapshot:/home/fordrl/Zotero/storage/43I2EWFX/2110.html:text/html;arXiv Fulltext PDF:/home/fordrl/Zotero/storage/IZZ7PVT9/Subramaniam - 2021 - From dependent type theory to higher algebraic str.pdf:application/pdf},
}

@article{kamburjan_deductive_2021,
	title = {Deductive Verification of Programs with Underspecified Semantics by Model Extraction},
	url = {http://arxiv.org/abs/2110.01964},
	abstract = {We present a novel and well automatable approach to formal veriﬁcation of programs with underspeciﬁed semantics, i.e., a language semantics that leaves open the order of certain evaluations. First, we reduce this problem to non-determinism of distributed systems, automatically extracting a distributed Active Object model from underspeciﬁed, sequential C code. This translation process provides a fully formal semantics for the considered C subset. In the extracted model every nondeterministic choice corresponds to one possible evaluation order. This step also automatically translates speciﬁcations in the {ANSI}/{ISO} C Speciﬁcation Language ({ACSL}) into method contracts and object invariants for Active Objects. We then perform veriﬁcation on the speciﬁed Active Objects model. For this we have implemented a theorem prover Crowbar based on the Behavioral Program Logic ({BPL}), which veriﬁes the extracted model with respect to the translated speciﬁcation and ensures the original property of the C code for all possible evaluation orders. By using model extraction, we can use standard tools, without designing a new complex program logic to deal with underspeciﬁcation. The case study used is highly underspeciﬁed and cannot be veriﬁed with existing tools for C.},
	journaltitle = {{arXiv}:2110.01964 [cs]},
	author = {Kamburjan, Eduard and Wasser, Nathan},
	urldate = {2021-10-12},
	date = {2021-10-05},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {2110.01964},
	keywords = {Computer Science - Programming Languages, Computer Science - Logic in Computer Science},
	file = {Kamburjan and Wasser - 2021 - Deductive Verification of Programs with Underspeci.pdf:/home/fordrl/Zotero/storage/E3WY5EP6/Kamburjan and Wasser - 2021 - Deductive Verification of Programs with Underspeci.pdf:application/pdf},
}

@article{lin_interactive_2021,
	title = {An Interactive Theorem Prover for Matching Logic with Proof Object Generation},
	abstract = {Matching logic is a uniform logical foundation for K, which is a language semantics framework with the philosophy that all tooling around a language should be automatically generated from a single, rigorous deﬁnition of its formal semantics. In practice, K has been widely used to deﬁne the formal semantics of many real-world languages and to generate their execution and veriﬁcation tools. However, there lacks a generic theorem prover that connects K with its logical foundation—matching logic. In this paper, we present {ITPML}, which is the ﬁrst interactive theorem prover for matching logic. The main advantage of {ITPML} is its ability to generate machine-checkable proof objects as certiﬁcates that witness the correctness of its formal reasoning. {ITPML} is built on top of Metamath, a language to deﬁne formal systems, which allows it to have a small trust base of only 250 lines of code. {ITPML} supports both backward and forward proofs, allows users to dynamically add intermediate lemmas, and features automated proof tactics for common utilities such as reasoning about notations and proving propositional tautologies.},
	pages = {12},
	author = {Lin, Zhengyao and Chen, Xiaohong and Roşu, Grigore},
	date = {2021-10-05},
	langid = {english},
	file = {Lin et al. - An Interactive Theorem Prover for Matching Logic w.pdf:/home/fordrl/Zotero/storage/FKCEPKTQ/Lin et al. - An Interactive Theorem Prover for Matching Logic w.pdf:application/pdf},
}

@incollection{apt_assessing_2021,
	location = {New York, {NY}, {USA}},
	edition = {1},
	title = {Assessing the Success and Impact of Hoare's Logic},
	volume = {39},
	isbn = {978-1-4503-8728-6},
	url = {https://doi.org/10.1145/3477355.3477359},
	pages = {41--76},
	booktitle = {Theories of Programming: The Life and Works of Tony Hoare},
	publisher = {Association for Computing Machinery},
	author = {Apt, Krzysztof R. and Olderog, Ernst-Rüdiger},
	urldate = {2021-10-12},
	date = {2021-10-04},
	file = {Full Text PDF:/home/fordrl/Zotero/storage/9KTJ7C4H/Apt and Olderog - 2021 - Assessing the Success and Impact of Hoare&#x2019\;s.pdf:application/pdf},
}

@incollection{muller_first_2021,
	location = {New York, {NY}, {USA}},
	edition = {1},
	title = {The First Fifteen Years of the Verified Software Project},
	volume = {39},
	isbn = {978-1-4503-8728-6},
	url = {https://doi.org/10.1145/3477355.3477362},
	pages = {93--124},
	booktitle = {Theories of Programming: The Life and Works of Tony Hoare},
	publisher = {Association for Computing Machinery},
	author = {Müller, Peter and Shankar, Natarajan},
	urldate = {2021-10-12},
	date = {2021-10-04},
	file = {Full Text PDF:/home/fordrl/Zotero/storage/UGEK2Y9I/Müller and Shankar - 2021 - The First Fifteen Years of the Verified Software P.pdf:application/pdf},
}

@article{pujet_observational_2022,
	title = {Observational Equality: Now For Good},
	pages = {29},
	author = {Pujet, Loïc and Tabareau, Nicolas},
	date = {2022},
	langid = {english},
	file = {Pujet and Tabareau - 2022 - Observational Equality Now For Good.pdf:/home/fordrl/Zotero/storage/QD3SG99X/Pujet and Tabareau - 2022 - Observational Equality Now For Good.pdf:application/pdf},
}

@thesis{koch_mechanizing_nodate,
	location = {8/23/2021},
	title = {Mechanizing Second-Order Logic in Coq},
	pagetotal = {102},
	institution = {Saarland University},
	type = {Bachelor's Thesis},
	author = {Koch, Mark},
	langid = {english},
	file = {Smolka and Finkbeiner - Submitted 23rd August 202.pdf:/home/fordrl/Zotero/storage/UYLDTBFL/Smolka and Finkbeiner - Submitted 23rd August 202.pdf:application/pdf},
}

@thesis{watt_mechanising_2021,
	location = {Cambridge, {UK}},
	title = {Mechanising and evolving the formal semantics of {WebAssembly}: the Web's new low-level language},
	pagetotal = {176},
	institution = {St Catharine's College, University of Cambridge},
	type = {phdthesis},
	author = {Watt, Conrad},
	date = {2021-02-05},
	langid = {english},
	file = {Watt - Mechanising and evolving the formal semantics of W.pdf:/home/fordrl/Zotero/storage/LL59WQK3/Watt - Mechanising and evolving the formal semantics of W.pdf:application/pdf},
}

@article{bornholt_using_2021,
	title = {Using Lightweight Formal Methods to Validate a Key-Value Storage Node in Amazon S3},
	abstract = {This paper reports our experience applying lightweight formal methods to validate the correctness of {ShardStore}, a new key-value storage node implementation for the Amazon S3 cloud object storage service. By “lightweight formal methodsž we mean a pragmatic approach to verifying the correctness of a production storage node that is under ongoing feature development by a full-time engineering team. We do not aim to achieve full formal verification, but instead emphasize automation, usability, and the ability to continually ensure correctness as both software and its specification evolve over time. Our approach decomposes correctness into independent properties, each checked by the most appropriate tool, and develops executable reference models as specifications to be checked against the implementation. Our work has prevented 16 issues from reaching production, including subtle crash consistency and concurrency problems, and has been extended by non-formal-methods experts to check new features and properties as {ShardStore} has evolved.},
	pages = {15},
	author = {Bornholt, James and Joshi, Rajeev and Astrauskas, Vytautas and Cully, Brendan and Kragl, Bernhard and Markle, Seth and Sauri, Kyle and Schleit, Drew and Slatton, Grant and Tasiran, Serdar},
	date = {2021},
	langid = {english},
	file = {Bornholt et al. - 2021 - Using Lightweight Formal Methods to Validate a Key.pdf:/home/fordrl/Zotero/storage/MMMB84TV/Bornholt et al. - 2021 - Using Lightweight Formal Methods to Validate a Key.pdf:application/pdf},
}

@thesis{ferles_practical_2020,
	location = {Austin, Texas},
	title = {Practical Formal Methods for Software Analysis and Development},
	abstract = {Developed tools: Trimmer, Expresso, and {CFPChecker}.},
	pagetotal = {218},
	institution = {University of Texas at Austin},
	type = {phdthesis},
	author = {Ferles, Kostas},
	date = {2020-12},
	langid = {english},
	file = {Dillig et al. - Practical Formal Methods for Software Analysis and.pdf:/home/fordrl/Zotero/storage/4HZU89L4/Dillig et al. - Practical Formal Methods for Software Analysis and.pdf:application/pdf},
}

@thesis{wilcox_compositional_2021,
	title = {Compositional and Automated Veriﬁcation of Distributed Systems},
	pagetotal = {160},
	institution = {University of Washington},
	type = {phdthesis},
	author = {Wilcox, James R},
	date = {2021},
	langid = {english},
	file = {Wilcox - Compositional and Automated Veriﬁcation of Distrib.pdf:/home/fordrl/Zotero/storage/4TLUX58L/Wilcox - Compositional and Automated Veriﬁcation of Distrib.pdf:application/pdf},
}

@article{chen_accelerating_nodate,
	title = {Accelerating Program Analyses in Datalog by Merging Library Facts},
	abstract = {Static program analysis uses sensitivity to balance between precision and scalability. However, ﬁner sensitivity does not necessarily lead to more precise results but may reduce scalability. Recently, a number of approaches have been proposed to ﬁnely tune the sensitivity of diﬀerent program parts. However, these approaches are usually designed for speciﬁc program analyses, and their abstraction adjustments are coarse-grained as they directly drop sensitivity elements.},
	pages = {24},
	author = {Chen, Yifan and Yang, Chenyang and Zhang, Xin and Xiong, Yingfei and Tang, Hao and Wang, Xiaoyin and Zhang, Lu},
	langid = {english},
	file = {Chen et al. - Accelerating Program Analyses in Datalog by Mergin.pdf:/home/fordrl/Zotero/storage/3VWLVAKG/Chen et al. - Accelerating Program Analyses in Datalog by Mergin.pdf:application/pdf},
}

@article{timany_trillium_2021,
	title = {Trillium: Unifying Refinement and Higher-Order Distributed Separation Logic},
	url = {http://arxiv.org/abs/2109.07863},
	shorttitle = {Trillium},
	abstract = {We present a unification of refinement and Hoare-style reasoning in a foundational mechanized higher-order distributed separation logic. This unification enables us to prove formally in the Coq proof assistant that concrete implementations of challenging distributed systems refine more abstract models and to combine refinement-style reasoning with Hoare-style program verification. We use our logic to prove correctness of concrete implementations of two-phase commit and single-decree Paxos by showing that they refine their abstract {TLA}+ specifications. We further use our notion of refinement to transfer fairness assumptions on program executions to model traces and then transfer liveness properties of fair model traces back to program executions, which enables us to prove liveness properties such as strong eventual consistency of a concrete implementation of a Conflict-Free Replicated Data Type and fair termination of a concurrent program.},
	journaltitle = {{arXiv}:2109.07863 [cs]},
	author = {Timany, Amin and Gregersen, Simon Oddershede and Stefanesco, Léo and Gondelman, Léon and Nieto, Abel and Birkedal, Lars},
	urldate = {2021-09-24},
	date = {2021-09-16},
	eprinttype = {arxiv},
	eprint = {2109.07863},
	keywords = {Computer Science - Programming Languages},
	file = {arXiv.org Snapshot:/home/fordrl/Zotero/storage/KYKPNTWK/2109.html:text/html;arXiv Fulltext PDF:/home/fordrl/Zotero/storage/MKWRBULD/Timany et al. - 2021 - Trillium Unifying Refinement and Higher-Order Dis.pdf:application/pdf},
}

@online{quines_type_nodate,
	title = {Type Theory by Example},
	url = {https://www.cjquines.com/files/typetheory.pdf},
	author = {Quines, Carl},
	urldate = {2021-09-24},
	file = {typetheory.pdf:/home/fordrl/Zotero/storage/XWTP5AGB/typetheory.pdf:application/pdf},
}

@online{garavel_formal_nodate,
	title = {Formal Methos for Safe and Secure Computers Systems},
	url = {https://www.bsi.bund.de/SharedDocs/Downloads/DE/BSI/Publikationen/Studien/formal_methods_study_875/formal_methods_study_875.pdf?__blob=publicationFile&v=1},
	author = {Garavel, Hubert},
	urldate = {2021-09-24},
	file = {formal_methods_study_875.pdf:/home/fordrl/Zotero/storage/MTAUX3IY/formal_methods_study_875.pdf:application/pdf},
}

@article{gleirscher_formal_2020,
	title = {Formal methods in dependable systems engineering: a survey of professionals from Europe and North America},
	volume = {25},
	issn = {1382-3256, 1573-7616},
	url = {https://link.springer.com/10.1007/s10664-020-09836-5},
	doi = {10.1007/s10664-020-09836-5},
	shorttitle = {Formal methods in dependable systems engineering},
	abstract = {Objective We study the use of formal methods in mission-critical software domains, examining industrial and academic views.
Method We perform a cross-sectional on-line survey.
Results Our results indicate an increased intent to apply {FMs} in industry, suggesting a positively perceived usefulness. But the results also indicate a negatively perceived ease of use. Scalability, skills, and education seem to be among the key challenges to support this intent.
Conclusions We present the largest study of this kind so far (N = 216), and our observations provide valuable insights, highlighting directions for future theoretical and empirical research of formal methods. Our findings are strongly coherent with earlier observations by Austin and Graeme (1993).},
	pages = {4473--4546},
	number = {6},
	journaltitle = {Empirical Software Engineering},
	shortjournal = {Empir Software Eng},
	author = {Gleirscher, Mario and Marmsoler, Diego},
	urldate = {2021-09-24},
	date = {2020-11},
	langid = {english},
	file = {Gleirscher and Marmsoler - 2020 - Formal methods in dependable systems engineering .pdf:/home/fordrl/Zotero/storage/93L7BJE6/Gleirscher and Marmsoler - 2020 - Formal methods in dependable systems engineering .pdf:application/pdf},
}

@article{abyaneh_ase_nodate,
	title = {{ASE}: A Value Set Decision Procedure for Symbolic Execution},
	abstract = {A symbolic execution engine regularly queries a Satisﬁability Modulo Theory ({SMT}) solver to determine reachability of code during execution. Unfortunately, the {SMT} solver is often the bottleneck of symbolic execution. Inspired by abstract interpretation, we propose an abstract symbolic execution ({ASE}) engine which aims at querying the {SMT} solver less often by trying to compute reachability faster through an increasingly weaker abstraction. For this purpose, we have designed and implemented a value set decision procedure based on strided value interval ({SVI}) sets for efﬁciently determining precise, or under-approximating value sets for variables. Our {ASE} engine begins reasoning with respect to the {SVI} abstraction, and then only if needed uses the theory of bit-vectors implemented in {SMT} solvers. Our {ASE} engine efﬁciently detects when the former abstraction becomes incomplete to move on and try the next abstraction.},
	pages = {12},
	author = {Abyaneh, Alireza S and Kirsch, Christoph M},
	langid = {english},
	file = {Abyaneh and Kirsch - ASE A Value Set Decision Procedure for Symbolic E.pdf:/home/fordrl/Zotero/storage/8ZAYBYV8/Abyaneh and Kirsch - ASE A Value Set Decision Procedure for Symbolic E.pdf:application/pdf},
}

@article{bartha_one_2021,
	title = {One Down, 699 to Go: or, synthesising compositional desugarings},
	url = {http://arxiv.org/abs/2109.06114},
	shorttitle = {One Down, 699 to Go},
	abstract = {Programming or scripting languages used in real-world systems are seldom designed with a formal semantics in mind from the outset. Therefore, developing well-founded analysis tools for these systems requires reverse-engineering a formal semantics as a first step. This can take months or years of effort. Can we (at least partially) automate this process? Though desirable, automatically reverse-engineering semantics rules from an implementation is very challenging, as found by Krishnamurthi et al. [2019]. In this paper, we highlight that scaling methods with the size of the language is very difficult due to state space explosion, so we propose to learn semantics incrementally. We give a formalisation of Krishnamurthi et al.'s desugaring learning framework in order to clarify the assumptions necessary for an incremental learning algorithm to be feasible. We show that this reformulation allows us to extend the search space and express rules that Krishnamurthi et al. described as challenging, while still retaining feasibility. We evaluate enumerative synthesis as a baseline algorithm, and demonstrate that, with our reformulation of the problem, it is possible to learn correct desugaring rules for the example source and core languages proposed by Krishnamurthi et al., in most cases identical to the intended rules. In addition, with user guidance, our system was able to synthesize rules for desugaring list comprehensions and try/catch/finally constructs.},
	journaltitle = {{arXiv}:2109.06114 [cs]},
	author = {Bartha, Sándor and Cheney, James and Belle, Vaishak},
	urldate = {2021-09-20},
	date = {2021-09-13},
	eprinttype = {arxiv},
	eprint = {2109.06114},
	keywords = {Computer Science - Programming Languages},
	file = {arXiv.org Snapshot:/home/fordrl/Zotero/storage/8M7TY5JJ/2109.html:text/html;arXiv Fulltext PDF:/home/fordrl/Zotero/storage/JMTMBPGR/Bartha et al. - 2021 - One Down, 699 to Go or, synthesising compositiona.pdf:application/pdf},
}

@article{meyer_concept_2021,
	title = {The concept of class invariant in object-oriented programming},
	url = {http://arxiv.org/abs/2109.06557},
	abstract = {Class invariants -- consistency constraints preserved by every operation on objects of a given type -- are fundamental to building and understanding object-oriented programs. They should also be a key help in verifying them, but turn out instead to raise major verification challenges which have prompted a significant literature with, until now, no widely accepted solution. The present work introduces a general proof rule meant to address invariant-related issues and allow verification tools benefit from invariants. It first clarifies the notion of invariant and identify the three problems: callbacks, furtive access and reference leak. As an example, the 2016 Ethereum {DAO} bug, in which {\textbackslash}\$50 million were stolen, resulted from a callback invalidating an invariant. The discussion starts with a "Simple Model" and an associated proof rule, demonstrating its soundness. It then removes one by one the three assumptions of the Simple Model, each removal bringing up one of the three issues, and introduces the corresponding adaptation to the proof rule. The final version of the rule can tackle tricky examples, including "challenge problems" listed in the literature.},
	journaltitle = {{arXiv}:2109.06557 [cs]},
	author = {Meyer, Bertrand and Arkadova, Alisa and Kogtenkov, Alexander and Naumchev, Alexandr},
	urldate = {2021-09-20},
	date = {2021-09-14},
	eprinttype = {arxiv},
	eprint = {2109.06557},
	keywords = {Computer Science - Programming Languages, F.3, Computer Science - Software Engineering, D.1, D.2, D.3},
	file = {arXiv.org Snapshot:/home/fordrl/Zotero/storage/IGNI3A6C/2109.html:text/html;arXiv Fulltext PDF:/home/fordrl/Zotero/storage/VIS2AVZT/Meyer et al. - 2021 - The concept of class invariant in object-oriented .pdf:application/pdf},
}

@thesis{sanchez-stern_hybrid-neural_nodate,
	title = {Hybrid-Neural Synthesis of Machine Checkable Software Correctness Proofs},
	url = {https://escholarship.org/uc/item/5j10b5w8},
	pagetotal = {99},
	institution = {{UC} San Diego},
	type = {phdthesis},
	author = {Sanchez-Stern, Alex},
	file = {qt5j10b5w8.pdf:/home/fordrl/Zotero/storage/CBFFHSN9/qt5j10b5w8.pdf:application/pdf},
}

@article{patel_verifying_2021,
	title = {Verifying Concurrent Multicopy Search Structures},
	url = {http://arxiv.org/abs/2109.05631},
	abstract = {Multicopy search structures such as log-structured merge ({LSM}) trees are optimized for high insert/update/delete (collectively known as upsert) performance. In such data structures, an upsert on key \$k\$, which adds \$(k,v)\$ where \$v\$ can be a value or a tombstone, is added to the root node even if \$k\$ is already present in other nodes. Thus there may be multiple copies of \$k\$ in the search structure. A search on \$k\$ aims to return the value associated with the most recent upsert. We present a general framework for verifying linearizability of concurrent multicopy search structures that abstracts from the underlying representation of the data structure in memory, enabling proof-reuse across diverse implementations. Based on our framework, we propose template algorithms for a) {LSM} structures forming arbitrary directed acyclic graphs and b) differential file structures, and formally verify these templates in the concurrent separation logic Iris. We also instantiate the {LSM} template to obtain the first verified concurrent in-memory {LSM} tree implementation.},
	journaltitle = {{arXiv}:2109.05631 [cs]},
	author = {Patel, Nisarg and Krishna, Siddharth and Shasha, Dennis and Wies, Thomas},
	urldate = {2021-09-20},
	date = {2021-09-12},
	eprinttype = {arxiv},
	eprint = {2109.05631},
	keywords = {Computer Science - Programming Languages, Computer Science - Logic in Computer Science},
	file = {arXiv.org Snapshot:/home/fordrl/Zotero/storage/SMBN6LEX/2109.html:text/html;arXiv Fulltext PDF:/home/fordrl/Zotero/storage/VRASWJQM/Patel et al. - 2021 - Verifying Concurrent Multicopy Search Structures.pdf:application/pdf},
}

@article{kim_memory-efficient_2020,
	title = {Memory-Efficient Fixpoint Computation},
	url = {http://arxiv.org/abs/2009.05865},
	abstract = {Practical adoption of static analysis often requires trading precision for performance. This paper focuses on improving the memory efficiency of abstract interpretation without sacrificing precision or time efficiency. Computationally, abstract interpretation reduces the problem of inferring program invariants to computing a fixpoint of a set of equations. This paper presents a method to minimize the memory footprint in Bourdoncle's iteration strategy, a widely-used technique for fixpoint computation. Our technique is agnostic to the abstract domain used. We prove that our technique is optimal (i.e., it results in minimum memory footprint) for Bourdoncle's iteration strategy while computing the same result. We evaluate the efficacy of our technique by implementing it in a tool called {MIKOS}, which extends the state-of-the-art abstract interpreter {IKOS}. When verifying user-provided assertions, {MIKOS} shows a decrease in peak-memory usage to 4.07\% (24.57x) on average compared to {IKOS}. When performing interprocedural buffer-overflow analysis, {MIKOS} shows a decrease in peak-memory usage to 43.7\% (2.29x) on average compared to {IKOS}.},
	journaltitle = {{arXiv}:2009.05865 [cs]},
	author = {Kim, Sung Kook and Venet, Arnaud J. and Thakur, Aditya V.},
	urldate = {2021-11-16},
	date = {2020-09-12},
	eprinttype = {arxiv},
	eprint = {2009.05865},
	keywords = {Computer Science - Programming Languages},
	file = {arXiv Fulltext PDF:/home/fordrl/Zotero/storage/U7LZMN9N/Kim et al. - 2020 - Memory-Efficient Fixpoint Computation.pdf:application/pdf;arXiv.org Snapshot:/home/fordrl/Zotero/storage/CKMMZNG6/2009.html:text/html},
}

@article{kim_deterministic_2020,
	title = {Deterministic Parallel Fixpoint Computation},
	volume = {4},
	issn = {2475-1421},
	url = {http://arxiv.org/abs/1909.05951},
	doi = {10.1145/3371082},
	abstract = {Abstract interpretation is a general framework for expressing static program analyses. It reduces the problem of extracting properties of a program to computing an approximation of the least fixpoint of a system of equations. The de facto approach for computing this approximation uses a sequential algorithm based on weak topological order ({WTO}). This paper presents a deterministic parallel algorithm for fixpoint computation by introducing the notion of weak partial order ({WPO}). We present an algorithm for constructing a {WPO} in almost-linear time. Finally, we describe {PIKOS}, our deterministic parallel abstract interpreter, which extends the sequential abstract interpreter {IKOS}. We evaluate the performance and scalability of {PIKOS} on a suite of 1017 C programs. When using 4 cores, {PIKOS} achieves an average speedup of 2.06x over {IKOS}, with a maximum speedup of 3.63x. When using 16 cores, {PIKOS} achieves a maximum speedup of 10.97x.},
	pages = {1--33},
	issue = {{POPL}},
	journaltitle = {Proceedings of the {ACM} on Programming Languages},
	shortjournal = {Proc. {ACM} Program. Lang.},
	author = {Kim, Sung Kook and Venet, Arnaud J. and Thakur, Aditya V.},
	urldate = {2021-11-16},
	date = {2020-01},
	eprinttype = {arxiv},
	eprint = {1909.05951},
	keywords = {Computer Science - Programming Languages},
	file = {arXiv Fulltext PDF:/home/fordrl/Zotero/storage/YHSMMQ5H/Kim et al. - 2020 - Deterministic Parallel Fixpoint Computation.pdf:application/pdf;arXiv.org Snapshot:/home/fordrl/Zotero/storage/WLTS6JVF/1909.html:text/html},
}

@online{noauthor_efficient_nodate,
	title = {Efficient Fixpoint Computation for Abstract Interpretation - University of California, Davis},
	url = {https://video.ucdavis.edu/media/Efficient+Fixpoint+Computation+for+Abstract+Interpretation/1_1trufm5a},
	urldate = {2021-11-16},
	file = {Efficient Fixpoint Computation for Abstract Interpretation - University of California, Davis:/home/fordrl/Zotero/storage/F9LA2DSL/1_1trufm5a.html:text/html},
}

@inproceedings{murphy_validating_2021,
	location = {Cham},
	title = {Validating Safety Arguments with Lean},
	isbn = {978-3-030-92124-8},
	doi = {10.1007/978-3-030-92124-8_2},
	series = {Lecture Notes in Computer Science},
	abstract = {Safety Assurance Cases ({ACs}) are structured arguments which demonstrate that a system fulfills its safety requirements. However, the reasoning used in {ACs} is often presented informally and thus difficult to rigorously evaluate. To protect against the acceptance of {ACs} based on fallacious reasoning, our previous work has proposed a framework for formalizing fragments of {ACs} and verifying their reasoning using the Lean Theorem Prover. This work expands on the use of Lean to automatically validate fragments of {ACs}, identifies challenges faced by {AC} developers who wish the leverage theorem proving software, and demonstrates our approach to mitigating these challenges.},
	pages = {23--43},
	booktitle = {Software Engineering and Formal Methods},
	publisher = {Springer International Publishing},
	author = {Murphy, Logan and Viger, Torin and Sandro, Alessio Di and Shahin, Ramy and Chechik, Marsha},
	editor = {Calinescu, Radu and Păsăreanu, Corina S.},
	date = {2021},
	langid = {english},
	keywords = {Assurance, Lean, Safety cases, Strategies, Theorem proving},
}

@online{shao_httpsjhcsjtueducnyutingwangfilespopl22pdf_nodate,
	title = {https://jhc.sjtu.edu.cn/{\textasciitilde}yutingwang/files/popl22.pdf},
	url = {https://jhc.sjtu.edu.cn/~yutingwang/files/popl22.pdf},
	author = {Shao, Zhong and Koenig, Jérémie},
	urldate = {2021-12-07},
	file = {popl22.pdf:/home/fordrl/Zotero/storage/6V35XYVJ/popl22.pdf:application/pdf},
}

@online{spitters_verified_nodate,
	title = {A Verified Pipeline from a Specification Language to Optimized, Safe Rust},
	url = {https://cs.au.dk/~spitters/CoqPL22.pdf},
	author = {Spitters, Bas},
	urldate = {2021-12-07},
	file = {CoqPL22.pdf:/home/fordrl/Zotero/storage/66NG9HA3/CoqPL22.pdf:application/pdf},
}

@article{bao_separation_2021,
	title = {A Separation Logic for Negative Dependence},
	url = {http://arxiv.org/abs/2111.14917},
	doi = {10.1145/3498719},
	abstract = {Formal reasoning about hashing-based probabilistic data structures often requires reasoning about random variables where when one variable gets larger (such as the number of elements hashed into one bucket), the others tend to be smaller (like the number of elements hashed into the other buckets). This is an example of negative dependence, a generalization of probabilistic independence that has recently found interesting applications in algorithm design and machine learning. Despite the usefulness of negative dependence for the analyses of probabilistic data structures, existing verification methods cannot establish this property for randomized programs. To fill this gap, we design {LINA}, a probabilistic separation logic for reasoning about negative dependence. Following recent works on probabilistic separation logic using separating conjunction to reason about the probabilistic independence of random variables, we use separating conjunction to reason about negative dependence. Our assertion logic features two separating conjunctions, one for independence and one for negative dependence. We generalize the logic of bunched implications ({BI}) to support multiple separating conjunctions, and provide a sound and complete proof system. Notably, the semantics for separating conjunction relies on a non-deterministic, rather than partial, operation for combining resources. By drawing on closure properties for negative dependence, our program logic supports a Frame-like rule for negative dependence and monotone operations. We demonstrate how {LINA} can verify probabilistic properties of hash-based data structures and balls-into-bins processes.},
	journaltitle = {{arXiv}:2111.14917 [cs]},
	author = {Bao, Jialu and Gaboardi, Marco and Hsu, Justin and Tassarotti, Joseph},
	urldate = {2021-12-07},
	date = {2021-11-29},
	eprinttype = {arxiv},
	eprint = {2111.14917},
	keywords = {Computer Science - Programming Languages, Computer Science - Logic in Computer Science},
	file = {arXiv.org Snapshot:/home/fordrl/Zotero/storage/BIVWDG7L/2111.html:text/html;arXiv Fulltext PDF:/home/fordrl/Zotero/storage/9KZ6IRQ2/Bao et al. - 2021 - A Separation Logic for Negative Dependence.pdf:application/pdf},
}

@online{rosu_guarded_2017,
	title = {Guarded Matching Logic is Decidable},
	url = {https://www.ideals.illinois.edu/bitstream/handle/2142/112795/rodrigues-chen-rosu-2022-tr-decidability.pdf?sequence=2&isAllowed=y},
	author = {Rosu, Grigore},
	urldate = {2021-12-07},
	date = {2017-07},
	file = {rodrigues-chen-rosu-2022-tr-decidability.pdf:/home/fordrl/Zotero/storage/SULKLGSS/rodrigues-chen-rosu-2022-tr-decidability.pdf:application/pdf},
}

@online{dreyer_concurrent_nodate,
	title = {Concurrent Incorrectness Separation Logic},
	url = {https://research.fb.com/wp-content/uploads/2021/11/Concurrent-Incorrectness-Separation-Logic.pdf},
	author = {Dreyer, Derek and O'Hearn, Peter W},
	urldate = {2021-12-07},
	file = {Concurrent-Incorrectness-Separation-Logic.pdf:/home/fordrl/Zotero/storage/X87BYQVS/Concurrent-Incorrectness-Separation-Logic.pdf:application/pdf},
}

@article{mi_general_2021,
	title = {General and Fast Inter-Process Communication via Bypassing Privileged Software},
	issn = {1557-9956},
	doi = {10.1109/TC.2021.3130751},
	abstract = {{IPC} (Inter-Process Communication) is a widely used operating system ({OS}) technique that allows one process to invoke the services of other processes. The {IPC} participants may share the same {OS} (internal {IPC}) or use a separate {OS} (external {IPC}). Even though a long line of researches has optimized the performance of {IPC}, it is still a major factor of the run-time overhead of {IPC}-intensive applications. Furthermore, there is no one-size-fits-all solution for both internal and external {IPC}. This paper presents {SkyBridge}, a general communication technique designed and optimized for both types of {IPC}. {SkyBridge} requires no involvement of the privileged software (the kernel or the hypervisor) and enables a process to directly switch to the virtual address space of the target process, regardless of whether they are running on the same {OS} or not. We have implemented {SkyBridge} on two microkernels ({seL}4 and Google Zircon) as well as an open-source serverless hypervisor (Firecracker). The evaluation results show that {SkyBridge} improves the latency of internal {IPC} and external {IPC} by up to 19.6x and 1265.7x, respectively.},
	pages = {1--1},
	journaltitle = {{IEEE} Transactions on Computers},
	author = {Mi, Zeyu and Zhuang, Haoqi and Zang, Binyu and Chen, Haibo},
	date = {2021},
	note = {Conference Name: {IEEE} Transactions on Computers},
	keywords = {Inter-Process Communication, Microkernel, Serverlesss Computing, {VMFUNC}},
	file = {IEEE Xplore Abstract Record:/home/fordrl/Zotero/storage/FUJHLJHX/9627571.html:text/html},
}

@online{krebbers_diaframe_nodate,
	title = {Diaframe: Automated Verification of Fine-Grained Concurrent Programs in Iris},
	url = {https://robbertkrebbers.nl/research/articles/diaframe.pdf},
	author = {Krebbers, Robbert},
	urldate = {2021-12-07},
	file = {diaframe.pdf:/home/fordrl/Zotero/storage/4C5JC2CW/diaframe.pdf:application/pdf},
}

@article{lin_making_nodate,
	title = {Making Formal Verification Trustworthy via Proof Generation},
	abstract = {Formal deductive verification aims at proving the correctness of programs via logical deduction. However, the fact that it is usually based on complex program logics makes it error-prone to implement. This paper addresses the important research question of how we can make a deductive verifier trustworthy through a practical approach. We propose a novel technique to generate machine-checkable proof objects to certify each verification task performed by the language-agnostic deductive verifier of K—a semanticsbased language framework. These proof objects encode formal proofs in matching logic—the logical foundation of K. They have a small 240-line trust base and can be directly verified by third-party proof checkers. Our preliminary experiments show promising performance in generating correctness proofs for deductive verification in different programming languages.},
	pages = {15},
	author = {Lin, Zhengyao and Chen, Xiaohong and Trinh, Minh-Thai and Wang, John and Roşu, Grigore},
	langid = {english},
	file = {Lin et al. - Making Formal Verification Trustworthy via Proof G.pdf:/home/fordrl/Zotero/storage/L9D7R2MC/Lin et al. - Making Formal Verification Trustworthy via Proof G.pdf:application/pdf},
}

@article{vale_layered_nodate,
	title = {Layered and Object-Based Game Semantics},
	volume = {6},
	pages = {49},
	author = {Vale, Arthur Oliveira},
	langid = {english},
	file = {Vale - Layered and Object-Based Game Semantics.pdf:/home/fordrl/Zotero/storage/537ND888/Vale - Layered and Object-Based Game Semantics.pdf:application/pdf},
}

@article{haase_separation_2021,
	title = {Separation logic and logics with team semantics},
	issn = {0168-0072},
	url = {https://www.sciencedirect.com/science/article/pii/S0168007221001214},
	doi = {10.1016/j.apal.2021.103063},
	abstract = {Separation logic is a successful logical system for formal reasoning about programs that mutate their data structures. Team semantics, on the other side, is the basis of modern logics of dependence and independence. Separation logic and team semantics have been introduced with quite different motivations, and are investigated by research communities with rather different backgrounds and objectives. Nevertheless, there are obvious similarities between these formalisms. Both separation logic and logics with team semantics involve the manipulation of second-order objects, such as heaps and teams, by first-order syntax without reference to second-order variables. Moreover, these semantical objects are closely related; it is for instance obvious that a heap can be seen as a team, and the separating conjunction of separation logic is (essentially) the same as the team-semantical disjunction. Based on such similarities, the possible connections between separation logic and team semantics have been raised as a question at several occasions, and lead to informal discussions between these research communities. The objective of this paper is to make this connection precise, and to study its potential but also its obstacles and limitations.},
	pages = {103063},
	journaltitle = {Annals of Pure and Applied Logic},
	shortjournal = {Annals of Pure and Applied Logic},
	author = {Haase, Darion and Grädel, Erich and Wilke, Richard},
	urldate = {2021-11-26},
	date = {2021-11-19},
	langid = {english},
	keywords = {Separation logic, Logics of dependence and independence, Team semantics},
	file = {Haase et al. - 2021 - Separation logic and logics with team semantics.pdf:/home/fordrl/Zotero/storage/CYJTTAUH/Haase et al. - 2021 - Separation logic and logics with team semantics.pdf:application/pdf;ScienceDirect Snapshot:/home/fordrl/Zotero/storage/FVNTC5V6/S0168007221001214.html:text/html},
}

@article{carbonneaux_applying_2021,
	title = {Applying Formal Verification to Microkernel {IPC} at Meta},
	pages = {14},
	author = {Carbonneaux, Quentin and Zilberstein, Noam and Klee, Christoph and O'Hearn, Peter W and Nardelli, Francesco Zappa},
	date = {2021},
	langid = {english},
	file = {Carbonneaux et al. - 2021 - Applying Formal Verification to Microkernel IPC at.pdf:/home/fordrl/Zotero/storage/HY7BPA2H/Carbonneaux et al. - 2021 - Applying Formal Verification to Microkernel IPC at.pdf:application/pdf},
}

@article{jacobs_connectivity_nodate,
	title = {Connectivity Graphs: A Method for Proving Deadlock Freedom Based on Separation Logic},
	volume = {6},
	pages = {33},
	author = {Jacobs, Jules and Balzer, Stephanie and Krebbers, Robbert},
	langid = {english},
	file = {Jacobs et al. - Connectivity Graphs A Method for Proving Deadlock.pdf:/home/fordrl/Zotero/storage/FSIJP9Z2/Jacobs et al. - Connectivity Graphs A Method for Proving Deadlock.pdf:application/pdf},
}

@article{jang_moebius_2021,
	title = {Moebius: Metaprogramming using Contextual Types -- The stage where System F can pattern match on itself (Long Version)},
	url = {http://arxiv.org/abs/2111.08099},
	shorttitle = {Moebius},
	abstract = {We describe the foundation of the metaprogramming language, Moebius, which supports the generation of polymorphic code and, more importantly the analysis of polymorphic code via pattern matching. Moebius has two main ingredients: 1) we exploit contextual modal types to describe open code together with the context in which it is meaningful. In Moebius, open code can depend on type and term variables (level 0) whose values are supplied at a later stage, as well as code variables (level 1) that stand for code templates supplied at a later stage. This leads to a multi-level modal lambda-calculus that supports System-F style polymorphism and forms the basis for polymorphic code generation. 2) we extend the multi-level modal lambda-calculus to support pattern matching on code. As pattern matching on polymorphic code may refine polymorphic type variables, we extend our type-theoretic foundation to generate and track typing constraints that arise. We also give an operational semantics and prove type preservation. Our multi-level modal foundation for Moebius provides the appropriate abstractions for both generating and pattern matching on open code without committing to a concrete representation of variable binding and contexts. Hence, our work is a step towards building a general type-theoretic foundation for multi-staged metaprogramming that, on the one hand, enforces strong type guarantees and, on the other hand, makes it easy to generate and manipulate code. This will allow us to exploit the full potential of metaprogramming without sacrificing the reliability of and trust in the code we are producing and running.},
	journaltitle = {{arXiv}:2111.08099 [cs]},
	author = {Jang, Junyoung and Gélineau, Samuel and Monnier, Stefan and Pientka, Brigitte},
	urldate = {2021-11-26},
	date = {2021-11-15},
	eprinttype = {arxiv},
	eprint = {2111.08099},
	keywords = {Computer Science - Programming Languages},
	file = {arXiv.org Snapshot:/home/fordrl/Zotero/storage/YFDWYTPQ/2111.html:text/html;arXiv Fulltext PDF:/home/fordrl/Zotero/storage/XXGWMJSD/Jang et al. - 2021 - Moebius Metaprogramming using Contextual Types --.pdf:application/pdf},
}

@inproceedings{griffin_verifying_2021,
	location = {Cham},
	title = {Verifying Secure Speculation in Isabelle/{HOL}},
	isbn = {978-3-030-90870-6},
	doi = {10.1007/978-3-030-90870-6_3},
	series = {Lecture Notes in Computer Science},
	abstract = {Secure speculation is an information flow security hyperproperty that prevents transient execution attacks such as Spectre, Meltdown and Foreshadow. Generic compiler mitigations for secure speculation are known to be insufficient for eliminating vulnerabilities. Moreover, these mitigation techniques often overprescribe speculative fences, causing the performance of the programs to suffer. Recently Cheang et al. have developed an operational semantics of program execution capable of characterising speculative executions as well as a new class of information flow hyperproperties named {TPOD} that ensure secure speculation. This paper presents a framework for verifying {TPOD} using the Isabelle/{HOL} proof assistant by encoding the operational semantics of Cheang et al. We provide translation tools for automatically generating the required Isabelle/{HOL} theory templates from a C-like program syntax, which speeds up verification. Our framework is capable of proving the existence of vulnerabilities and correctness of secure speculation. We exemplify our framework by proving the existence of secure speculation bugs in 15 victim functions for the {MSVC} compiler as well as correctness of some proposed fixes.},
	pages = {43--60},
	booktitle = {Formal Methods},
	publisher = {Springer International Publishing},
	author = {Griffin, Matt and Dongol, Brijesh},
	editor = {Huisman, Marieke and Păsăreanu, Corina and Zhan, Naijun},
	date = {2021},
	langid = {english},
	keywords = {Isabelle/{HOL}, Formal verification, Hyperproperties, Secure speculation, Spectre, Transient execution vulnerabilities},
}

@inproceedings{wolf_concise_2021,
	location = {Cham},
	title = {Concise Outlines for a Complex Logic: A Proof Outline Checker for {TaDA}},
	isbn = {978-3-030-90870-6},
	doi = {10.1007/978-3-030-90870-6_22},
	series = {Lecture Notes in Computer Science},
	shorttitle = {Concise Outlines for a Complex Logic},
	abstract = {Modern separation logics allow one to prove rich properties of intricate code, e.g. functional correctness and linearizability of non-blocking concurrent code. However, this expressiveness leads to a complexity that makes these logics difficult to apply. Manual proofs or proofs in interactive theorem provers consist of a large number of steps, often with subtle side conditions. On the other hand, automation with dedicated verifiers typically requires sophisticated proof search algorithms that are specific to the given program logic, resulting in limited tool support that makes it difficult to experiment with program logics, e.g. when learning, improving, or comparing them. Proof outline checkers fill this gap. Their input is a program annotated with the most essential proof steps, just like the proof outlines typically presented in papers. The tool then checks automatically that this outline represents a valid proof in the program logic. In this paper, we systematically develop a proof outline checker for the {TaDA} logic, which reduces the checking to a simpler verification problem, for which automated tools exist. Our approach leads to proof outline checkers that provide substantially more automation than interactive provers, but are much simpler to develop than custom automatic verifiers.},
	pages = {407--426},
	booktitle = {Formal Methods},
	publisher = {Springer International Publishing},
	author = {Wolf, Felix A. and Schwerhoff, Malte and Müller, Peter},
	editor = {Huisman, Marieke and Păsăreanu, Corina and Zhan, Naijun},
	date = {2021},
	langid = {english},
	file = {Submitted Version:/home/fordrl/Zotero/storage/2ZMXUN4G/Wolf et al. - 2021 - Concise Outlines for a Complex Logic A Proof Outl.pdf:application/pdf},
}

@article{ferrando_incrementally_nodate,
	title = {Incrementally Predictive Runtime Veriﬁcation},
	abstract = {Runtime Veriﬁcation is a lightweight formal veriﬁcation technique used to verify the runtime behaviour of software (resp. hardware) systems. Given a formal property, one or more monitors are synthesised to verify the latter against a system execution. A monitor can only conclude the violation of a property when it observes such a violation. Unfortunately, in safety-critical scenarios, this might happen too late for the system to react properly. In such scenarios, it is advised to use Predictive Runtime Veriﬁcation, where monitors are capable of anticipating (by using a model of the system) future events before actually observing them. In this work, instead of assuming such a model is given, we describe a runtime veriﬁcation workﬂow where the model is learnt and incrementally reﬁned by using process mining techniques. We present the approach and the resulting prototype tool.},
	pages = {15},
	author = {Ferrando, Angelo},
	langid = {english},
	file = {Ferrando - Incrementally Predictive Runtime Veriﬁcation.pdf:/home/fordrl/Zotero/storage/SB383QZC/Ferrando - Incrementally Predictive Runtime Veriﬁcation.pdf:application/pdf},
}

@article{lepigre_vip_nodate,
	title = {{VIP}: Verifying Real-World C Idioms with Integer-Pointer Casts},
	volume = {6},
	pages = {32},
	author = {Lepigre, Rodolphe and Sammler, Michael and Memarian, Kayvan and Krebbers, Robbert and Dreyer, Derek and Sewell, Peter},
	langid = {english},
	file = {Lepigre et al. - VIP Verifying Real-World C Idioms with Integer-Po.pdf:/home/fordrl/Zotero/storage/K9LPB2L4/Lepigre et al. - VIP Verifying Real-World C Idioms with Integer-Po.pdf:application/pdf},
}

@article{bruening_transparent_nodate,
	title = {Transparent Dynamic Instrumentation},
	abstract = {Process virtualization provides a virtual execution environment within which an unmodiﬁed application can be monitored and controlled while it executes. The provided layer of control can be used for purposes ranging from sandboxing to compatibility to proﬁling. The additional operations required for this layer are performed clandestinely alongside regular program execution. Software dynamic instrumentation is one method for implementing process virtualization which dynamically instruments an application such that the application’s code and the inserted code are interleaved together.},
	pages = {11},
	author = {Bruening, Derek and Zhao, Qin and Amarasinghe, Saman},
	langid = {english},
	file = {Bruening et al. - Transparent Dynamic Instrumentation.pdf:/home/fordrl/Zotero/storage/NC9NU5WZ/Bruening et al. - Transparent Dynamic Instrumentation.pdf:application/pdf},
}

@article{vindum_mechanized_2022,
	title = {Mechanized Verification of a Fine-Grained Concurrent Queue from Meta's Folly Library},
	abstract = {We present the first formal specification and verification of
the fine-grained concurrent multi-producer-multi-consumer
queue algorithm from Meta’s C++ library Folly of core infrastructure components. The queue is highly optimized,
practical, and used by Meta in production where it scales to
thousands of consumer and producer threads. We present
an implementation of the algorithm in an {ML}-like language
and formally prove that it is a contextual refinement of a
simple coarse-grained queue (a property that implies that
the {MPMC} queue is linearizable). We use the {ReLoC} relational logic and the Iris program logic to carry out the proof
and to mechanize it in the Coq proof assistant. The {MPMC}
queue is implemented using three modules, and our proof
is similarly modular. By using {ReLoC} and Iris’s support for
modular reasoning we verify each module in isolation and
compose these together. A key challenge of the {MPMC} queue
is that it has a so-called external linearization point, which
{ReLoC} has no support for reasoning about. Thus we extend
{ReLoC}, both on paper and in Coq, with novel support for
reasoning about external linearization points.},
	pages = {16},
	author = {Vindum, Simon Friis and Frumin, Dan and Birkedal, Lars},
	date = {2022},
	langid = {english},
	file = {Vindum et al. - 2022 - Mechanized Verification of a Fine-Grained Concurre.pdf:/home/fordrl/Zotero/storage/EU4ZPUFG/Vindum et al. - 2022 - Mechanized Verification of a Fine-Grained Concurre.pdf:application/pdf},
}

@article{kumar_efficient_2021,
	title = {Efficient Data Race Detection of Async-Finish Programs Using Vector Clocks},
	url = {http://arxiv.org/abs/2112.04352},
	abstract = {Existing data race detectors for task-based programs incur large run time and space overheads. The overheads arise because of frequent lookups in fine-grained tree data structures to check whether two accesses can happen in parallel. This work shows how to efficiently apply vector clocks for dynamic race detection of async-finish programs with locks. Our proposed technique, {FastRacer}, builds on the {FastTrack} algorithm with per-task and per-variable optimizations to reduce the size of vector clocks. {FastRacer} also exploits the structured parallelism of async-finish programs to use a coarse-grained encoding of the dynamic task inheritance to limit the metadata in the presence of many concurrent readers. Our evaluation shows that {FastRacer} substantially improves time and space overheads over {FastTrack} and is competitive with the state-of-the-art data race detectors for async-finish programs with locks.},
	journaltitle = {{arXiv}:2112.04352 [cs]},
	author = {Kumar, Shivam and Agrawal, Anupam and Biswas, Swarnendu},
	urldate = {2021-12-15},
	date = {2021-12-08},
	eprinttype = {arxiv},
	eprint = {2112.04352},
	keywords = {Computer Science - Programming Languages},
	file = {arXiv Fulltext PDF:/home/fordrl/Zotero/storage/G58ANJ59/Kumar et al. - 2021 - Efficient Data Race Detection of Async-Finish Prog.pdf:application/pdf;arXiv.org Snapshot:/home/fordrl/Zotero/storage/M7K7YMZG/2112.html:text/html},
}

@incollection{huisman_formal_2021,
	location = {Cham},
	title = {Formal Verification of a {JavaCard} Virtual Machine with Frama-C},
	volume = {13047},
	isbn = {978-3-030-90869-0 978-3-030-90870-6},
	url = {https://link.springer.com/10.1007/978-3-030-90870-6_23},
	abstract = {Formal veriﬁcation of real-life industrial software remains a challenging task. It provides strong guarantees of correctness, which are particularly important for security-critical products, such as smart cards. Security of a smart card strongly relies on the requirement that the underlying {JavaCard} virtual machine ensures necessary isolation properties. This case study paper presents a recent formal veriﬁcation of a {JavaCard} Virtual Machine implementation performed by Thales using the {FramaC} veriﬁcation toolset. This is the ﬁrst veriﬁcation project for such a large-scale industrial smart card product where deductive veriﬁcation is applied on the real-life C code. The target properties include common security properties such as integrity and conﬁdentiality. The implementation contains over 7,000 lines of C code. After a formal speciﬁcation in the {ACSL} speciﬁcation language, over 52,000 veriﬁcation conditions were generated and successfully proved. We present several issues identiﬁed during the project, illustrate them by representative examples and present solutions we used to solve them. Finally, we describe proof results, some lessons learned and desired tool improvements.},
	pages = {427--444},
	booktitle = {Formal Methods},
	publisher = {Springer International Publishing},
	author = {Djoudi, Adel and Hána, Martin and Kosmatov, Nikolai},
	editor = {Huisman, Marieke and Păsăreanu, Corina and Zhan, Naijun},
	urldate = {2021-12-20},
	date = {2021},
	langid = {english},
	doi = {10.1007/978-3-030-90870-6_23},
	note = {Series Title: Lecture Notes in Computer Science},
	file = {Djoudi et al. - 2021 - Formal Verification of a JavaCard Virtual Machine .pdf:/home/fordrl/Zotero/storage/5BRASPFQ/Djoudi et al. - 2021 - Formal Verification of a JavaCard Virtual Machine .pdf:application/pdf},
}

@book{zhaohui_verifying_2021,
	title = {Verifying Contextual Refinement with Ownership Transfer(Extended Version)},
	abstract = {Contextual refinement is a compositional approach to compositional verification of concurrent objects. There has been much work designing program logics to prove the contextual refinement between the object implementation and its abstract specification. However, these program logics for contextual refinement verification cannot support objects with resource ownership transfer, which is a common pattern in many concurrent objects, such as the memory management module in {OS} kernels, which transfers the allocated memory block between the object and clients. In this paper, we propose a new approach to give abstract and implementation independent specifications to concurrent objects with ownership transfer. We also design a program logic to verify contextual refinement of concurrent objects w.r.t their abstract specifications. We have successfully apply our logic to verify an implementation of the memory management module, where the implementation is an appropriately simplified version of the original version from a real-world preemptive {OS} kernel.},
	author = {Zhaohui, Li and Feng, Xinyu},
	date = {2021-08-03},
	file = {Full Text PDF:/home/fordrl/Zotero/storage/79FW864Z/Zhaohui and Feng - 2021 - Verifying Contextual Refinement with Ownership Tra.pdf:application/pdf},
}

@article{fasse_code_nodate,
	title = {Code Transformations to Increase Prepass Scheduling Opportunities in {CompCert}},
	pages = {53},
	author = {Fasse, Justus},
	langid = {english},
	file = {Fasse - Code Transformations to Increase Prepass Schedulin.pdf:/home/fordrl/Zotero/storage/Z8TPHG3K/Fasse - Code Transformations to Increase Prepass Schedulin.pdf:application/pdf},
}

@article{komel_meta-analysis_2021,
	title = {{META}-{ANALYSIS} {OF} {TYPE} {THEORIES} {WITH} {AN} {APPLICATION} {TO} {THE} {DESIGN} {OF} {FORMAL} {PROOFS}},
	pages = {194},
	author = {Komel, Anja Petković},
	date = {2021},
	langid = {english},
	file = {Komel - 2021 - META-ANALYSIS OF TYPE THEORIES WITH AN APPLICATION.pdf:/home/fordrl/Zotero/storage/U7WRQKTX/Komel - 2021 - META-ANALYSIS OF TYPE THEORIES WITH AN APPLICATION.pdf:application/pdf},
}

@article{vishwanathan_sound_nodate,
	title = {Sound, Precise, and Fast Abstract Interpretation with Tristate Numbers},
	abstract = {Extended Berkeley Packet Filter ({BPF}) is a language and run-time system that allows non-superusers to extend the Linux and Windows operating systems by downloading user code into the kernel. To ensure that user code is safe to run in kernel context, {BPF} relies on a static analyzer that proves properties about the code, such as bounded memory access and the absence of operations that crash. The {BPF} static analyzer checks safety using abstract interpretation with several abstract domains. Among these, the domain of tnums (tristate numbers) is a key domain used to reason about the bitwise uncertainty in program values. This paper formally speciﬁes the tnum abstract domain and its arithmetic operators. We provide the ﬁrst proofs of soundness and optimality of the abstract arithmetic operators for tnum addition and subtraction used in the {BPF} analyzer. Further, we describe a novel sound algorithm for multiplication of tnums that is more precise and efﬁcient (runs 33\% faster on average) than the Linux kernel’s algorithm. Our tnum multiplication is now merged in the Linux kernel.},
	pages = {12},
	author = {Vishwanathan, Harishankar and Shachnai, Matan and Narayana, Srinivas and Nagarakatte, Santosh},
	langid = {english},
	file = {Vishwanathan et al. - Sound, Precise, and Fast Abstract Interpretation w.pdf:/home/fordrl/Zotero/storage/3BZKVQFF/Vishwanathan et al. - Sound, Precise, and Fast Abstract Interpretation w.pdf:application/pdf},
}

@article{chajed_record_nodate,
	title = {Record Updates in Coq},
	abstract = {We describe the implementation of coq-record-update, a library that generates functions to set and update fields of Coq records to complement Coq’s existing support for field projections. The implementation abuses features of Coq typeclasses and is thus fun to describe. The library has industrial and academic users that are not in the authors’ institution, which lends credibility to the assertion that it is useful.},
	pages = {2},
	author = {Chajed, Tej},
	langid = {english},
	file = {Chajed - Record Updates in Coq.pdf:/home/fordrl/Zotero/storage/SBPG43XH/Chajed - Record Updates in Coq.pdf:application/pdf},
}

@incollection{yang_verified_2017,
	location = {Berlin, Heidelberg},
	title = {Verified Characteristic Formulae for {CakeML}},
	volume = {10201},
	isbn = {978-3-662-54433-4 978-3-662-54434-1},
	url = {https://link.springer.com/10.1007/978-3-662-54434-1_22},
	abstract = {Characteristic Formulae ({CF}) oﬀer a productive, principled approach to generating veriﬁcation conditions for higher-order imperative programs, but so far the soundness of {CF} has only been considered with respect to an informal speciﬁcation of a programming language ({OCaml}). This leaves a gap between what is established by the veriﬁcation framework and the program that actually runs. We present a fullyﬂedged {CF} framework for the formally speciﬁed {CakeML} programming language. Our framework extends the existing {CF} approach to support exceptions and I/O, thereby covering the full feature set of {CakeML}, and comes with a formally veriﬁed soundness theorem. Furthermore, it integrates with existing proof techniques for verifying {CakeML} programs. This validates the {CF} approach, and allows users to prove end-to-end theorems for higher-order imperative programs, from speciﬁcation to language semantics, within a single theorem prover.},
	pages = {584--610},
	booktitle = {Programming Languages and Systems},
	publisher = {Springer Berlin Heidelberg},
	author = {Guéneau, Armaël and Myreen, Magnus O. and Kumar, Ramana and Norrish, Michael},
	editor = {Yang, Hongseok},
	urldate = {2021-12-28},
	date = {2017},
	langid = {english},
	doi = {10.1007/978-3-662-54434-1_22},
	note = {Series Title: Lecture Notes in Computer Science},
	file = {Guéneau et al. - 2017 - Verified Characteristic Formulae for CakeML.pdf:/home/fordrl/Zotero/storage/AIYIE6FT/Guéneau et al. - 2017 - Verified Characteristic Formulae for CakeML.pdf:application/pdf},
}

@inproceedings{myreen_minimalistic_2021-1,
	location = {Virtual Denmark},
	title = {A minimalistic verified bootstrapped compiler (proof pearl)},
	isbn = {978-1-4503-8299-1},
	url = {https://dl.acm.org/doi/10.1145/3437992.3439915},
	doi = {10.1145/3437992.3439915},
	abstract = {This paper shows how a small verified bootstrapped compiler can be developed inside an interactive theorem prover ({ITP}). Throughout, emphasis is put on clarity and minimalism.},
	eventtitle = {{CPP} '21: 10th {ACM} {SIGPLAN} International Conference on Certified Programs and Proofs},
	pages = {32--45},
	booktitle = {Proceedings of the 10th {ACM} {SIGPLAN} International Conference on Certified Programs and Proofs},
	publisher = {{ACM}},
	author = {Myreen, Magnus O.},
	urldate = {2021-12-28},
	date = {2021-01-17},
	langid = {english},
	file = {Myreen - 2021 - A minimalistic verified bootstrapped compiler (pro.pdf:/home/fordrl/Zotero/storage/F2NSJGBC/Myreen - 2021 - A minimalistic verified bootstrapped compiler (pro.pdf:application/pdf},
}

@online{noauthor_coq_nodate,
	title = {Coq Coq correct! verification of type checking and erasure for Coq, in Coq},
	url = {https://dl.acm.org/doi/epdf/10.1145/3371076},
	urldate = {2021-12-30},
	doi = {10.1145/3371076},
	file = {Full Text:/home/fordrl/Zotero/storage/C24T463Y/Coq Coq correct! verification of type checking and.pdf:application/pdf;Snapshot:/home/fordrl/Zotero/storage/HP6UAIMI/3371076.html:text/html},
}

@article{beeson_proof-checking_2019,
	title = {Proof-checking Euclid},
	volume = {85},
	issn = {1012-2443, 1573-7470},
	url = {http://link.springer.com/10.1007/s10472-018-9606-x},
	doi = {10.1007/s10472-018-9606-x},
	abstract = {We used computer proof-checking methods to verify the correctness of our proofs of the propositions in Euclid Book I. We used axioms as close as possible to those of Euclid, in a language closely related to that used in Tarski’s formal geometry. We used proofs as close as possible to those given by Euclid, but ﬁlling Euclid’s gaps and correcting errors. Euclid Book I has 48 propositions; we proved 235 theorems. The extras were partly “Book Zero”, preliminaries of a very fundamental nature, partly propositions that Euclid omitted but were used implicitly, partly advanced theorems that we found necessary to ﬁll Euclid’s gaps, and partly just variants of Euclid’s propositions. We wrote these proofs in a simple fragment of ﬁrst-order logic corresponding to Euclid’s logic, debugged them using a custom software tool, and then checked them in the well-known and trusted proof checkers {HOL} Light and Coq.},
	pages = {213--257},
	number = {2},
	journaltitle = {Annals of Mathematics and Artificial Intelligence},
	shortjournal = {Ann Math Artif Intell},
	author = {Beeson, Michael and Narboux, Julien and Wiedijk, Freek},
	urldate = {2021-12-30},
	date = {2019-04},
	langid = {english},
	file = {Beeson et al. - 2019 - Proof-checking Euclid.pdf:/home/fordrl/Zotero/storage/Y7K9LCQN/Beeson et al. - 2019 - Proof-checking Euclid.pdf:application/pdf},
}

@inproceedings{bourdoncle_efficient_1993,
	title = {Efficient chaotic iteration strategies with widenings},
	abstract = {Abstract. Abstract interpretation is a formal method that enables the static and automatic determination of run-time properties of programs. This method uses a characterization of program invariants as least and greatest fixed points of continuous functions over complete lattices of program properties. In this paper, we study precise and efficient chaotic iteration strategies for computing such fixed points when lattices are of infinite height and speedup techniques, known as widening and narrowing, have to be used. These strategies are based on a weak topological ordering of the dependency graph of the system of semantic equations associated with the program and minimize the loss in precision due to the use of widening operators. We discuss complexity and implementation issues and give precise upper bounds on the complexity of the intraprocedural and interprocedural abstract interpretation of higher-order programs based on the structure of their control flow graph. 1},
	pages = {128--141},
	publisher = {Springer-Verlag},
	author = {Bourdoncle, François},
	date = {1993},
	file = {Citeseer - Full Text PDF:/home/fordrl/Zotero/storage/BZP8M2MU/Bourdoncle - 1993 - Efficient chaotic iteration strategies with wideni.pdf:application/pdf;Citeseer - Snapshot:/home/fordrl/Zotero/storage/WB9QR5I9/download.html:text/html},
}

@article{de_vilhena_separation_2021,
	title = {A separation logic for effect handlers},
	volume = {5},
	url = {https://doi.org/10.1145/3434314},
	doi = {10.1145/3434314},
	abstract = {User-defined effects and effect handlers are advertised and advocated as a relatively easy-to-understand and modular approach to delimited control. They offer the ability of suspending and resuming a computation and allow information to be transmitted both ways between the computation, which requests a certain service, and the handler, which provides this service. Yet, a key question remains, to this day, largely unanswered: how does one modularly specify and verify programs in the presence of both user-defined effect handlers and primitive effects, such as heap-allocated mutable state? We answer this question by presenting a Separation Logic with built-in support for effect handlers, both shallow and deep. The specification of a program fragment includes a protocol that describes the effects that the program may perform as well as the replies that it can expect to receive. The logic allows local reasoning via a frame rule and a bind rule. It is based on Iris and inherits all of its advanced features, including support for higher-order functions, user-defined ghost state, and invariants. We illustrate its power via several case studies, including (1) a generic formulation of control inversion, which turns a producer that ``pushes'' elements towards a consumer into a producer from which one can ``pull'' elements on demand, and (2) a simple system for cooperative concurrency, where several threads execute concurrently, can spawn new threads, and communicate via promises.},
	pages = {33:1--33:28},
	issue = {{POPL}},
	journaltitle = {Proceedings of the {ACM} on Programming Languages},
	shortjournal = {Proc. {ACM} Program. Lang.},
	author = {de Vilhena, Paulo Emílio and Pottier, François},
	urldate = {2022-01-05},
	date = {2021-01-04},
	keywords = {program verification, separation logic, effect handlers},
	file = {Full Text PDF:/home/fordrl/Zotero/storage/S4DB25Q3/de Vilhena and Pottier - 2021 - A separation logic for effect handlers.pdf:application/pdf},
}

@article{medina-martinez_database_2021,
	title = {Database Management System Verification with Separation Logics},
	volume = {47},
	issn = {1608-3261},
	url = {https://doi.org/10.1134/S036176882108017X},
	doi = {10.1134/S036176882108017X},
	abstract = {Program verification consists in finding a formal proof that the program satisfies a given specification. This specification can be described as assertions about the input and output a correct program must satisfy. Assertions and programs are traditionally specified in terms of classical first order logic ({FOL}). {FOL} reasoners (inference systems) automatically find the correspondent program correctness proof, if any. However, verification of programs with mutable data structures, such as pointers, is currently a major challenge for the {FOL} assertion based approach. Mutable data structures are often written in terms of syntactically unrelated expressions, whose specification represents a significant defiance for {FOL}. Separation logics are a family of formal languages with specially-purposed constructors designed to model mutable data structures. In this paper, we formally verify a database management system using separation logics. We focused on the verification of libraries containing programs about heap manipulation. Several detected bugs are described in detail, respective solutions are also provided.},
	pages = {654--672},
	number = {8},
	journaltitle = {Programming and Computer Software},
	shortjournal = {Program Comput Soft},
	author = {Medina-Martínez, Diego and Bárcenas, Everardo and Molero-Castillo, Guillermo and Velázquez-Mena, Alejandro and Aldeco-Pérez, Rocío},
	urldate = {2022-01-05},
	date = {2021-12-01},
	langid = {english},
	file = {Medina-Martínez et al. - 2021 - Database Management System Verification with Separ.pdf:/home/fordrl/Zotero/storage/Q9QCEX35/Medina-Martínez et al. - 2021 - Database Management System Verification with Separ.pdf:application/pdf},
}

@article{ambal_certified_nodate,
	title = {Certified Abstract Machines for Skeletal Semantics},
	pages = {14},
	author = {Ambal, Guillaume and Lenglet, Sergueï and Schmitt, Alan},
	langid = {english},
	file = {Ambal et al. - Certified Abstract Machines for Skeletal Semantics.pdf:/home/fordrl/Zotero/storage/VKIF9PRC/Ambal et al. - Certified Abstract Machines for Skeletal Semantics.pdf:application/pdf},
}

@inproceedings{appel_coqs_2022,
	location = {Philadelphia {PA} {USA}},
	title = {Coq’s vibrant ecosystem for verification engineering (invited talk)},
	isbn = {978-1-4503-9182-5},
	url = {https://dl.acm.org/doi/10.1145/3497775.3503951},
	doi = {10.1145/3497775.3503951},
	abstract = {Program verification in the large is not only a matter of mechanizing a program logic to handle the semantics of your programming language. You must reason in the mathematics of your application domain—and there are many application domains, each with their own community of domain experts. So you will need to import mechanized proof theories from many domains, and they must all interoperate. Such an ecosystem is not only a matter of mathematics, it is a matter of software process engineering and social engineering. Coq’s ecosystem has been maturing nicely in these senses.},
	eventtitle = {{CPP} '22: 11th {ACM} {SIGPLAN} International Conference on Certified Programs and Proofs},
	pages = {2--11},
	booktitle = {Proceedings of the 11th {ACM} {SIGPLAN} International Conference on Certified Programs and Proofs},
	publisher = {{ACM}},
	author = {Appel, Andrew W.},
	urldate = {2022-01-14},
	date = {2022-01-17},
	langid = {english},
	file = {Appel - 2022 - Coq’s vibrant ecosystem for verification engineeri.pdf:/home/fordrl/Zotero/storage/PBYYLIU9/Appel - 2022 - Coq’s vibrant ecosystem for verification engineeri.pdf:application/pdf},
}

@article{porncharoenwase_formal_2022,
	title = {A formal foundation for symbolic evaluation with merging},
	volume = {6},
	issn = {2475-1421},
	url = {https://dl.acm.org/doi/10.1145/3498709},
	doi = {10.1145/3498709},
	abstract = {Reusable symbolic evaluators are a key building block of solver-aided verification and synthesis tools. A reusable evaluator reduces the semantics of all paths in a program to logical constraints, and a client tool uses these constraints to formulate a satisfiability query that is discharged with {SAT} or {SMT} solvers. The correctness of the evaluator is critical to the soundness of the tool and the domain properties it aims to guarantee. Yet so far, the trust in these evaluators has been based on an ad-hoc foundation of testing and manual reasoning.
            This paper presents the first formal framework for reasoning about the behavior of reusable symbolic evaluators. We develop a new symbolic semantics for these evaluators that incorporates state merging. Symbolic evaluators use state merging to avoid path explosion and generate compact encodings. To accommodate a wide range of implementations, our semantics is parameterized by a symbolic factory, which abstracts away the details of merging and creation of symbolic values. The semantics targets a rich language that extends Core Scheme with assumptions and assertions, and thus supports branching, loops, and (first-class) procedures. The semantics is designed to support reusability, by guaranteeing two key properties: legality of the generated symbolic states, and the reducibility of symbolic evaluation to concrete evaluation. Legality makes it simpler for client tools to formulate queries, and reducibility enables testing of client tools on concrete inputs. We use the Lean theorem prover to mechanize our symbolic semantics, prove that it is sound and complete with respect to the concrete semantics, and prove that it guarantees legality and reducibility.
            To demonstrate the generality of our semantics, we develop Leanette, a reference evaluator written in Lean, and Rosette 4, an optimized evaluator written in Racket. We prove Leanette correct with respect to the semantics, and validate Rosette 4 against Leanette via solver-aided differential testing. To demonstrate the practicality of our approach, we port 16 published verification and synthesis tools from Rosette 3 to Rosette 4. Rosette 3 is an existing reusable evaluator that implements the classic merging semantics, adopted from bounded model checking. Rosette 4 replaces the semantic core of Rosette 3 but keeps its optimized symbolic factory. Our results show that Rosette 4 matches the performance of Rosette 3 across a wide range of benchmarks, while providing a cleaner interface that simplifies the implementation of client tools.},
	pages = {1--28},
	issue = {{POPL}},
	journaltitle = {Proceedings of the {ACM} on Programming Languages},
	shortjournal = {Proc. {ACM} Program. Lang.},
	author = {Porncharoenwase, Sorawee and Nelson, Luke and Wang, Xi and Torlak, Emina},
	urldate = {2022-01-14},
	date = {2022-01-16},
	langid = {english},
	file = {Porncharoenwase et al. - 2022 - A formal foundation for symbolic evaluation with m.pdf:/home/fordrl/Zotero/storage/LEVE5HTW/Porncharoenwase et al. - 2022 - A formal foundation for symbolic evaluation with m.pdf:application/pdf},
}

@article{coward_formal_nodate,
	title = {Formal Veriﬁcation of Transcendental Fixed and Floating Point Algorithms using an Automatic Theorem Prover},
	abstract = {We present a method for formal veriﬁcation of transcendental hardware and software algorithms that scales to higher precision without suﬀering an exponential growth in runtimes. A class of implementations using piecewise polynomial approximation to compute the result is veriﬁed using {MetiTarski}, an automated theorem prover, which veriﬁes a range of inputs for each call. The method was applied to commercial implementations from Cadence Design Systems with signiﬁcant runtime gains over exhaustive testing methods and was successful in proving that the expected accuracy of one implementation was overly optimistic. Reproducing the veriﬁcation of a sine implementation in software, previously done using an alternative theorem proving technique, demonstrates that the {MetiTarski} approach is a viable competitor. Veriﬁcation of a 52 bit implementation of the square root function highlights the method’s high precision capabilities.},
	pages = {20},
	author = {Coward, Samuel and Paulson, Lawrence and Drane, Theo and Morini, Emiliano},
	langid = {english},
	file = {Coward et al. - Formal Veriﬁcation of Transcendental Fixed and Flo.pdf:/home/fordrl/Zotero/storage/5K3JQEYV/Coward et al. - Formal Veriﬁcation of Transcendental Fixed and Flo.pdf:application/pdf},
}

@inproceedings{bodin_trusted_2014,
	location = {San Diego California {USA}},
	title = {A trusted mechanised {JavaScript} specification},
	isbn = {978-1-4503-2544-8},
	url = {https://dl.acm.org/doi/10.1145/2535838.2535876},
	doi = {10.1145/2535838.2535876},
	abstract = {{JavaScript} is the most widely used web language for client-side applications. Whilst the development of {JavaScript} was initially just led by implementation, there is now increasing momentum behind the {ECMA} standardisation process. The time is ripe for a formal, mechanised speciﬁcation of {JavaScript}, to clarify ambiguities in the {ECMA} standards, to serve as a trusted reference for high-level language compilation and {JavaScript} implementations, and to provide a platform for high-assurance proofs of language properties.},
	eventtitle = {{POPL} '14: The 41st Annual {ACM} {SIGPLAN}-{SIGACT} Symposium on Principles of Programming Languages},
	pages = {87--100},
	booktitle = {Proceedings of the 41st {ACM} {SIGPLAN}-{SIGACT} Symposium on Principles of Programming Languages},
	publisher = {{ACM}},
	author = {Bodin, Martin and Chargueraud, Arthur and Filaretti, Daniele and Gardner, Philippa and Maffeis, Sergio and Naudziuniene, Daiva and Schmitt, Alan and Smith, Gareth},
	urldate = {2022-01-20},
	date = {2014-01-08},
	langid = {english},
	file = {Bodin et al. - 2014 - A trusted mechanised JavaScript specification.pdf:/home/fordrl/Zotero/storage/RE8C73VT/Bodin et al. - 2014 - A trusted mechanised JavaScript specification.pdf:application/pdf},
}

@article{distefano_scaling_2019,
	title = {Scaling static analyses at Facebook},
	volume = {62},
	issn = {0001-0782},
	url = {https://doi.org/10.1145/3338112},
	doi = {10.1145/3338112},
	abstract = {Key lessons for designing static analyses tools deployed to find bugs in hundreds of millions of lines of code.},
	pages = {62--70},
	number = {8},
	journaltitle = {Communications of the {ACM}},
	shortjournal = {Commun. {ACM}},
	author = {Distefano, Dino and Fähndrich, Manuel and Logozzo, Francesco and O'Hearn, Peter W.},
	urldate = {2022-01-20},
	date = {2019-07-24},
	file = {Full Text PDF:/home/fordrl/Zotero/storage/6FPWBVK2/Distefano et al. - 2019 - Scaling static analyses at Facebook.pdf:application/pdf},
}

@article{le_finding_nodate-1,
	title = {Finding Real Bugs in Big Programs Appendix},
	volume = {1},
	pages = {6},
	number = {1},
	author = {Le, Quang Loc and Raad, Azalea and Villard, Jules and Berdine, Josh and Dreyer, Derek and O'Hearn, Peter W},
	langid = {english},
	file = {Le et al. - Finding Real Bugs in Big Programs Appendix:/home/fordrl/Zotero/storage/FQRYIYCB/Le et al. - Finding Real Bugs in Big Programs with Incorrectne.pdf:application/pdf},
}

@incollection{finkbeiner_loop_2022,
	location = {Cham},
	title = {Loop Verification with Invariants and Contracts},
	volume = {13182},
	isbn = {978-3-030-94582-4 978-3-030-94583-1},
	url = {https://link.springer.com/10.1007/978-3-030-94583-1_4},
	abstract = {Invariants are the predominant approach to verify the correctness of loops. As an alternative, loop contracts, which make explicit the premise and conclusion of the underlying induction proof, can sometimes capture correctness conditions more naturally. But despite this advantage, the second approach receives little attention overall, and the goal of this paper is to lift it out of its niche. We give the ﬁrst comprehensive exposition of the theory of loop contracts, including a characterization of its completeness. We show concrete examples on standard algorithms that showcase their relative merits. Moreover, we demonstrate a novel constructive translation between the two approaches, which decouples the chosen speciﬁcation approach from the veriﬁcation backend.},
	pages = {69--92},
	booktitle = {Verification, Model Checking, and Abstract Interpretation},
	publisher = {Springer International Publishing},
	author = {Ernst, Gidon},
	editor = {Finkbeiner, Bernd and Wies, Thomas},
	urldate = {2022-01-27},
	date = {2022},
	langid = {english},
	doi = {10.1007/978-3-030-94583-1_4},
	note = {Series Title: Lecture Notes in Computer Science},
	file = {Ernst - 2022 - Loop Verification with Invariants and Contracts.pdf:/home/fordrl/Zotero/storage/9GJK3SYA/Ernst - 2022 - Loop Verification with Invariants and Contracts.pdf:application/pdf},
}

@article{bereczky_mechanizing_2022,
	title = {Mechanizing Matching Logic in Coq},
	url = {http://arxiv.org/abs/2201.05716},
	abstract = {Matching logic is a formalism for specifying and reasoning about structures using patterns and pattern matching. Growing in popularity, matching logic has been used to define many logical systems such as separation logic with recursive definitions and linear-temporal logic. Despite this, there is no way for a user to define his or her own matching logic theories using a theorem prover, with maximal assurance of the properties being proved. Hence, in this work, we formalized a version of matching logic using the Coq proof assistant. Specifically, we create a new version of matching logic that uses a locally nameless representation, where quantified variables are unnamed in order to aid verification. We formalize the syntax, semantics, and proof system of this representation of matching logic using the Coq proof assistant. Crucially, we also verify the soundness of the formalized proof system, thereby guaranteeing that any matching logic properties proved in our Coq formalization are indeed correct. We believe this work provides a previously unexplored avenue for defining and proving matching logic theories and properties.},
	journaltitle = {{arXiv}:2201.05716 [cs]},
	author = {Bereczky, Péter and Chen, Xiaohong and Horpácsi, Dániel and Mizsei, Tamás Bálint and Peña, Lucas and Tusil, Jan},
	urldate = {2022-01-27},
	date = {2022-01-19},
	eprinttype = {arxiv},
	eprint = {2201.05716},
	keywords = {Computer Science - Logic in Computer Science},
	file = {arXiv.org Snapshot:/home/fordrl/Zotero/storage/KLAHJYYM/2201.html:text/html;arXiv Fulltext PDF:/home/fordrl/Zotero/storage/EVNS3KBP/Bereczky et al. - 2022 - Mechanizing Matching Logic in Coq.pdf:application/pdf},
}

@report{zeng_static_2012,
	location = {Bethlehem, {PA}},
	title = {Static Analysis on Binary Code},
	abstract = {As the number and sophistication of attacks increase, static analysis gains attention. Since it is binary code that is executed directly on the bare-metal, binary-level static analysis oﬀers root-cause approaches to security problems such as malware detection. In this survey, we start with the challenges to do binary-level static analysis and then transfer to the advantages of carrying out static analysis on binary code. After that, we introduce some typical binary-level static analysis algorithms including disassembly, control ﬂow graph construction, dataﬂow analysis, alias analysis algorithms et al. Based on the current situation and approaches, we express our own opinions on the future work and propose some preliminary ideas to solve these problems.},
	pages = {19},
	institution = {Lehigh University},
	type = {Technical Report},
	author = {Zeng, Bin},
	date = {2012},
	langid = {english},
	file = {Zeng - Static Analysis on Binary Code.pdf:/home/fordrl/Zotero/storage/NNZXKXZK/Zeng - Static Analysis on Binary Code.pdf:application/pdf},
}

@book{fornaia_jscan_2019,
	title = {{JSCAN}: Designing an Easy to use {LLVM}-Based Static Analysis Framework},
	shorttitle = {{JSCAN}},
	pagetotal = {237},
	author = {Fornaia, Andrea and Scafiti, Stefano and Tramontana, Emiliano},
	date = {2019-06-01},
	doi = {10.1109/WETICE.2019.00058},
	note = {Pages: 242},
	file = {Fornaia et al. - 2019 - JSCAN Designing an Easy to use LLVM-Based Static .pdf:/home/fordrl/Zotero/storage/Q86BKVKL/Fornaia et al. - 2019 - JSCAN Designing an Easy to use LLVM-Based Static .pdf:application/pdf},
}

@article{bora_openmp_2021,
	title = {{OpenMP} aware {MHP} Analysis for Improved Static Data-Race Detection},
	url = {http://arxiv.org/abs/2111.04259},
	abstract = {Data races, a major source of bugs in concurrent programs, can result in loss of manpower and time as well as data loss due to system failures. {OpenMP}, the de facto shared memory parallelism framework used in the {HPC} community, also suffers from data races. To detect race conditions in {OpenMP} programs and improve turnaround time and/or developer productivity, we present a data flow analysis based, fast, static data race checker in the {LLVM} compiler framework. Our tool can detect races in the presence or absence of explicit barriers, with implicit or explicit synchronization. In addition, our tool effectively works for the {OpenMP} target offloading constructs and also supports the frequently used {OpenMP} constructs. We formalize and provide a data flow analysis framework to perform Phase Interval Analysis ({PIA}) of {OpenMP} programs. Phase intervals are then used to compute the {MHP} (and its complement {NHP}) sets for the programs, which, in turn, are used to detect data races statically. We evaluate our work using multiple {OpenMP} race detection benchmarks and real world applications. Our experiments show that the checker is comparable to the state-of-the-art in various performance metrics with around 90\% accuracy, almost perfect recall, and significantly lower runtime and memory footprint.},
	journaltitle = {{arXiv}:2111.04259 [cs]},
	author = {Bora, Utpal and Vaishay, Shraiysh and Joshi, Saurabh and Upadrasta, Ramakrishna},
	urldate = {2022-01-31},
	date = {2021-11-07},
	eprinttype = {arxiv},
	eprint = {2111.04259},
	keywords = {Computer Science - Programming Languages, D.2.4, D.1.3, D.3.4, Computer Science - Software Engineering, D.2.5},
	file = {arXiv.org Snapshot:/home/fordrl/Zotero/storage/IYSG6MSB/2111.html:text/html;arXiv Fulltext PDF:/home/fordrl/Zotero/storage/79G68HI7/Bora et al. - 2021 - OpenMP aware MHP Analysis for Improved Static Data.pdf:application/pdf},
}

@inproceedings{ballabriga_static_2019,
	location = {Cascais, Portugal},
	title = {Static Analysis Of Binary Code With Memory Indirections Using Polyhedra},
	volume = {11388},
	url = {https://hal.archives-ouvertes.fr/hal-01939659},
	doi = {10.1007/978-3-030-11245-5_6},
	series = {{LNCS}},
	abstract = {In this paper we propose a new abstract domain for staticanalysis of binary code. Our motivation stems from the need to im-prove the precision of the estimation of the Worst-Case Execution Time({WCET}) of safety-critical real-time code. {WCET} estimation requirescomputing information such as upper bounds on the number of loopiterations, unfeasible execution paths, etc. These estimations are usuallyperformed on binary code, mainly to avoid making assumptions on howthe compiler works. Our abstract domain, based on polyhedra and ontwo mapping functions that associate polyhedra variables with registersand memory, targets the precise computation of such information. Weprove the correctness of the method, and demonstrate its effectivenesson benchmarks and examples from typical embedded code.},
	pages = {114--135},
	booktitle = {{VMCAI}'19 - International Conference on Verification, Model Checking, and Abstract Interpretation},
	publisher = {Springer},
	author = {Ballabriga, Clément and Forget, Julien and Gonnord, Laure and Lipari, Giuseppe and Ruiz, Jordy},
	urldate = {2022-01-31},
	date = {2019-01},
	keywords = {binary analysis, polyhedra, Worst-case Execution Time {WCET}},
	file = {HAL PDF Full Text:/home/fordrl/Zotero/storage/SI6JVHDQ/Ballabriga et al. - 2019 - Static Analysis Of Binary Code With Memory Indirec.pdf:application/pdf},
}

@thesis{dral_verified_2022,
	title = {Verified Compiler Optimisations},
	abstract = {This thesis explores how to formally verify the correctness of a certifying compiler where the correctness of individual compiler runs is specified by translation relations, each of which characterises the admissible behaviour of a single
compiler pass. Whereas the correctness of compiler passes follows from the fact that we can recognise compiler behaviour, there is no guarantee that the recognised behaviour is correct. This motivates the need for formal guarantees
that express that translation relations themselves are well-behaved.

...},
	pagetotal = {62},
	institution = {Utrecht University},
	type = {Masters},
	author = {Dral, Joris},
	date = {2022},
	langid = {english},
	file = {Dral - Verified Compiler Optimisations.pdf:/home/fordrl/Zotero/storage/X9W2B3EH/Dral - Verified Compiler Optimisations.pdf:application/pdf},
}

@article{echenim_proof_2022,
	title = {A Proof Procedure For Separation Logic With Inductive Definitions and Theory Reasoning},
	url = {http://arxiv.org/abs/2201.13227},
	abstract = {A proof procedure, in the spirit of the sequent calculus, is proposed to check the validity of entailments between Separation Logic formulas combining inductively defined predicates denoted structures of bounded tree width and theory reasoning. The calculus is sound and complete, in the sense that a sequent is valid iff it admits a (possibly infinite) proof tree. We show that the procedure terminates in the two following cases: (i) When the inductive rules that define the predicates occurring on the left-hand side of the entailment terminate, in which case the proof tree is always finite. (ii) When the theory is empty, in which case every valid sequent admits a rational proof tree, where the total number of pairwise distinct sequents occurring in the proof tree is doubly exponential w.r.t.{\textbackslash} the size of the end-sequent. We also show that the validity problem is undecidable for a wide class of theories, even with a very low expressive power.},
	journaltitle = {{arXiv}:2201.13227 [cs]},
	author = {Echenim, Mnacho and Peltier, Nicolas},
	urldate = {2022-02-08},
	date = {2022-01-31},
	eprinttype = {arxiv},
	eprint = {2201.13227},
	keywords = {Computer Science - Logic in Computer Science, F.4.1, 03B70},
	file = {arXiv Fulltext PDF:/home/fordrl/Zotero/storage/HVZFTANF/Echenim and Peltier - 2022 - A Proof Procedure For Separation Logic With Induct.pdf:application/pdf;arXiv.org Snapshot:/home/fordrl/Zotero/storage/DFCL4FNF/2201.html:text/html},
}

@article{konecny_extracting_2022,
	title = {Extracting efficient exact real number computation from proofs in constructive type theory},
	url = {http://arxiv.org/abs/2202.00891},
	abstract = {Exact real computation is an alternative to floating-point arithmetic where operations on real numbers are performed exactly, without the introduction of rounding errors. When proving the correctness of an implementation, one can focus solely on the mathematical properties of the problem without thinking about the subtleties of representing real numbers. We propose a new axiomatization of the real numbers in a dependent type theory with the goal of extracting certified exact real computation programs from constructive proofs. Our formalization differs from similar approaches, in that we formalize the reals in a conceptually similar way as some mature implementations of exact real computation. Primitive operations on reals can be extracted directly to the corresponding operations in such an implementation, producing more efficient programs. We particularly focus on the formalization of partial and nondeterministic computation, which is essential in exact real computation. We prove the soundness of our formalization with regards of the standard realizability interpretation from computable analysis and show how to relate our theory to a classical formalization of the reals. We demonstrate the feasibility of our theory by implementing it in the Coq proof assistant and present several natural examples. From the examples we have automatically extracted Haskell programs that use the exact real computation framework {AERN} for efficiently performing exact operations on real numbers. In experiments, the extracted programs behave similarly to native implementations in {AERN} in terms of running time and memory usage.},
	journaltitle = {{arXiv}:2202.00891 [cs]},
	author = {Konečný, Michal and Park, Sewon and Thies, Holger},
	urldate = {2022-02-08},
	date = {2022-02-02},
	eprinttype = {arxiv},
	eprint = {2202.00891},
	keywords = {Computer Science - Logic in Computer Science},
	file = {arXiv Fulltext PDF:/home/fordrl/Zotero/storage/TR3BNEP9/Konečný et al. - 2022 - Extracting efficient exact real number computation.pdf:application/pdf;arXiv.org Snapshot:/home/fordrl/Zotero/storage/4XBK6VD7/2202.html:text/html},
}

@article{stefano_verification_nodate,
	title = {Verification of Distributed Systems via Sequential Emulation},
	abstract = {{LUCA} {DI} {STEFANO}, Univ. Grenoble Alpes, Inria, {CNRS}, Grenoble {INP}∗, {LIG}, France {ROCCO} {DE} {NICOLA}, {IMT} School of Advanced Studies, Italy {OMAR} {INVERSO}, Gran Sasso Science Institute ({GSSI}), Italy Sequential emulation is a semantics-based technique to automatically reduce property checking of distributed systems to the analysis of sequential programs. An automated procedure takes as input a formal specification of a distributed system, a property of interest and the structural operational semantics of the specification language and generates a sequential program whose execution traces emulate the possible evolutions of the considered system. The problem as to whether the property of interest holds for the system can then be expressed either as a reachability or as a termination query on the program. This allows to immediately adapt mature verification techniques developed for general-purpose languages to domain-specific languages, and to effortlessly integrate new techniques as soon as they become available. We test our approach on a selection of concurrent systems originated from different contexts from population protocols to models of flocking behaviour. By combining a comprehensive range of program verification techniques, from traditional symbolic execution to modern inductive-based methods such as property-directed reachability, we are able to draw consistent and correct verification verdicts for the considered systems. {CCS} Concepts: • General and reference → Verification; • Software and its engineering → Automated static analysis; • Theory of computation → Process calculi.},
	pages = {42},
	author = {Stefano, Luca Di},
	langid = {english},
	file = {Stefano - Verification of Distributed Systems via Sequential.pdf:/home/fordrl/Zotero/storage/E5H7TEVS/Stefano - Verification of Distributed Systems via Sequential.pdf:application/pdf},
}

@article{li_formal_2022,
	title = {A Formal Model of Checked C},
	url = {http://arxiv.org/abs/2201.13394},
	abstract = {We present a formal model of Checked C, a dialect of C that aims to enforce spatial memory safety. Our model pays particular attention to the semantics of dynamically sized, potentially null-terminated arrays. We formalize this model in Coq, and prove that any spatial memory safety errors can be blamed on portions of the program labeled unchecked; this is a Checked C feature that supports incremental porting and backward compatibility. While our model's operational semantics uses annotated ("fat") pointers to enforce spatial safety, we show that such annotations can be safely erased: Using {PLT} Redex we formalize an executable version of our model and a compilation procedure from it to an untyped C-like language, and use randomized testing to validate that generated code faithfully simulates the original. Finally, we develop a custom random generator for well-typed and almost-well-typed terms in our Redex model, and use it to search for inconsistencies between our model and the Clang Checked C implementation. We find these steps to be a useful way to co-develop a language (Checked C is still in development) and a core model of it.},
	journaltitle = {{arXiv}:2201.13394 [cs]},
	author = {Li, Liyi and Liu, Yiyun and Postol, Deena L. and Lampropoulos, Leonidas and Van Horn, David and Hicks, Michael},
	urldate = {2022-02-08},
	date = {2022-01-31},
	eprinttype = {arxiv},
	eprint = {2201.13394},
	keywords = {Computer Science - Programming Languages, Computer Science - Software Engineering, D.3.1},
	file = {arXiv Fulltext PDF:/home/fordrl/Zotero/storage/FASQV6LF/Li et al. - 2022 - A Formal Model of Checked C.pdf:application/pdf;arXiv.org Snapshot:/home/fordrl/Zotero/storage/WU36VUZP/2201.html:text/html},
}

@article{kanabar_taming_nodate,
	title = {Taming an Authoritative Armv8 {ISA} Specification: L3 Validation and {CakeML} Compiler Verification},
	abstract = {Machine-readable specifications for the Armv8 instruction set architecture have become publicly available as part of Arm’s release processes, providing an official and unambiguous source of truth for the semantics of Arm instructions. To date, compiler and machine code verification efforts have made use of unofficial theorem proving friendly specifications of Armv8, e.g. {CakeML} uses an L3-based specification. The validity of these verification efforts hinges upon their unofficial {ISA} specifications being valid with respect to the official Arm specification.},
	pages = {21},
	author = {Kanabar, Hrutvik and Fox, Anthony C J and Myreen, Magnus O},
	langid = {english},
	file = {Kanabar et al. - Taming an Authoritative Armv8 ISA Specification L.pdf:/home/fordrl/Zotero/storage/WMX7CZYA/Kanabar et al. - Taming an Authoritative Armv8 ISA Specification L.pdf:application/pdf},
}

@article{batz_foundations_2022,
	title = {Foundations for Entailment Checking in Quantitative Separation Logic (extended version)},
	url = {http://arxiv.org/abs/2201.11464},
	abstract = {Quantitative separation logic ({QSL}) is an extension of separation logic ({SL}) for the verification of probabilistic pointer programs. In {QSL}, formulae evaluate to real numbers instead of truth values, e.g., the probability of memory-safe termination in a given symbolic heap. As with {\textbackslash}{SL}, one of the key problems when reasoning with {QSL} is {\textbackslash}emph\{entailment\}: does a formula f entail another formula g? We give a generic reduction from entailment checking in {QSL} to entailment checking in {SL}. This allows to leverage the large body of {SL} research for the automated verification of probabilistic pointer programs. We analyze the complexity of our approach and demonstrate its applicability. In particular, we obtain the first decidability results for the verification of such programs by applying our reduction to a quantitative extension of the well-known symbolic-heap fragment of separation logic.},
	journaltitle = {{arXiv}:2201.11464 [cs]},
	author = {Batz, Kevin and Fesefeldt, Ira and Jansen, Marvin and Katoen, Joost-Pieter and Keßler, Florian and Matheja, Christoph and Noll, Thomas},
	urldate = {2022-02-08},
	date = {2022-01-27},
	eprinttype = {arxiv},
	eprint = {2201.11464},
	keywords = {Computer Science - Programming Languages, Computer Science - Logic in Computer Science},
	file = {arXiv Fulltext PDF:/home/fordrl/Zotero/storage/LWF4S37Y/Batz et al. - 2022 - Foundations for Entailment Checking in Quantitativ.pdf:application/pdf;arXiv.org Snapshot:/home/fordrl/Zotero/storage/24B2MXGL/2201.html:text/html},
}

@article{pit-claudel_relational_nodate,
	title = {Relational compilation: functional-to-imperative code generation for performance-critical applications},
	abstract = {Purely functional programs verified using interactive theorem provers typically need to be translated to run: either by extracting them to a similar language (like Coq to {OCaml}) or by proving them equivalent to deeply embedded implementations (like C programs). Traditionally, the first approach is automated but produces unverified programs with average performance, and the second approach is manual but produces verified, highperformance programs. This thesis shows how to recast program extraction as a proof-search problem to automatically derive correct-by-construction, high-performance code from shallowly embedded functional programs. It introduces a unifying framework, relational compilation, to capture and extend recent developments in program extraction, with a focus on modularity and sound extensibility. To demonstrate the value of this approach, it then presents Rupicola, a relational compiler-construction toolkit designed to extract fast, verified, idiomatic low-level code from annotated functional models. The originality of this approach lies in its combination of foundational proofs, extensibility, and performance, backed by an unconventional take on compiler extensions: unlike traditional compilers, Rupicola generates good code not because of clever built-in optimizations, but because it allows expert users to plug in domain- and sometimes programspecific extensions that allow them to generate exactly the low-level code that they want. This thesis demonstrates the benefits of this approach through case studies and performance benchmarks that highlight how easy Rupicola makes it to create domain-specific compilers that generate code with performance comparable to that of handwritten C programs.},
	pages = {160},
	author = {Pit-Claudel, Clément},
	langid = {english},
	file = {Pit-Claudel - Relational compilation functional-to-imperative c.pdf:/home/fordrl/Zotero/storage/BPJ23X9S/Pit-Claudel - Relational compilation functional-to-imperative c.pdf:application/pdf},
}

@article{choudhury_towards_nodate,
	title = {Towards a Formalization of Nominal Sets in Coq},
	pages = {3},
	author = {Choudhury, Pritam},
	langid = {english},
	file = {Choudhury - Towards a Formalization of Nominal Sets in Coq.pdf:/home/fordrl/Zotero/storage/WIBB2PY9/Choudhury - Towards a Formalization of Nominal Sets in Coq.pdf:application/pdf},
}

@article{appel_c-language_2020,
	title = {C-language ﬂoating-point proofs layered with {VST} and Flocq},
	pages = {16},
	author = {Appel, Andrew W},
	date = {2020},
	langid = {english},
	file = {Appel - 2020 - C-language ﬂoating-point proofs layered with VST a.pdf:/home/fordrl/Zotero/storage/9IPEWBR7/Appel - 2020 - C-language ﬂoating-point proofs layered with VST a.pdf:application/pdf},
}

@article{darais_constructive_2016,
	title = {Constructive Galois Connections: Taming the Galois Connection Framework for Mechanized Metatheory},
	url = {http://arxiv.org/abs/1511.06965},
	shorttitle = {Constructive Galois Connections},
	abstract = {Galois connections are a foundational tool for structuring abstraction in semantics and their use lies at the heart of the theory of abstract interpretation. Yet, mechanization of Galois connections remains limited to restricted modes of use, preventing their general application in mechanized metatheory and certified programming. This paper presents constructive Galois connections, a variant of Galois connections that is effective both on paper and in proof assistants; is complete with respect to a large subset of classical Galois connections; and enables more general reasoning principles, including the "calculational" style advocated by Cousot. To design constructive Galois connection we identify a restricted mode of use of classical ones which is both general and amenable to mechanization in dependently-typed functional programming languages. Crucial to our metatheory is the addition of monadic structure to Galois connections to control a "specification effect". Effectful calculations may reason classically, while pure calculations have extractable computational content. Explicitly moving between the worlds of specification and implementation is enabled by our metatheory. To validate our approach, we provide two case studies in mechanizing existing proofs from the literature: one uses calculational abstract interpretation to design a static analyzer, the other forms a semantic basis for gradual typing. Both mechanized proofs closely follow their original paper-and-pencil counterparts, employ reasoning principles not captured by previous mechanization approaches, support the extraction of verified algorithms, and are novel.},
	journaltitle = {{arXiv}:1511.06965 [cs]},
	author = {Darais, David and Van Horn, David},
	urldate = {2022-02-11},
	date = {2016-10-26},
	eprinttype = {arxiv},
	eprint = {1511.06965},
	keywords = {Computer Science - Programming Languages},
	file = {arXiv Fulltext PDF:/home/fordrl/Zotero/storage/LTU5GPXB/Darais and Van Horn - 2016 - Constructive Galois Connections Taming the Galois.pdf:application/pdf;arXiv.org Snapshot:/home/fordrl/Zotero/storage/DXDTANTL/1511.html:text/html},
}

@article{pichardie_building_2008,
	title = {Building Certified Static Analysers by Modular Construction of Well-founded Lattices},
	volume = {212},
	issn = {15710661},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S157106610800279X},
	doi = {10.1016/j.entcs.2008.04.064},
	abstract = {This paper presents ﬁxpoint calculations on lattice structures as example of highly modular programming in a dependently typed functional language. We propose a library of Coq module functors for constructing complex lattices using eﬃcient data structures. The lattice signature contains a well-foundedness proof obligation which ensures termination of generic ﬁxpoint iteration algorithms. With this library, complex well-foundedness proofs can hence be constructed in a functorial fashion. This paper demonstrates the ability of the recent Coq module system in manipulating algebraic structures and extracting eﬃcient Ocaml implementations from them. The second contribution of this work is a generic result, based on the constructive notion of accessibility predicate, about preservation of accessibility properties when combining relations.},
	pages = {225--239},
	journaltitle = {Electronic Notes in Theoretical Computer Science},
	shortjournal = {Electronic Notes in Theoretical Computer Science},
	author = {Pichardie, David},
	urldate = {2022-02-11},
	date = {2008-04},
	langid = {english},
	file = {Pichardie - 2008 - Building Certified Static Analysers by Modular Con.pdf:/home/fordrl/Zotero/storage/G62ISK5Y/Pichardie - 2008 - Building Certified Static Analysers by Modular Con.pdf:application/pdf},
}

@thesis{theng_gotxn_2022,
	title = {{GoTxn}: Verifying a Crash-Safe, Concurrent Transaction System},
	abstract = {Bugs related to concurrency and crash safety are infamous for being subtle and hard to reproduce. Formal veriőcation provides a way to combat such bugs through the use of machine-checked proofs about program behavior. However, reasoning about concurrency and crashes can be tricky, especially when scaling up to larger systems that must also have good performance.},
	pagetotal = {71},
	institution = {{MIT}},
	type = {phdthesis},
	author = {Theng, Mark},
	date = {2022-02},
	langid = {english},
	file = {Theng - GoTxn Verifying a Crash-Safe, Concurrent Transact.pdf:/home/fordrl/Zotero/storage/ACGMNJ2G/Theng - GoTxn Verifying a Crash-Safe, Concurrent Transact.pdf:application/pdf},
}

@article{chajed_verifying_nodate,
	title = {Verifying concurrent Go code in Coq with Goose},
	abstract = {This paper describes Goose, a system for writing code in Go and translating it to a model in Coq. The Coq model plugs into Iris for concurrency proofs, giving an end-to-end system for writing and verifying concurrent systems. We have used Goose as part of our work on Perennial to verify a concurrent, crash-safe mail server that gets good performance.},
	pages = {3},
	author = {Chajed, Tej and Tassarotti, Joseph and Kaashoek, M Frans and Zeldovich, Nickolai},
	langid = {english},
	file = {Chajed et al. - Verifying concurrent Go code in Coq with Goose.pdf:/home/fordrl/Zotero/storage/IKI5XN9J/Chajed et al. - Verifying concurrent Go code in Coq with Goose.pdf:application/pdf},
}

@inproceedings{chajed_verifying_2019,
	location = {Huntsville Ontario Canada},
	title = {Verifying concurrent, crash-safe systems with Perennial},
	isbn = {978-1-4503-6873-5},
	url = {https://dl.acm.org/doi/10.1145/3341301.3359632},
	doi = {10.1145/3341301.3359632},
	abstract = {This paper introduces Perennial, a framework for verifying concurrent, crash-safe systems. Perennial extends the Iris concurrency framework with three techniques to enable crash-safety reasoning: recovery leases, recovery helping, and versioned memory. To ease development and deployment of applications, Perennial provides Goose, a subset of Go and a translator from that subset to a model in Perennial with support for reasoning about Go threads, data structures, and file-system primitives. We implemented and verified a crash-safe, concurrent mail server using Perennial and Goose that achieves speedup on multiple cores. Both Perennial and Iris use the Coq proof assistant, and the mail server and the framework’s proofs are machine checked.},
	eventtitle = {{SOSP} '19: {ACM} {SIGOPS} 27th Symposium on Operating Systems Principles},
	pages = {243--258},
	booktitle = {Proceedings of the 27th {ACM} Symposium on Operating Systems Principles},
	publisher = {{ACM}},
	author = {Chajed, Tej and Tassarotti, Joseph and Kaashoek, M. Frans and Zeldovich, Nickolai},
	urldate = {2022-02-13},
	date = {2019-10-27},
	langid = {english},
	file = {Chajed et al. - 2019 - Verifying concurrent, crash-safe systems with Pere.pdf:/home/fordrl/Zotero/storage/KMHYPI5Z/Chajed et al. - 2019 - Verifying concurrent, crash-safe systems with Pere.pdf:application/pdf},
}

@article{dubut_fixed_2022,
	title = {Fixed Points Theorems for Non-Transitive Relations},
	volume = {Volume 18, Issue 1},
	issn = {1860-5974},
	url = {https://lmcs.episciences.org/6809},
	doi = {10.46298/lmcs-18(1:30)2022},
	abstract = {In this paper, we develop an Isabelle/{HOL} library of order-theoretic ﬁxedpoint theorems. We keep our formalization as general as possible: we reprove several well-known results about complete orders, often with only antisymmetry or attractivity, a mild condition implied by either antisymmetry or transitivity. In particular, we generalize various theorems ensuring the existence of a quasi-ﬁxed point of monotone maps over complete relations, and show that the set of (quasi-)ﬁxed points is itself complete. This result generalizes and strengthens theorems of Knaster–Tarski, Bourbaki–Witt, Kleene, Markowsky, Pataraia, Mashburn, Bhatta–George, and Stouti–Maaden.},
	pages = {6809},
	journaltitle = {Logical Methods in Computer Science},
	author = {Dubut, Jérémy and Yamada, Akihisa},
	urldate = {2022-02-13},
	date = {2022-02-04},
	langid = {english},
	file = {Dubut and Yamada - 2022 - Fixed Points Theorems for Non-Transitive Relations.pdf:/home/fordrl/Zotero/storage/EUUPXSKV/Dubut and Yamada - 2022 - Fixed Points Theorems for Non-Transitive Relations.pdf:application/pdf},
}

@incollection{di_pierro_galois_2020,
	location = {Cham},
	title = {Galois Connections for Recursive Types},
	volume = {12065},
	isbn = {978-3-030-41102-2 978-3-030-41103-9},
	url = {http://link.springer.com/10.1007/978-3-030-41103-9_4},
	abstract = {Building a static analyser for a real language involves modeling of large domains capturing the many available data types. To scale domain design and support eﬃcient development of project-speciﬁc analyzers, it is desirable to be able to build, extend, and change abstractions in a systematic and modular fashion. We present a framework for modular design of abstract domains for recursive types and higher-order functions, based on the theory of solving recursive domain equations. We show how to relate computable abstract domains to our framework, and illustrate the potential of the construction by modularizing a monolithic domain for regular tree grammars. A prototype implementation in the dependently typed functional language Agda shows how the theoretical solution can be used in practice to construct static analysers.},
	pages = {105--131},
	booktitle = {From Lambda Calculus to Cybersecurity Through Program Analysis},
	publisher = {Springer International Publishing},
	author = {Al-Sibahi, Ahmad Salim and Jensen, Thomas and Møgelberg, Rasmus Ejlers and Wąsowski, Andrzej},
	editor = {Di Pierro, Alessandra and Malacaria, Pasquale and Nagarajan, Rajagopal},
	urldate = {2022-02-15},
	date = {2020},
	langid = {english},
	doi = {10.1007/978-3-030-41103-9_4},
	note = {Series Title: Lecture Notes in Computer Science},
	file = {Al-Sibahi et al. - 2020 - Galois Connections for Recursive Types.pdf:/home/fordrl/Zotero/storage/FHTGR8BI/Al-Sibahi et al. - 2020 - Galois Connections for Recursive Types.pdf:application/pdf},
}

@article{khan_executable_2022,
	title = {An Executable Formal Model of the {VHDL} in Isabelle/{HOL}},
	url = {http://arxiv.org/abs/2202.04192},
	abstract = {In the hardware design process, hardware components are usually described in a hardware description language. Most of the hardware description languages, such as Verilog and {VHDL}, do not have mathematical foundation and hence are not fit for formal reasoning about the design. To enable formal reasoning in one of the most commonly used description language {VHDL}, we define a formal model of the {VHDL} language in Isabelle/{HOL}. Our model targets the functional part of {VHDL} designs used in industry, specifically the design of the {LEON}3 processor's integer unit. We cover a wide range of features in the {VHDL} language that are usually not modelled in the literature and define a novel operational semantics for it. Furthermore, our model can be exported to {OCaml} code for execution, turning the formal model into a {VHDL} simulator. We have tested our simulator against simple designs used in the literature, as well as the div32 module in the {LEON}3 design. The Isabelle/{HOL} code is publicly available: https://zhehou.github.io/apps/{VHDLModel}.zip},
	journaltitle = {{arXiv}:2202.04192 [cs]},
	author = {Khan, Wilayat and Hou, Zhe and Sanan, David and Nebhen, Jamel and Liu, Yang and Tiu, Alwen},
	urldate = {2022-02-15},
	date = {2022-02-08},
	eprinttype = {arxiv},
	eprint = {2202.04192},
	keywords = {Computer Science - Logic in Computer Science, Computer Science - Formal Languages and Automata Theory, Computer Science - Computation and Language},
	file = {arXiv Fulltext PDF:/home/fordrl/Zotero/storage/DB9EWCC7/Khan et al. - 2022 - An Executable Formal Model of the VHDL in Isabelle.pdf:application/pdf;arXiv.org Snapshot:/home/fordrl/Zotero/storage/FY4H9LNI/2202.html:text/html},
}

@article{sakaguchi_reflexive_2022,
	title = {Reflexive tactics for algebra, revisited},
	url = {http://arxiv.org/abs/2202.04330},
	abstract = {Computational reflection allows us to turn verified decision procedures into efficient automated reasoning tools in proof assistants. The typical applications of such methodology include mathematical structures that have decidable theory fragments, e.g., equational theories of commutative rings and lattices. However, such existing tools are known not to cooperate with packed classes, a methodology to define mathematical structures in dependent type theory, that allows for the sharing of vocabulary across the inheritance hierarchy. Additionally, such tools do not support homomorphisms whose domain and codomain types may differ. This paper demonstrates how to implement reflexive tactics that support packed classes and homomorphisms. As applications of our methodology, we adapt the ring and field tactics of Coq to the commutative ring and field structures of the Mathematical Components library, and apply the resulting tactics to the formal proof of the irrationality of \${\textbackslash}zeta(3)\$ by Chyzak, Mahboubi, and Sibut-Pinote, to bring more proof automation.},
	journaltitle = {{arXiv}:2202.04330 [cs]},
	author = {Sakaguchi, Kazuhiko},
	urldate = {2022-02-15},
	date = {2022-02-09},
	eprinttype = {arxiv},
	eprint = {2202.04330},
	keywords = {Computer Science - Programming Languages, Computer Science - Logic in Computer Science},
	file = {arXiv Fulltext PDF:/home/fordrl/Zotero/storage/6WAEBP62/Sakaguchi - 2022 - Reflexive tactics for algebra, revisited.pdf:application/pdf;arXiv.org Snapshot:/home/fordrl/Zotero/storage/VJ5RIKMN/2202.html:text/html},
}

@article{wang_k-st_2022,
	title = {K-{ST}: A Formal Executable Semantics of {PLC} Structured Text Language},
	url = {http://arxiv.org/abs/2202.04076},
	shorttitle = {K-{ST}},
	abstract = {Programmable Logic Controllers ({PLCs}) are responsible for automating process control in many industrial systems (e.g. in manufacturing and public infrastructure), and thus it is critical to ensure that they operate correctly and safely. The majority of {PLCs} are programmed in languages such as Structured Text ({ST}). However, a lack of formal semantics makes it difficult to ascertain the correctness of their translators and compilers, which vary from vendor-to-vendor. In this work, we develop K-{ST}, a formal executable semantics for {ST} in the K framework. Defined with respect to the {IEC} 61131-3 standard and {PLC} vendor manuals, K-{ST} is a high-level reference semantics that can be used to evaluate the correctness and consistency of different {ST} implementations. We validate K-{ST} by executing 509 {ST} programs extracted from Github and comparing the results against existing commercial compilers (i.e., {CODESYS}, {CX}-Programmer, and {GX} Works2). We then apply K-{ST} to validate the implementation of the open source {OpenPLC} platform, comparing the executions of several test programs to uncover five bugs and nine functional defects in the compiler.},
	journaltitle = {{arXiv}:2202.04076 [cs]},
	author = {Wang, Kun and Wang, Jingyi and Poskitt, Christopher M. and Chen, Xiangxiang and Sun, Jun and Cheng, Peng},
	urldate = {2022-02-15},
	date = {2022-02-08},
	eprinttype = {arxiv},
	eprint = {2202.04076},
	keywords = {Computer Science - Programming Languages, Computer Science - Software Engineering},
	file = {arXiv Fulltext PDF:/home/fordrl/Zotero/storage/LTE88LKP/Wang et al. - 2022 - K-ST A Formal Executable Semantics of PLC Structu.pdf:application/pdf;arXiv.org Snapshot:/home/fordrl/Zotero/storage/ZKJ2KRE7/2202.html:text/html},
}

@article{bhat_lambda_2022,
	title = {Lambda the Ultimate {SSA}: Optimizing Functional Programs in {SSA}},
	url = {https://arxiv.org/abs/2201.07272v1},
	shorttitle = {Lambda the Ultimate {SSA}},
	abstract = {Static Single Assignment ({SSA}) is the workhorse of modern optimizing compilers for imperative programming languages. However, functional languages have been slow to adopt {SSA} and prefer to use intermediate representations based on minimal lambda calculi due to {SSA}'s inability to express higher order constructs. We exploit a new {SSA} construct -- regions -- in order to express functional optimizations via classical {SSA} based reasoning. Region optimization currently relies on ad-hoc analyses and transformations on imperative programs. These ad-hoc transformations are sufficient for imperative languages as regions are used in a limited fashion. In contrast, we use regions pervasively to model sub-expressions in our functional {IR}. This motivates us to systematize region optimizations. We extend classical {SSA} reasoning to regions for functional-style analyses and transformations. We implement a new {SSA}+regions based backend for {LEAN}4, a theorem prover that implements a purely functional, dependently typed programming language. Our backend is feature-complete and handles all constructs of {LEAN}4's functional intermediate representation \{{\textbackslash}lambda\}rc within the {SSA} framework. We evaluate our proposed region optimizations by optimizing \{{\textbackslash}lambda\}rc within an {SSA}+regions based framework implemented in {MLIR} and demonstrating performance parity with the current {LEAN}4 backend. We believe our work will pave the way for a unified optimization framework capable of representing, analyzing, and optimizing both functional and imperative languages.},
	author = {Bhat, Siddharth and Grosser, Tobias},
	urldate = {2022-02-22},
	date = {2022-01-18},
	langid = {english},
	file = {Full Text PDF:/home/fordrl/Zotero/storage/NWMCLBDD/Bhat and Grosser - 2022 - Lambda the Ultimate SSA Optimizing Functional Pro.pdf:application/pdf;Snapshot:/home/fordrl/Zotero/storage/LZV4NJG7/2201.html:text/html},
}

@online{grannan_rest_nodate,
	title = {{REST}: Integrating Term Rewriting with Program Verification},
	url = {https://arxiv.org/pdf/2202.05872.pdf},
	abstract = {We introduce {REST}, a novel term rewriting technique for theorem proving that uses online termination
checking and can be integrated with existing program verifiers. {REST} enables flexible but terminating
term rewriting for theorem proving by: (1) exploiting newly-introduced term orderings that are more
permissive than standard rewrite simplification orderings; (2) dynamically and iteratively selecting
orderings based on the path of rewrites taken so far; and (3) integrating external oracles that allow
steps that cannot be justified with rewrite rules. Our {REST} approach is designed around an easily
implementable core algorithm, parameterizable by choices of term orderings and their implementations; in this way our approach can be easily integrated into existing tools. We implemented
{REST} as a Haskell library and incorporated it into Liquid Haskell’s evaluation strategy, extending
Liquid Haskell with rewriting rules. We evaluated our {REST} implementation by comparing it against
both existing rewriting techniques and E-matching and by showing that it can be used to supplant
manual lemma application in many existing Liquid Haskell proofs.},
	author = {Grannan, Zachary and Vazou, Niki and Darulova, Eva and Summers, Alexander J.},
	urldate = {2022-02-22},
}

@collection{groote_tools_2021,
	location = {Cham},
	title = {Tools and Algorithms for the Construction and Analysis of Systems: 27th International Conference, {TACAS} 2021, Held as Part of the European Joint Conferences on Theory and Practice of Software, {ETAPS} 2021, Luxembourg City, Luxembourg, March 27 – April 1, 2021, Proceedings, Part {II}},
	volume = {12652},
	isbn = {978-3-030-72012-4 978-3-030-72013-1},
	url = {http://link.springer.com/10.1007/978-3-030-72013-1},
	series = {Lecture Notes in Computer Science},
	shorttitle = {Tools and Algorithms for the Construction and Analysis of Systems},
	publisher = {Springer International Publishing},
	editor = {Groote, Jan Friso and Larsen, Kim Guldstrand},
	urldate = {2022-02-22},
	date = {2021},
	langid = {english},
	doi = {10.1007/978-3-030-72013-1},
	file = {Groote and Larsen - 2021 - Tools and Algorithms for the Construction and Anal.pdf:/home/fordrl/Zotero/storage/HCSHSPB8/Groote and Larsen - 2021 - Tools and Algorithms for the Construction and Anal.pdf:application/pdf},
}

@inproceedings{tan_cake_lpr_2021,
	location = {Cham},
	title = {cake\_lpr: Verified Propagation Redundancy Checking in {CakeML}},
	isbn = {978-3-030-72013-1},
	doi = {10.1007/978-3-030-72013-1_12},
	series = {Lecture Notes in Computer Science},
	shorttitle = {cake\_lpr},
	abstract = {Modern {SAT} solvers can emit independently checkable proof certificates to validate their results. The state-of-the-art proof system that allows for compact proof certificates is propagation redundancy ({PR}). However, the only existing method to validate proofs in this system with a formally verified tool requires a transformation to a weaker proof system, which can result in a significant blowup in the size of the proof and increased proof validation time. This paper describes the first approach to formally verify {PR} proofs on a succinct representation; we present (i) a new Linear {PR} ({LPR}) proof format, (ii) a tool to efficiently convert {PR} proofs into {LPR} format, and (iii) cake\_lpr, a verified {LPR} proof checker developed in {CakeML}. The {LPR} format is backwards compatible with the existing {LRAT} format, but extends the latter with support for the addition of {PR} clauses. Moreover, cake\_lpr is verified using {CakeML} ’s binary code extraction toolchain, which yields correctness guarantees for its machine code (binary) implementation. This further distinguishes our clausal proof checker from existing ones because unverified extraction and compilation tools are removed from its trusted computing base. We experimentally show that {LPR} provides efficiency gains over existing proof formats and that the strong correctness guarantees are obtained without significant sacrifice in the performance of the verified executable.},
	pages = {223--241},
	booktitle = {Tools and Algorithms for the Construction and Analysis of Systems},
	publisher = {Springer International Publishing},
	author = {Tan, Yong Kiam and Heule, Marijn J. H. and Myreen, Magnus O.},
	editor = {Groote, Jan Friso and Larsen, Kim Guldstrand},
	date = {2021},
	langid = {english},
	keywords = {binary code extraction, linear propagation redundancy},
	file = {Springer Full Text PDF:/home/fordrl/Zotero/storage/MK2PSLT7/Tan et al. - 2021 - cake_lpr Verified Propagation Redundancy Checking.pdf:application/pdf},
}

@article{gorjiara_yashme_2022,
	title = {Yashme: Detecting Persistency Races},
	abstract = {Persistent memory ({PM}) or Non-Volatile Random-Access Memory ({NVRAM}) hardware such as Intel’s Optane memory product promises to transform how programs store and manipulate information. Ensuring that persistent memory programs are crash consistent is a major challenge. We present a novel class of crash consistency bugs for persistent memory programs, which we call persistency races. Persistency races can cause non-atomic stores to be made partially persistent. Persistency races arise due to the interaction of standard compiler optimizations with persistent memory semantics. We present Yashme, the first detector for persistency races. A major challenge is that in order to detect persistency races, the execution must crash in a very narrow window between a store with a persistency race and its corresponding cache flush operation, making it challenging for naïve techniques to be effective. Yashme overcomes this challenge with a novel technique for detecting races in executions that are prefixes of the pre-crash execution. This technique enables Yashme to effectively find persistency races even if the injected crashes do not fall into that window. We have evaluated Yashme on a range of persistent memory benchmarks and have found 24 real persistency races that have never been reported before.},
	pages = {16},
	author = {Gorjiara, Hamed and Xu, Guoqing Harry and Demsky, Brian},
	date = {2022},
	langid = {english},
	file = {Gorjiara et al. - 2022 - Yashme Detecting Persistency Races.pdf:/home/fordrl/Zotero/storage/46QJSDGR/Gorjiara et al. - 2022 - Yashme Detecting Persistency Races.pdf:application/pdf},
}

@article{forster_constructive_nodate,
	title = {A Constructive and Synthetic Theory of Reducibility: Myhill's Isomorphism Theorem and Post's Problem for Many-one and Truth-table Reducibility in Coq (Full Version)},
	abstract = {We present a constructive analysis and machine-checked synthetic approach to the theory of one-one, many-one, and truth-table reductions carried out in the Calculus of Inductive Constructions, the type theory underlying the proof assistant Coq. In synthetic computability, one assumes axioms allowing to carry out computability theory with all deﬁnitions and proofs purely in terms of functions of the type theory with no mention of a model of computation. Our synthetic proof of Myhill’s isomorphism theorem that one-one equivalence yields a computational isomorphism makes a compelling case for synthetic computability due to its simplicity without sacriﬁcing formality.},
	pages = {26},
	author = {Forster, Yannick and Jahn, Felix and Smolka, Gert},
	langid = {english},
	file = {Forster et al. - A Constructive and Synthetic Theory of Reducibilit.pdf:/home/fordrl/Zotero/storage/XGUBTVGX/Forster et al. - A Constructive and Synthetic Theory of Reducibilit.pdf:application/pdf},
}

@article{first_diversity-driven_2022,
	title = {Diversity-Driven Automated Formal Verification},
	abstract = {Formally verified correctness is one of the most desirable properties of software systems. But despite great progress made via interactive theorem provers, such as Coq, writing proof scripts for verification remains one of the most effort-intensive (and often prohibitively difficult) software development activities. Recent work has created tools that automatically synthesize proofs or proof scripts. For example, {CoqHammer} can prove 26.6\% of theorems completely automatically by reasoning using precomputed facts, while {TacTok} and {ASTactic}, which use machine learning to model proof scripts and then perform biased search through the proof-script space, can prove 12.9\% and 12.3\% of the theorems, respectively. Further, these three tools are highly complementary; together, they can prove 30.4\% of the theorems fully automatically. Our key insight is that control over the learning process can produce a diverse set of models, and that, due to the unique nature of proof synthesis (the existence of the theorem prover, an oracle that infallibly judges a proof’s correctness), this diversity can significantly improve these tools’ proving power. Accordingly, we develop Diva, which uses a diverse set of models with {TacTok}’s and {ASTactic}’s search mechanism to prove 21.7\% of the theorems. That is, Diva proves 68\% more theorems than {TacTok} and 77\% more than {ASTactic}. Complementary to {CoqHammer}, Diva proves 781 theorems (27\% added value) that {CoqHammer} does not, and 364 theorems no existing tool has proved automatically. Together with {CoqHammer}, Diva proves 33.8\% of the theorems, the largest fraction to date. We explore nine dimensions for learning diverse models, and identify which dimensions lead to the most useful diversity. Further, we develop an optimization to speed up Diva’s execution by 40×. Our study introduces a completely new idea for using diversity in machine learning to improve the power of state-of-the-art proof-script synthesis techniques, and empirically demonstrates that the improvement is significant on a dataset of 68K theorems from 122 open-source software projects.},
	pages = {13},
	author = {First, Emily},
	date = {2022},
	langid = {english},
	file = {First - 2022 - Diversity-Driven Automated Formal Verification.pdf:/home/fordrl/Zotero/storage/55HFL4JA/First - 2022 - Diversity-Driven Automated Formal Verification.pdf:application/pdf},
}

@article{gratzer_stratified_nodate,
	title = {A stratified approach to Löb induction},
	abstract = {Guarded type theory extends type theory with a handful of modalities and constants to encode productive recursion. While these theories have seen widespread use, the metatheory of guarded type theories, particularly guarded dependent type theories remains underdeveloped. We show that integrating Löb induction is the key obstruction to unifying guarded recursion and dependence in a well-behaved type theory and prove a no-go theorem sharply bounding such type theories.},
	pages = {23},
	author = {Gratzer, Daniel and Birkedal, Lars},
	langid = {english},
	file = {Gratzer and Birkedal - A stratified approach to Löb induction.pdf:/home/fordrl/Zotero/storage/AWDY5VTM/Gratzer and Birkedal - A stratified approach to Löb induction.pdf:application/pdf},
}

@article{ullrich_beyond_2020,
	title = {Beyond Notations: Hygienic Macro Expansion for Theorem Proving Languages},
	volume = {12167},
	url = {http://arxiv.org/abs/2001.10490},
	doi = {10.1007/978-3-030-51054-1_10},
	shorttitle = {Beyond Notations},
	abstract = {In interactive theorem provers ({ITPs}), extensible syntax is not only crucial to lower the cognitive burden of manipulating complex mathematical objects, but plays a critical role in developing reusable abstractions in libraries. Most {ITPs} support such extensions in the form of restrictive "syntax sugar" substitutions and other ad hoc mechanisms, which are too rudimentary to support many desirable abstractions. As a result, libraries are littered with unnecessary redundancy. Tactic languages in these systems are plagued by a seemingly unrelated issue: accidental name capture, which often produces unexpected and counterintuitive behavior. We take ideas from the Scheme family of programming languages and solve these two problems simultaneously by proposing a novel hygienic macro system custom-built for {ITPs}. We further describe how our approach can be extended to cover type-directed macro expansion resulting in a single, uniform system offering multiple abstraction levels that range from supporting simplest syntax sugars to elaboration of formerly baked-in syntax. We have implemented our new macro system and integrated it into the new version of the Lean theorem prover, Lean 4. Despite its expressivity, the macro system is simple enough that it can easily be integrated into other systems.},
	pages = {167--182},
	journaltitle = {{arXiv}:2001.10490 [cs]},
	author = {Ullrich, Sebastian and de Moura, Leonardo},
	urldate = {2022-03-02},
	date = {2020},
	eprinttype = {arxiv},
	eprint = {2001.10490},
	keywords = {Computer Science - Programming Languages},
	file = {arXiv Fulltext PDF:/home/fordrl/Zotero/storage/4BDEWV9M/Ullrich and de Moura - 2020 - Beyond Notations Hygienic Macro Expansion for The.pdf:application/pdf;arXiv.org Snapshot:/home/fordrl/Zotero/storage/YUIDNQDG/2001.html:text/html},
}

@article{beyer_decomposing_2022,
	title = {Decomposing Software Verification into Off-the-Shelf Components: An Application to {CEGAR}},
	abstract = {Techniques for software verification are typically realized as cohesive units of software with tightly coupled components. This makes it difficult to re-use components, and the potential for workload distribution is limited. Innovations in software verification might find their way into practice faster if provided in smaller, more specialized components.},
	pages = {13},
	author = {Beyer, Dirk and Haltermann, Jan and Lemberger, Thomas and Wehrheim, Heike},
	date = {2022},
	langid = {english},
	file = {Beyer et al. - 2022 - Decomposing Software Verification into Off-the-She.pdf:/home/fordrl/Zotero/storage/KCG2QKNR/Beyer et al. - 2022 - Decomposing Software Verification into Off-the-She.pdf:application/pdf},
}

@article{guo_precise_2022,
	title = {Precise Divide-By-Zero Detection with Affirmative Evidence},
	abstract = {The static detection of divide-by-zero, a common programming error, is particularly prone to false positives because conventional static analysis reports a divide-by-zero bug whenever it cannot prove the safety property — the divisor variable is not zero in all executions. When reasoning the program semantics over a large number of under-constrained variables, conventional static analyses significantly loose the bounds of divisor variables, which easily fails the safety proof and leads to a massive number of false positives. We propose a static analysis to detect divide-by-zero bugs taking additional evidence for under-constrained variables into consideration. Based on an extensive empirical study of known divide-by-zero bugs, we no longer arbitrarily report a bug once the safety verification fails. Instead, we actively look for affirmative evidences, namely source evidence and bound evidence, that imply a high possibility of the bug to be triggerable at runtime. When applying our tool Wit to the real-world software such as the Linux kernel, we have found 72 new divide-by-zero bugs with a low false positive rate of 22\%.},
	pages = {12},
	author = {Guo, Yiyuan and Zhou, Jinguo and Yao, Peisen and Shi, Qingkai and Zhang, Charles},
	date = {2022},
	langid = {english},
	file = {Guo et al. - 2022 - Precise Divide-By-Zero Detection with Affirmative .pdf:/home/fordrl/Zotero/storage/KARVRZRF/Guo et al. - 2022 - Precise Divide-By-Zero Detection with Affirmative .pdf:application/pdf},
}

@article{bosamiya_provably-safe_nodate,
	title = {Provably-Safe Multilingual Software Sandboxing using {WebAssembly}},
	abstract = {Many applications, from the Web to smart contracts, need to safely execute untrusted code. We observe that {WebAssembly} (Wasm) is ideally positioned to support such applications, since it promises safety and performance, while serving as a compiler target for many high-level languages. However, Wasm’s safety guarantees are only as strong as the implementation that enforces them. Hence, we explore two distinct approaches to producing provably sandboxed Wasm code. One draws on traditional formal methods to produce mathematical, machine-checked proofs of safety. The second carefully embeds Wasm semantics in safe Rust code such that the Rust compiler can emit safe executable code with good performance. Our implementation and evaluation of these two techniques indicate that leveraging Wasm gives us provablysafe multilingual sandboxing with performance comparable to standard, unsafe approaches.},
	pages = {18},
	author = {Bosamiya, Jay and Lim, Wen Shih and Parno, Bryan},
	langid = {english},
	file = {Bosamiya et al. - Provably-Safe Multilingual Software Sandboxing usi.pdf:/home/fordrl/Zotero/storage/9FUIEH7I/Bosamiya et al. - Provably-Safe Multilingual Software Sandboxing usi.pdf:application/pdf},
}

@article{din_lagc_2022,
	title = {{LAGC} Semantics of Concurrent Programming Languages},
	url = {http://arxiv.org/abs/2202.12195},
	abstract = {Formal, mathematically rigorous programming language semantics are the essential prerequisite for the design of logics and calculi that permit automated reasoning about concurrent programs. We propose a novel modular semantics designed to align smoothly with program logics used in deductive verification and formal specification of concurrent programs. Our semantics separates local evaluation of expressions and statements performed in an abstract, symbolic environment from their composition into global computations, at which point they are concretised. This makes incremental addition of new language concepts possible, without the need to revise the framework. The basis is a generalisation of the notion of a program trace as a sequence of evolving states that we enrich with event descriptors and trailing continuation markers. This allows to postpone scheduling constraints from the level of local evaluation to the global composition stage, where well-formedness predicates over the event structure declaratively characterise a wide range of concurrency models. We also illustrate how a sound program logic and calculus can be defined for this semantics.},
	journaltitle = {{arXiv}:2202.12195 [cs]},
	author = {Din, Crystal Chang and Hähnle, Reiner and Henrio, Ludovic and Johnsen, Einar Broch and Pun, Violet Ka I. and Tarifa, Silvia Lizeth Tapia},
	urldate = {2022-03-03},
	date = {2022-02-24},
	eprinttype = {arxiv},
	eprint = {2202.12195},
	keywords = {Computer Science - Programming Languages},
	file = {arXiv Fulltext PDF:/home/fordrl/Zotero/storage/J2L7NVM9/Din et al. - 2022 - LAGC Semantics of Concurrent Programming Languages.pdf:application/pdf;arXiv.org Snapshot:/home/fordrl/Zotero/storage/C5LGCCVR/2202.html:text/html},
}

@article{noauthor_temps_nodate,
	title = {Le Temps des Cerises: Efficient Temporal Stack Safety on Capability Machines using Directed Capabilities},
	volume = {1},
	pages = {30},
	langid = {english},
	file = {Le Temps des Cerises Efficient Temporal Stack Saf.pdf:/home/fordrl/Zotero/storage/DBM8DWEI/Le Temps des Cerises Efficient Temporal Stack Saf.pdf:application/pdf},
}

@article{aguirre_step-indexed_2017,
	title = {Step-Indexed Logical Relations for Nondeterministic and Probabilistic Choice},
	abstract = {Developing denotational models for higher-order languages that combine probabilistic and nondeterministic choice is known to be very challenging. In this paper, we propose an alternative approach based on operational techniques. We study a higher-order language combining parametric polymorphism, recursive types, discrete probabilistic choice and countable nondeterminism. We define probabilistic generalizations of may- and must-termination as the optimal and pessimal probabilities of termination. Then we define stepindexed logical relations and show that they are sound and complete with respect to the induced contextual preorders. For may-equivalence we use step-indexing over the natural numbers whereas for must-equivalence we index over the countable ordinals. We then show than the probabilities of may- and must-termination coincide with the maximal and minimal probabilities of termination under all schedulers. Finally we derive the equational theory induced by contextual equivalence and show that it validates the combination of the algebraic theories for probabilistic and nondeterministic choice and the distributive property between them.},
	pages = {27},
	author = {Aguirre, Alejandro and Birkedal, Lars},
	date = {2017},
	langid = {english},
	file = {Aguirre and Birkedal - 2017 - Step-Indexed Logical Relations for Nondeterministi.pdf:/home/fordrl/Zotero/storage/SD384BDN/Aguirre and Birkedal - 2017 - Step-Indexed Logical Relations for Nondeterministi.pdf:application/pdf},
}

@article{masuda_unied_nodate,
	title = {Uniﬁed Program Generation and Veriﬁcation: A Case Study on Number-Theoretic Transform},
	abstract = {Giving correctness assurance to the generated code in the context of generative programming is a poorly explored problem. Such assurance is particularly desired for applications where correctness of the optimized code is far from obvious, such as cryptography.},
	pages = {19},
	author = {Masuda, Masahiro and Kameyama, Yukiyoshi},
	langid = {english},
	file = {Masuda and Kameyama - Uniﬁed Program Generation and Veriﬁcation A Case .pdf:/home/fordrl/Zotero/storage/RD9HR339/Masuda and Kameyama - Uniﬁed Program Generation and Veriﬁcation A Case .pdf:application/pdf},
}

@inproceedings{li_path-sensitive_2022,
	location = {New York, {NY}, {USA}},
	title = {Path-sensitive and alias-aware typestate analysis for detecting {OS} bugs},
	isbn = {978-1-4503-9205-1},
	url = {https://doi.org/10.1145/3503222.3507770},
	doi = {10.1145/3503222.3507770},
	series = {{ASPLOS} 2022},
	abstract = {Operating system ({OS}) is the cornerstone for modern computer systems. It manages devices and provides fundamental service for user-level applications. Thus, detecting bugs in {OSes} is important to improve reliability and security of computer systems. Static typestate analysis is a common technique for detecting different types of bugs, but it is often inaccurate or unscalable for large-size {OS} code, due to imprecision of identifying alias relationships as well as high costs of typestate tracking and path-feasibility validation. In this paper, we present {PATA}, a novel path-sensitive and aliasaware typestate analysis framework to detect {OS} bugs. To improve the precision of identifying alias relationships in {OS} code, {PATA} performs a path-based alias analysis based on control-flow paths and access paths. With these alias relationships, {PATA} reduces the costs of typestate tracking and path-feasibility validation, to boost the efficiency of path-sensitive typestate analysis for bug detection. We have evaluated {PATA} on the Linux kernel and three popular {IoT} {OSes} (Zephyr, {RIOT} and {TencentOS}-tiny) to detect three common types of bugs (null-pointer dereferences, uninitialized variable accesses and memory leaks). {PATA} finds 574 real bugs with a false positive rate of 28\%. 206 of these bugs have been confirmed by the developers of the four {OSes}.We also compare {PATA} to seven state-of-the-art static approaches (Cppcheck, Coccinelle, Smatch,{CSA}, Infer, Saber and {SVF}). {PATA} finds many real bugs missed by them, with a lower false positive rate.},
	pages = {859--872},
	booktitle = {Proceedings of the 27th {ACM} International Conference on Architectural Support for Programming Languages and Operating Systems},
	publisher = {Association for Computing Machinery},
	author = {Li, Tuo and Bai, Jia-Ju and Sui, Yulei and Hu, Shi-Min},
	urldate = {2022-03-03},
	date = {2022-02-28},
	keywords = {bug detection, operation system, static analysis},
	file = {Full Text PDF:/home/fordrl/Zotero/storage/BNLVGWYL/Li et al. - 2022 - Path-sensitive and alias-aware typestate analysis .pdf:application/pdf},
}

@article{utture_fast_2022,
	title = {Fast and Precise Application Code Analysis using a Partial Library},
	abstract = {Long analysis times are a key bottleneck for the widespread adoption of whole-program static analysis tools. Fortunately, however, a user is often only interested in finding errors in the application code, which constitutes a small fraction of the whole program. Current application-focused analysis tools overapproximate the effect of the library and hence reduce the precision of the analysis results. However, empirical studies have shown that users have high expectations on precision and will ignore tool results that don’t meet these expectations. In this paper, we introduce the first tool {QueryMax} that significantly speeds up an application code analysis without dropping any precision. {QueryMax} acts as a pre-processor to an existing analysis tool to select a partial library that is most relevant to the analysis queries in the application code. The selected partial library plus the application is given as input to the existing static analysis tool, with the remaining library pointers treated as the bottom element in the abstract domain. This achieves a significant speedup over a whole-program analysis, at the cost of a few lost errors, and with no loss in precision. We instantiate and run experiments on {QueryMax} for a cast-check analysis and a null-pointer analysis. For a particular configuration, {QueryMax} enables these two analyses to achieve, relative to a whole-program analysis, an average recall of 87\%, a precision of 100\% and a geometric mean speedup of 10x.},
	pages = {12},
	author = {Utture, Akshay},
	date = {2022},
	langid = {english},
	file = {Utture - 2022 - Fast and Precise Application Code Analysis using a.pdf:/home/fordrl/Zotero/storage/J9Z2HDPE/Utture - 2022 - Fast and Precise Application Code Analysis using a.pdf:application/pdf},
}

@article{benzmuller_simplified_2022,
	title = {A Simplified Variant of G{\textbackslash}"odel's Ontological Argument},
	url = {http://arxiv.org/abs/2202.06264},
	abstract = {A simplified variant of G{\textbackslash}"odel's ontological argument is presented. The simplified argument is valid already in basic modal logics K or {KT}, it does not suffer from modal collapse, and it avoids the rather complex predicates of essence (Ess.) and necessary existence ({NE}) as used by G{\textbackslash}"odel. The variant presented has been obtained as a side result of a series of theory simplification experiments conducted in interaction with a modern proof assistant system. The starting point for these experiments was the computer encoding of G{\textbackslash}"odel's argument, and then automated reasoning techniques were systematically applied to arrive at the simplified variant presented. The presented work thus exemplifies a fruitful human-computer interaction in computational metaphysics. Whether the presented result increases or decreases the attractiveness and persuasiveness of the ontological argument is a question I would like to pass on to philosophy and theology.},
	journaltitle = {{arXiv}:2202.06264 [cs, math]},
	author = {Benzmüller, Christoph},
	urldate = {2022-03-08},
	date = {2022-02-13},
	eprinttype = {arxiv},
	eprint = {2202.06264},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Logic in Computer Science, Mathematics - Logic},
	file = {arXiv Fulltext PDF:/home/fordrl/Zotero/storage/74DCP5E9/Benzmüller - 2022 - A Simplified Variant of Godel's Ontological Argu.pdf:application/pdf;arXiv.org Snapshot:/home/fordrl/Zotero/storage/HDYGL9JX/2202.html:text/html},
}

@article{forster_synthetic_nodate,
	title = {Synthetic Kolmogorov Complexity in Coq},
	abstract = {We present a generalised, constructive, and machine-checked approach to Kolmogorov complexity in the constructive type theory underlying the Coq proof assistant. By proving that nonrandom numbers form a simple predicate, we obtain elegant proofs of undecidability for random and nonrandom numbers and a proof of uncomputability of Kolmogorov complexity.},
	pages = {20},
	author = {Forster, Yannick and Kunze, Fabian and Lauermann, Nils},
	langid = {english},
	file = {Forster et al. - Synthetic Kolmogorov Complexity in Coq.pdf:/home/fordrl/Zotero/storage/5FRHARPM/Forster et al. - Synthetic Kolmogorov Complexity in Coq.pdf:application/pdf},
}

@inproceedings{rastogi_wys_2019,
	title = {Wys*: A {DSL} for Verified Secure Multi-party Computations},
	url = {https://www.microsoft.com/en-us/research/publication/wys-a-dsl-for-verified-secure-multi-party-computations/},
	abstract = {Secure multi-party computation ({MPC}) enables a set of mutually distrusting parties to cooperatively compute, using a cryptographic protocol, a function over their private data. This paper presents Wys*, a new domain-specific language ({DSL}) for writing {MPCs}. Wys* is an embedded {DSL} hosted in F*, a verification-oriented, effectful programming language. Wys* source programs are essentially F* programs written in a custom {MPC} effect, meaning that the programmers can use F*'s logic to verify the correctness and security properties of their programs. To reason about the distributed runtime semantics of these programs, we formalize a deep embedding of Wys*, also in F*. We mechanize the necessary metatheory to prove that the properties verified for the Wys* source programs carry over to the distributed, multi-party semantics. Finally, we use F*'s extraction mechanism to extract an interpreter that we have proved matches this semantics, yielding a verified implementation. Wys* is the first {DSL} to enable formal verification of source {MPC} programs, and also the first {MPC} {DSL} to provide a verified implementation. With Wys* we have implemented several {MPC} protocols, including private set intersection, joint median, and an {MPC}-based card dealing application, and have verified their security and correctness.},
	booktitle = {Principles of Security and Trust ({POST} 2019)},
	author = {Rastogi, Aseem and Swamy, Nikhil and Hicks, Michael},
	date = {2019-04},
}